---
title: "Your Title"
abstract: |
  **Background**: (Brief few sentences)
  **Objectives**: 
    1. Estimate the causal effect of YOUR EXPOSURE on YOUR OUTCOMES measured one year later.
    2. Evaluate whether these effects vary across the population.
    3. Provide policy guidance on which individuals might benefit most.
  **Method**: We conducted a three-wave retrospective cohort study (waves XX-XXX, October XXXX--October XXXX) using data from the New Zealand Attitudes and Values Study, a nationally representative panel. Participants were eligible if they participated in the NZAVS in the baseline wave (XXXX, were under the age of 62, and were employed > 20 hours per week. We defined the exposure as (XXXX  > NUMBER on a 1-7 Likert Scale (1 = yes, 0 = no)). To address attrition, we applied inverse probability of censoring weights; to improve external validity, we applied weighted to the population distribution of Age, Ethnicity, and Gender. We computed expected mean outcomes for the population in each exposure condition (high XXXX/low XXXXX). Under standard causal assumptions of unconfoundedness, the contrast provides an unbiased average treatment effect. We then used causal forests to detect heterogeneity in these effects and employed policy tree algorithms to identify individuals ("strong responders") likely to experience the greatest benefits.
  **Results**:   Increasing XXXXX leads to XXXXX. Heterogeneous responses to (e.g. *Forgiveness*, *Personal Well-Being*, and *Life-Satisfaction*...) reveal structural variability in subpopulations...
  **Implications**: (Brief few sentences)
  **Keywords**: *Causal Inference*;  *Cross-validation*; *Distress*; *Employment*; *Longitudinal*; *Machine sLearning*; *Religion*; *Semi-parametric*; *Targeted Learning*.
author: 
  - name: YOUR NAME
    affiliation: Victoria University of Wellington, New Zealand
    email: XXXXX
    corresponding: yes
keywords: [Causal Inference, Cross-validation,...]
editor_options: 
  chunk_output_type: console
date: "last-modified"
fontfamily: libertinus
bibliography: references.bib
csl: apa7.csl
format:
  docx: # comment this out if you want pdf
    default: false  # comment this out if you want pdf
    output-dir: "quarto"  # or wherever you want to save it  # comment this out if you want pdf
  pdf:
    pdf-engine: lualatex
    sanitise: true
    keep-tex: true
    link-citations: true
    colorlinks: true
    documentclass: article
    classoption: ["single column"]
    lof: false
    lot: false
    geometry:
      - top=30mm
      - left=25mm
      - heightrounded
      - headsep=22pt
      - headheight=11pt
      - footskip=33pt
      - ignorehead
      - ignorefoot
    header-includes:
      - \let\oldtabular\tabular
      - \renewcommand{\tabular}{\small\oldtabular}
      - \setlength{\tabcolsep}{4pt}  # adjust this value as needed
execute:
  echo: false
  warning: false
  include: true
  eval: true
---

```{r}
#| label: setup
#| echo: false
#| include: false
#| eval: true

# save this file in your project root (e.g. 'quarto/1_setup.R')

# load here to manage paths
dep <- requireNamespace("here", quietly = TRUE)
if (!dep) install.packages("here")
library(here)

# create required folders
dirs <- c(
  here("quarto"),
  here("bibliography"),
  here("save_directory"),
  here("csl")
)
for (d in dirs) {
  if (!dir.exists(d)) dir.create(d, recursive = TRUE)
}

# ensure tinytex for PDF rendering
if (!requireNamespace("tinytex", quietly = TRUE)) {
  install.packages("tinytex")
  tinytex::install_tinytex()
}

# ensure pacman for package management
if (!requireNamespace("pacman", quietly = TRUE)) {
  install.packages("pacman")
}

# load (and install if needed) all required packages
pacman::p_load(
  boilerplate, margot, shiny, tidyverse,
  kableExtra, glue, patchwork, stringr,
  ggplot2, ggeffects, parameters,
  table1, knitr, extrafont
)

# load fonts (requires prior extrafont::font_import())
if (requireNamespace("extrafont", quietly = TRUE)) {
  extrafont::loadfonts(device = "all")
} else {
  message("'extrafont' not installed; skipping font loading")
}

# reproducibility
set.seed(123)

# copy CSL and BibTeX into quarto folder
src_files <- list(
  c(here("csl", "apa7.csl"),     here("quarto", "apa7.csl")),
  c(here("bibliography", "references.bib"), here("quarto", "references.bib"))
)
for (f in src_files) {
  if (!file.exists(f[2]) && file.exists(f[1])) {
    file.copy(f[1], f[2])
  }
}

# now you're ready to import data and proceed with analysis
# e.g.
# unified_db <- boilerplate_import(data_path = here("final_boilerplate_data"))
# df_grf     <- margot::here_read('df_grf',   here("save_directory"))

# ---- define paths and import data ----------------------------------------
push_mods             <- here::here("save_directory")
final_boilerplate_data <- here::here("final_boilerplate_data")
unified_db            <- boilerplate_import(data_path = final_boilerplate_data)

# check paths
# ---- inspect available boilerplate entries -------------------------------
cat(unified_db$methods$confounding_control$vanderweele)
cat(unified_db$methods$sample$nzavs)
cat(unified_db$methods$causal_intervention$grf_simple_text)
cat(unified_db$appendix$explain$grf_short)

# ---- read variable definitions -------------------------------------------
baseline_vars           <- margot::here_read("baseline_vars")
exposure_var            <- margot::here_read("exposure_var")
outcome_vars            <- margot::here_read("outcome_vars")

# ---- define study waves --------------------------------------------------
baseline_wave           <- margot::here_read("baseline_wave")
exposure_waves          <- margot::here_read("exposure_waves")
outcome_wave            <- margot::here_read("outcome_wave")

# 
baseline_wave_glued <- glue::glue(baseline_wave)

# ---- define study parameters ---------------------------------------------
study_years             <- "2018-2021"
name_exposure           <- here_read("name_exposure")
name_outcome_variables  <- "MY OUTCOME VARIABLES IN THIS STUDY"
name_exposure_lower     <- tolower(name_exposure)
name_exposure_lower

# ---- templates and thresholds --------------------------------------------
eligibility_template    <- "Participants were eligible if they participated in the {baseline wave}"
percent_missing_baseline <- margot::here_read("percent_missing_baseline")

# ---- read tables for manuscript ------------------------------------------
markdown_table_baseline  <- margot::here_read("baseline_table")
markdown_table_exposures <- margot::here_read("exposure_table")
markdown_table_outcomes  <- margot::here_read("outcomes_table")
margot_bind_tables_markdown <- margot::here_read("margot_bind_tables_markdown")
# ---- sample size information --------------------------------------------
n_total                  <- margot::here_read("n_total")
n_participants           <- here_read("n_participants")

# ---- variable labels and mappings ----------------------------------------
var_labels_measures      <- here_read("var_labels_measures")
label_mapping_all        <- here_read("label_mapping_all")

# ---- plot titles and analysis settings -----------------------------------
ate_title                <- here_read("ate_title")
flipped_names            <- here_read("flipped_names")

flipped_list             <- paste(flipped_names, collapse = ", ")

# ---- import data for visualisation --------------------------------------
original_df              <- margot::here_read('df_wide', push_mods)
df_grf <- margot::here_read('df_grf', push_mods)

# co-variates
E <- margot::here_read('E', push_mods)
# select covariates and drop numeric attributes
X <- margot::remove_numeric_attributes(df_grf[E])


# ---- define nice names and regimes ---------------------------------------
nice_name_exposure_variable <- stringr::str_to_sentence(name_exposure)
name_outcomes_lower          <- "multi-dimensional wellbeing"

# ---- define exposure thresholds and regimes ------------------------------
lower_cut               <- here_read("lower_cut")
upper_cut               <- here_read("upper_cut")
threshold               <- here_read("threshold")
inverse_threshold       <- here_read("inverse_threshold")
scale_range             <- margot::here_read("scale_range")

# create and check variables
value_exposure = glue::glue( threshold,"", upper_cut,", ", scale_range)
value_control =   glue::glue(inverse_threshold, upper_cut,", ", scale_range)

# regimes
name_control_regime_lower <- glue::glue("low {name_exposure_lower}")
value_exposure_regime     <- glue::glue("Set {name_exposure} {threshold} {upper_cut} {scale_range}")
value_control_regime      <- glue::glue("Set {name_exposure} {inverse_threshold} {upper_cut} {scale_range}")


contrast_template         <- "We used causal forests to estimate an average treatment effect as a contrast between *{name_control_regime_lower}* and *{name_exposure_lower}* on {name_outcomes_lower}."
contrast_text             <- glue(contrast_template)

#chedk
contrast_text
# ---- verify assumptions (positivity) -------------------------------------
transition_tables        <- margot::here_read("transition_tables")
transition_tables_binary <- here_read("transition_tables_binary")

baseline_vars
# ---- generate measures text for methods section -------------------------
baseline_measures_text   <- boilerplate_generate_measures(
  variable_heading = "Baseline Covariates",
  variables        = baseline_vars,
  db               = unified_db,
  heading_level    = 3,
  subheading_level = 4,
  print_waves      = FALSE,
  label_mappings   = var_labels_measures
)
cat(baseline_measures_text)
exposure_measures_text   <- boilerplate_generate_measures(
  variable_heading = "Exposure Variable",
  variables        = name_exposure,
  db               = unified_db,
  heading_level    = 3,
  subheading_level = 4,
  print_waves      = FALSE,
  label_mappings   = var_labels_measures
)
outcome_measures_text    <- boilerplate_generate_measures(
  variable_heading = "Outcome Variables",
  variables        = outcome_vars,
  db               = unified_db,
  heading_level    = 3,
  subheading_level = 4,
  print_waves      = FALSE,
  label_mappings   = var_labels_measures
)

# ---- exposure description from database --------------------------------
measures_exposure        <- glue::glue(unified_db$measures[[name_exposure]]$description)


# ---- set plot defaults for ate plots -------------------------------------
base_defaults_binary     <- list(
  type                   = "RD",
  title                  = ate_title,
  e_val_bound_threshold  = 1.2,
  colors                 = c(
    "positive"    = "#E69F00",
    "not reliable"= "grey50",
    "negative"    = "#56B4E9"
  ),
  x_offset               = -0.25,
  x_lim_lo               = -0.25,
  x_lim_hi               = 0.25,
  text_size              = 5,
  linewidth              = 0.75,
  estimate_scale         = 1,
  base_size              = 20, #<- change to make outcome labels bigger or smaller
  point_size             = 4,
  title_size             = 24,
  subtitle_size          = 16,
  legend_text_size       = 10,
  legend_title_size      = 10,
  include_coefficients   = FALSE
)

# ---- create plot options for outcomes -----------------------------------
outcomes_options_all     <- margot_plot_create_options(
  title         = ate_title,
  base_defaults = base_defaults_binary,
  subtitle      = "",
  filename_prefix = "grf"
)

# ---- policy tree graph settings -----------------------------------------
decision_tree_defaults  <- list(
  span_ratio         = 0.3,
  text_size          = 3.8,
  y_padding          = 0.25,
  edge_label_offset  = 0.002,
  border_size        = 0.05
)

policy_tree_defaults    <- list(
  point_alpha            = 0.5,
  title_size             = 12,
  subtitle_size          = 12,
  axis_title_size        = 12,
  legend_title_size      = 12,
  split_line_color       = "red",
  split_line_alpha       = 0.8,
  split_label_color      = "red",
  split_label_nudge_factor = 0.007
)




# ---- load and check model results ---------------------------------------
# takes more time but allows you to flexibly modify plots in the quarto document
# if you use the option comment out this code above

# takes less time if you used the pre-processed results but a little harder to adjust
# ate_results           <- margot::here_read_qs("ate_results", push_mods)
# margot::margot_size(ate_results)

models_binary <- margot::here_read_qs("models_binary", push_mods)

# make ate plots ----------------------------------------------------------
#   ************* NEW - CORRECTION FOR FAMILY-WISE ERROR **********
# then pass to the results
ate_results <- margot_plot(
  models_binary$combined_table, # <- now pass the corrected results.
  options = outcomes_options_all,
  label_mapping = label_mapping_all,
  include_coefficients = FALSE,
  save_output = FALSE,
  order = "evaluebound_asc",
  original_df = original_df,
  e_val_bound_threshold = 1.2,
  rename_ate = TRUE,
  adjust = "bonferroni", #<- new 
  alpha = 0.05 # <- new 
)

# check
ate_results$plot

# view
cat(ate_results$interpretation)



# ---- heterogeneity analysis ---------------------------------------------
models_binary_flipped_all <- here_read_qs("models_binary_flipped_all", push_mods)

# this is a new function requires margot 1.0.48 or higher
# only useful if you flip labels outcomes -- if so replace "label_mapping_all" 
# with "label_mapping_all_flipped" 
label_mapping_all_flipped <- margot_reversed_labels(label_mapping_all, 
                                                    flipped_names)

# could be used in an appendix
result_ominbus_hetero     <- margot_omnibus_hetero_test(
  models_binary_flipped_all,
  label_mapping  = label_mapping_all_flipped,
  alpha          = 0.05,
  detail_level   = "standard",
  format         = "markdown"
)
result_ominbus_hetero$summary_table |> kbl("markdown")
cat(result_ominbus_hetero$brief_interpretation)


rate_results <-
  margot_rate(
    models   = models_binary_flipped_all,
    policy   = "treat_best",
    alpha  = 0.20,# raw p < 0.20 is enough to keep
    adjust = "fdr", # <‑‑correction
    label_mapping = label_mapping_all_flipped
  )

# show rate tables
rate_results$rate_autoc %>% kbl("markdown")
rate_results$rate_qini %>% kbl("markdown")


# generate textual interpretations for rate metrics
# 2. then run the interpreter, passing through adjust_positives_only = TRUE
rate_interp <- margot::margot_interpret_rate(rate_results,
                                             flipped_outcomes       = flipped_names,
                                             adjust_positives_only  = TRUE) # <- new requires margot 1.0.50 or higher

# review
cat(rate_interp$comparison)
cat(rate_interp$autoc_results, "\n")
cat(rate_interp$qini_results, "\n")
cat(rate_interp$comparison, "\n")
cat(rate_interp$not_excluded_either, "\n")

# organise model groups by heterogeneity evidence
model_groups <- list(
  autoc  = rate_interp$autoc_model_names,
  qini   = rate_interp$qini_model_names,
  either = rate_interp$either_model_names,
  exploratory = rate_interp$not_excluded_either # not excluded, for exploratory research
)

# plot rate curves -----------------------------------------------
autoc_plots <-
  margot_plot_rate_batch(
    models      = models_binary_flipped_all, # <- changed to "models_binary" if you did not flip outcomes # optional use "label_mapping_all_flipped" 
    save_plots  = FALSE,
    label_mapping      = label_mapping_all_flipped,
    model_names = model_groups$autoc
  )

# check length
length(autoc_plots)
autoc_plots[[1]]


# Qini model curves --------------------------------------------
devtools::load_all("/Users/joseph/GIT/margot/")

qini_results <-
  margot_policy(
    models_binary_flipped_all,
    save_plots         = FALSE,
    output_dir         = here::here(push_mods),
    decision_tree_args = decision_tree_args,
    policy_tree_args   = policy_tree_args,
    model_names        = names(models_binary_flipped_all$results), 
    original_df        = original_df,
    label_mapping      = label_mapping_all_flipped,
    max_depth          = 2L,
    output_objects     = c("qini_plot", "diff_gain_summaries")
  )

label_mapping_all_flipped
names(models_binary_flipped_all$results)

# view qini plots
qini_plots <- purrr::map(qini_results, ~ .x$qini_plot)
names(qini_results)
str(qini_results, max.level = 3)
# interpret qini
qini_gain_interpretation <- margot_interpret_qini(qini_results, 
                                                  label_mapping = label_mapping_all_flipped)

# table (only use if more than one qini gain interpretation)
qini_gain_interpretation$summary_table |> 
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kbl(format = "markdown")

# the interpretation - used below
cat(qini_gain_interpretation$qini_explanation)

qini_gain_interpretation$reliable_model_ids

cli::cli_h1("Qini model curves plotted ✔")



# ---- policy analysis with qini and trees -------------------------------
# focus of study
 policy_results_2L            <- margot_policy(
  models_binary_flipped_all,
  save_plots         = FALSE,
  output_dir         = here::here(push_mods),
  decision_tree_args = decision_tree_defaults,
  policy_tree_args   = policy_tree_defaults,
  # model_names        = model_keep_either, #<- test all
  max_depth          = 2L,
  original_df        = original_df,
  label_mapping      = label_mapping_all_flipped,
    output_objects = c("combined_plot")
)

policy_plots <- purrr::map(policy_results_2L, ~ .x[[1]])


# plot 1
# policy_plots[[1]]
# 
# # plot 2
# policy_plots[[2]]
# 
# # and so on...


# 4. interpretation ----------------------------------
# -------------------------------------------------------------------
# generates a short paragraph per outcome explaining the splits and     
# their implied treatment rule.                                         
policy_interpretation_2L <- margot::margot_interpret_policy_batch(
  models = models_binary_flipped_all,
  original_df        = original_df,
  label_mapping      = label_mapping_all_flipped,
  max_depth          = 2L)

# check
cat(policy_interpretation_2L, "\n")


# end‑of‑workflow -----------------------------
cli::cli_h1("main 2l policy trees analysed ✔")


# NAMES --------------------------------------------------------------

# get names
autoc_names <- margot_get_labels(model_groups$autoc, label_mapping_all)
autoc_names

qini_names <- margot_get_labels(model_groups$qini, label_mapping_all)
qini_names


policy_names <- margot_get_labels(names(models_binary_flipped_all$results), label_mapping_all_flipped)
glued_policy_names <- glue::glue("{policy_names}")
glued_policy_names_1 <- glued_policy_names[[1]]
glued_policy_names_2 <- glued_policy_names[[2]]
glued_policy_names_3 <- glued_policy_names[[3]]
glued_policy_names_4 <- glued_policy_names[[4]]
glued_policy_names_5 <- glued_policy_names[[5]]
glued_policy_names_6 <- glued_policy_names[[6]]
glued_policy_names_7 <- glued_policy_names[[7]]
glued_policy_names_8 <- glued_policy_names[[8]]
glued_policy_names_9 <- glued_policy_names[[9]]
glued_policy_names_10 <- glued_policy_names[[10]]
glued_policy_names_11 <- glued_policy_names[[11]]
glued_policy_names_12 <- glued_policy_names[[12]]

policy_names
# GROUP COMPARISON EXAMPLE ------------------------------------------------
# play around with these values
x_offset_comp <- 1.0
x_lim_lo_comp <- -1.0
x_lim_hi_comp <- 1.0 

base_defaults_comparisons <- list(
  type = "RD",
  title = ate_title,
  e_val_bound_threshold = 1.2,
  label_mapping = "label_mapping_all",
  adjust = "bonferroni", #<- new
  alpha = 0.05, # <- new
  colors = c(
    "positive" = "#E69F00",
    "not reliable" = "grey50",
    "negative" = "#56B4E9"
  ),
  x_offset = x_offset_comp,
  # will be set based on type
  x_lim_lo = x_lim_lo_comp,
  # will be set based on type
  x_lim_hi = x_lim_hi_comp,
  text_size = 8,
  linewidth = 0.75,
  estimate_scale = 1,
  base_size = 18,
  point_size = 2.5,
  title_size = 19,
  subtitle_size = 16,
  legend_text_size = 10,
  legend_title_size = 10,
  include_coefficients = FALSE
)

complex_condition_age  <- between(X[,"t0_age_z"], -1, 1)

# sanity‑check age bounds on the raw scale
mean(original_df$t0_age) + c(-1, 1) * sd(original_df$t0_age)

# age subsets
subsets_standard_age <- list(
  Younger = list(
    var = "t0_age_z",
    value = -1,
    operator = "<",
    label = "Age < 35"
  ),
  Middle = list(
    var = "t0_age_z",
    # operator = "<",
    subset_condition = complex_condition_age,
    label = "Age 35-62"
  ),
  Older = list(
    var = "t0_age_z",
    value = 1,
    operator = ">",
    label = "Age > 62"
  )
)

# 3. batch subgroup analysis -----------------------------------------
planned_subset_results <- margot_planned_subgroups_batch(
  domain_models  = list(models_binary),
  X              = X,
  base_defaults  = base_defaults_comparisons,
  subset_types   = list(cohort = subsets_standard_age),
  original_df    = original_df,
  label_mapping  = label_mapping_all,          # ← supply it here
  domain_names   = "wellbeing",
  subtitles      = "",
  adjust         = "bonferroni",  # ← here
  alpha          = 0.05           # ← and here
)

# make comparison plot
plots_subgroup_age_young_old<- wrap_plots(
  list(
    planned_subset_results$wellbeing$cohort$results$`Age < 35`$plot,
    planned_subset_results$wellbeing$cohort$results$`Age > 62`$plot
  ), ncol = 1) +
  plot_annotation(
    title = "Younger vs Older",
    theme = theme(plot.title = element_text(size = 18, face = "bold"))
  )



# are groups different from each other? 
# example: young (<35) vs older (>62)
group_comparison_age_young_old <- margot_compare_groups(
  group1_name = "People Under 35 Years Old",
  group2_name = "People Over 62 Years Old", 
  planned_subset_results$wellbeing$cohort$results$`Age < 35`$transformed_table, # reference
  planned_subset_results$wellbeing$cohort$results$`Age > 62`$transformed_table, # comparison
  type            = "RD",          # risk‑difference scale
  decimal_places  = 3
)
print(group_comparison_age_young_old$results |> kbl("markdown", digits = 3))
cat(group_comparison_age_young_old$interpretation)


# ---- define global variables for text generation ------------------------
global_vars <- list(
  name_exposure_variable     = nice_name_exposure_variable,
  n_total                    = n_total,
  ate_adjustment             = "bonferroni", 
  ate_alpha                  = "0.05",
  cate_adjustment            = "Benjamini–Hochberg false-discovery-rate adjustment",
  cate_alpha                 =  "0.1",             
  sample_ratio_policy        =  "70/30",
  n_participants             = n_participants,
  exposure_variable          = name_exposure,
  name_exposure_lower        = name_exposure_lower,
  name_control_regime_lower  = name_control_regime_lower,
  name_outcome_variables     = "Self Esteem", # <- adjust to your study, your decision
  name_outcomes_lower        = name_outcomes_lower,
  name_exposure_capfirst     = nice_name_exposure_variable,
  measures_exposure          = measures_exposure,
  value_exposure_regime      = value_exposure_regime,
  value_control_regime       = value_control_regime,
  flipped_list               = flipped_list,
  appendix_explain_grf       = "D",
  appendix_assumptions_grf   = "D",
  name_exposure_threshold    =  "1",
  name_control_threshold     =  "0",
  appendix_measures          =  "A",
  value_control              = value_control,     # ← named
  value_exposure             = value_exposure,    # ← named
  appendix_positivity        = "G",
  appendix_rate              = "E",
  appendix_qini_curve        = "F",
  train_proportion_decision_tree = ".7",
  traning_proportion         = ".7",
  baseline_wave              = baseline_wave,
  exposure_waves             = exposure_waves,
  outcome_wave               = outcome_wave,
  protocol_url               = "https://osf.io/ce4t9/", # if used
  appendix_timeline          = "A" # if used
)
```

{{< pagebreak >}}

## Introduction

FILL OUT

## Method

```{r, results='asis'}
#| eval: true # |eval: false # <- set to false as needed/desired for your own material
#| echo: false
library(boilerplate)
cat(
  boilerplate::boilerplate_generate_text(
    category     = "methods",      # ← choose the right top-level list
    sections     = c(
      "sample.nzavs",
      "target_population",
      "eligibility.standard",
      "causal_intervention.grf_simple_text",
      "analytic_approach.general_approach_cate_long", # <- new
      "exposure_indicator",
      "causal_identification_criteria",
      "confounding_control.vanderweele",
      "statistical_models.grf_short_explanation",
      "missing_data.missing_grf_simple",
      "sensitivity_analysis.short_evalue"
    ),
    global_vars  = global_vars,
    db           = unified_db
  )
)
```

{{< pagebreak >}}

## Results

### Average Treatement Effects

```{r}
#| label: fig-ate
#| fig-cap: "Average Treatment Effects on Multi-dimensional Wellbeing"
#| eval: true # |eval: false # <- set to false as needed/desired for your own material
#| echo: false
#| fig-height: 14
#| fig-width: 18
ate_results$plot
```

{{< pagebreak >}}

```{r}
#| label: tbl-outcomes
#| tbl-cap: "Average Treatment Effects on Multi-dimensional Wellbeing"
#| eval: true # |eval: false # <- set to false as needed/desired for your own material
#| echo: false

# ate_results$transformed_table|> kbl("markdown")
margot_bind_tables_markdown
```

```{r, results = 'asis'}
#| eval: true # |eval: false # <- set to false as needed/desired for your own material

cat(ate_results$interpretation)
```

Confidence intervals were adjusted for multiple comparisons using bonferroni correction ($\alpha$ = 0.05). E‑values were also adjusted using bonferroni correction ($\alpha$ = 0.05). The following outcomes showed reliable causal evidence (E‑value lower bound \> 1.2):

-   **Social Belonging**: 0.125(0.064,0.186); on the original scale, 0.136 (0.07,0.203). E‑value bound = 1.311
-   **Neighbourhood Community**: 0.119(0.052,0.186); on the original scale, 0.187 (0.082,0.292). E‑value bound = 1.273
-   Social Support: 0.096(0.032,0.16); on the original scale, 0.107 (0.036,0.179). E‑value bound = 1.203.

{{< pagebreak >}}

### Heterogeneous Treatment Effects

#### Decision Rules (Who is Most Sensitive to Treatment?)

```{r, results='asis'}
#| eval: true  # <- set to false: copy and paste your own text using this material
#| echo: false
cat(
  boilerplate::boilerplate_generate_text(
    category     = "results",      # ← choose the right top-level list
    sections     = c(
    "grf.interpretation_policy_tree"
    ),
    global_vars  = global_vars,
    db           = unified_db
  )
)
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-1
#| fig-cap: "Decision Tree: {glued_policy_names_1}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
# plot 1
policy_plots[[1]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-2
#| fig-cap: "Decision Tree: {glued_policy_names_2}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[2]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-3
#| fig-cap: "Decision Tree: {glued_policy_names_3}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[3]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-4
#| fig-cap: "Decision Tree: {glued_policy_names_4}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[4]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-5
#| fig-cap: "Decision Tree: {glued_policy_names_5}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[5]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-6
#| fig-cap: "Decision Tree: {glued_policy_names_6}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[6]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-7
#| fig-cap: "Decision Tree: {glued_policy_names_7}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[7]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-8
#| fig-cap: "Decision Tree: {glued_policy_names_8}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9

policy_plots[[8]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-9
#| fig-cap: "Decision Tree: {glued_policy_names_9}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[9]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-10
#| fig-cap: "Decision Tree: {glued_policy_names_10}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[10]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-11
#| fig-cap: "Decision Tree: {glued_policy_names_11}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[11]]
```

{{< pagebreak >}}

```{r}
#| label: fig-policy-12
#| fig-cap: "Decision Tree: {glued_policy_names_12}"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
policy_plots[[12]]
```

{{< pagebreak >}}

```{r, results = 'asis'}
#| eval: true # <- set to false if you want to copy and paste your own text
cat(policy_interpretation_2L, "\n")
```

{{< pagebreak >}} \## Planned Subgroup Comparisons (Optional)

Based on theoretical findings we expected that the effects of {name_exposure} would vary by age...\@fig-planned-comparison and @tbl-planned-comparison

```{r}
#| label: fig-planned-comparison
#| fig-cap: "Planned Comparison Plot"
#| eval: true
#| echo: false
#| fig-height: 16
#| fig-width: 9
plots_subgroup_age_young_old
```

```{r}
#| label: tbl-planned-comparison
#| tbl-cap: "Planned Comparison Table"
#| eval: true  # <- set to false: copy and paste your own text using this material
#| echo: false
# table (only use if more than one qini gain interpretation)
group_comparison_age_young_old$results |> 
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kbl(format = "markdown")

```

```{r, results = 'asis'}
#| eval: true # <- set to false if you want to copy and paste your own text
cat(group_comparison_age_young_old$interpretation)
```

{{< pagebreak >}}

## Discussion

```{r,  results='asis'}
#| eval: false  # <- set to false: copy and paste your own text using this material
#| echo: false
cat(boilerplate_generate_text(
  category = "discussion",
  sections = c(
    "ethics.nzavs_2021_2027",
    "authors_statment_empty",
    "acknowlegements.nzavs_acknowledgements_2025",
    "nzavs_data_availabily"
  ),
  global_vars = list(
    exposure_variable = name_exposure
  ),
  db = unified_db
))
```

{{< pagebreak >}}

## Appendix A: Measures {#appendix-measures}

### Measures

#### Baseline Covariate Measures

```{r, results='asis'}
cat(baseline_measures_text)
```

#### Exposure Measures

```{r, results='asis'}
cat(exposure_measures_text)
```

#### Outcome Measures

```{r, results='asis'}
cat(outcome_measures_text)
```

{{< pagebreak >}}

## Appendix B: Sample Characteristics {#appendix-sample}

#### Sample Statistics: Baseline Covariates

@tbl-appendix-baseline presents sample demographic statistics.

::: {#tbl-appendix-baseline}
```{r, results = 'asis'}
#| eval: true
#| include: true
#| echo: false
markdown_table_baseline
```

Demographic statistics for New Zealand Attitudes and Values Cohort: {baseline_wave_glued}.
:::

### Sample Statistics: Exposure Variable {#appendix-exposure}

<!-- @tbl-sample-exposures presents sample statistics for the exposure variable, religious service attendance, during the baseline and exposure waves. This variable was not measured in part of NZAVS time 12 (years 2020-2021) and part of NZAVS time 13 (years 2021-2022). To address missingness, if a value was observed after NZAVS time 14, we carried the previous observation forward and created and NA indicator. If there was no future observation, the participant was treated as censored, and inverse probability of censoring weights were applied, following our standard method for handling missing observations (see mansucript **Method**/**Handling of Missing Data**). Here, our carry-forward imputation approach may result in conservative causal effect estimation because it introduces measurement error. However, this approach would not generally bias causal effect estimation away from the null because the measurement error is unsystematic and random and unrelated to the outcomes. -->

::: {#tbl-appendix-exposures}
```{r, results = 'asis'}
#| eval: true
#| include: true
#| echo: false

markdown_table_exposures

```

Demographic statistics for New Zealand Attitudes and Values Cohort waves 2018.
:::

{{< pagebreak >}}

### Sample Statistics: Outcome Variables {#appendix-outcomes}

::: {#tbl-appendix-outcomes}
```{r, results = 'asis'}
#| eval: true
#| include: true
#| echo: false

markdown_table_outcomes

```

Outcome variables measured at {baseline_wave_glued} and {outcome_wave}
:::

{{< pagebreak >}}

## Appendix C: Transition Matrix to Check The Positivity Assumption {#appendix-transition}

```{r, results = 'asis'}
#| label: tbl-transition
#| tbl-cap: "Transition Matrix Showing Change"
#| eval: true
#| include: true
#| echo: false

transition_tables_binary$tables[[1]]
```

```{r, results = 'asis'}
cat(transition_tables_binary$explanation)
```

{{< pagebreak >}}

## Appendix D: Approach to Heterogeneous Treatment Effects {#appendix-cate-validation}

```{r, results='asis'}
#| eval: true
#| echo: false
library(boilerplate)
cat(
  boilerplate::boilerplate_generate_text(
    category     = "appendix",      # ← choose the right top-level list
    sections     = c(
      "explain.grf_short"
    ),
    global_vars  = global_vars,
    db           = unified_db
  )
)
```

{{< pagebreak >}}

{{< pagebreak >}}

## Appendix E: RATE AUTOC and RATE Qini {#appendix-rate}

```{r, results='asis'}
#| eval: true # <- set to false as needed/desired
#| echo: false
cat(
  boilerplate::boilerplate_generate_text(
    category     = "results",      # ← choose the right top-level list
    sections     = c(
    "grf.interpretation_rate"
    ),
    global_vars  = global_vars,
    db           = unified_db
  )
)
```

```{r, results='asis'}
#| eval: true # <- set to false as needed/desired
#| echo: false
cat(rate_interp$comparison)
```

Refer to [Appendix E](#appendix-cate-validation) for details.

##### RATE AUTOC Results

```{r, results = 'asis'}
# only reliable results
cat(rate_interp$autoc_results)
```

```{r}
#| label: fig-rate-1
#| fig-cap: "RATE AUTOC Graphs"
#| eval: true  # <- set to false as needed/desired
#| echo: false
#| fig-height: 16
#| fig-width: 9
autoc_plots[[1]]
```

@fig-rate-1 presents the RATE AUTOC curve for `r autoc_names[[1]]`

{{< pagebreak >}}

## Appendix F QINI Curve Analysis {#appendix-qini-curve}

```{r, results='asis'}
#| eval: true  # <- set to false: copy and paste your own text using this material
#| echo: false
cat(
  boilerplate::boilerplate_generate_text(
    category     = "results",      # ← choose the right top-level list
    sections     = c(
    "grf.interpretation_qini"
    ),
    global_vars  = global_vars,
    db           = unified_db
  )
)
```

```{r, results = 'asis'}
# only reliable results
cat(qini_gain_interpretation$qini_explanation) 
```

@tbl-qini presents results for our Qini curve analysis at different spend rates.

```{r}
#| label: tbl-qini
#| tbl-cap: "Qini Curve Results"
#| eval: true  # <- set to false: copy and paste your own text using this material
#| echo: false
# table (only use if more than one qini gain interpretation)
qini_gain_interpretation$summary_table |> 
  mutate(across(where(is.numeric), ~ round(., 2))) %>%
  kbl(format = "markdown") #<-- only if you have this, otherwise delete this code
```

@fig-qini-1 presents results for reliable Qini results

```{r}
#| label: fig-qini-1
#| fig-cap: "Qini Graphs"
#| eval: true # <- set to false as needed/desired
#| echo: false
#| fig-height: 18
#| fig-width: 12

library(patchwork)
# combine first column of plots (4,6,7,8) and second column (9,11,12)
# these showed reliable qini results
combined_qini <- (
  qini_plots[[4]]  /
  qini_plots[[6]]  /
  qini_plots[[7]]  /
  qini_plots[[8]]
) | (
  # remove this block if you don't have plots 9,11,12
  qini_plots[[9]]  /
  qini_plots[[11]] /
  qini_plots[[12]]
) +
  # collect all legends into one shared guide
  plot_layout(guides = "collect") +
  # add title (and optionally subtitle)
  plot_annotation(
    title    = "Combined Qini Plots",
    subtitle = "Panels arranged with shared legend"
  ) &
  # apply theme modifications to all subplots
  theme(
    legend.position   = "bottom",           # place legend below
    plot.title        = element_text(hjust = 0.5),  # centre title
    plot.subtitle     = element_text(hjust = 0.5)   # centre subtitle
  )

# draw it
print(combined_qini)

```

{{< pagebreak >}}

## References {.appendix-refs}
