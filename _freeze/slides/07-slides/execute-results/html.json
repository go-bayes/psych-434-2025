{
  "hash": "4e0da9900b89bc252db1cb323f277d42",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Introduction to Causal Inference\"\nsubtitle: \"Data Exercise\"\nformat:\n  revealjs: \n    slide-number: true\n    smaller: false\n    scrollable: true\n    incremental: true\n    chalkboard: true \n    buttons: false\n    preview-links: auto\n    theme: moon\n    embed-resources: false\n    code-fold: true\n    code-overflow: scroll\n    code-line-numbers: true\n    auto-stretch: true\n    html-math-method: katex\n    progress: true\n    bibliography: references.bib\nexecute:\n  warning: false\n---\n\n\n\n\n\n\n## Goals\n\n### By the end of this seminaryou will be able to:\n\n1.  Understand the definition of \"causality\" as it is used in the human and health sciences.\n2.  Understand the assumptions required for consistently estimating causal effects. \n3.  Understand how to use causal diagrammes to assess these assumptions.\n\n### Key Concepts\n\n1.  Cause/Effect\n2.  Confounder \n3.  Collider \n\n\n## 0Where does psychology start?\n\n\n::: {.fragment .highlight-red}\nPsychology starts with a question about how people think or behave.\n:::\n\n\n## Group discussion {.incremental}\n\n- We know that bilingual children tend to perform better on various cognitive tasks. Why might this be the case? \n\n- How can we know whether it is bilingualism that causes better performance on various cognitive tasks? \n\n\n## Hume's definitions of a causality \n\n\n> “we may define a cause to be an object followed by another, and where all the objects, similar to the first, are followed by objects similar to the second [definition 1]. Or, in other words, **where, if the first object had not been, the second never would have existed** [definition 2].” - David Hume, Enquiries Concerning Human Understanding, and Concerning the Principles of Morals, Section VII\n\n\n## Individual causal effects\n\n$Y_i^{a = 1}$: The cognitive ability of child $i$ if they were bilingual.  This is the counterfactual outcome when A = 1.\n\n$Y_i^{a = 0}$: The cognitive ability of child $i$ if they were monolingual. This is the counterfactual outcome when A = 0.\n\n$$\n\\text{Causal Effect}_i = Y^{a = 1} - Y^{a = 0} \n$$\n\n##  Individual causal quantities\n\nWe say there is a causal effect for individual $i$ if: \n\n$$\nY_i^{a=1} - Y_i^{a=0}  \\neq 0\n$$\n\n## What is the problem? \n\n- These data required to compute this quantity is generally not available.\n\n\n## Two Roads Diverge in a Yellow Wood\n\nRobert Frost writes, \n\n>Two roads diverged in a yellow wood,\n\n>And sorry I could not travel both\u000b\n\n>And be one traveler, long I stood\u000b\n\n>And looked down one as far as I could\u000b\n\n>To where it bent in the undergrowth;\u000b\n\n\n\n>Then took the other, as just as fair,\u000b\n\n>And having perhaps the better claim,\u000b\n\n>Because it was grassy and wanted wear;\u000b\n\n>Though as for that the passing there\u000b\n\n>Had worn them really about the same,\u000b\n\u000b\n\n>And both that morning equally lay\u000b\n\n>In leaves no step had trodden black.\u000b\n\n>Oh, I kept the first for another day!\u000b\n\n>Yet knowing how way leads on to way,\u000b\n\n\n>I doubted if I should ever come back.\u000b\n\n>I shall be telling this with a sigh\u000b\n\n>Somewhere ages and ages hence:\u000b\n\n>Two roads diverged in a wood, and I—\u000b\n\n>I took the one less traveled by,\u000b\n\n>And that has made all the difference. \n\n> Robert Frost, The Road Not Taken\n\n## How can we identify causal effects? {.incremental}\n\n-   Recall the answers you proposed to bilingual causal question\n\n    -   e.g. experiment: random assigment to bilingual training.\n\n-   How does this work?\n\n    -  Confounders equally distributed\n    -  Count up results\n    -  Take the average of the differences in the two groups.\n    \n\n## Average Treatement Effect in a Randomised Experiment\n\n\n\\begin{align}\nE(\\delta) = E(Y^{a=1} - Y^{a=0})\\\\\n          ~  = E(Y^{a=1}) - E(Y^{a=0}) \\\\\n          ~  = ATE\n\\end{align} \n\n:::{.notes}\n- E($\\delta$) is the \"estimand\" or causal quantity of interest (the expected difference between the means of two randomised groups, or equivalentally, the mean of the differences)\n:::\n\n\n## Assumptions Required for Estimating Causal Effects From Data\n\n- Causal Consistency: The values of exposure under comparisons correspond to well-defined interventions that, in turn, correspond to the versions of treatment in the data.(see: Chatton, Hernan & Robbins)\n- Positivity:  The probability of receiving every value of the exposure within all strata of co-variates is greater than zero \n- Exchangeablility:The conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates (see: Chatton, Hernan & Robbins)\n\n\n## Causal Consistency assumption \n\n\n::: {.fragment .highlight-red}\nThe values of exposure under comparisons correspond to well-defined interventions that, in turn, correspond to the versions of treatment in the data.\n:::\n\n\\begin{equation} \nY^{obs} = AY^{a=1} + (1-A)Y^{a=0}\n\\end{equation}\n\n\n## Causal Consistency gets from observations to counterfactuals\n\n\nFor individuals with exposure level $A = 1$:\n\n\\begin{equation}\n\\begin{split}\n(Y^{obs}|A = 1) &= 1 \\times A  \\times Y^{a=1} + (1-1) \\times Y^{a=0}\\\\\n& = 1 \\times Y^{a=1} + 0 \\times  Y^{a=0} \\\\\n & =  Y^{a=1}\n\\end{split}\n\\end{equation}\n\n\nFor individuals with exposure level $A = 0$:\n\n\\begin{equation}\n\\begin{split}\n(Y^{obs}|A = 0) &= 0 \\times A  \\times Y^{a=1} + (1-0) \\times Y^{a=0}\\\\\n& = 0 \\times Y^{a=1} + 1 \\times  Y^{a=0} \\\\\n & =  Y^{a=0}\n\\end{split}\n\\end{equation}\n\nWhich implies:\n\n\\begin{equation}\n\\begin{split}\nY_i &= Y_i^{a=1}~~~\\text{if}~ A_i = 1\\\\\nY_i &= Y_i^{a=0}~~~ \\text{if}~  A_i = 0\n\\end{split}\n\\end{equation}\n\n\n## Positivity\n\n::: {.fragment .highlight-red}\nThe probability of receiving every value of the exposure within all strata of co-variates is greater than zero \n:::\n\n\\begin{equation}\n0 < \\Pr(A=a|L)<1, ~ \\forall a \\in A, ~ \\forall a \\in L\n\\end{equation}\n\n- Two types of positivity violations\n  - Random non-positivity:  the casual effect of aging with observations missing at ages 40-41 (we use parametric models as a work around.)\n  - Deterministic non-positivity: the causal effect of hysterectomy in biological males (assumption violated).\n\n\n## Conditional Exchangeability \n\n::: {.fragment .highlight-red}\nThe conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates\n:::\n\ndef: $\\coprod$ means \"independent of\", $a|b$ translates to \"$a$ conditional on $b$\"\n\n\n\\begin{equation}\nY^{a=1},Y^{a=0}\\coprod A|L\n\\end{equation}\n\n\n\nor equivalently\n\n\\begin{equation}\nA \\coprod Y^{a=1},Y^{a=0}|L\n\\end{equation}\n\n\nWhere $L$ is the set of co-variates sufficient to ensure the independence of the counterfactual outcomes and the exposure.\n\n## Average Treatement Effect in Observational Studies\n\nWhere $L$ is observed: \n\n$$\n\\begin{aligned}\nATE = E[Y^{a=1}|L = l] - E[Y^{a=0}|L = l] ~ \\text{for any value}~l\n\\end{aligned}\n$$\n\n\n\n\n## Causal Graphs \n\nPsychology starts with a question. \"Does A cause Y?\"\n\n![cg-1](Slide1.jpeg)\n\n\n\n\n\n## Question:\n\n![cg-2](Slide2.jpeg)\n\n## One Problem\n\n\n![cg-3](Slide3.jpeg)\n\n## Solution: collect time-series data\n\n![cg-4](Slide4.jpeg)\n\n\n## Why time series data are critical\n\n![cg-5](Slide5.jpeg)\n\n\n## Another problem: common causes of A an Y (D-separation)\n\n\n![cg-6](Slide6.jpeg)\n\n## Solution: condition on common causes to ensure d-separation\n\n\n![cg-8](Slide8.jpeg)\n\n\n## Another problem: conditioning on a mediator\n\n![cg-7](Slide7.jpeg)\n\n## Conditioning on a mediator is a common problem\n\n![cg-9](Slide9.jpeg)\n\n## Forshadowing: in the weeks ahead we will discuss inferring mediated causal effects\n\n\n![cg-10](Slide10.jpeg)\n![cg-11](Slide11.jpeg)\n\n\n## Collider bias\n\n\n![cg-13](Slide13.jpeg)\n\n## Collider bias: solution do not condition on a collider\n\n![cg-13](Slide13.jpeg)\n\n\n## Conditioning on descendants \n\n![cg-14](Slide14.jpeg)\n\n## Summary\n\n![cg-15](Slide15.jpeg)\n\n\n\n##  Clear Advice for Drawing Causal Graphs\n\n- Ensure that causes come before effects. Assign time indices to your variables.\n- Organize your variables chronologically.\n- Simplify your graph by removing unnecessary nodes that don't impact the assessment of bias between an exposure and an outcome.\n- Keep in mind that Directed Acyclic Graphs (DAGs) are qualitative tools. They don't represent non-linear associations or interactions. \n- Avoid depicting interactions by crossing arrows.\n- Remember that DAGs are distinct from graphs used in Structural Equation Modeling (SEM). Be cautious of SEM literature, as it often overlooks the assumptions needed for causal inference.\n\n\n## Summary: Drawing Causal Graphs (DAGs)\n\n- Directed Acyclic Graphs (DAGs) help visualize sources of bias.\n\n- There are five main sources of bias:\n  1. Temporal order ambiguity: Uncertainty about whether causes precede effects. Solution: Collect time series data or clarify assumptions when unavailable.\n  2. Common causes of exposure and outcome: Address this by including common causes in your statistical model (e.g., using regression).\n  3. Conditioning on a mediator: Avoid this unless mediation is of interest.\n  4. Conditioning on a collider: Refrain from doing this.\n  5. Bias induced by conditioning on a confounder's descendant: Draw your DAG and follow guidelines for points 1-4.\n\n- Important Note 1: In observational studies, it's impossible to guarantee complete control for confounding. Always conduct sensitivity analyses. Techniques for sensitivity analyses will be discussed next week.\n\n- Important Note 2: Methods for computing causal effects for group comparisons will be covered in the following week's lecture.\n\n\n## What have we learned? \n\n\n1.  Cause/Effect: a contrast between the world under different interventions, at most one of which is realised. \n2.  Confounding: failure to condition on a common cause.\n3.  Collider bias: conditioning on a common effect\n\n\n\n\n\n:::{.notes}\nMetric equivalence: Factor loadings are similar across groups.\nConfigural equivalence: The factor structure is the same across groups in a multi-group confirmatory factor analysis.\nScalar equivalence: Values/Means are also equivalent across groups.\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}