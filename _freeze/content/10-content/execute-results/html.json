{
  "hash": "43fd029b28f84987685920e7fa004715",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands On Working With Quarto Manuscript\"\ndate: \"2025-MAY-13\"\nbibliography: /Users/joseph/GIT/templates/bib/references.bib\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    warnings: FALSE\n    error: FALSE\n    messages: FALSE\n    code-overflow: scroll\n    highlight-style: Ayu\n    code-tools:\n      source: true\n      toggle: FALSE\nhtml-math-method: katex\nreference-location: margin\ncitation-location: margin\ncap-location: margin\ncode-block-border-left: true\n---\n\n## Part 1: Quarto manuscripts\n\n\n\n\n::: {.callout-note}\n**Required**\nDownload Quarto here: \n- Use the `prelease` version: https://quarto.org/docs/download/\n**Optional**\n- [@Bulbulia2024PracticalGuide] [link](https://osf.io/preprints/psyarxiv/uyg3d)\n- [@hoffman2023] [link](https://arxiv.org/pdf/2304.09460.pdf)\n:::\n\n::: {.callout-important}\n## Key concepts\n- Entering bibliographic details\n- Writing up your manuscript\n:::\n\n# Code review: YOUR analysis\n\n-  Create a new Rstudio project\n-  Modify *these* scripts\n\n\n::: {.callout-note-script-0}\n[Download full lab scripts 0](../laboratory/lab-10/00-setup-L10.R)\n:::\n\n\n::: {.callout-note-script-1}\n[Download full lab scripts 1](../laboratory/ ../laboratory/lab-10/01-init-L10.R)\n:::\n\n::: {.callout-note-script-2}\n[Download full lab scripts 2]( ../laboratory/lab-10/02-make-wide-L10.R)\n:::\n\n::: {.callout-note-script-3}\n[Download full lab scripts 3](../laboratory/lab-10/03-models-L10-v3.R)\n:::\n\n\n\n\n#  Quarto with `boilerplate`\n\n::: {.callout-quarto-manuscript-template}\n[Download Quarto Template](../quarto/initial_quarto_document.qmd)\n:::\n\n\n## Script 0: Set up your library/\n\nNote -- rerun this script if you are missing updated templates, as they have been updated 23 May 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# script 00: read initial boilerplate data (for students)\n\n# load required packages --------------------------------------------------\nif (!requireNamespace(\"boilerplate\", quietly = TRUE)) {\n  if (!requireNamespace(\"devtools\", quietly = TRUE)) {\n    install.packages(\"devtools\")  # install devtools if missing\n  }\n  devtools::install_github(\"go-bayes/boilerplate\")  # install boilerplate\n}\n\nlibrary(boilerplate)  # manage boilerplate data\nlibrary(cli)          # friendly messages\nlibrary(here)         # project paths\nlibrary(fs)           # file system utilities\n\n# ensure correct boilerplate version --------------------------------------\nmin_version <- \"1.0.43\"\nif (utils::packageVersion(\"boilerplate\") < min_version) {\n  stop(\n    \"please install boilerplate >= \", min_version, \":\\n\",\n    \"  devtools::install_github('go-bayes/boilerplate')\"\n  )\n}\n\ncli::cli_h1(\"boilerplate loaded ✔\")\n\n# create local data folders ------------------------------------------------\npath_data   <- here::here(\"example_boilerplate_data\")\npath_quarto <- here::here(\"quarto\")\n\nfs::dir_create(path_data)    # create data folder if needed\ncli::cli_h2(\"data folder ready ✔\")\n\n# import student boilerplate data ------------------------------------------\nload_student_boilerplate <- function() {\n  base_url   <- \"https://raw.githubusercontent.com/go-bayes/templates/main/student_boilerplate_data/\"\n  categories <- c(\"measures\", \"methods\", \"results\", \"discussion\", \"appendix\", \"template\")\n  cli::cli_text(\"loading student boilerplate data from GitHub...\")\n  \n  student_db <- list()\n  for (cat in categories) {\n    cli::cli_text(\"  - loading {cat} database...\")\n    rds_url <- paste0(base_url, cat, \"_db.rds\")\n    student_db[[cat]] <- tryCatch(\n      readRDS(url(rds_url)),\n      error = function(e) {\n        cli::cli_alert_warning(\"failed to load {cat}: {e$message}\")\n        list()  # fallback empty list\n      }\n    )\n  }\n  \n  cli::cli_text(\"successfully loaded {length(categories)} categories\")\n  student_db\n}\nstudent_unified_db <- load_student_boilerplate()\n# save imported data -------------------------------------------------------\nboilerplate_save(\n  student_unified_db,\n  data_path     = path_data,\n  create_backup = FALSE\n)\ncat(student_unified_db$discussion$strengths$strengths_grf_long)\ncli::cli_h1(\"data saved ✔\")\n\n# set up bibliography and APA-7 template -----------------------------------\nfs::dir_create(\"quarto\")  # for title.tex\n\ndownload.file(\n  url      = \"https://raw.githubusercontent.com/go-bayes/templates/refs/heads/main/quarto/title.tex\",\n  destfile = \"quarto/title.tex\",\n  mode     = \"wb\"\n)\n\nfs::dir_create(\"bibliography\")\nfs::dir_create(\"csl\")\n\ndownload.file(\n  url      = \"https://raw.githubusercontent.com/go-bayes/templates/refs/heads/main/bib/references.bib\",\n  destfile = \"quarto/references.bib\",\n  mode     = \"wb\"\n)\n\ndownload.file(\n  url      = \"https://raw.githubusercontent.com/go-bayes/templates/refs/heads/main/csl/apa-7.csl\",\n  destfile = \"quarto/apa7.csl\",\n  mode     = \"wb\"\n)\n\ncli::cli_h1(\"bibliography and CSL setup complete ✔\")\n\n# end of script: do not rerun this file ------------------------------------\n\ncat(student_unified_db$methods$analytic_approach$general_approach_cate_long)\n```\n:::\n\n\n::: {.callout-note}\nType `y` when R asks whether to overwrite the boilerplate files; this replaces them with the latest versions.\nPress `n` (or just hit Enter) to keep what you already have.\n\nYour own edits—such as custom rows in the measures table -- are stored elsewhere, so they will not be overwritten. One tap, no tears.\n\nTake-away: `y` refreshes the templates; `n` preserves the status quo.\n:::\n\nThis is how the the printout in your R console should look (depending on how recently you've run your script):\n\n```r\n> # save imported data -------------------------------------------------------\n> boilerplate_save(\n+   student_unified_db,\n+   data_path     = path_data,\n+   create_backup = FALSE\n+ )\nℹ preparing to save 6 databases\nℹ processing measures database (1/6)\nℹ no changes detected in measures database\nℹ saving measures database to /Users/your_machine_path-/example_boilerplate_data/measures_db.rds\n✔ saved measures database\nℹ processing methods database (2/6)\nℹ 1 new entries will be added:\nℹ   + student_target_population\n! 2 entries will be removed:\n!   - target_population\n!   - sample\nSave methods database with these changes? [y/n]: y\nℹ saving methods database to /Users/joseph/GIT/psych-434-2025/example_boilerplate_data/methods_db.rds\n✔ saved methods database\nℹ processing results database (3/6)\nℹ no changes detected in results database\nℹ saving results database to /Users/joseph/GIT/psych-434-2025/example_boilerplate_data/results_db.rds\n✔ saved results database\nℹ processing discussion database (4/6)\nℹ 2 existing entries will be modified:\nℹ   ~ student_authors_statement\nℹ   ~ student_ethics\nSave discussion database with these changes? [y/n]: y\nℹ saving discussion database to /Users/joseph/GIT/psych-434-2025/example_boilerplate_data/discussion_db.rds\n✔ saved discussion database\nℹ processing appendix database (5/6)\nℹ no changes detected in appendix database\nℹ saving appendix database to /Users/joseph/GIT/psych-434-2025/example_boilerplate_data/appendix_db.rds\n✔ saved appendix database\nℹ processing template database (6/6)\nℹ no changes detected in template database\nℹ saving template database to /Users/joseph/GIT/psych-434-2025/example_boilerplate_data/template_db.rds\n✔ saved template database\n✔ successfully saved all 6 databases\n```\n\n## Script 1: Adding/Revising Measures\n\nNote -- rerun this script if you are missing updated templates, as they have been updated 23 May 2025\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# script 01: add or revise measures (for students)\n# load required packages --------------------------------------------------\nif (!requireNamespace(\"boilerplate\", quietly = TRUE)) {\n  if (!requireNamespace(\"devtools\", quietly = TRUE)) {\n    install.packages(\"devtools\")  # install devtools if missing\n  }\n  devtools::install_github(\"go-bayes/boilerplate\")  # install boilerplate\n}\n\nlibrary(boilerplate)  # tools for measure management\nlibrary(cli)          # user-friendly messages\nlibrary(here)         # project-friendly file paths\n\n# ensure correct boilerplate version --------------------------------------\nif (utils::packageVersion(\"boilerplate\") < \"1.0.41\") {\n  stop(\"please install boilerplate >= 1.0.41: \\\n       devtools::install_github('go-bayes/boilerplate')\")\n}\n\ncli::cli_h1(\"boilerplate loaded ✔\")\n\n# define data paths --------------------------------------------------------\npath_src   <- here::here(\"example_boilerplate_data\")\npath_final <- here::here(\"final_boilerplate_data\")\n\n# create final data directory if needed -----------------------------------\nif (!dir.exists(path_final)) {\n  dir.create(path_final)\n}\ncli::cli_h1(\"data folder ready ✔\")\n\n# import unified database --------------------------------------------------\nunified_db <- boilerplate_import(data_path = path_src)\n\n# save a copy to avoid overwriting original --------------------------------\nboilerplate_save(\n  unified_db,\n  data_path   = path_final,\n  output_file = \"unified_db\"\n)\n\ncli::cli_h2(\"database imported and saved ✔\")\n\n# inspect structure and existing measures ----------------------------------\nstr(unified_db, max.level = 2)     # glance at top-level structure\nprint(names(unified_db$measures))  # list defined measures\n\n# example: check for a specific measure ------------------------------------\nmeasure_name <- \"emp_job_satisfaction\"\nif (is.null(unified_db$measures[[measure_name]])) {\n  cli::cli_alert_info(\"{measure_name} not defined yet\")\n} else {\n  print(unified_db$measures[[measure_name]])\n}\n\n# add a new measure --------------------------------------------------------\nunified_db$measures[[measure_name]] <- list(\n  name        = \"Job Satisfaction\",\n  description = \"job satisfaction was measured with a single item.\",\n  reference   = \"[@eisenbarth2022aspects]\",\n  waves       = \"1-present\",\n  keywords    = c(\"employment\", \"mental health\"),\n  items       = list(\"how satisfied are you with your current job?\")\n)\n\nunified_db$measures[[cyberbulling]] <- list( # use the measure name in `colnames(df_nz_long)`\n  # note that cyberbulling is not actually in our simulated dataset \n  # this is just an llustration\n  name        = \"Cyberbulling\",\n  description = \"Cyberbulling was measured with a single item.\",\n  reference   = \"wang2019cyberbullying\",\n  waves       = \"6-11\",\n  keywords    = c(\"mental health\"),\n  items       = list(\"Has someone ever used the internet, a mobile phone, or digital camera to hurt, intimidate or embarrass you?\")\n)\n\n\n# saving a new measure\nunified_db$measures[[\"pwi\"]] <- list(\n  name        = \"Personal Well-Being Index\",\n  description = \"The Personal Well-Being Index consists of three items, asking 'How satisfied are you with...' \",\n  reference   = \"cummins2003development\",\n  waves       = \"1-present\",\n  keywords    = c(\"employment\", \"mental health\"),\n  items       = list(\"'Your standard of living.'\", \"'Your health.'\", \"'Your future security.'\", \"'Your personal relationships.'\")\n)\n\n\n# save with backup ---------------------------------------------------------\nboilerplate_save(\n  unified_db,\n  data_path     = path_final,\n  create_backup = TRUE\n)\ncli::cli_h2(\"new measure added and saved ✔\")\n\n# revise an existing measure ------------------------------------------------\nrevise_name <- \"family_time_binary\"\ncli::cli_h1(\"revising {revise_name}\")\n\n# use modifyList to update only changed fields\nunified_db$measures[[revise_name]] <- modifyList(\n  unified_db$measures[[revise_name]],\n  list(\n    name        = \"Family Time (binary)\",\n    description = \"code string (binary): 0 = none, 1 = any time\",\n    reference   = \"@sibley2020\",\n    waves       = \"10-13\",\n    keywords    = c(\"cooperation\")\n  )\n)\n\n# view revised measure ------------------------------------------------------\nprint(unified_db$measures[[revise_name]])\n\n# save all changes -----------------------------------------------------------\nboilerplate_save(\n  unified_db,\n  data_path = path_final,\n  confirm   = TRUE\n)\ncli::cli_h2(\"measure revised and saved ✔\")\n\n# to reload updated database, uncomment the following line --------------\n# unified_db <- boilerplate_import(data_path = path_final)\n```\n:::\n\n\n::: {.callout-note}\n- remember to type 'y' to save changes\n:::\n\n\nWhen re-running your scripts, the printout should allow you to save to your working database folder. \nWhen saving tick 'y'\n\n```r\n> # save a copy to avoid overwriting original --------------------------------\n> boilerplate_save(\n+   unified_db,\n+   data_path   = path_final,\n+   output_file = \"unified_db\"\n+ )\nℹ preparing to save 6 databases\nℹ processing measures database (1/6)\nℹ no changes detected in measures database\nℹ saving measures database to /Users/joseph/GIT/psych-434-2025/final_boilerplate_data/measures_db.rds\n✔ saved measures database\nℹ processing methods database (2/6)\nℹ 1 new entries will be added:\nℹ   + student_target_population\n! 2 entries will be removed:\n!   - target_population\n!   - sample\nSave methods database with these changes? [y/n]: y\nℹ created backup at: /Users/your_path/final_boilerplate_data/methods_db.rds.20250523_131930.bak\nℹ saving methods database to  /Users/your_path/final_boilerplate_data/methods_db.rds\n✔ saved methods database\nℹ processing results database (3/6)\nℹ no changes detected in results database\nℹ saving results database to  /Users/your_path/final_boilerplate_data/results_db.rds\n✔ saved results database\nℹ processing discussion database (4/6)\nℹ 2 existing entries will be modified:\nℹ   ~ student_authors_statement\nℹ   ~ student_ethics\nSave discussion database with these changes? [y/n]: y\nℹ created backup at: /Users/joseph/GIT/psych-434-2025/final_boilerplate_data/discussion_db.rds.20250523_131933.bak\nℹ saving discussion database to /Users/joseph/GIT/psych-434-2025/final_boilerplate_data/discussion_db.rds\n✔ saved discussion database\nℹ processing appendix database (5/6)\nℹ no changes detected in appendix database\nℹ saving appendix database to /Users/joseph/GIT/psych-434-2025/final_boilerplate_data/appendix_db.rds\n✔ saved appendix database\nℹ processing template database (6/6)\nℹ no changes detected in template database\nℹ saving template database to /Users/joseph/GIT/psych-434-2025/final_boilerplate_data/template_db.rds\n✔ saved template database\n✔ successfully saved all 6 databases\n```\n\n\n\n## Script 3: Setting Up Your Manuscript Document\n\n::: {.callout-note}\n- save this document as a `.qmd` file in a directory called 'quarto' (in your rstudio project)\n- - to render a document click 'Render'\n:::\n\n\n\n\n\n\n::: {.cell}\n\n````{.r .cell-code}\n---\ntitle: \"Your Title\"\nabstract: |\n  **Background**: (Brief few sentences)\n  **Objectives**: \n    1. Estimate the causal effect of YOUR EXPOSURE on YOUR OUTCOMES measured one year later.\n    2. Evaluate whether these effects vary across the population.\n    3. Provide policy guidance on which individuals might benefit most.\n  **Method**: We conducted a three-wave retrospective cohort study (waves XX-XXX, October XXXX--October XXXX) using data from the New Zealand Attitudes and Values Study, a nationally representative panel. Participants were eligible if they participated in the NZAVS in the baseline wave (XXXX, were under the age of 62, and were employed > 20 hours per week. We defined the exposure as (XXXX  > NUMBER on a 1-7 Likert Scale (1 = yes, 0 = no)). To address attrition, we applied inverse probability of censoring weights; to improve external validity, we applied weighted to the population distribution of Age, Ethnicity, and Gender. We computed expected mean outcomes for the population in each exposure condition (high XXXX/low XXXXX). Under standard causal assumptions of unconfoundedness, the contrast provides an unbiased average treatment effect. We then used causal forests to detect heterogeneity in these effects and employed policy tree algorithms to identify individuals (\"strong responders\") likely to experience the greatest benefits.\n  **Results**:   Increasing XXXXX leads to XXXXX. Heterogeneous responses to (e.g. *Forgiveness*, *Personal Well-Being*, and *Life-Satisfaction*...) reveal structural variability in subpopulations...\n  **Implications**: (Brief few sentences)\n  **Keywords**: *Causal Inference*;  *Cross-validation*; *Distress*; *Employment*; *Longitudinal*; *Machine sLearning*; *Religion*; *Semi-parametric*; *Targeted Learning*.\nauthor: \n  - name: YOUR NAME\n    affiliation: Victoria University of Wellington, New Zealand\n    email: XXXXX\n    corresponding: yes\nkeywords: [Causal Inference, Cross-validation,...]\neditor_options: \n  chunk_output_type: console\ndate: \"last-modified\"\nfontfamily: libertinus\nbibliography: references.bib\ncsl: apa7.csl\nformat:\n  docx: # comment this out if you want pdf\n    default: false  # comment this out if you want pdf\n    output-dir: \"quarto\"  # or wherever you want to save it  # comment this out if you want pdf\n  pdf:\n    pdf-engine: lualatex\n    sanitise: true\n    keep-tex: true\n    link-citations: true\n    colorlinks: true\n    documentclass: article\n    classoption: [\"single column\"]\n    lof: false\n    lot: false\n    geometry:\n      - top=30mm\n      - left=25mm\n      - heightrounded\n      - headsep=22pt\n      - headheight=11pt\n      - footskip=33pt\n      - ignorehead\n      - ignorefoot\n    header-includes:\n      - \\let\\oldtabular\\tabular\n      - \\renewcommand{\\tabular}{\\small\\oldtabular}\n      - \\setlength{\\tabcolsep}{4pt}  # adjust this value as needed\nexecute:\n  echo: false\n  warning: false\n  include: true\n  eval: true\n---\n\n```{r}\n#| label: setup\n#| echo: false\n#| include: false\n#| eval: true\n\n# save this file in your project root (e.g. 'quarto/1_setup.R')\n\n# load here to manage paths\ndep <- requireNamespace(\"here\", quietly = TRUE)\nif (!dep) install.packages(\"here\")\nlibrary(here)\n\n# create required folders\ndirs <- c(\n  here(\"quarto\"),\n  here(\"bibliography\"),\n  here(\"save_directory\"),\n  here(\"csl\")\n)\nfor (d in dirs) {\n  if (!dir.exists(d)) dir.create(d, recursive = TRUE)\n}\n\n# ensure tinytex for PDF rendering\nif (!requireNamespace(\"tinytex\", quietly = TRUE)) {\n  install.packages(\"tinytex\")\n  tinytex::install_tinytex()\n}\n\n# ensure pacman for package management\nif (!requireNamespace(\"pacman\", quietly = TRUE)) {\n  install.packages(\"pacman\")\n}\n\n\n# min version of margot\nif (packageVersion(\"margot\") < \"1.0.52\") {\n  stop(\n    \"please install margot >= 1.0.52 for this workflow\\n\n       run: \n       devtools::install_github('go-bayes/margot')\n\"\n  )\n}\n\n# call library\nlibrary(\"margot\")\n\n# check package version\npackageVersion(pkg = \"margot\")\n\n# load (and install if needed) all required packages\npacman::p_load(\n  boilerplate, shiny, tidyverse,\n  kableExtra, glue, patchwork, stringr,\n  ggplot2, ggeffects, parameters,\n  table1, knitr, extrafont, here, cli\n)\n\n# load fonts (requires prior extrafont::font_import())\nif (requireNamespace(\"extrafont\", quietly = TRUE)) {\n  extrafont::loadfonts(device = \"all\")\n} else {\n  message(\"'extrafont' not installed; skipping font loading\")\n}\n\n# reproducibility\nset.seed(123)\n\n# copy CSL and BibTeX into quarto folder\nsrc_files <- list(\n  c(here(\"csl\", \"apa7.csl\"),     here(\"quarto\", \"apa7.csl\")),\n  c(here(\"bibliography\", \"references.bib\"), here(\"quarto\", \"references.bib\"))\n)\nfor (f in src_files) {\n  if (!file.exists(f[2]) && file.exists(f[1])) {\n    file.copy(f[1], f[2])\n  }\n}\n\n# now you're ready to import data and proceed with analysis\n# e.g.\n# unified_db <- boilerplate_import(data_path = here(\"final_boilerplate_data\"))\n# df_grf     <- margot::here_read('df_grf',   here(\"save_directory\"))\n\n# ---- define paths and import data ----------------------------------------\npush_mods             <- here::here(\"save_directory\")\nfinal_boilerplate_data <- here::here(\"final_boilerplate_data\")\nunified_db            <- boilerplate_import(data_path = final_boilerplate_data)\n\n# check paths\n# ---- inspect available boilerplate entries -------------------------------\ncat(unified_db$methods$confounding_control$vanderweele)\ncat(unified_db$methods$sample$nzavs)\ncat(unified_db$methods$causal_intervention$grf_simple_text)\ncat(unified_db$appendix$explain$grf_short)\n\n# ---- read variable definitions -------------------------------------------\nbaseline_vars           <- margot::here_read(\"baseline_vars\")\nexposure_var            <- margot::here_read(\"exposure_var\")\noutcome_vars            <- margot::here_read(\"outcome_vars\")\n\n# ---- define study waves --------------------------------------------------\nbaseline_wave           <- margot::here_read(\"baseline_wave\")\nexposure_waves          <- margot::here_read(\"exposure_waves\")\noutcome_wave            <- margot::here_read(\"outcome_wave\")\n\n# \nbaseline_wave_glued <- glue::glue(baseline_wave)\n\n# ---- define study parameters ---------------------------------------------\nstudy_years             <- \"2018-2021\"\nname_exposure           <- here_read(\"name_exposure\")\nname_outcome_variables  <- \"MY OUTCOME VARIABLES IN THIS STUDY\"\nname_exposure_lower     <- tolower(name_exposure)\nname_exposure_lower\n\n# ---- templates and thresholds --------------------------------------------\neligibility_template    <- \"Participants were eligible if they participated in the {baseline wave}\"\npercent_missing_baseline <- margot::here_read(\"percent_missing_baseline\")\n\n# ---- read tables for manuscript ------------------------------------------\nmarkdown_table_baseline  <- margot::here_read(\"baseline_table\")\nmarkdown_table_exposures <- margot::here_read(\"exposure_table\")\nmarkdown_table_outcomes  <- margot::here_read(\"outcomes_table\")\nmargot_bind_tables_markdown <- margot::here_read(\"margot_bind_tables_markdown\")\n# ---- sample size information --------------------------------------------\nn_total                  <- margot::here_read(\"n_total\")\nn_participants           <- here_read(\"n_participants\")\n\n# ---- variable labels and mappings ----------------------------------------\nvar_labels_measures      <- here_read(\"var_labels_measures\")\nlabel_mapping_all        <- here_read(\"label_mapping_all\")\n\n# ---- plot titles and analysis settings -----------------------------------\nate_title                <- here_read(\"ate_title\")\nflipped_names            <- here_read(\"flipped_names\")\nflip_outcomes            <- here_read(\"flip_outcomes\")\nflipped_list             <- paste(flipped_names, collapse = \", \")\n\n# ---- import data for visualisation --------------------------------------\noriginal_df              <- margot::here_read('df_wide', push_mods)\ndf_grf <- margot::here_read('df_grf', push_mods)\n\n# co-variates\nE <- margot::here_read('E', push_mods)\n# select covariates and drop numeric attributes\nX <- margot::remove_numeric_attributes(df_grf[E])\n\n\n# ---- define nice names and regimes ---------------------------------------\nnice_name_exposure_variable <- stringr::str_to_sentence(name_exposure)\nname_outcomes_lower          <- \"multi-dimensional wellbeing\"\n\n# ---- define exposure thresholds and regimes ------------------------------\nlower_cut               <- here_read(\"lower_cut\")\nupper_cut               <- here_read(\"upper_cut\")\nthreshold               <- here_read(\"threshold\")\ninverse_threshold       <- here_read(\"inverse_threshold\")\nscale_range             <- margot::here_read(\"scale_range\")\n\n# create and check variables\nvalue_exposure = glue::glue( threshold,\"\", upper_cut,\", \", scale_range)\nvalue_control = glue::glue(inverse_threshold, upper_cut,\", \", scale_range)\n\n# regimes\nname_control_regime_lower <- glue::glue(\"low {name_exposure_lower}\")\nvalue_exposure_regime     <- glue::glue(\"Set {name_exposure} {threshold} {upper_cut} {scale_range}\")\nvalue_control_regime      <- glue::glue(\"Set {name_exposure} {inverse_threshold} {upper_cut} {scale_range}\")\n\n\ncontrast_template         <- \"We used causal forests to estimate an average treatment effect as a contrast between *{name_control_regime_lower}* and *{name_exposure_lower}* on {name_outcomes_lower}.\"\ncontrast_text             <- glue(contrast_template)\n\n#chedk\ncontrast_text\n# ---- verify assumptions (positivity) -------------------------------------\ntransition_tables        <- margot::here_read(\"transition_tables\")\ntransition_tables_binary <- here_read(\"transition_tables_binary\")\n\nbaseline_vars\n# ---- generate measures text for methods section -------------------------\nbaseline_measures_text   <- boilerplate_generate_measures(\n  variable_heading = \"Baseline Covariates\",\n  variables        = baseline_vars,\n  db               = unified_db,\n  heading_level    = 3,\n  subheading_level = 4,\n  print_waves      = FALSE,\n  label_mappings   = var_labels_measures\n)\ncat(baseline_measures_text)\nexposure_measures_text   <- boilerplate_generate_measures(\n  variable_heading = \"Exposure Variable\",\n  variables        = name_exposure,\n  db               = unified_db,\n  heading_level    = 3,\n  subheading_level = 4,\n  print_waves      = FALSE,\n  label_mappings   = var_labels_measures\n)\noutcome_measures_text    <- boilerplate_generate_measures(\n  variable_heading = \"Outcome Variables\",\n  variables        = outcome_vars,\n  db               = unified_db,\n  heading_level    = 3,\n  subheading_level = 4,\n  print_waves      = FALSE,\n  label_mappings   = var_labels_measures\n)\n\n# ---- exposure description from database --------------------------------\nmeasures_exposure        <- glue::glue(unified_db$measures[[name_exposure]]$description)\n\n\n# ---- set plot defaults for ate plots -------------------------------------\nbase_defaults_binary     <- list(\n  type                   = \"RD\",\n  title                  = ate_title,\n  e_val_bound_threshold  = 1.2,\n  colors                 = c(\n    \"positive\"    = \"#E69F00\",\n    \"not reliable\"= \"grey50\",\n    \"negative\"    = \"#56B4E9\"\n  ),\n  x_offset               = -0.25,\n  x_lim_lo               = -0.25,\n  x_lim_hi               = 0.25,\n  text_size              = 5,\n  linewidth              = 0.75,\n  estimate_scale         = 1,\n  base_size              = 20, #<- change to make outcome labels bigger or smaller\n  point_size             = 4,\n  title_size             = 24,\n  subtitle_size          = 16,\n  legend_text_size       = 10,\n  legend_title_size      = 10,\n  include_coefficients   = FALSE\n)\n\n# ---- create plot options for outcomes -----------------------------------\noutcomes_options_all     <- margot_plot_create_options(\n  title         = ate_title,\n  base_defaults = base_defaults_binary,\n  subtitle      = \"\",\n  filename_prefix = \"grf\"\n)\n\n# ---- policy tree graph settings -----------------------------------------\ndecision_tree_defaults  <- list(\n  span_ratio         = 0.3,\n  text_size          = 3.8,\n  y_padding          = 0.25,\n  edge_label_offset  = 0.002,\n  border_size        = 0.05\n)\n\npolicy_tree_defaults    <- list(\n  point_alpha            = 0.5,\n  title_size             = 12,\n  subtitle_size          = 12,\n  axis_title_size        = 12,\n  legend_title_size      = 12,\n  split_line_color       = \"red\",\n  split_line_alpha       = 0.8,\n  split_label_color      = \"red\",\n  split_label_nudge_factor = 0.007\n)\n\n\n\n\n# ---- load and check model results ---------------------------------------\n# takes more time but allows you to flexibly modify plots in the quarto document\n# if you use the option comment out this code above\n\n# takes less time if you used the pre-processed results but a little harder to adjust\n# ate_results           <- margot::here_read_qs(\"ate_results\", push_mods)\n# margot::margot_size(ate_results)\n\nmodels_binary <- margot::here_read_qs(\"models_binary\", push_mods)\n\n# make ate plots ----------------------------------------------------------\n#   ************* NEW - CORRECTION FOR FAMILY-WISE ERROR **********\n# then pass to the results\nate_results <- margot_plot(\n  models_binary$combined_table, # <- now pass the corrected results.\n  options = outcomes_options_all,\n  label_mapping = label_mapping_all,\n  include_coefficients = FALSE,\n  save_output = FALSE,\n  order = \"evaluebound_asc\",\n  original_df = original_df,\n  e_val_bound_threshold = 1.2,\n  rename_ate = TRUE,\n  adjust = \"bonferroni\", #<- new \n  alpha = 0.05 # <- new \n)\n\n# check\nate_results$plot\n\n# view\ncat(ate_results$interpretation)\n\n# ---- heterogeneity analysis ---------------------------------------------\nmodels_binary_flipped_all <- here_read_qs(\"models_binary_flipped_all\", push_mods)\n\n# this is a new function requires margot 1.0.48 or higher\n# only useful if you flip labels outcomes -- if so replace \"label_mapping_all\" \n# with \"label_mapping_all_flipped\" \nlabel_mapping_all_flipped <- margot_reversed_labels(label_mapping_all, \n                                                    flip_outcomes)\n\n# optional\n# could be used in an appendix\n# result_ominbus_hetero     <- margot_omnibus_hetero_test(\n#   models_binary_flipped_all,\n#   label_mapping  = label_mapping_all_flipped,\n#   alpha          = 0.05,\n#   detail_level   = \"standard\",\n#   format         = \"markdown\"\n# )\n# result_ominbus_hetero$summary_table |> kbl(\"markdown\")\n# cat(result_ominbus_hetero$brief_interpretation)\n\n# ──────────────────────────────────────────────────────────────────────────────\n# SCRIPT:  HETEROGENEITY WORKFLOW\n# PURPOSE: screen outcomes for heterogeneity, plot RATE & Qini curves,\n#          fit shallow policy trees, and produce plain-language summaries.\n# REQUIREMENTS:\n#   • margot ≥ 1.0.52\n#   • models_binary_flipped_all        – list returned by margot_causal_forest()\n#   • original_df                      – raw data frame used in the forest\n#   • label_mapping_all_flipped        – named vector of pretty labels\n#   • flipped_names                    – vector of outcomes that were flipped\n#   • decision_tree_defaults           – list of control parameters\n#   • policy_tree_defaults             – list of control parameters\n#   • push_mods                        – sub-folder for caches/outputs\n#   • use 'models_binary', `label_mapping_all`, and set `flipped_names = \"\"` if no outcome flipped\n# ──────────────────────────────────────────────────────────────────────────────\n\n# check package version early\nstopifnot(utils::packageVersion(\"margot\") >= \"1.0.52\")\n\n# helper: quick kable printer --------------------------------------------------\nprint_rate <- function(tbl) {\n  tbl |>\n    mutate(across(where(is.numeric), \\(x) round(x, 2))) |>\n    kbl(format = \"markdown\")\n}\n\n# 1  SCREEN FOR HETEROGENEITY (RATE AUTOC + RATE Qini)  ----------------------\n\nrate_results <- margot_rate(\n  models        = models_binary_flipped_all,\n  policy        = \"treat_best\",\n  alpha         = 0.20,        # keep raw p < .20\n  adjust        = \"fdr\",       # false-discovery-rate correction\n  label_mapping = label_mapping_all_flipped\n)\n\nprint_rate(rate_results$rate_autoc)\nprint_rate(rate_results$rate_qini)\n# convert RATE numbers into plain-language text\nrate_interp <- margot_interpret_rate(\n  rate_results,\n  flipped_outcomes      = flipped_names,\n  adjust_positives_only = TRUE\n)\n\ncat(rate_interp$comparison, \"\\n\")\ncli_h2(\"Analysis ready for Appendix ✔\")\n\n# organise model names by evidence strength\nmodel_groups <- list(\n  autoc       = rate_interp$autoc_model_names,\n  qini        = rate_interp$qini_model_names,\n  either      = rate_interp$either_model_names,\n  exploratory = rate_interp$not_excluded_either\n)\n\n# 2  PLOT RATE AUTOC CURVES ---------------------------------------------------\n\nautoc_plots <- margot_plot_rate_batch(\n  models        = models_binary_flipped_all,\n  save_plots    = FALSE,  # set TRUE to store .png files\n  label_mapping = label_mapping_all_flipped,\n  model_names   = model_groups$autoc\n)\n\n# inspect the first curve - note there may be more/none.\n# if none, comment out\nautoc_plots[[1]]\nautoc_name_1 <- rate_results$rate_autoc$outcome[[1]]\n\n# 3  QINI CURVES + GAIN INTERPRETATION ---------------------------------------\nqini_results <- margot_policy(\n  models_binary_flipped_all,\n  save_plots         = FALSE,\n  output_dir         = here::here(push_mods),\n  decision_tree_args = decision_tree_args,\n  policy_tree_args   = policy_tree_args,\n  model_names        = names(models_binary_flipped_all$results),\n  original_df        = original_df,\n  label_mapping      = label_mapping_all_flipped,\n  max_depth          = 2L,\n  output_objects     = c(\"qini_plot\", \"diff_gain_summaries\")\n)\n\nqini_gain <- margot_interpret_qini(\n  qini_results,\n  label_mapping = label_mapping_all_flipped\n)\n\nprint_rate(qini_gain$summary_table)\ncat(qini_gain$qini_explanation, \"\\n\")\n\nreliable_ids <- qini_gain$reliable_model_ids\n\n# (re-)compute plots only for models that passed Qini reliability\nqini_results_valid <- margot_policy(\n  models_binary_flipped_all,\n  save_plots         = FALSE,\n  output_dir         = here::here(push_mods),\n  decision_tree_args = decision_tree_args,\n  policy_tree_args   = policy_tree_args,\n  model_names        = reliable_ids,\n  original_df        = original_df,\n  label_mapping      = label_mapping_all_flipped,\n  max_depth          = 2L,\n  output_objects     = c(\"qini_plot\", \"diff_gain_summaries\")\n)\n\nqini_plots <- map(qini_results_valid, ~ .x$qini_plot)\n\n# grab pretty outcome names\nqini_names <- margot_get_labels(reliable_ids, label_mapping_all_flipped)\n\ncli_h1(\"Qini curves generated ✔\")\n\n# 4  POLICY TREES (max depth = 2) -------------------------------------------\n\npolicy_results_2L <- margot_policy(\n  models_binary_flipped_all,\n  save_plots         = FALSE,\n  output_dir         = here::here(push_mods),\n  decision_tree_args = decision_tree_defaults,\n  policy_tree_args   = policy_tree_defaults,\n  model_names        = reliable_ids,      # only those passing Qini\n  max_depth          = 2L,\n  original_df        = original_df,\n  label_mapping      = label_mapping_all_flipped,\n  output_objects     = c(\"combined_plot\")\n)\n\npolicy_plots <- map(policy_results_2L, ~ .x$combined_plot)\n\n# ️5  PLAIN-LANGUAGE INTERPRETATION OF TREES ----------------------------------\n\npolicy_text <- margot_interpret_policy_batch(\n  models            = models_binary_flipped_all,\n  original_df       = original_df,\n  model_names       = reliable_ids,\n  label_mapping     = label_mapping_all_flipped,\n  max_depth         = 2L\n)\n\ncat(policy_text, \"\\n\")\n\ncli::cli_h1(\"Finished: depth-2 policy trees analysed ✔\")\n\n# ───────────────────────────── EOF ────────────────────────────────────────────\n\n# names of valid models\nglued_policy_names_1 <- qini_names[[1]]\nglued_policy_names_2 <- qini_names[[2]]\nglued_policy_names_3 <- qini_names[[3]]\nglued_policy_names_4 <- qini_names[[4]]\nglued_policy_names_5 <- qini_names[[5]]\nglued_policy_names_6 <- qini_names[[6]]\nglued_policy_names_7 <- qini_names[[7]]\n\n\n# cli::cli_h1(\"Names of Reliable HTE Models Set\")\n\n# GROUP COMPARISON EXAMPLE ------------------------------------------------\n# play around with these values\nx_offset_comp <- 1.0\nx_lim_lo_comp <- -1.0\nx_lim_hi_comp <- 1.0 \n\nbase_defaults_comparisons <- list(\n  type = \"RD\",\n  title = ate_title,\n  e_val_bound_threshold = 1.2,\n  label_mapping = \"label_mapping_all\",\n  adjust = \"bonferroni\", #<- new\n  alpha = 0.05, # <- new\n  colors = c(\n    \"positive\" = \"#E69F00\",\n    \"not reliable\" = \"grey50\",\n    \"negative\" = \"#56B4E9\"\n  ),\n  x_offset = x_offset_comp,\n  # will be set based on type\n  x_lim_lo = x_lim_lo_comp,\n  # will be set based on type\n  x_lim_hi = x_lim_hi_comp,\n  text_size = 8,\n  linewidth = 0.75,\n  estimate_scale = 1,\n  base_size = 18,\n  point_size = 2.5,\n  title_size = 19,\n  subtitle_size = 16,\n  legend_text_size = 10,\n  legend_title_size = 10,\n  include_coefficients = FALSE\n)\n\n# see\ncomplex_condition_age  <- between(X[,\"t0_age_z\"], -1, 1)\n\n# sanity‑check age bounds on the raw scale\nmean(original_df$t0_age) + c(-1, 1) * sd(original_df$t0_age)\n\n# age subsets\nsubsets_standard_age <- list(\n  Younger = list(\n    var = \"t0_age_z\",\n    value = -1,\n    operator = \"<\",\n    label = \"Age < 35\"\n  ),\n  Middle = list(\n    var = \"t0_age_z\",\n    # operator = \"<\",\n    subset_condition = complex_condition_age,\n    label = \"Age 35-62\"\n  ),\n  Older = list(\n    var = \"t0_age_z\",\n    value = 1,\n    operator = \">\",\n    label = \"Age > 62\"\n  )\n)\n\n# 3. batch subgroup analysis -----------------------------------------\nplanned_subset_results <- margot_planned_subgroups_batch(\n  domain_models  = list(models_binary),\n  X              = X,\n  base_defaults  = base_defaults_comparisons,\n  subset_types   = list(cohort = subsets_standard_age),\n  original_df    = original_df,\n  label_mapping  = label_mapping_all,          # ← supply it here\n  domain_names   = \"wellbeing\",\n  subtitles      = \"\",\n  adjust         = \"bonferroni\",  # ← here\n  alpha          = 0.05           # ← and here\n)\n\n# make comparison plot\nplots_subgroup_age_young_old<- wrap_plots(\n  list(\n    planned_subset_results$wellbeing$cohort$results$`Age < 35`$plot,\n    planned_subset_results$wellbeing$cohort$results$`Age > 62`$plot\n  ), ncol = 1) +\n  plot_annotation(\n    title = \"Younger vs Older\",\n    theme = theme(plot.title = element_text(size = 18, face = \"bold\"))\n  )\n\n\n\n# are groups different from each other? \n# example: young (<35) vs older (>62)\ngroup_comparison_age_young_old <- margot_compare_groups(\n  group1_name = \"People Under 35 Years Old\",\n  group2_name = \"People Over 62 Years Old\", \n  planned_subset_results$wellbeing$cohort$results$`Age < 35`$transformed_table, # reference\n  planned_subset_results$wellbeing$cohort$results$`Age > 62`$transformed_table, # comparison\n  type            = \"RD\",          # risk‑difference scale\n  decimal_places  = 3\n)\nprint(group_comparison_age_young_old$results |> kbl(\"markdown\", digits = 3))\ncat(group_comparison_age_young_old$interpretation)\n\n\n# ---- define global variables for text generation ------------------------\nglobal_vars <- list(\n  name_exposure_variable     = nice_name_exposure_variable,\n  n_total                    = n_total,\n  ate_adjustment             = \"bonferroni\", \n  ate_alpha                  = \"0.05\",\n  cate_adjustment            = \"Benjamini–Hochberg false-discovery-rate adjustment\",\n  cate_alpha                 =  \"0.1\",             \n  sample_ratio_policy        =  \"70/30\",\n  n_participants             = n_participants,\n  exposure_variable          = name_exposure,\n  name_exposure_lower        = name_exposure_lower,\n  name_control_regime_lower  = name_control_regime_lower,\n  name_outcome_variables     = \"Self Esteem\", # <- adjust to your study, your decision\n  name_outcomes_lower        = name_outcomes_lower,\n  name_exposure_capfirst     = nice_name_exposure_variable,\n  measures_exposure          = measures_exposure,\n  value_exposure_regime      = value_exposure_regime,\n  value_control_regime       = value_control_regime,\n  flipped_list               = flipped_list, # set flipped_list = \"\" if nothing flipped\n  appendix_explain_grf       = \"E\",\n  appendix_assumptions_grf   = \"F\",\n  name_exposure_threshold    =  \"1\",\n  name_control_threshold     =  \"0\",\n  appendix_measures          =  \"A\",\n  value_control              = value_control,     # ← named\n  value_exposure             = value_exposure,    # ← named\n  appendix_positivity        = \"C\",\n  appendix_rate              = \"D\",\n  appendix_qini_curve        = \"D\",\n  train_proportion_decision_tree = \".7\",\n  traning_proportion         = \".7\",\n  sample_split              = \"70/30\",\n  sample_ratio_policy        = \"70/30\",\n  baseline_wave              = baseline_wave,\n  exposure_waves             = exposure_waves,\n  outcome_wave               = outcome_wave,\n  protocol_url               = \"https://osf.io/ce4t9/\", # if used\n  appendix_timeline          = \"A\" # if used\n)\n```\n\n{{< pagebreak >}}\n\n## Introduction\n\n**Your place to shine here**\n\n## Method\n\n```{r, results='asis'}\n#| eval: true # |eval: false # <- set to false as needed/desired for your own material\n#| echo: false\nlibrary(boilerplate)\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"methods\",      # ← choose the right top-level list\n    sections     = c(\n      \"student_sample.nzavs\",\n      \"student_target_population\",\n      \"eligibility.standard\",\n      \"causal_intervention.grf_simple_text\",\n      \"analytic_approach.general_approach_cate_long\", # <- new\n      \"exposure_indicator\",\n      \"causal_identification_criteria\",\n      \"confounding_control.vanderweele\",\n      \"statistical_models.grf_short_explanation\",\n      \"missing_data.missing_grf_simple\",\n      \"sensitivity_analysis.short_evalue\"\n    ),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n{{< pagebreak >}}\n\n## Results\n\n### Average Treatement Effects\n\n```{r}\n#| label: fig-ate\n#| fig-cap: \"Average Treatment Effects on Multi-dimensional Wellbeing\"\n#| eval: true # |eval: false # <- set to false as needed/desired for your own material\n#| fig-height: 14\n#| fig-width: 18\nate_results$plot\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: tbl-outcomes\n#| tbl-cap: \"Average Treatment Effects on Multi-dimensional Wellbeing\"\n#| eval: true # |eval: false # <- set to false as needed/desired for your own material\n\n# ate_results$transformed_table|> kbl(\"markdown\")\nmargot_bind_tables_markdown\n```\n\n```{r, results = 'asis'}\n#| eval: true # |eval: false # <- set to false as needed/desired for your own material\n\ncat(ate_results$interpretation)\n```\n\n\n{{< pagebreak >}}\n\n### Heterogeneous Treatment Effects\n\n#### Qini Curves: (How Much Do We Gain By Treating Using $\\tau{x}$ At Different Budgets?) {#results-qini-curve}\n\n```{r, results='asis'}\n#| eval: true  # <- set to false: copy and paste your own text using this material\n\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"results\",      # ← choose the right top-level list\n    sections     = c(\n    \"grf.interpretation_qini\"\n    ),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n```{r, results = 'asis'}\n# only reliable results\ncat(qini_gain$qini_explanation) \n```\n\n@tbl-qini presents results for our Qini curve analysis at different spend rates.\n\n```{r}\n#| label: tbl-qini\n#| tbl-cap: \"Qini Curve Results\"\n#| eval: true  # <- set to false: copy and paste your own text using this material\n\n# table (only use if more than one qini gain interpretation)\nqini_gain$summary_table |> \n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\") #<-- only if you have this, otherwise delete this code\n```\n\n@fig-qini-1 presents results for reliable Qini results\n\n```{r}\n#| label: fig-qini-1\n#| fig-cap: \"Qini Graphs\"\n#| eval: true # <- set to false as needed/desired\n#| echo: false\n#| fig-height: 18\n#| fig-width: 12\n\nlibrary(patchwork)\n# combine first column of plots (4,6,7,8) and second column (9,11,12)\n# these showed reliable qini results\n\ncombined_qini <- (\n  qini_plots[[1]] /\n  qini_plots[[2]] /\n  qini_plots[[3]] /\n  qini_plots[[4]]\n) | (\n  # remove this block if you don't have plots 9,11,12\n  qini_plots[[5]] /\n  qini_plots[[6]] /\n  qini_plots[[7]]\n) +\n  # collect all legends into one shared guide\n  plot_layout(guides = \"collect\") +\n  # add title (and optionally subtitle)\n  plot_annotation(\n    title    = \"Combined Qini Plots\",\n    subtitle = \"Panels arranged with shared legend\"\n  ) &\n  # apply theme modifications to all subplots\n  theme(\n    legend.position   = \"bottom\",           # place legend below\n    plot.title        = element_text(hjust = 0.5),  # centre title\n    plot.subtitle     = element_text(hjust = 0.5)   # centre subtitle\n  )\n\n# draw it\nprint(combined_qini)\n\n```\n\n\n#### Decision Rules (Who is Most Sensitive to Treatment?)\n\n```{r, results='asis'}\n#| eval: true  # <- set to false: copy and paste your own text using this material\n\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"results\",      # ← choose the right top-level list\n    sections     = c(\n    \"grf.interpretation_policy_tree\"\n    ),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-1\n#| fig-cap: \"Decision Tree: {glued_policy_names_1}\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 9\n# plot 1\npolicy_plots[[1]]\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-2\n#| fig-cap: \"Decision Tree: {glued_policy_names_2}\"\n#| eval: true\n#| fig-height: 16\n#| fig-width: 9\n\npolicy_plots[[2]]\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-3\n#| fig-cap: \"Decision Tree: {glued_policy_names_3}\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 9\n\npolicy_plots[[3]]\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-4\n#| fig-cap: \"Decision Tree: {glued_policy_names_4}\"\n#| eval: true\n#| fig-height: 16\n#| fig-width: 9\n\npolicy_plots[[4]]\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-5\n#| fig-cap: \"Decision Tree: {glued_policy_names_5}\"\n#| eval: true\n#| fig-height: 16\n#| fig-width: 9\n\npolicy_plots[[5]]\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-6\n#| fig-cap: \"Decision Tree: {glued_policy_names_6}\"\n#| eval: true\n#| fig-height: 16\n#| fig-width: 9\n\npolicy_plots[[6]]\n\n```\n\n{{< pagebreak >}}\n\n```{r}\n#| label: fig-policy-7\n#| fig-cap: \"Decision Tree: {glued_policy_names_7}\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 9\npolicy_plots[[7]]\n```\n\n{{< pagebreak >}}\n\n```{r, results = 'asis'}\n#| eval: true # <- set to false if you want to copy and paste your own text\ncat(policy_text, \"\\n\")\n```\n\n{{< pagebreak >}} \n\n## Planned Subgroup Comparisons (Optional)\n\nBased on theoretical findings we expected that the effects of {name_exposure} would vary by age...\\@fig-planned-comparison and @tbl-planned-comparison\n\n```{r}\n#| label: fig-planned-comparison\n#| fig-cap: \"Planned Comparison Plot\"\n#| eval: true\n#| echo: false\n#| fig-height: 16\n#| fig-width: 9\nplots_subgroup_age_young_old\n```\n\n```{r}\n#| label: tbl-planned-comparison\n#| tbl-cap: \"Planned Comparison Table\"\n#| eval: true  # <- set to false: copy and paste your own text using this material\n#| echo: false\n# table (only use if more than one qini gain interpretation)\ngroup_comparison_age_young_old$results |> \n  mutate(across(where(is.numeric), ~ round(., 2))) %>%\n  kbl(format = \"markdown\")\n\n```\n\n```{r, results = 'asis'}\n#| eval: true # <- set to false if you want to copy and paste your own text\ncat(group_comparison_age_young_old$interpretation)\n```\n\n{{< pagebreak >}}\n\n## Discussion\n\n```{r,  results='asis'}\n#| eval: false  # <- set to false: copy and paste your own text using this material\n#| echo: false\ncat(boilerplate_generate_text(\n  category = \"discussion\",\n  sections = c(\n    \"student_ethics\",\n    \"student_data\",\n    \"student_authors_statement\"  ),\n  global_vars = list(\n    exposure_variable = name_exposure\n  ),\n  db = unified_db\n))\nunified_db$discussion$student_authors_statement\n```\n\n{{< pagebreak >}}\n\n## Appendix A: Measures {#appendix-measures}\n\n### Measures\n\n#### Baseline Covariate Measures\n\n```{r, results='asis'}\ncat(baseline_measures_text)\n```\n\n#### Exposure Measures\n\n```{r, results='asis'}\ncat(exposure_measures_text)\n```\n\n#### Outcome Measures\n\n```{r, results='asis'}\ncat(outcome_measures_text)\n```\n\n{{< pagebreak >}}\n\n## Appendix B: Sample Characteristics {#appendix-sample}\n\n#### Sample Statistics: Baseline Covariates\n\n@tbl-appendix-baseline presents sample demographic statistics.\n\n::: {#tbl-appendix-baseline}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\nmarkdown_table_baseline\n```\n\nDemographic statistics for New Zealand Attitudes and Values Cohort: {baseline_wave_glued}.\n:::\n\n### Sample Statistics: Exposure Variable {#appendix-exposure}\n\n<!-- @tbl-sample-exposures presents sample statistics for the exposure variable, religious service attendance, during the baseline and exposure waves. This variable was not measured in part of NZAVS time 12 (years 2020-2021) and part of NZAVS time 13 (years 2021-2022). To address missingness, if a value was observed after NZAVS time 14, we carried the previous observation forward and created and NA indicator. If there was no future observation, the participant was treated as censored, and inverse probability of censoring weights were applied, following our standard method for handling missing observations (see mansucript **Method**/**Handling of Missing Data**). Here, our carry-forward imputation approach may result in conservative causal effect estimation because it introduces measurement error. However, this approach would not generally bias causal effect estimation away from the null because the measurement error is unsystematic and random and unrelated to the outcomes. -->\n\n::: {#tbl-appendix-exposures}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\nmarkdown_table_exposures\n\n```\n\nDemographic statistics for New Zealand Attitudes and Values Cohort waves 2018.\n:::\n\n{{< pagebreak >}}\n\n### Sample Statistics: Outcome Variables {#appendix-outcomes}\n\n::: {#tbl-appendix-outcomes}\n```{r, results = 'asis'}\n#| eval: true\n#| include: true\n#| echo: false\n\nmarkdown_table_outcomes\n\n```\n\nOutcome variables measured at {baseline_wave_glued} and {outcome_wave}\n:::\n\n{{< pagebreak >}}\n\n## Appendix C: Transition Matrix to Check The Positivity Assumption {#appendix-transition}\n\n```{r, results = 'asis'}\n#| label: tbl-transition\n#| tbl-cap: \"Transition Matrix Showing Change\"\n#| eval: true\n#| include: true\n#| echo: false\n\ntransition_tables_binary$tables[[1]]\n```\n\n```{r, results = 'asis'}\ncat(transition_tables_binary$explanation)\n```\n\n{{< pagebreak >}}\n\n## Appendix D: RATE AUTOC and RATE Qini {#appendix-rate}\n\n```{r, results='asis'}\n#| eval: true # <- set to false as needed/desired\n#| echo: false\n\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"results\",\n    # ← choose the right top-level list\n    sections     = c(\"grf.interpretation_rate\"),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n```{r, results='asis'}\n#| eval: true # <- set to false as needed/desired\n#| echo: false\ncat(rate_interp$comparison)\n```\n\nRefer to [Appendix D](#appendix-cate-validation) for details.\n\n##### RATE AUTOC RESULTS\n\n```{r, results = 'asis'}\n# only reliable results\ncat(rate_interp$autoc_results)\n```\n\n```{r}\n#| label: fig-rate-1\n#| fig-cap: \"RATE AUTOC Graphs\"\n#| eval: true  # <- set to false as needed/desired\n#| echo: false\n#| fig-height: 12\n#| fig-width: 8\nautoc_plots[[1]]\n```\n\n@fig-rate-1 presents the RATE AUTOC curve for `r autoc_name_1`\n\n{{< pagebreak >}}\n\n## Appendix E: Approach to Heterogeneous Treatment Effects {#appendix-cate-validation}\n\n```{r, results='asis'}\n#| eval: true\n#| echo: false\nlibrary(boilerplate)\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"appendix\",\n    # ← choose the right top-level list\n    sections     = c(\"explain.grf_short\"),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n{{< pagebreak >}}\n\n## Appendix F: Strengths and Limitations of Causal Forests  {#appendix-rate}\n\n```{r, results='asis'}\n#| eval: true # <- set to false as needed/desired\n\ncat(\n  boilerplate::boilerplate_generate_text(\n    category     = \"discussion\",\n    # ← choose the right top-level list\n    sections     = c(\"strengths.strengths_grf_short\"),\n    global_vars  = global_vars,\n    db           = unified_db\n  )\n)\n```\n\n## References {.appendix-refs}\n````\n:::\n\n\n#### Pro Tip\n\nYou can adjust figure by changing:\n\n`#| fig-height: 16` and `#| fig-width: 9`\n\n\n```r\n#| label: fig-policy-6\n#| fig-cap: \"Decision Tree: {glued_policy_names_6}\"\n#| eval: true\n#| fig-height: 16 # <- change here\n#| fig-width: 9 # <- change here\n\npolicy_plots[[6]]\n\n```\n\n\n\n## What You Have Learned \n\n- **How to create a publication quality manuscript** \n\n- **How to create a workflow for references** \n\n- **How to import results into your manuscript** \n\n- **How to make graphs of your results (using) `margot`** \n\n- **How to report your results**\n\n- **How to interpret your results**\n\n## Frequently Asked Questions\n\n### Do I need to use `quarto` for making my report?\n\nNo. The suggested workflow should make your life *easier*. If, after a fair trial -- *and* after asking us for help -- `quarto` still feels like extra friction, switch to whatever you like (`rmarkdown`, plain `R` scripts, or even Word). The science matters more than the wrapper. \n\n👉 Quick-start: <https://quarto.org/docs/get-started/>\n\n---\n\n### I cannot save or retrieve files from folders\n\nWhen hunting path errors, ask yourself:\n\n- **Packages** – have I updated everything, especially **`margot`** and **`here`**?  \n- **Clean slate** – did I restart R (⌘⇧F10) *and* rerun the data-prep scripts from the top?  \n- **Project root** – am I inside the correct **RStudio Project**? Check with `here::here()`.  \n- **Search** – have I used *Edit → Find in Files* (⌘⇧F / Ctrl⇧F) to locate the object or path?  \n- **Data really there?** – do the objects exist in my data frame?\n\n```r\n# waves where `variable_name` was measured\nwith(df_nz_long, table(variable_name, wave))\n```\n\n- **Permissions / cloud sync** – is the save folder writable *and* local? Dropbox/OneDrive may off-load files; right-click and choose *Make available offline*.\n\n---\n\n### I cannot run `margot_causal_forest_parallel()`\n\n- **Fallback** – does `margot_causal_forest()` work? It is slower but prints progress.  \n- **Formula richness** – causal forests need many covariates [@grf2024]. Include the full demographic block.  \n- **Resources** – parallel forests spawn one worker per core. Keep some RAM free.  \n- **Reduce load** – try fewer trees or a smaller variable pool:\n\n```r\ngrf_defaults <- list(\n  seed             = 123,\n  stabilize.splits = TRUE,\n  num.trees        = 1000,  # fewer trees\n  top_n_vars       = 10     # smaller policy-tree search space\n)\n```\n\n---\n\n### I cannot run `margot_flip_forests_parallel()`\n\nFirst test the serial version `margot_flip_forests()`. All parallel caveats above apply.\n\n---\n\n### My R code is not working\n\n- Update packages (`pak::pak()` is handy).  \n- Re-download the example code and run from the top.  \n- Read the full error and traceback (`rlang::last_trace()`).  \n- Compare with the example: what is different in *your* data or model?\n\n---\n\n### I do not know how `margot` functions work\n\nSee the indexed reference: <https://go-bayes.github.io/margot/reference/index.html>\n\n---\n\n### What is the recommended workflow for investigating heterogeneity?\n\n1. **State your causal question.** Statistics cannot rescue an ill-posed question.  \n2. Estimate the **ATE** for the target population.  \n3. Compute **CATEs** and evaluate gain at 20 % and 50 % budget constraints with the **Qini** metric.  \n4. For outcomes with convincing heterogeneity, fit shallow **policy trees** (depth = 2) to obtain transparent rules.  \n5. Optionally, compare pre-specified subgroups directly.  \n6. Report **RATE–AUTOC** and **RATE–Qini** tables in an online supplement.  \n\n*Take-away:* start from a clean, updated project, read errors carefully, and ensure each step answers *your* research question.\n\n---\n\n### I cannot create a `quarto` document\n\n- Save the file with a `.qmd` suffix **inside** the `quarto` folder.  \n- Ensure the boiler-plate directory structure exists (run Script 0 and Script 1).  \n- Run the initial code block line-by-line before hitting **Render**.  \n- Define all `global_vars` required by the boiler-plate.  \n- If you are *not* flipping outcomes, stub the flip variables:\n\n```r\nflipped_names <- \"\"\nflip_outcomes <- \"\"\nflipped_list  <- \"\"\n```\n\n::: {.callout-note}\nIf you are not flipping forests, comment out or edit any boiler-plate code that assumes flips.\n:::\n\n---\n\n### I cannot render the `quarto` document as PDF\n\nInstall **TinyTeX** once:\n\n```r\ninstall.packages(\"tinytex\")\ntinytex::install_tinytex()\n```\n\nThen, in your YAML front-matter, comment out unwanted formats. For PDF-only output:\n\n```yaml\nformat:\n  # docx:\n  #   default: false\n  pdf:\n    pdf-engine: lualatex\n```\n\n---\n\n### Is it plagiarism to use the boiler-plate outputs verbatim?\n\nNo—provided you cite the source. The templates come from the NZAVS and EPIC (Bulbulia) Lab. Tailor the text to match your study and give credit. To edit, set `eval: false`, render, and copy-paste the plain text blocks.\n\n---\n\n### I do not have a boiler-plate template used in the example script\n\nRun **Script 0** and **Script 1** from the start; they refresh every template.\n  \n  \n\n::: {.cell}\n\n```{.r .cell-code}\nreport::cite_packages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 <https://doi.org/10.5281/zenodo.10907724>, R package version 1.0.52 Functions to obtain MARGinal Observational Treatment-effects from observational data., <https://go-bayes.github.io/margot/>.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. doi:10.32614/CRAN.package.extrafont <https://doi.org/10.32614/CRAN.package.extrafont>, R package version 0.19, <https://CRAN.R-project.org/package=extrafont>.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. doi:10.32614/CRAN.package.tibble <https://doi.org/10.32614/CRAN.package.tibble>, R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - R Core Team (2025). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. doi:10.32614/CRAN.package.forcats <https://doi.org/10.32614/CRAN.package.forcats>, R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. doi:10.32614/CRAN.package.stringr <https://doi.org/10.32614/CRAN.package.stringr>, R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. doi:10.32614/CRAN.package.dplyr <https://doi.org/10.32614/CRAN.package.dplyr>, R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. doi:10.32614/CRAN.package.purrr <https://doi.org/10.32614/CRAN.package.purrr>, R package version 1.0.4, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. doi:10.32614/CRAN.package.readr <https://doi.org/10.32614/CRAN.package.readr>, R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. doi:10.32614/CRAN.package.tidyr <https://doi.org/10.32614/CRAN.package.tidyr>, R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n  - Xie Y (2025). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.57, <https://github.com/rstudio/tinytex>. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. <https://tug.org/TUGboat/Contents/contents40-1.html>.\n```\n\n\n:::\n:::\n\n\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}