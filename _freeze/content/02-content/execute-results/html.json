{
  "hash": "ba121e197722e87dc9b945b009615b32",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal diagrams: Five Elementary Structures\"\ndate: \"2025-MAR-04\"\nbibliography: /Users/joseph/GIT/templates/bib/references.bib\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    warnings: FALSE\n    error: FALSE\n    messages: FALSE\n    code-overflow: scroll\n    highlight-style: kate\n    code-tools:\n      source: true\n      toggle: FALSE\nhtml-math-method: katex\nreference-location: margin\ncitation-location: margin\ncap-location: margin\ncode-block-border-left: true\n---\n\n::: {.cell}\n\n:::\n\n::: {.callout-note}\n## Readings\n- Barrett M (2023). _ggdag: Analyze and Create Elegant Directed Acyclic Graphs_. R package version 0.2.7.9000, <https://github.com/malcolmbarrett/ggdag>\n- \"An Introduction to Directed Acyclic Graphs\", <https://r-causal.github.io/ggdag/articles/intro-to-dags.html>\n- \"Common Structures of Bias\", <https://r-causal.github.io/ggdag/articles/bias-structures.html>\n:::\n\n::: {.callout-important}\n## Key concepts for the test(s):\n  - **Confounding**\n  - **Causal Directed Acyclic Graph** \n  - **Five Elementary Causal Structures**\n  - **d-separation**\n  - **Back door path**\n  - **Conditioning**\n  - **Fork bias**\n  - **Collider bias**\n  - **Mediator bias**\n  - **Four Rules of Confounding Control**\n:::\n\n::: {.callout-important}\n## Download Your Laboratory R Script Here\n\nAssuming you have installed R and RStudio:\n\n1. Download the R script for Lab 01 by clicking the link below. This script contains the code you will work with during your laboratory session.\n\n2. After downloading, open RStudio. \n\n3. In RStudio, create a new R script file by going to `File > New File > R Script`.\n\n4. Create a new`.R` file called `02-lab.R` and provide your name, contact, data, and a brief title such as \"Rimulating the basic five basic causal structures in R\" \n\nExample: \n\n::: {.cell}\n\n```{.r .cell-code}\n#  Bob leBob\n#  29 Feb 2024\n#  bob@lebob.fr\n#. Lab 02 - Simulating The Five Basic Structures of Cauality\n```\n:::\n\n\n5. Copy and paste the code chunks below from your computer onto the script during class. \n\n\n6. Save the new R script file in a clearly defined project directory folder for easy access during the lab.\n\n\n7. Bring your computer to the lab.  \n\n\nNote: you may also download the lab here [Download the R script for Lab 02](https://raw.githubusercontent.com/go-bayes/psyc-434-2024/main/laboratory/02-lab.R)\n\n:::\n\n\n# Seminar\n\n\n### Overview \n\n- Understand basic features of causal diagrams: definitions and applications\n- Introduction to the five elementary causal structures\n- Lab: Gentle Introduction to Simulation and Regression (TBC over the upcoming weeks)\n\n\n### Review\n\n1. Psychological research begins with two questions: \n\n> 1. What do I want to know? \n> 2. For which population does this knowledge generalise?  \n\nThis course considers how to ask psychological questions that pertain to populations with different characteristics \n\n2. In psychological research, we typically ask questions about the causes and consequences of thought and behaviour - \"What if?\" questions [@hernan2024WHATIF]. \n\n3. The following concepts help us to describe two distinct failure modes in psychological research when asking \"What if?\" questions:\n\n  - **The Concept of External Validity**: the extent to which the findings of a study can be generalised to other situations, people, settings, and time periods. That is, we want to know if our findings carry beyond the *sample population* to the *target population*.  We fail when our results do not generalise as we think.  More fundamentally, we fail when we have not clearly defined our question or our target population.\n\n  - **The Concept of Internal Validity**: the extent to which the associations we obtain from data reflect causality. In psychological science, we use \"independent variable\" and \"dependent variable.\" Sometimes we use the terms \"exogenous variable\" and \"endogenous variable.\"  Sometimes we use the term \"predictor variable\" to describe the \"dependent\" or \"endogenous\" variable. These words are confusing.  When asking \"What if?\" questions, we want to understand what would happen if we intervened.  In this course, we will use the term \"treatment\" or, equivalently the term \"exposure\" to denote the intervention; we will use the term \"outcome\" to denote the effect of an intervention.[^note]\n\n[^note]: \"What if?\" questions implicitly invoke the idea of intervening on the world. \"If we did *this*, *then* what would happen to *that*...?\" Our preferred terminology reflects our interest in the effects of interventions.\n\n5. During the first part of the course, our primary focus will be on challenges to internal validity from **confounding bias.**  \n\n\n## Definitions\n\n::: {#def-internal-validity}\nWe say internal validity is compromised if the association between the treatment and outcome in a study does not consistently reflect causality in the sample population as defined at baseline.\n:::\n\n::: {#def-external-validity}\nWe say external validity is compromised if the association between the treatment and outcome in a study does not consistently reflect causality in the target population as defined at baseline.\n:::\n\nThe concept of \"confounding bias\" helps to clarify what it is at stake when evaluating the *internal validity* of a study.  As we shall see, there are several equivalent definitions of \"confounding bias,\" which we will describe during the upcoming weeks. \n\nThe definition of confounding bias that we will examine today is:\n\n::: {#def-confounding}\nWe say there is confounding bias if there is an open back-door path between the treatment and outcome or if the path between the treatment and outcome is blocked.\n:::\n\nToday, our purpose will be to clarify the meaning of each term in this definition. To that end, we will introduce the five elementary graphical structures employed in causal diagrams. We will then explain the four elementary rules that allow investigators to identify causal effects from the asserted relations in a causal diagram. First, what are causal diagrams? \n\n\n## Introduction to Causal Diagrams.\n\nCausal diagrams, also called causal graphs, Directed Acyclic Graphs, and Causal Directed Acyclic Graphs, are graphical tools whose primary purpose is to enable investigators to detect confounding biases.\n\n**Remarkably, causal diagrams are rarely used in psychology!**\n\n\nBefore describing how causal diagrams work, we first define the meanings of their symbols. Note there is no single convention for creating causal diagrams, so it is important that we are clear when defining our meanings.\n\n\n### The meaning of our symbols\n\nThe conventions that describe the meanings of our symbols are given in @fig-conventions.\n\n::: {#fig-conventions}\n![](terminologylocalconventions.pdf){fig-align=\"left\" height=100% width=100%}\n\nOur variable naming conventions. This figure is adapted from [@bulbulia2023]\n:::\n\nFor us:\n\n$X$ denotes a variable without reference to its role;\n\n$A$ denotes the \"treatment\" or \"exposure\" variable. This is the variable for which we seek to understand the effect of intervening on it. It is the \"cause;\" \n\n$Y$ denotes the outcome or response of an intervention. It is the \"effect.\" Last week we considered whether marriage $A$ causes happiness $Y$.\n\n$Y(a)$ denotes the counterfactual or potential state of $Y$ in response to setting the level of the exposure to a specific level, $A=a$. As we will consider in the second half of the course, to consistently estimate causal effects we will need to evaluate counterfactual or potential states of the world.  Keeping to our example, we will need to do more than evaluate marriage and happiness in people over time. We will need to evaluate how happy the unmarried people would have been had they been married and how happy the married people would have been had they not been married. Of course, these events cannot be directly observed. Thus to address fundamental questions in psychology, we need to contrast counterfactual states of the world. This might seem like science fiction; however, we are already familiar with methods for obtaining such counterfactual contrasts -- namely, randomised controlled experiments! We will return to this concept later, but for now, it will be useful for you to understand the notation. \n\n$L$ denotes a measured confounder or set of confounders is defined as a variable which, if conditioned upon, closes an open back-door path between the treatment $A$ and the outcome $Y$.  Consider the scenario where happiness at time 0 ($L$) affects both the probability of getting married at time 1 ($A$) and one's happiness at time 2 ($Y$). In this case, $L$ serves as a confounder because it influences both the treatment (marriage at time 1) and the outcome (happiness at time 2), potentially opening a back-door path that confounds the estimated effect of marriage on happiness.\n\nTo accurately estimate the causal effect of marriage on happiness, then, it is essential to control for $L$. With cross-sectional data, such control might be difficult. \n\n$U$ denotes an unmeasured confounder -- that is a variable that may affect both the treatment and the outcome, but for which we have no direct measurement. Suppose cultural upbringing affects both whether someone gets married and whether they are happy.  If this variable is not measured, we cannot accurately estimate a causal effect of marriage on happiness.\n\n$M$ denotes a mediator or a variable along the path from exposure to outcome. For example, perhaps marriage causes wealth and wealth causes happiness. As we shall see, conditioning on \"wealth\" when estimating the effect of marriage on happiness will make it seem that marriage does not cause happiness when it does, *through* wealth.\n\n$\\bar{X}$ denotes a sequence of variables, for example, a sequence of treatments.  Imagine we were interested in the causal effect of marriage and remarriage on well-being. In this case, there are two treatments $A_0$ and $A_1$ and four potential contrasts. For the scenario of marriage and remarriage affecting well-being, we denote the potential outcomes as $Y(a_0, a_1)$, where $a_0$ and $a_1$ represent the specific values taken by $A_0$ and $A_1$, respectively. Given two treatments, $A_0$ and $A_1$, four primary contrasts of interest correspond to the different combinations of these treatments. These contrasts allow us to compare the causal effects of being married versus not and remarried versus not on well-being. The potential outcomes under these conditions can be specified as follows:\n\n1. $Y(0, 0)$: The potential outcome when there is no marriage.\n2. $Y(0, 1)$: The potential outcome when there is marriage. \n2. $Y(1, 0)$: The potential outcome when there is divorce.\n4. $Y(1, 1)$: The potential outcome from marriage prevalence.\n\nEach of these outcomes allows for a specific contrast to be made, comparing the well-being under different scenarios of marriage and remarriage. Which do we want to contrast?  Note, the question about 'the causal effects of marriage on happiness' is ambiguous because we have not stated the causal contrast we are interested in. \n\n$\\mathcal{R}$ denotes a randomisation or a chance event.\n\n### Elements of our Causal Graphs \n\nThe conventions that describe components of our causal graphs are given in @fig-general.\n\n\n::: {#fig-general}\n![](terminologygeneral.pdf){fig-align=\"left\" height=100% width=100%}\n\nNodes, Edges, Conditioning Conventions. This figure is adapted from [@bulbulia2023]\n:::\n\n\n\n\n#### Time indexing\n\n\nIn our causal diagrams, we will implement two conventions to accurately depict the temporal order of events.\n\nFirst, the layout of a causal diagram will be structured from left to right to reflect the sequence of causality as it unfolds in reality. This orientation is crucial because causal diagrams must inherently be acyclic and because causality itself is inherently temporal. \n\nSecond, we will enhance the representation of the event sequence within our diagrams by systematically indexing our nodes according to the relative timing of events. If an event represented by $X_0$ precedes another event represented by $X_1$, the indexing will indicate this chronological order.\n\n\n\n#### Representing uncertainty in timing explicitly\n\nIn settings in which the sequence of events is ambiguous or cannot be definitively known, particularly in the context of cross-sectional data where all measurements are taken at a single point in time, we adopt a specific convention to express causality under uncertainty: $X_{\\phi t}$. This notation allows us to propose a temporal order without clear, time-specific measurements, acknowledging our speculation.\n\nFor instance, when the timing between events is unclear, we denote an event that is presumed to occur first as $X_{\\phi 0}$ and a subsequent event as $X_{\\phi 1}$, indicating a tentative ordering where $X_{\\phi 0}$ is thought to precede $X_{\\phi 1}$. However, it is essential to underscore that this notation signals our uncertainty regarding the actual timing of events; our measurements do not give us the confidence to assert this sequence definitively.\n\n\n\n#### Arrows\n\nAs indicated in @fig-general, black arrows denote causality, red arrows reveal an open backdoor path, dashed black arrows denote attenuation, and red dashed arrows denote bias in a true causal association between $A$ and $Y$. Finally, a blue arrow with a circle point denotes effect-measure modification, also known as \"effect modification.\"  We might be interested in treatment effect heterogeneity without evaluating the causality in the sources of this heterogeneity.  For example, we cannot typically imagine any intervention in which people could be randomised into cultures.  However, we may be interested in whether the effects of an intervention that might be manipulable, such as marriage, differ by culture.  To clarify this interest, we require a non-causal arrow. \n\n$\\mathcal{R}\\to A$ denotes a random treatment assignment. \n\n\n#### Boxes\n\nWe use a black box to denote conditioning that reduces confounding or that is inert. \n\n\nWe use a red box to describe settings in which conditioning on a variable introduces confounding bias. \n\n\nOccasionally we will use a dashed circle do denote a latent variable, that is, a variable that is either not measured or not conditioned upon. \n\n\n#### Terminology for Conditional Independence\n\nThe bottom panel of @fig-general shows some mathematical notation. Do not be alarmed, we are safe! Part 1 of the course will not require more complicated math than this notation. And we shall see that the notation is a compact way to describe intuitions that can be expressed less compactly in words:\n\n- **Statistical Independence ($\\coprod$):** in the context of causal inference, statistical independence between the treatment and potential outcomes, denoted as $A \\coprod Y(a)$, means the treatment assignment is independent of the potential outcomes. This assumption is critical for estimating causal effects without bias.\n\n- **Statistical Dependence ($\\cancel\\coprod$):** conversely, $\\cancel\\coprod$ denotes statistical dependence, indicating that the distribution of one variable is influenced by the other. For example, $A \\cancel\\coprod Y(a)$ implies that the treatment assignment is related to the potential outcomes, potentially introducing bias into causal estimates.\n\n- **Conditioning ($|$):** conditioning, denoted by the vertical line $|$, allows for specifying contexts or conditions under which independence or dependence holds.\n\n    - **Conditional Independence ($A \\coprod Y(a)|L$):** This means that once we account for a set of variables $L$, the treatment and potential outcomes are independent. This condition is often the basis for strategies aiming to control for confounding.\n\n    - **Conditional Dependence ($A \\cancel\\coprod Y(a)|L$):** States that potential outcomes and treatments are not independent after conditioning on $L$, indicating a need for careful consideration in the analysis to avoid biased causal inferences.\n\n\n\n## The Five Elementary Structures of Causality\n\n\nJudea Pearl proved that all elementary structures of causality can be represented graphically [@pearl2009a].  @fig-directedgraph presents this five elementary structures. \n\n\n\n::: {#fig-directedgraph}\n![](terminologydirectedgraph.pdf){fig-align=\"left\" height=100% width=100%}\n\nFive elementary structures. This figure is adapted from [@bulbulia2023].\n:::\n\n\n\nThe structures are as follows: \n\n- **Two Variables:**\n    1. **Causality Absent:** There is no causal effect between variables $A$ and $B$. They do not influence each other, denoted as $A \\coprod B$, indicating they are statistically independent.\n    2. **Causality:** Variable $A$ causally affects variable $B$. This relationship suggests an association between them, denoted as $A \\cancel\\coprod B$, indicating they are statistically dependent.\n\n- **Three Variables:**\n    3. **Fork:** Variable $A$ causally affects both $B$ and $C$. Variables $B$ and $C$ are conditionally independent given $A$, denoted as $B \\coprod C | A$. This structure implies that knowing $A$ removes any association between $B$ and $C$ due to their common cause.\n    4. **Chain:** A causal chain exists where $C$ is affected by $B$, which in turn is affected by $A$. Variables $A$ and $C$ are conditionally independent given $B$, denoted as $A \\coprod C | B$. This indicates that $B$ mediates the effect of $A$ on $C$, and knowing $B$ breaks the association between $A$ and $C$.\n    5. **Collider:** Variable $C$ is affected by both $A$ and $B$, which are independent. However, conditioning on $C$ induces an association between $A$ and $B$, denoted as $A \\cancel\\coprod B | C$. This structure is unique because it suggests that $A$ and $B$, while initially independent, become associated when we account for their common effect $C$.\n\n\nOnce we understand the basic relationships between two variables, we can build upon these to create more complex relationships. These structures help us see how statistical independences and dependencies emerge from the data, allowing us to clarify the causal relationships we presume exist. Such clarity is crucial for ensuring that confounders are balanced across treatment groups, given all measured confounders, so that $Y(a) \\coprod A | L$.\n\nYou might wonder, \"If not from the data, where do our assumptions about causality come from?\" This question will come up repeatedly throughout the course. The short answer is that our assumptions are based on existing knowledge. This reliance on current knowledge might seem counterintuitive for buiding scientific knowledge-— shouldn't we use data to build knowledge, not the other way around? Yes, but it is not that straightforward. Data often hold the answers we're looking for but can be ambiguous. When the causal structure is unclear, it is important to sketch out different causal diagrams, explore their implications, and, if necessary, conduct separate analyses based on these diagrams.\n\nOtto Neurath, an Austrian philosopher and a member of the Vienna Circle, famously used the metaphor of a ship that must be rebuilt at sea to describe the process of scientific theory and knowledge development. \n\n> Duhem has shown ... that every statement about any happening is saturated with hypotheses of all sorts and that these in the end are derived from our whole world-view. We are like sailors who on the open sea must reconstruct their ship but are never able to start afresh from the bottom. Where a beam is taken away a new one must at once be put there, and for this the rest of the ship is used as support. In this way, by using the old beams and driftwood, the ship can be shaped entirely anew, but only by gradual reconstruction. [@neurath1973, p.199]\n\nThis quotation emphasises the iterative process that accumulates scientific knowledge;  new insights are cast from the foundation of existing knowledge. Causal diagrams are at home in Neurath's boat. The tradition of science that believes that knowledge develops from the results of statistical tests applied to data should be resisted. The data alone typically do not contain the answers we seek.\n\n\n## The Four Rules of Confounding Control\n\n\n@fig-terminologyconfounders describe the four elementary rules of confounding control:\n\n\n::: {#fig-terminologyconfounders}\n![](terminologyelconfounders.pdf){fig-align=\"left\" height=100% width=100%}\n\nFour rules of confounding control\n\n:::\n\n\n1. **Condition on Common Cause or its Proxy**: this rule applies to settings in which the treatment ($A$) and the outcome ($Y$) share common causes. By conditioning on these common causes, we block the open backdoor paths that could introduce bias into our causal estimates. Controlling for these common causes (or their proxies) helps tp isolate the specific effect of $A$ on $Y$. (We do not draw a path from $ A \\to Y$ because we do not assume this path.)\n\n2. **Do Not Condition on a Mediator**:  this rule applies to settings in which the variable $L$ is a mediator of $A \\to Y$. Here, conditioning on a mediator will bias the total causal effect estimate. Later in the course, we will discuss the assumptions required for causal mediation.  For now, if we are interested in total effect estimates, we must not condition on a mediator.  Here we draw the path from $A \\to Y$ to ensure that if such a path exists, it will not become biased from our conditioning strategy. \n\n3. **Do Not Condition on a Collider**: this rule applies to settings in which we $L$ is a common effect of $A$ and $Y$. Conditioning on a collider may invoke a spurious association.  Last week we considered an example in which marriage caused wealth and happiness caused wealth. Conditioning on wealth in this setting will induce an association between happiness and marriage. Why?  If we know the outcome, wealth, then we know there are at least two ways of wealth.  Among those wealthy but low on happiness, we can predict that they are more likely to be married, for how else would they be wealthy? Similarly, among those who are wealthy and are not married, we can predict that they are happy, for how else would they be wealthy if not through marriage? These relationships are predictable entirely without a causal association between marriage and happiness!\n\n4. **Proxy Rule: Conditioning on a Descendent Is Akin to Conditioning on Its Parent**: this rule applies to settings in which we $L’$ is an effect from another variable $L$.  The graph considers when $L’$ is downstream of a collider.  For example, suppose we condition on home ownership, which is an effect of wealth. Such conditioning will open up a non-causal path without causation because home ownership is a proxy for wealth.  Consider, if someone owns a house but is not married, they are more likely to be happy, for how else could they accumulate the wealth required for home ownership?  Likewise, if someone is unhappy and owns a house, we can infer that they are more likely to be married because how else would they be wealthy? Conditioning on a proxy for a collider here is akin to conditioning on the collider itself.  \n\nHowever, we can also use the proxy rule to reduce bias. Return to the earlier example in which there is an unmeasured common cause of marriage and happiness, which we called \"cultural upbringing\"  Suppose we have not measured this variable but have measured proxies for this variable, such as country of birth, childhood religion, number of languages one speaks, and others.  By controlling for baseline values of these proxies, we can exert more control over unmeasured confounding. Even if bias is not eliminated, we should reduce bias wherever possible, which includes not introducing new biases, such as mediator bias, along the way.  Later in the course, we will teach you how to perform sensitivity analyses to verify the robustness of your results to unmeasured confounding.  Sensitivity analysis is critical because where the data are observational, we cannot entirely rule out unmeasured confounding. \n\n\n\n\n\n# Lab -- Regression in R, Graphing, and Elements of Simulation \n\n\n\n## Simulating Data in R:  `Outcome ~ Treatment`\n\n\n#### Step 1: Set Up Your R Environment\n\nEnsure R or RStudio is installed and open. \n\n\n#### Step 2: Set a Seed for Reproducibility\n\nTo ensure that your simulated data can be reproduced exactly. Again, it is good practice to set a seed before generating random data. This makes your analyses and simulations replicable.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123) # use any number to set the seed\n```\n:::\n\n#### Step 3: Simulate Continuous Data: One Variable \n\nTo simulate continuous data, you can use functions like `rnorm()` for normal distributions, `runif()` for uniform distributions, etc. Here we simulate 100 normally distributed data points with a mean of 50 and a standard deviation of 10:\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\nn <- 100 # number of observations\nmean <- 50\nsd <- 10\ndata_continuous <- rnorm(n, mean, sd)\n\n# view\nhead(data_continuous)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 44.39524 47.69823 65.58708 50.70508 51.29288 67.15065\n```\n\n\n:::\n\n```{.r .cell-code}\n# view using base R histogram\nhist(data_continuous)\n```\n\n::: {.cell-output-display}\n![](02-content_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n#### Step 4: Simulate Categorical Data\n\nCategorical data can be simulated using the `sample()` function. Here, we simulate a binary variable (gender) with two levels for 100 observations. There is equal probability of assignment.\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels <- c(\"Male\", \"Female\")\ndata_categorical <- sample(levels, n, replace = TRUE)\n\n# view\nhead(data_categorical)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Female\" \"Female\" \"Female\" \"Male\"   \"Female\" \"Female\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# check\ntable(data_categorical)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndata_categorical\nFemale   Male \n    49     51 \n```\n\n\n:::\n:::\n\nTo generate categories with unequal probabilities, you can use the `sample()` function by specifying the `prob` parameter, which defines the probability of selecting each level. This allows for simulating categorical data where the distribution between categories is not uniform. \n\nBelow is an example that modifies your initial code to create a categorical variable with unequal probabilities for \"Male\" and \"Female\". Here is an example with unequal probabilities:\n\n::: {.cell}\n\n```{.r .cell-code}\n# define levels and number of observations\nlevels <- c(\"Male\", \"Female\")\nn <- 100 # total number of observations\n\n# generate categorical data with unequal probabilities\ndata_categorical_unequal <- sample(levels, n, replace = TRUE, prob = c(0.3, 0.7))\n\n# view the first few elements\n# head(data_categorical_unequal)\n\n# check\ntable(data_categorical_unequal)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndata_categorical_unequal\nFemale   Male \n    69     31 \n```\n\n\n:::\n:::\n\n## Simulating Outcomes from Treatments\n\n\nIn this example, the `prob` parameter is set to `c(0.3, 0.7)`, indicating a 30% probability for \"Male\" and a 70% probability for \"Female\". This results in a simulated dataset where approximately 30% of the observations are \"Male\" and 70% are \"Female\", reflecting the specified unequal probabilities. Adjust the probabilities as needed to fit the scenario you wish to simulate.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#|fig-cap: \"Box plot of simulated scores by groups.\"\n# note: running this code will do no harm if the libraries are already installed.\n# install (if necessary) libraries\n# load libraries\n# libraries\n# graphs\nif (!require(ggplot2)) {\n  install.packages(\"ggplot2\")\n  library(ggplot2)\n} else {\n  library(ggplot2)\n}\n\n# data wrangling\nif (!require(tidyverse)) {\n  install.packages(\"tidyverse\")\n  library(tidyverse)\n} else {\n  library(tidyverse)\n}\n\n# tables\nif (!require(parameters)) {\n  install.packages(\"parameters\")\n  library(parameters)\n} else {\n  library(parameters)\n}\n\n# reporting\nif (!require(report)) {\n  install.packages(\"report\")\n  library(report)\n} else {\n  library(report)\n}\n\n\n# predictive graphs\nif (!require(ggeffects)) {\n  install.packages(\"ggeffects\")\n  library(ggeffects)\n} else {\n  library(ggeffects)\n}\n\n# assembling graphs\nif (!require(patchwork)) {\n  install.packages(\"patchwork\")\n  library(patchwork)\n} else {\n  library(patchwork)\n}\n\n# if libraries are already install, start here\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(parameters)\nlibrary(report)\n\n\nset.seed(123) # reproducibility\ngroupA_scores <- rnorm(100, mean = 100, sd = 15) # simulate scores for group A\ngroupB_scores <- rnorm(100, mean = 105, sd = 15) # simulate scores for group B\n\n# ombine into a data frame\ndf_scores <- data.frame(group = rep(c(\"A\", \"B\"), each = 100), scores = c(groupA_scores, groupB_scores))\n\n# commands to view data\n #str(df_scores)\n\n# summary of columns\n#summary(df_scores)\n\n# top rows (uncomment)\n# head(df_scores)\n\n# bottom rows  (uncomment)\n# tail(df_scores)\n\n# check structure of data  (uncomment)\n# str(df_scores)\n\n\n# make group a factor (not strictly necessary here, but useful in outher applications)\ndf_scores_1 <- df_scores |> \n  mutate(group = as.factor(group))\n\nhead(df_scores_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  group    scores\n1     A  91.59287\n2     A  96.54734\n3     A 123.38062\n4     A 101.05763\n5     A 101.93932\n6     A 125.72597\n```\n\n\n:::\n:::\n\n## Visualising Our Simulated Data\n\nUnderstanding your data visually is as important as the statistical analysis itself. Let's create a simple plot to compare the score distributions between the two groups.\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot your data\nggplot(df_scores_1, aes(x = group, y = scores, fill = group)) +\n  geom_boxplot() +\n  theme_minimal() +\n  labs(title = \"Score Distribution by Group\", x = \"Group\", y = \"Scores\")\n```\n\n::: {.cell-output-display}\n![Score Distribution by Group](02-content_files/figure-html/visualize-data-1.png){width=672}\n:::\n:::\n\n\n## Histogram {#sec-histogram}\n\n::: {.cell}\n\n```{.r .cell-code}\n#fig-cap: \"Histogram of simulated scores, by group, using facet_wrap()\"\nlibrary(ggplot2)\n\n# H=histograms for both groups\nggplot(df_scores_1, aes(x = scores, fill = group)) +\n  geom_histogram(binwidth = 5, color = \"black\") +\n  labs(title = \"Distribution of Scores by Group\",\n       x = \"Scores\",\n       y = \"Frequency\") +\n  facet_wrap(~group, ncol = 1) +   theme_minimal() \n```\n\n::: {.cell-output-display}\n![](02-content_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n## Excercise 1\n\n1. Modify the simulation parameters to change each group's mean and standard deviation. Observe how these changes affect the distribution.\n\n2. Go to the [histogram](#sec-histogram). Experiment with different bin widths. In your own words, how do large and small numbers speak differently to the data? When might you use one histogram and not another. \n\n\n## Simulating data for familiar statistical tests \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tbl-caption: \"results of a one-sample t-test.\"\n# simulate some data\nset.seed(123)\ndata <- rnorm(100, mean = 5, sd = 1) # 100 random normal values with mean = 5\n\n# perform one-sample t-test\n# testing if the mean of the data is reliably different from 4\nmod_first_test<- t.test(data, mu = 4)\n\n# table\nparameters::parameters(mod_first_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nOne Sample t-test\n\nParameter | Mean |   mu | Difference |       95% CI | t(99) |      p\n--------------------------------------------------------------------\ndata      | 5.09 | 4.00 |       1.09 | [4.91, 5.27] | 11.95 | < .001\n\nAlternative hypothesis: true mean is not equal to 4\n```\n\n\n:::\n:::\n\nWe can automatically report these results using the `report` package: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# report results automatically\nreport::report(mod_first_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe One Sample t-test testing the difference between data (mean = 5.09) and mu\n= 4 suggests that the effect is positive, statistically significant, and large\n(difference = 1.09, 95% CI [4.91, 5.27], t(99) = 11.95, p < .001; Cohen's d =\n1.19, 95% CI [0.94, 1.45])\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate data for two groups\nset.seed(123)\n\ngroup1 <- rnorm(50, mean = 5, sd = 1) # 50 random normal values, mean = 5\ngroup2 <- rnorm(50, mean = 5.5, sd = 1) # 50 random normal values, mean = 5.5\n\n# two-sample t-test\nmod_t_test_result <- t.test(group1, group2)\n\nreport::report(mod_t_test_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Welch Two Sample t-test testing the difference between group1 and group2\n(mean of x = 5.03, mean of y = 5.65) suggests that the effect is negative,\nstatistically significant, and medium (difference = -0.61, 95% CI [-0.98,\n-0.25], t(97.95) = -3.34, p = 0.001; Cohen's d = -0.67, 95% CI [-1.07, -0.26])\n```\n\n\n:::\n\n```{.r .cell-code}\nparameters::parameters(mod_t_test_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWelch Two Sample t-test\n\nParameter1 | Parameter2 | Mean_Parameter1 | Mean_Parameter2 | Difference\n------------------------------------------------------------------------\ngroup1     |     group2 |            5.03 |            5.65 |      -0.61\n\nParameter1 |         95% CI | t(97.95) |     p\n----------------------------------------------\ngroup1     | [-0.98, -0.25] |    -3.34 | 0.001\n\nAlternative hypothesis: true difference in means is not equal to 0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# simulate pre-test and post-test scores\nset.seed(123)\n\npre_test <- rnorm(30, mean = 80, sd = 10)\npost_test <- rnorm(30, mean =  pre_test + 5, sd = 5) # assume an increase\n\n# perform paired t-test\nmod_pre_post <- t.test(pre_test, post_test, paired = TRUE)\n\nreport::report(mod_pre_post)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between pre_test and post_test (mean\ndifference = -5.89) suggests that the effect is negative, statistically\nsignificant, and large (difference = -5.89, 95% CI [-7.45, -4.33], t(29) =\n-7.73, p < .001; Cohen's d = -1.41, 95% CI [-1.91, -0.90])\n```\n\n\n:::\n\n```{.r .cell-code}\nparameters::parameters(mod_pre_post)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nPaired t-test\n\nParameter |     Group | Difference | t(29) |      p |         95% CI\n--------------------------------------------------------------------\npre_test  | post_test |      -5.89 | -7.73 | < .001 | [-7.45, -4.33]\n\nAlternative hypothesis: true mean difference is not equal to 0\n```\n\n\n:::\n:::\n\n##  Understanding Regression Using Data Simulation\n\n### Simulating Continuous Treatment Variable and Outcome Variable\n\n::: {.cell}\n\n```{.r .cell-code}\n# library for enhanced model reporting\nset.seed(123)\n\nlibrary(parameters)\nlibrary(report)\n\n\n# set seed for reproducibility\nset.seed(123) # choose a seed number for consistency\n\n# define the number of observations\nn <- 100 # total observations\n\n# simulate continuous treatment variable A\ntreatment <- rnorm(n, mean = 50, sd = 10) # mean = 50, sd = 10 for A\n\n# specify the effect size of A on Y\nbeta_a <- 2 # explicit effect size\n\n# simulate outcome variable Y including an error term\noutcome <- 5 + beta_a * treatment + rnorm(n, mean = 0, sd = 20) # Y = intercept + beta_a*A + error\n\n# create a dataframe\ndf <- data.frame(treatment = treatment,outcome = outcome)\n\n# view the structure and first few rows of the data frame\nstr(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t100 obs. of  2 variables:\n $ treatment: num  44.4 47.7 65.6 50.7 51.3 ...\n $ outcome  : num  79.6 105.5 131.2 99.5 88.6 ...\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  treatment   outcome\n1  44.39524  79.58236\n2  47.69823 105.53412\n3  65.58708 131.24033\n4  50.70508  99.45932\n5  51.29288  88.55338\n6  67.15065 138.40075\n```\n\n\n:::\n:::\n\n### Run Linear Model\n\nBefore moving on to regression analysis, ensure students understand the structure and distribution of the simulated data. Encourage them to use `summary()`, `plot()`, and other exploratory data analysis functions.\n\n####  Regression Analysis of Continuous Treatment Effect\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n\n# perform linear regression of Y on A\nfit <- lm(outcome ~ treatment, data = df)\n\n# display the regression model summary\nsummary(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = outcome ~ treatment, data = df)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-38.15 -13.67  -1.75  11.61  65.81 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)   8.1911    11.0530   0.741     0.46    \ntreatment     1.8951     0.2138   8.865  3.5e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 19.41 on 98 degrees of freedom\nMultiple R-squared:  0.4451,\tAdjusted R-squared:  0.4394 \nF-statistic:  78.6 on 1 and 98 DF,  p-value: 3.497e-14\n```\n\n\n:::\n\n```{.r .cell-code}\n# report the model in a reader-friendly format\nreport_fit <- report::report(fit)\n\n\n# uncomment to print the model report\n# print(report_fit)\n\n# use ggeffects to view predicted values\nlibrary(ggeffects)\n\npredicted_values <- ggeffects::ggemmeans(fit,\n                     terms = c(\"treatment\"))\n\n# plot see\nplot(predicted_values,  dot_alpha = 0.35,   show_data = TRUE, jitter = .1)\n```\n\n::: {.cell-output-display}\n![Graph of regression line showing uncertainty.](02-content_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n## Equivalence of ANOVA and Regression\n\n\nWe will simulate data in R to show that a one-way ANOVA is a particular case of linear regression with categorical predictors. We will give some reasons for preferring regression (in some settings).\n\n## Method\n\nFirst, we simulate a dataset with one categorical independent variable with three levels (groups) and a continuous outcome (also called a \"dependant\") variable. This setup allows us to apply both ANOVA and linear regression for comparison.\n\n::: {.cell}\n\n```{.r .cell-code}\n# nice tables\nlibrary(parameters)\n\nset.seed(123) # reproducibility\nn <- 90 # total number of observations\nk <- 3 # number of groups\n\n# simulate independent variable (grouping factor)\ngroup <- factor(rep(1:k, each = n/k))\n\n# inspect\nstr(group)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Factor w/ 3 levels \"1\",\"2\",\"3\": 1 1 1 1 1 1 1 1 1 1 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# simulate outcome variable\nmeans <- c(100, 100, 220) # Mean for each group\nsd <- 15 # Standard deviation (same for all groups)\n\n# generate random data\ny <- rnorm(n, mean = rep(means, each = n/k), sd = sd)\n\n\n# make data frame\ndf_1 <- cbind.data.frame(y, group)\n\nanova_model <- aov(y ~ group, data = df_1)\n# summary(anova_model)\ntable_anova <- model_parameters(anova_model)\n\n# report the model\nreport::report(anova_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThe ANOVA (formula: y ~ group) suggests that:\n\n  - The main effect of group is statistically significant and large (F(2, 87) =\n786.88, p < .001; Eta2 = 0.95, 95% CI [0.93, 1.00])\n\nEffect sizes were labelled following Field's (2013) recommendations.\n```\n\n\n:::\n:::\n\n\nNext, we analyse the same data using linear regression. In R, regression models automatically convert categorical variables into dummy variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for tables (just installed)\nlibrary(parameters)\n\n# regression model \nfit_regression <- lm(y ~ group, data = df_1)\n\n# uncomment if you want an ordinary summary\n# summary(regression_model)\n\ntable_fit <- parameters::model_parameters(fit_regression)\n\n# print table\ntable_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |   SE |           95% CI | t(87) |      p\n--------------------------------------------------------------------\n(Intercept) |       99.29 | 2.46 | [ 94.41, 104.18] | 40.40 | < .001\ngroup [2]   |        3.38 | 3.48 | [ -3.53,  10.29] |  0.97 | 0.333 \ngroup [3]   |      121.07 | 3.48 | [114.16, 127.98] | 34.83 | < .001\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\nlibrary(report)\n\n# report the model\nreport_fit <- report_parameters(fit_regression)\n\n#print\nreport_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - The intercept is statistically significant and positive (beta = 99.29, 95% CI [94.41, 104.18], t(87) = 40.40, p < .001; Std. beta = -0.71, 95% CI [-0.80, -0.63])\n  - The effect of group [2] is statistically non-significant and positive (beta = 3.38, 95% CI [-3.53, 10.29], t(87) = 0.97, p = 0.333; Std. beta = 0.06, 95% CI [-0.06, 0.18])\n  - The effect of group [3] is statistically significant and positive (beta = 121.07, 95% CI [114.16, 127.98], t(87) = 34.83, p < .001; Std. beta = 2.08, 95% CI [1.96, 2.20])\n```\n\n\n:::\n:::\n\n## Combination Plots\n\nWe can create and combine individual plots, as showin in @fig-coefplot, as follows: \n\n::: {.cell .fig-column-page-inset-right}\n\n```{.r .cell-code}\n# regression --------------------------------------------------------------\n# graph the output of the parameters table and assign to object\ncoefficient_plot <- plot(table_fit)\n\n\n# ggeffects plot - create predictive plot.\n# this gives the expected values by group \npredictive_plot <- plot(\n  ggeffects::ggpredict(fit_regression, terms = \"group\"),\n  dot_alpha = 0.35,\n  show_data = TRUE,\n  jitter = .1,\n  colors =  \"reefs\"\n) +\n  scale_y_continuous(limits = c(0, 260)) + # change y axis\n  labs(title = \"Predictive Graph\", x = \"Treatment Group\", y = \"Response\")\n\n# view (uncomment to see it alone)\n#predictive_plot\n\n# show all color palettes (uncomment to see colour options)\n# show_pals()\n\n\n# multiple plots using `patchwork`\nlibrary(patchwork)\n\n# create a plot\nmy_first_combination_plot <- coefficient_plot / predictive_plot  +\n  plot_annotation(title = \"Coefficient and Predictive plots with two panels \",\n                  tag_levels = \"A\")\n\n# save a plot to your directory, make sure to create one called \"figs\"\n\n## check directory (uncomments)\n# here::here()\n\n# save (change values if necessary )\nggsave(\n  my_first_combination_plot,\n  path = here::here(\"figs\"),\n  width = 12,\n  height = 8,\n  units = \"in\",\n  filename = \"my_first_combination_plot.jpeg\",\n  device = 'jpeg',\n  limitsize = FALSE,\n  dpi = 600\n)\n\n# view\nmy_first_combination_plot\n```\n\n::: {.cell-output-display}\n![This is a combined plot](02-content_files/figure-html/fig-coefplot-1.png){#fig-coefplot width=672}\n:::\n:::\n\n## Upshot\n\nANOVA partitions variance into between-group and within-group components. Regression analysis estimates the mean of the `dependent variable` as a linear function of the `independent (including categorical)` variables. For many questions, ANOVA is appropriate, however, when comparing groups, we often want a finer-grained interpretation. Regression is built for obtaining this finer grain comparisons. Note: comparisons do not establish causality. We will return to regression over the next few weeks and use regression to hone your skills in R. Later, along the way, you'll learn more about data visualisation, modelling, and reporting. These skills are essential for your final report. They are also skills that you will serve you beyond this course. \n\n\n## Exercise 2\n\nPerform a linear regression analysis using R. Follow the detailed instructions below to simulate the necessary data, execute the regression, and report your findings:\n\n1. **Simulate Data:**\n   - Generate two continuous variables, `Y` and `A`, with `n = 100` observations each.\n   - The variable `A` should have a mean of `50` and a standard deviation (`sd`) of `10`.\n\n2. **Define the Relationship:**\n   - Simulate the variable `Y` such that it is linearly related to `A` with a specified effect size. The effect size of `A` on `Y` must be explicitly defined as `2`.\n\n3. **Incorporate an Error Term:**\n   - When simulating `Y`, include an error term with a standard deviation (`sd`) of `20` to introduce variability.\n\n4. **Regression Analysis:**\n   - Use the `lm()` function in R to regress `Y` on `A`.\n   - Ensure the regression model captures the specified effect of `A` on `Y`.\n\n5. **Report the Results:**\n   - Output the regression model summary to examine the coefficients, including the effect of `A` on `Y`, and assess the model's overall fit and significance.\n\n\nHere is a template to get you started. Copy the code and paste it into your R script. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\n#  seed for reproducibility\nset.seed( ) # numbers go in brackets\n\n# number of observations\nn <-   # number goes here\n\n# simulate data for variable A with specified mean and sd\nA <- rnorm(n, \n           mean = , # set your number here \n           sd = )# set your number here \n\n# define the specified effect size of A on Y\nbeta_A <-   # define your effect with a number here \n\n\n# simulate data and make data frame in one step\n\ndf_3 <- data.frame(\n  # simulate data for variable A with specified mean and sd\n  A = A, # from above\n  Y = 5 + beta_A * A + rnorm(n, mean = 0, sd = 20) #  effect is intercept + ...\n)\n\n# view\nhead(df_3)\nstr(df_3)\n\n#  linear regression of Y on A\nfit_3 <- lm(Y ~ A, data = df_3)\n\n#  results (standard code)\n# summary(model)\n\n# time saving reports\nparameters::model_parameters(fit_3)\nreport(fit_3)\n```\n:::\n\n\n## What You Have Learned\n\n- **Data simulation:** \n\nYou've learned to simulate datasets in R. This is a important skill for exploring statistical concepts and causal inference. Congratulations! \n  \n- **Data visualisation:** \n\nYou've expanded your capacity for data visualisation.\n  \n- **Statistical tests:** You've conducted basic statistical tests, including t-tests and ANOVA, and regression.\n  \n- **Understanding ANOVA and regression:** \n\nYou've examined the equivalence of ANOVA and regression analysis\n\n\n## For more information about the packages used here:\n\n  - [ggplot2](https://ggplot2.tidyverse.org/): A system for declaratively creating graphics, based on The Grammar of Graphics.\n\n  - [Parameters package](https://easystats.github.io/parameters/): Provides utilities for processing model parameters and their metrics.\n\n  - [Report package](https://easystats.github.io/report/index.html): Facilitates the automated generation of reports from statistical models.\n\n  - @montgomery2018 describes confounding in experiments - well worth a read.\n\n\n## Appendix A: Solutions {#appendix-a}\n\n\n### Solution Excercise 2: simulate data and regression reporting \n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(parameters)\n#  seed for reproducibility\nset.seed(12345)\n\n# number of observations\nn <- 100\n\n# simulate data for variable A with specified mean and sd\nA <- rnorm(n, mean = 50, sd = 10)\n\n# define the specified effect size of A on Y\nbeta_A <- 2\n\n\n# simulate data and make data frame in one step\n\ndf_3 <- data.frame(\n  # simulate data for variable A with specified mean and sd\n  A =  rnorm(n, mean = 50, sd = 10),\n  Y = 5 +  # intercept (optional)\n    beta_A * A + rnorm(n, mean = 0, sd = 20)\n)\n\n# view\nhead(df_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         A         Y\n1 52.23925  87.98766\n2 38.43777 106.60413\n3 54.22419 107.68437\n4 36.75245 117.09730\n5 51.41084 133.74473\n6 44.63952  70.74512\n```\n\n\n:::\n\n```{.r .cell-code}\nstr(df_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n'data.frame':\t100 obs. of  2 variables:\n $ A: num  52.2 38.4 54.2 36.8 51.4 ...\n $ Y: num  88 107 108 117 134 ...\n```\n\n\n:::\n\n```{.r .cell-code}\n# linear regression of Y on A\n\nfit_3 <- lm(Y ~ A, data = df_3)\n\n# results \n# summary(model)\n\n# nicer report\nparameters::model_parameters(fit_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter   | Coefficient |    SE |          95% CI | t(98) |      p\n--------------------------------------------------------------------\n(Intercept) |      109.17 | 14.62 | [80.17, 138.18] |  7.47 | < .001\nA           |   -3.80e-03 |  0.28 | [-0.57,   0.56] | -0.01 | 0.989 \n```\n\n\n:::\n\n```{.r .cell-code}\nreport(fit_3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nWe fitted a linear model (estimated using OLS) to predict Y with A (formula: Y\n~ A). The model explains a statistically not significant and very weak\nproportion of variance (R2 = 1.83e-06, F(1, 98) = 1.79e-04, p = 0.989, adj. R2\n= -0.01). The model's intercept, corresponding to A = 0, is at 109.17 (95% CI\n[80.17, 138.18], t(98) = 7.47, p < .001). Within this model:\n\n  - The effect of A is statistically non-significant and negative (beta =\n-3.80e-03, 95% CI [-0.57, 0.56], t(98) = -0.01, p = 0.989; Std. beta =\n-1.35e-03, 95% CI [-0.20, 0.20])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n```\n\n\n:::\n:::\n\n\n\n\n## Appendix B: How ANOVA can deliver the functionality of Linear Regressions\n\nWe can get group comparisons with ANOVA, for example:\n\n::: {.cell}\n\n```{.r .cell-code}\n# Conduct Tukey's HSD test for post hoc comparisons\ntukey_post_hoc <- TukeyHSD(anova_model)\n\n# Display the results\nprint(tukey_post_hoc)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = y ~ group, data = df_1)\n\n$group\n          diff        lwr       upr     p adj\n2-1   3.381631  -4.906624  11.66989 0.5958959\n3-1 121.072862 112.784607 129.36112 0.0000000\n3-2 117.691231 109.402975 125.97949 0.0000000\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(tukey_post_hoc)\n```\n\n::: {.cell-output-display}\n![](02-content_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\nRegression and ANOVA are equivalent\n\n\n## Appendix C: Adding Complexity in Simulation\n\n\n### Simulating Data... Continued\n\nData frames are used in R to store data tables. To simulate a dataset with both continuous and categorical data, you can combine the above steps:\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a data frame with simulated data for ID, Gender, Age, and Income\ndata_frame <- data.frame(\n  # generate a sequence of IDs from 1 to n\n  ID = 1:n,\n  \n  # randomly assign 'Male' or 'Female' to each observation\n  Gender = sample(c(\"Male\", \"Female\"), n, replace = TRUE),\n  \n  # simulate 'Age' data: normally distributed with mean 30 and sd 5\n  Age = rnorm(n, mean = 30, sd = 5),\n  \n  # simulate 'Income' data: normally distributed with mean 50000 and sd 10000\n  Income = rnorm(n, mean = 50000, sd = 10000)\n)\n```\n:::\n\n\nNote that you can sample probabilistically for your groups\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- 100 # total number of observations\n\n# sample 'Gender' with a 40/60 proportion for Male/Female\nGender = sample(c(\"Male\", \"Female\"), n, replace = TRUE, prob = c(0.4, 0.6))\n```\n:::\n\n### More complexity \n\n::: {.cell}\n\n```{.r .cell-code}\n# set the number of observations\nn <- 100\n\n# simulate the 'Age' variable\nmean_age <- 30\nsd_age <- 5\nAge <- rnorm(n, mean = mean_age, sd = sd_age)\n\n# define coefficients explicitly\nintercept <- 20000   # Intercept for the income equation\nbeta_age <- 1500     # Coefficient for the effect of age on income\nerror_sd <- 10000    # Standard deviation of the error term\n\n# simulate 'Income' based on 'Age' and defined coefficients\nIncome <- intercept + beta_age * Age + rnorm(n, mean = 0, sd = error_sd)\n\n# create a data frame to hold the simulated data\ndata_complex <- data.frame(Age, Income)\n```\n:::\n\n### Visualising Simulated Data\n\nVisualising your simulated data can help understand its distribution and relationships. Use the `ggplot2` package for this:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nggplot(data_complex, aes(x = Age, y = Income)) +\n  geom_point() +\n  theme_minimal() +\n  labs(title = \"Simulated Age vs. Income\", x = \"Age\", y = \"Income\")\n```\n\n::: {.cell-output-display}\n![](02-content_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\n\n## Appendix D: Causal Inference Glossary\n\nNote, as of yet, we have only encountered several of the terms in this glossary.\n\n[Glossary of key terms in causal inference](/content/glossary.pdf)\n\n\n\n### Packages\n\n::: {.cell}\n\n```{.r .cell-code}\nreport::cite_packages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, <https://CRAN.R-project.org/package=extrafont>.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - Lüdecke D (2018). \"ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.\" _Journal of Open Source Software_, *3*(26), 772. doi:10.21105/joss.00772 <https://doi.org/10.21105/joss.00772>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. <https://easystats.github.io/report/>.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, <https://CRAN.R-project.org/package=patchwork>.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, <https://github.com/rstudio/tinytex>. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. <https://tug.org/TUGboat/Contents/contents40-1.html>.\n```\n\n\n:::\n:::\n",
    "supporting": [
      "02-content_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}