{
  "hash": "244bcf9c6f7ab8af0f8a66d47a0e187e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Causal Inference: Understanding How Effects Differ\"\nsubtitle: \"Effect Modification, Interaction, and Conditional Average Treatment Effects\"\ndate: \"2025-APR-01\"\nbibliography: /Users/joseph/GIT/templates/bib/references.bib\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    warnings: FALSE\n    error: FALSE\n    messages: FALSE\n    code-overflow: scroll\n    highlight-style: kate\n    code-tools:\n      source: true\n      toggle: FALSE\nhtml-math-method: katex\nreference-location: margin\ncitation-location: margin\ncap-location: margin\ncode-block-border-left: true\n---\n\n\n```{=html}\n<style>\n  .boxedblue {\n      border: 2px solid blue;\n      border-radius: 4px; /* slight roundness */\n      padding: 3px 6px; /* vertical | horizontal */\n      display: inline-block;\n      color: blue;\n    }\n  .circleblue {\n      border: 2px dashed blue;\n      border-radius: 50%;\n      padding: 3px 6px;\n      display: inline-block;\n      color: blue;\n    }\n</style>\n```\n\n\n\n\n::: {.callout-note}\n**Required Reading**\n\n- [@hernan2024WHATIF] Chapters 4-5 [link](https://www.dropbox.com/scl/fi/9hy6xw1g1o4yz94ip8cvd/hernanrobins_WhatIf_2jan24.pdf?rlkey=8eaw6lqhmes7ddepuriwk5xk9&dl=0)\n\n**Optional Reading**\n\n- [@vanderweele2007FOURTYPESOFEFFECT] [link](https://www.dropbox.com/scl/fi/drytp2ui2b8o9jplh4bm9/four_types_of_effect_modification__a.6.pdf?rlkey=mb9nl599v93m6kyyo69iv5nz1&dl=0)\n\n- [@vanderweele2009distinction] [link](https://www.dropbox.com/scl/fi/srpynr0dvjcndveplcydn/OutcomeWide_StatisticalScience.pdf?rlkey=h4fv32oyjegdfl3jq9u1fifc3&dl=0)\n:::\n\n::: {.callout-important}\n## Key Concepts for Assessment\n  - **Causal Estimand:** The specific causal question we want to answer (e.g., the average effect in the whole population).\n  - **Statistical Estimand:** The calculation we perform on our data to try and answer the causal question.\n  - **Interaction:** The combined effect of *two or more* interventions.\n  - **Effect Modification:** When the effect of *one* intervention changes depending on a person's characteristics.\n  - **Heterogeneous Treatment Effects (HTE):** The general *idea* that treatment effects vary across people.\n  - **Conditional Average Treatment Effect (CATE) $\\tau(x)$:** The *average* treatment effect for a specific subgroup defined by characteristics $x$.\n  - **Estimated Conditional Average Treatment Effect $\\hat{\\tau}(X)$:** Our *estimate* (from data) of the average treatment effect for a subgroup with characteristics $X$.\n:::\n\n\n## If you learn nothing else from this course...\n\nTo answer psychological questions properly, we first need to state them very clearly. Causal inference gives us the tools to do this.\n\n\n## Causal inference asks: \"What if?\"\n\nThe core idea is to compare what *actually happened* with what *could have happened* under different conditions (these \"what ifs\" are called **counterfactuals**).\n\nImagine an outcome we care about, like student test scores ($Y$). We might compare the score if *everyone* got a new teaching method (let's call this condition $a^*$) versus if *everyone* got the old method (condition $a$).\n\nThe difference in the potential outcome ($Y$) under these two scenarios is the causal effect for one person: $Y(a^*) - Y(a)$.\n\nSince we can't see both scenarios for the same person, we often look at the average effect across a group. The **Average Treatment Effect (ATE)** is the average difference in potential outcomes across the whole population:\n\n$$\n\\text{ATE} = \\mathbb{E}[Y(a^*) - Y(a)]\n$$\n\nThis asks: \"On average, how much would scores change if we switched everyone from the old method ($a$) to the new method ($a^*$)?\".\n\nA big challenge is dealing with **confounders** â€“ other factors that mix up the relationship between the treatment ($A$) and the outcome ($Y$), potentially misleading us about the true causal effect. We need to account for these.\n\n\n## What do 'Interaction' and 'Effect Modification' mean in Causal Inference?\n\nWords like 'moderation' and 'interaction' are often used loosely. Causal inference needs precise terms.\n\nWe'll focus on two specific ideas:\n\n1.  **Interaction:** About the effect of *combining* interventions.\n2.  **Effect Modification:** About how the effect of *one* intervention changes for different *types of people*.\n\n\n## Interaction: The Effect of Teamwork (or Lack Thereof)\n\n**Interaction** in causal inference is about **joint interventions**. We look at what happens when we apply *two or more different treatments* at the same time.\n\nLet's say we have two treatments, $A$ and $B$, and an outcome $Y$.\n\n* $Y(\\tilde{a})$ is the potential outcome if we set treatment $A$ to level $\\tilde{a}$.\n* $Y(\\tilde{b})$ is the potential outcome if we set treatment $B$ to level $\\tilde{b}$.\n* $Y(\\tilde{a}, \\tilde{b})$ is the potential outcome if we set $A$ to $\\tilde{a}$ *and* $B$ to $\\tilde{b}$ simultaneously.\n\nTo figure out these effects from observational data, we usually need assumptions like:\n\n- **Consistency:** The outcome we see for someone who got treatment $\\tilde{a}$ is the same as their potential outcome $Y(\\tilde{a})$.\n\n- **Conditional Exchangeability (No Unmeasured Confounding):** We can make the groups receiving different treatments comparable by adjusting for measured confounders ($L$ for $A \\to Y$, and $Q$ for $B \\to Y$). The sets $L$ and $Q$ might overlap.\n\n- **Positivity**: the exposures to be compared occur in all subgroups.\n\n\nTo study the *interaction* between $A$ and $B$, we need to be able to estimate the effect of $A$ and the effect of $B$, which means we need to adjust for *all* confounders in **both** $L$ and $Q$ (i.e., their union $L \\cup Q$).\n\n\n### Defining Interaction: Does 1 + 1 = 2?\n\nLet's use an education example:\n\n* $A$: New teaching method (1=New, 0=Old)\n* $B$: Extra tutoring (1=Yes, 0=No)\n* $Y$: Test score\n\nIs the boost in scores from getting *both* the new method *and* tutoring simply the sum of the boost from *only* the new method and the boost from *only* tutoring?\n\nWe define **causal interaction on the additive scale** (looking at differences) by comparing the effect of the joint intervention to the sum of the individual effects (all compared to getting neither):\n\n$$\n\\underbrace{(\\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(0,0)])}_{\\text{Effect of Both}} \\quad \\text{vs} \\quad \\underbrace{(\\mathbb{E}[Y(1,0)] - \\mathbb{E}[Y(0,0)])}_{\\text{Effect of A only}} + \\underbrace{(\\mathbb{E}[Y(0,1)] - \\mathbb{E}[Y(0,0)])}_{\\text{Effect of B only}}\n$$\n\nInteraction exists if these are not equal. This simplifies to checking if the following is non-zero (see Appendix):\n\n$$\n\\underbrace{\\mathbb{E}[Y(1,1)]}_{\\text{Both}} - \\underbrace{\\mathbb{E}[Y(1,0)]}_{\\text{A only}} - \\underbrace{\\mathbb{E}[Y(0,1)]}_{\\text{B only}} + \\underbrace{\\mathbb{E}[Y(0,0)]}_{\\text{Neither}} \\neq 0\n$$\n\n- If this is positive: **Synergy** (the combination is better than expected).\n- If this is negative: **Antagonism** (the combination is worse than expected).\n\n*(We could also look at interaction on other scales, like ratios, which might give different answers. Always state the scale you're using -- we'll come back to this in later lectures)*\n\n#### Finding Causal Interaction in Data\n\nTo estimate this interaction, we need valid estimates for all four average potential outcomes:\n\n$$\\mathbb{E}[Y(0,0)], \\mathbb{E}[Y(1,0)], \\mathbb{E}[Y(0,1)], \\mathbb{E}[Y(1,1)]$$\n\nThis means we must control for confounders of *both* the $A \\to Y$ link and the $B \\to Y$ link.\n\n@fig-dag-interaction shows this. $L_A$ are confounders for $A \\to Y$, and $L_B$ are confounders for $B \\to Y$. We need to block the backdoor paths (red arrows).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Diagram illustrating causal interaction. Assessing the joint effect of two interventions, A (e.g., teaching method) and B (e.g., tutoring), on outcome Y (e.g., test score). L_A represents confounders of the A-Y relationship, and L_B represents confounders of the B-Y relationship. Red arrows indicate biasing backdoor paths requiring adjustment. Assumes A and B are decided independently here.](06-content_files/figure-html/fig-dag-interaction-1.png){#fig-dag-interaction width=100%}\n:::\n:::\n\n\n@fig-dag-interaction-solved shows we need to condition on (adjust for) *both* $L_0$ and $Q_0$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Identification of causal interaction requires adjusting for all confounders of A-Y (L) and B-Y (Q). Boxes around L_A and L_B indicate conditioning, closing backdoor paths.](06-content_files/figure-html/fig-dag-interaction-solved-1.png){#fig-dag-interaction-solved width=80%}\n:::\n:::\n\n\nIn our education example:\n\n- **$L_A$ (Confounders for Teaching Method $\\to$ Score):** Prior achievement, motivation, family background (SES), school quality, teacher differences (if not randomly assigned).\n\n- **$L_B$ (Confounders for Tutoring $\\to$ Score):** Prior achievement, motivation, family background (SES - paying for tutoring), student availability, specific learning needs.\n\nNotice that prior achievement and motivation are in *both* $L_A$ and $L_B$. We need to measure and adjust for *all* important factors in $\\boxed{L_A}$ and $\\boxed{L_B}$ to get a reliable estimate for interaction.\n\n\n## Effect Modification: Different Effects for Different People\n\nUnlike interaction (about combining treatments), **effect modification** is about whether the causal effect of a *single* intervention ($A$) on an outcome ($Y$) is *different* for different subgroups in the population. These subgroups are defined by baseline characteristics (like age, sex, prior history - let's call these $G$ or $X$).\n\nEffect modification helps us understand *who* benefits most (or least) from an intervention. We explore this using ideas like Heterogeneous Treatment Effects (HTE) and Conditional Average Treatment Effects (CATE).\n\n\n### Heterogeneous Treatment Effects (HTE): The Idea of Variation\n\n**Heterogeneous Treatment Effects (HTE)** just means that the effect of a treatment ($A$ on $Y$) isn't the same for everyone. The effect *varies*. This variation *is* effect modification.\n\nWhy does it vary?\n\n- Differences in things we can measure (like age, sex, baseline health - our $X$ variables).\n- Differences in things we can't easily measure (like genetics, unmeasured background factors).\n\nHTE is the reality; treatments rarely work identically for all.\n\n\n### Conditional Average Treatment Effect (CATE): Measuring Variation with Data $\\tau(x)$\n\nTo study HTE using data, we focus on the\n\n**Conditional Average Treatment Effect (CATE)**. CATE is a specific *causal question (estimand)*: What is the average treatment effect *for the subgroup of people who share specific measured characteristics* $X=x$?\n\n$$\n\\tau(x) = \\text{CATE}(x) = \\mathbb{E}[Y(1) - Y(0) | X = x]\n$$\n\nHere, $Y(1)$ is the potential outcome with treatment, $Y(0)$ without. $\\tau(x)$ tells us the average effect specifically for people with characteristics $X=x$. By looking at how $\\tau(x)$ changes for different $x$, we quantify effect modification *by the characteristics we measured in X*.\n\n\n### Comparing Effects Across Defined Groups\n\nA simple way to check for effect modification by a category $G$ (like comparing males vs females, or different locations) is to estimate the Average Treatment Effect (ATE) *separately within each group*. This is like comparing CATEs where $X$ is just the group variable $G$.\n\nLet's say $A$ is the treatment (0=control, 1=treated) and $G$ is the potential modifier (e.g., $g=$female, $g'=$male).\n\nWe compare:\n\n1.  The average effect for females ($G=g_1$): $\\delta_{g_1} = \\mathbb{E}[Y(1) | G=g_1] - \\mathbb{E}[Y(0) | G=g_1]$\n\n2.  The average effect for males ($G=g_2$): $\\delta_{g_2} = \\mathbb{E}[Y(1) | G=g_2] - \\mathbb{E}[Y(0) | G=g_2]$\n\nEffect modification by $G$ exists if these are different: $\\gamma = \\delta_{g_1} - \\delta_{g_2} \\neq 0$.\n\nIf our estimate $\\hat{\\gamma}$ is far from zero, it suggests the treatment effect differs between males and females.\n\n#### Finding Effect Modification in Data\n\nTo estimate these group-specific effects ($\\delta_g$) and their difference ($\\gamma$) correctly, we need to control for confounders ($L$) of the $A \\to Y$ relationship within each group defined by $G$. Note that we are not estimating the causal effect of $G$. As such, we do not need to control for things that cause $G$ itself, *unless* they also confound the $A \\to Y$ relationship (i.e., are also in $L$).\n\nLook at @fig-dag-effect-modification. To estimate the $A \\to Y$ effect within levels of $G$, we need to adjust for the confounders $L_0$. But this will partially block the effect-modification of $G$ on $Y$ because $L_0$ is a mediator for that path.  Moreover, if we were identifying the causal effect of $G$ on $Y$, after conditioning on $L$, we would find that a backdoor path opens from $G \\to Y$ because $\\boxed{L}$ is a collider.  $G$ does not have a causal interpretation in this model. However we would be wrong to thing that $G$ is not and an effect modifier of the effect of $A$ on $Y$. (See Appendix C).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![How shall we investigate effect modification of A on Y by G? Can you see the problem?](06-content_files/figure-html/fig-dag-effect-modification-1.png){#fig-dag-effect-modification width=80%}\n:::\n:::\n\n\nThus it is essential to understand that when we control for confounding along the the $A \\to Y$ path, we do not identify the causal effects of effect-modifiers.\n\nTo clarify:\n\n1. If the statistical model correctly identifies causal effect modification (by appropriately handling confounders and avoiding collider bias), then it has prognostic value regarding the differential outcomes expected under intervention $A=1$ vs $A=0$ depending on $G=g$.\n\n2. If the statistical model contains interaction terms that are artifacts of bias (like conditioning on a collider) or reflect a different target (like conditioning on a mediator when the total effect was intended), its causal prognostic value is compromised or needs careful interpretation. It might still predict $Y$ well given $A$, $G$, and $L$ in an observational setting, but it wouldn't accurately predict the results of intervening on A differently for different $G$ groups. (See Appendix B).\n\nThe choice of variables fundamentally determines which causal question (if any) the statistical model is estimating. As with the average treatment effect, we interpret evidence for effect modification in the context of our assumptions about the causal relationships that obtain in the world.  This is because the statistical interaction we observe is highly sensitive to model choices. Any interpretation as causal effect modification, and therefore any reliable prognostic value for intervention effects within different segments of the population, depends entirely on whether and how our statistical model accounts for the causal structure.\n\n\n## Estimating How Effects Vary: Getting $\\hat{\\tau}(x)$ from Data\n\nWe defined the Conditional Average Treatment Effect (CATE), $\\tau(x)$, as the *true* average effect for a subgroup with specific features $X=x$:\n\n$$\n\\tau(x) = \\mathbb{E}[Y(1) - Y(0) | X = x]\n$$\n\nNow, we want to *estimate* this from our actual data. We call our estimate $\\hat{\\tau}(x)$. For any person $i$ in our study with features $X_i$, the value $\\hat{\\tau}(X_i)$ is our data-based *prediction* of the average treatment effect *for people like person i*.\n\n### \"Personalised\" Effects vs. True Individual Effects\n\nWait - didn't we say we *can't* know the true effect for one specific person, $Y_i(1) - Y_i(0)$? Yes, that's still true.\n\nSo what does $\\hat{\\tau}(X_i)$ mean?\n\n- **Individual Causal Effect (Unknowable):** $Y_i(1) - Y_i(0)$. This is the true effect for person $i$. We can't observe both $Y_i(1)$ and $Y_i(0)$.\n\n- **Estimated CATE ($\\hat{\\tau}(X_i)$) (What we calculate):** This is our estimate of the *average* effect, $\\mathbb{E}[Y(1) - Y(0)]$, for the *subgroup* of people who share the same measured characteristics $X_i$ as person $i$.\n\nWhen people talk about \"personalised\" or \"individualised\" treatment effects in this context, they usually mean $\\hat{\\tau}(x)$. It's \"personalised\" because the prediction uses person $i$'s specific characteristics $X_i = x$. But remember, it's an **estimated average effect for a group**, not the unique effect for that single individual.\n\n### People Have Many Characteristics\n\nPeople aren't just in one group; they have many features at once. A student might be:\n\n- Female\n- 21 years old\n- From a low-income family\n- Did well on previous tests\n- Goes to a rural school\n- Highly motivated\n\nAll these factors ($X_i$) together might influence how they respond to a new teaching method.\n\nTrying to figure this out with traditional regression by manually adding interaction terms (like `A*gender*age*income*...`) becomes impossible very quickly:\n\n- Too many combinations, not enough data in each specific combo.\n- High risk of finding \"effects\" just by chance (false positives).\n- Hard to know which interactions to even include.\n- Can't easily discover unexpected patterns.\n\nThus, while simple linear regression with interaction terms (`lm(Y ~ A * X1 + A * X2)`) can estimate CATEs if the model is simple and correct, it often fails when things get complex (many $X$ variables, non-linear effects).\n\n**Causal forests** (using the `grf` package in R) [@grf2024] are a powerful, flexible alternative designed for this task. They build decision trees that specifically aim to find groups with different treatment effects.\n\nWe'll learn how to use `grf` after the mid-term break. It will allow us to get the $\\hat{\\tau}(x)$ predictions and then think about how to use them, for instance, to prioritise who gets a treatment if resources are limited.\n\n\n<!-- This is where modern methods like **causal forests** come in, which we'll come back to after the mid-term break. -->\n\n<!-- ### Causal Forests: A Modern Tool for Estimating $\\hat{\\tau}(X)$ -->\n\n<!-- Causal forests (implemented in the R package `grf`) are designed for this complex situation. They are like random forests but built specifically to find differences in *treatment effects*. -->\n\n<!-- How they help: -->\n<!-- 1.  **Look at all features ($X$) at once:** They automatically search across all measured characteristics to see which ones explain differences in the treatment effect. -->\n<!-- 2.  **Flexible:** They don't assume simple linear relationships and can find complex patterns. -->\n<!-- 3.  **Local Averaging:** The estimate $\\hat{\\tau}(X_i)$ for person $i$ is based on the outcomes of other people in the data who are \"similar\" to person $i$ based on their characteristics $X$. -->\n<!-- 4.  **\"Honest\" Estimates:** They use clever statistical techniques (like splitting the data) to try and give reliable estimates and confidence intervals, reducing the risk of overfitting. -->\n\n<!-- The result is a prediction $\\hat{\\tau}(X_i)$ for each person $i$, based on their unique combination of measured features $X_i$. This gets us closer to understanding effect heterogeneity in a realistic way. -->\n\n<!-- ### Why Estimate CATEs ($\\hat{\\tau}(X)$)? -->\n\n<!-- Estimating $\\hat{\\tau}(X)$ is how we investigate HTE using our measured data $X$. We look at how $\\hat{\\tau}(X)$ changes across different types of people (different $X$ values) to: -->\n\n<!-- 1.  **See if the effect varies:** Go beyond the overall average (ATE) and see *if* and *how* the effect differs. -->\n\n<!-- 2.  **Find subgroups:** Identify groups (defined by $X$) who might benefit much more (or less, or even be harmed) by the intervention. -->\n\n<!-- 3.  **Inform targeted policies:** Use the predictions $\\hat{\\tau}(X_i)$ to investigate if giving the treatment only to those predicted to benefit most would lead to better outcomes overall (we'll evaluate this later using tools like RATE curves -- again this is all coming after the mid-term break). -->\n\n\n### Summary\n\nLet's revisit the core concepts:\n\n####  **Interaction:**\n\n- **Think:** Teamwork effect.\n- **What:** Effect of *two or more different interventions* ($A$ and $B$) applied together.\n- **Question:** Is the joint effect $\\mathbb{E}[Y(a,b)]$ different from the sum of individual effects?\n- **Needs:** Control confounders for *all* interventions involved ($L \\cup Q$).\n\n####  **Effect Modification / HTE / CATE:**\n- **Think:** Different effects for different groups.\n- **What:** Effect of a *single intervention* ($A$) varies depending on people's *baseline characteristics* ($G$ or $X$).\n- **Question (HTE):** *Does* the effect vary? (The phenomenon).\n-  **Question (CATE $\\tau(x)$):** *What is* the average effect for a specific subgroup with features $X=x$? (The measure).\n- **Needs:** Control confounders for the *single* intervention ($L$) within subgroups.\n\n#### **Estimated \"Individualised\" Treatment Effects ($\\hat{\\tau}(x)$):**\n- **Think:** Personal profile prediction.\n- **What:** Our *estimate* of the average treatment effect for the subgroup of people sharing characteristics $X_i$.\n- **How:** Calculated using models (like causal forests) that use the person's full profile $X_i$.\n- **Important:** This is **not** the true effect for that single person (which is unknowable). It's an average for *people like them*.\n- **Use:** Explore HTE, identify subgroups, potentially inform targeted treatment strategies.\n\nKeeping these concepts distinct helps us ask clear research questions and choose the right methods.\n\n\n## Course Review So Far: A Quick Recap\n\nLet's quickly review the main ideas of causal inference we've covered.\n\n### The Big Question: Does A cause Y?\n\nCausal inference helps us answer if something (like a teaching method, $A$) causes a change in something else (like test scores, $Y$).\n\n### Core Idea: \"What If?\" (Counterfactuals)\n\nWe compare what actually happened to what *would have happened* in a different scenario.\n\n- $Y(1)$: Score if the student *had* received the new method.\n- $Y(0)$: Score if the student *had* received the old method.\n\nThe **Average Treatment Effect (ATE)** = $\\mathbb{E}[Y(1) - Y(0)]$ is the average difference across the whole group.\n\n### This Lecture Clarified Concepts of Interaction vs. Effect Modification vs. Individual Predictions\n\n#### Interaction (Think: Teamwork Effects)\n\n- **About:** Combining *two different interventions* (A and B).\n- **Question:** Does using both A and B together give a result different from just adding up their separate effects? (e.g., new teaching method + tutoring).\n- **Needs:** Analyse effects of A alone, B alone, and A+B together. Control confounders for *both* A and B.\n\n#### Effect Modification (Think: Different Effects for Different Groups)\n\n- **About:** How the effect of *one intervention* (A) changes based on people's *characteristics* (X, like prior grades).\n- **Question:** Does the teaching method (A) work better for high-achieving students (X=high) than low-achieving students (X=low)?\n    - **HTE:** The *idea* that effects differ.\n    - **CATE $\\tau(x)$:** The *average effect* for the specific group with characteristics $X=x$.\n- **Needs:** Analyse effect of A *within* different groups (levels of X). Control confounders for A.\n\n#### Estimated Individualised Effects ($\\hat{\\tau}(X_i)$) (Think: Personal Profile Prediction)\n\n- **About:** Using a person's *whole profile* of characteristics ($X_i$ - age, gender, background, etc.) to predict their likely response to treatment A.\n- **How:** Modern methods (like causal forests) take all of $X_i$ and estimate $\\hat{\\tau}(X_i)$.\n- **Result:** this $\\hat{\\tau}(X_i)$ is **not** the true unknowable effect for person $i$. It is the estimated *average effect for people similar to person i* (sharing characteristics $X_i$).\n- **Use:** helps explore if tailoring treatment based on these profiles ($X_i$) could be beneficial.\n\n### Simple Summary:\n\n- **Interaction:** Do A and B work together well/badly?\n- **Effect Modification:** Does A's effect depend on *who* you are (based on X)?\n- **$\\hat{\\tau}(X_i)$:** Can we *predict* A's average effect for someone based on their specific profile $X_i$?\n\nUnderstanding these differences is key to doing good causal research!\n\n\n## Lab Part 1: Setting up your data\n\n\n### Set up your libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"margot\")\nlibrary(\"tidyverse\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"skimr\")\nif (!require(gtsummary)) install.packages(\"gtsummary\")\nif (!require(janitor)) install.packages(\"janitor\")\n\n\n# if you need to update the margot package, uncomment and do this\n# devtools::install_github(\"go-bayes/margot\")\n```\n:::\n\n\n\n\n\n### Set up a path to a folder in your directory \n\n\nThis will allow you to save the outputs of models and other information, which will be handy when you are producing your manuscript. Call this `push_mods`\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Set up a path to a folder in your directory \n\n# create a folder called saved and make a path like this\npush_mods <- here::here('/Users/joseph/v-project\\ Dropbox/data/courses/25-psych-434')\n\n# view it (will be different for you)\npush_mods\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"/Users/joseph/v-project Dropbox/data/courses/25-psych-434\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# another option\n# saveRDS(object, here::here(push_mods, \"object\"))\n```\n:::\n\n\n\n\n### Initial Data Wrangling to select the study sample\n\n#### Where to find variable names information\n\nFind it the data directory here: <https://osf.io/75snb/>\n\nAlso see here: <https://github.com/go-bayes/templates/tree/main/method>\n\n\n#### Think, what are my eligibility criteria? \n\n- Participated in at baseline\n- Participated at treatment wave\n- May have been lost to follow up at the end of the study\n- Full information on the treatment variable (think about this...)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(margot)\nlibrary(tidyverse)\nlibrary(table1)\nlibrary(gtsummary)\n\n# eliminate haven labels\ndf_nz <- as.data.frame(df_nz)\ndf_nz <- haven::zap_formats(df_nz)\ndf_nz <- haven::zap_label(df_nz)\ndf_nz <- haven::zap_widths(df_nz)\n\n# name output folder\npush_mods <- here::here(\"outputs\")\n\n# set exposure name\nname_exposure <-  \"perfectionism\"\n\n# obtain ids for individuals who participated in 2018 and have no missing baseline exposure\nids_2018 <- df_nz %>%\n   dplyr::filter(year_measured == 1, wave == 2018) %>%\n   dplyr::filter(!is.na(!!sym(name_exposure))) |> # criteria, no missing\n  pull(id)\n\n# obtain ids for individuals who participated in 2019\nids_2019 <- df_nz %>%\n   dplyr::filter(year_measured == 1, wave == 2019) %>%\n   dplyr::filter(!is.na(!!sym(name_exposure))) |> # criteria, no missing\n  pull(id)\n\n# intersect IDs from 2018 and 2019 to ensure participation in both years\nids_2018_2019 <- intersect(ids_2018, ids_2019)\n\n# data wrangling\ndat_long <- df_nz |>\n  dplyr::filter(id %in% ids_2018_2019 &\n                  wave %in% c(2018, 2019, 2020)) |>\n  arrange(id, wave) |>\n  select(\n    \"id\",\n    \"wave\",\n    \"year_measured\",\n    \"age\",\n    \"male\",\n    \"born_nz\",\n    \"eth_cat\",\n    #factor(EthCat, labels = c(\"Euro\", \"Maori\", \"Pacific\", \"Asian\")),\n    \"employed\",\n    # Are you currently employed? (this includes self-employment or casual work)\n    \"edu\",\n    # \"gen_cohort\",\n    \"household_inc\",\n    \"partner\",\n    # 0 = no, 1 = yes\n    \"parent\",\n    \"alert_level_combined_lead\", # see bibliography\n    # 0 = no, 1 = yes\n    \"political_conservative\", # see nzavs sheet\n    \"hours_exercise\", # see nzavs sheet\n    \"agreeableness\", \n    # Mini-IPIP6 Agreeableness (also modelled as empathy facet)\n    # Sympathize with others' feelings.\n    # Am not interested in other people's problems.\n    # Feel others' emotions.\n    # Am not really interested in others.\n    \"conscientiousness\",\n    # see mini ipip6\n    # Get chores done right away.\n    # Like order.\n    # Make a mess of things.\n    # Often forget to put things back in their proper place.\n    \"extraversion\",\n    # Mini-IPIP6 Extraversion\n    # Am the life of the party.\n    # Don't talk a lot.\n    # Keep in the background.\n    # Talk to a lot of different people at parties.\n    \"honesty_humility\",\n    # see mini ipip6\n    # Would like to be seen driving around in a very expensive car.\n    # Would get a lot of pleasure from owning expensive luxury goods.\n    # Feel entitled to more of everything.\n    # Deserve more things in life.\n    \"openness\",\n    # see mini ipip6\n    # Have a vivid imagination.\n    # Have difficulty understanding abstract ideas.\n    # Do not have a good imagination.\n    # Am not interested in abstract ideas.\n    \"neuroticism\",\n    # see mini ipip6\n    # Have frequent mood swings.\n    # Am relaxed most of the time.\n    # Get upset easily.\n    # Seldom feel blue.\n    \"modesty\",\n    # # see mini ipip6\n    # # I want people to know that I am an important person of high status,\n    # # I am an ordinary person who is no better than others.\n    # # I wouldnâ€™t want people to treat me as though I were superior to them.\n    # # I think that I am entitled to more respect than the average person is\n    #\"w_gend_age_ethnic\",\n    \"sample_weights\", # see nzavs sheet\n    \"neighbourhood_community\",\n    # #I feel a sense of community with others in my local neighbourhood.\n    \"belong\", # see nzavs sheet\n    \"rural_gch_2018_l\",# see nzavs sheet\n    \"support\",\n    # \"support_help\",\n    # # 'There are people I can depend on to help me if I really need it.\n    # \"support_turnto\",\n    # # There is no one I can turn to for guidance in times of stress.\n    # \"support_rnoguidance\",\n    #There is no one I can turn to for guidance in times of stress.\n    \"perfectionism\",\n    \"religion_religious\",\n    \"kessler_latent_depression\",\n    \"kessler_latent_anxiety\"\n  ) |>\n  mutate(\n    #initialize 'censored'\n    censored = ifelse(lead(year_measured) == 1, 1, 0),\n    \n    # modify 'censored' based on the condition; no need to check for NA here as 'censored' is already defined in the previous step\n    censored =  ifelse(is.na(censored) &\n                         year_measured == 1, 1, censored)\n  ) |>\n  select(-year_measured) |>\n  dplyr::mutate(\n    # rescale these variables, to get all variables on a similar scale\n    # otherwise your models can blow up, or become uninterpretable. \n    household_inc_log = log(household_inc + 1),\n    hours_exercise_log = log(hours_exercise + 1)  ) |>\n  dplyr::select(\n    -c(\n      household_inc,\n      hours_exercise)\n  ) |>\n  droplevels() |>\n  # dplyr::rename(sample_weights = w_gend_age_ethnic,\n  #               sample_origin =  sample_origin_names_combined) |>\n  arrange(id, wave) |>\n  mutate(\n  rural_gch_2018_l = as.numeric(as.character(rural_gch_2018_l)),\n  #   parent = as.numeric(as.character(parent)),\n  partner = as.numeric(as.character(partner)),\n  born_nz = as.numeric(as.character(born_nz)),\n  censored = as.numeric(as.character(censored)),\n  employed = as.numeric(as.character(employed))\n  ) |>\n  droplevels() |>\n  data.frame() |>\n  droplevels() |>\n  arrange(id, wave) |>\n  data.frame()\n\n# check n in this sample\nn_participants <- skimr::n_unique(dat_long$id)\n\n\n# make number pretty\nn_participants<- prettyNum(n_participants,big.mark=\",\")\n\n# save this so that you can use it in your manuscript\nmargot::here_save(n_participants, \"n_participants\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nObject saved to: /Users/joseph/GIT/psych-434-2025/outputs/n_participants.rds\nObject size: 0.00 MB\nðŸ‘ Save operation completed successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\n# try reading \nn_participants_did_it_work_question_mark <- margot::here_read(\"n_participants\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nObject read from: /Users/joseph/GIT/psych-434-2025/outputs/n_participants.rds\nObject size: 0.00 MB\nðŸ‘ Read operation completed successfully!\n```\n\n\n:::\n\n```{.r .cell-code}\n# view\n# n_participants_did_it_work_question_mark\n```\n:::\n\n\nThere are N = 14,439 participants.\n\n### Define your baseline covariates, treatment (exposure), and outcome\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# for example \nbaseline_vars = c(\"age\", \"male\", \"edu\", \"eth_cat\", \"partner\", \"employed\", \"born_nz\", \"neighbourhood_community\", \"household_inc_log\",\n\"parent\", \"religion_religious\", \"rural_gch_2018_l\",\"sample_weights\", \"employed\", \"alert_level_combined_lead\")\n\n# treatment\nexposure_var = c(\"perfectionism\", \"censored\") # we will use the censored variable later\n\n# outcome, can be many\noutcome_vars = c(\"kessler_latent_anxiety\", \"kessler_latent_depression\")\n\n# define waves\nbaseline_wave = \"2018\"\n\n# exposure waves\nexposure_waves = c(\"2018\",\"2019\")\n\n#outcome wave\noutcome_wave = \"2020\"\n\n# exoposure\nname_exposure = \"perfectionism\"\n```\n:::\n\n\n\n### Make your baseline table\n\n\n### Make tables\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntables <- margot::margot_summary_tables(dat_long, \nexposure_waves = exposure_waves, \nbaseline_wave = baseline_wave, \noutcome_wave = outcome_wave, \nname_exposure = name_exposure, \nbaseline_vars = baseline_vars, \noutcome_vars = outcome_vars)\n\n\n# save tables\n# margot::here_save_qs(table_exposures, \"table_exposures\", push_mods)\n```\n:::\n\n\n## Baseline table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntables$baseline_table\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"jlyhlgnbeg\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#jlyhlgnbeg table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#jlyhlgnbeg thead, #jlyhlgnbeg tbody, #jlyhlgnbeg tfoot, #jlyhlgnbeg tr, #jlyhlgnbeg td, #jlyhlgnbeg th {\n  border-style: none;\n}\n\n#jlyhlgnbeg p {\n  margin: 0;\n  padding: 0;\n}\n\n#jlyhlgnbeg .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#jlyhlgnbeg .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#jlyhlgnbeg .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#jlyhlgnbeg .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#jlyhlgnbeg .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#jlyhlgnbeg .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#jlyhlgnbeg .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#jlyhlgnbeg .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#jlyhlgnbeg .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#jlyhlgnbeg .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#jlyhlgnbeg .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#jlyhlgnbeg .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#jlyhlgnbeg .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#jlyhlgnbeg .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#jlyhlgnbeg .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jlyhlgnbeg .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#jlyhlgnbeg .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#jlyhlgnbeg .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#jlyhlgnbeg .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jlyhlgnbeg .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#jlyhlgnbeg .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jlyhlgnbeg .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#jlyhlgnbeg .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jlyhlgnbeg .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#jlyhlgnbeg .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#jlyhlgnbeg .gt_left {\n  text-align: left;\n}\n\n#jlyhlgnbeg .gt_center {\n  text-align: center;\n}\n\n#jlyhlgnbeg .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#jlyhlgnbeg .gt_font_normal {\n  font-weight: normal;\n}\n\n#jlyhlgnbeg .gt_font_bold {\n  font-weight: bold;\n}\n\n#jlyhlgnbeg .gt_font_italic {\n  font-style: italic;\n}\n\n#jlyhlgnbeg .gt_super {\n  font-size: 65%;\n}\n\n#jlyhlgnbeg .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#jlyhlgnbeg .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#jlyhlgnbeg .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#jlyhlgnbeg .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#jlyhlgnbeg .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#jlyhlgnbeg .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#jlyhlgnbeg .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#jlyhlgnbeg .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#jlyhlgnbeg div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"><span data-qmd-base64=\"PHN0cm9uZz5FeHBvc3VyZSArIERlbW9ncmFwaGljIFZhcmlhYmxlczwvc3Ryb25nPg==\"><span class='gt_from_md'><strong>Exposure + Demographic Variables</strong></span></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"stat_0\"><span data-qmd-base64=\"PHN0cm9uZz5OID0gMTQsNDM5PC9zdHJvbmc+\"><span class='gt_from_md'><strong>N = 14,439</strong></span></span><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Age</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Mean (SD)</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">50 (14)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Min, Max</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">18, 94</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Q1, Q3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">41, 61</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Alert Level Combined Lead</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â no_alert</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">10,261 (71%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â early_covid</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">1,617 (11%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â alert_level_1</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">1,272 (8.8%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â alert_level_2</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">366 (2.5%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â alert_level_2_5_3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">253 (1.8%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â alert_level_4</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">670 (4.6%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Born Nz</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">11,398 (79%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">25</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Edu</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Mean (SD)</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">5.38 (2.72)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Min, Max</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">0.00, 10.00</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Q1, Q3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">3.00, 7.00</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">110</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Employed</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">11,466 (80%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">22</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Eth Cat</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â euro</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">11,835 (83%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â maori</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">1,526 (11%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â pacific</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">314 (2.2%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â asian</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">655 (4.6%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">109</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Household Inc log</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Mean (SD)</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">11.41 (0.74)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Min, Max</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">0.71, 14.40</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Q1, Q3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">11.00, 11.92</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">655</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Male</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">5,238 (36%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Neighbourhood Community</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Mean (SD)</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">4.23 (1.66)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Min, Max</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">1.00, 7.00</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Q1, Q3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">2.99, 5.95</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">73</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Parent</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">10,350 (72%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">8</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Partner</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">10,661 (76%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">399</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Religion Religious</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">5,218 (36%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">19</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Rural Gch 2018 l</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â 1</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">8,822 (62%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â 2</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">2,784 (19%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â 3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">1,740 (12%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â 4</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">820 (5.7%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â 5</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">170 (1.2%)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">103</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Sample Weights</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Mean (SD)</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">0.94 (1.22)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Min, Max</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">0.30, 19.96</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Q1, Q3</td>\n<td headers=\"stat_0\" class=\"gt_row gt_center\">0.40, 1.03</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"2\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span> <span data-qmd-base64=\"biAoJSk=\"><span class='gt_from_md'>n (%)</span></span></td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\n\n## Exposure table\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tables$exposure_tables\n```\n:::\n\n\n\n# Outcome table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntables$outcome_table\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"lfgsusmcbk\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#lfgsusmcbk table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#lfgsusmcbk thead, #lfgsusmcbk tbody, #lfgsusmcbk tfoot, #lfgsusmcbk tr, #lfgsusmcbk td, #lfgsusmcbk th {\n  border-style: none;\n}\n\n#lfgsusmcbk p {\n  margin: 0;\n  padding: 0;\n}\n\n#lfgsusmcbk .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#lfgsusmcbk .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#lfgsusmcbk .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#lfgsusmcbk .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#lfgsusmcbk .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#lfgsusmcbk .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#lfgsusmcbk .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#lfgsusmcbk .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#lfgsusmcbk .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#lfgsusmcbk .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#lfgsusmcbk .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#lfgsusmcbk .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#lfgsusmcbk .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#lfgsusmcbk .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#lfgsusmcbk .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lfgsusmcbk .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#lfgsusmcbk .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#lfgsusmcbk .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#lfgsusmcbk .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lfgsusmcbk .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#lfgsusmcbk .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lfgsusmcbk .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#lfgsusmcbk .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lfgsusmcbk .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#lfgsusmcbk .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#lfgsusmcbk .gt_left {\n  text-align: left;\n}\n\n#lfgsusmcbk .gt_center {\n  text-align: center;\n}\n\n#lfgsusmcbk .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#lfgsusmcbk .gt_font_normal {\n  font-weight: normal;\n}\n\n#lfgsusmcbk .gt_font_bold {\n  font-weight: bold;\n}\n\n#lfgsusmcbk .gt_font_italic {\n  font-style: italic;\n}\n\n#lfgsusmcbk .gt_super {\n  font-size: 65%;\n}\n\n#lfgsusmcbk .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#lfgsusmcbk .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#lfgsusmcbk .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#lfgsusmcbk .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#lfgsusmcbk .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#lfgsusmcbk .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#lfgsusmcbk .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#lfgsusmcbk .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#lfgsusmcbk div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"label\"><span data-qmd-base64=\"PHN0cm9uZz5PdXRjb21lIFZhcmlhYmxlcyBieSBXYXZlPC9zdHJvbmc+\"><span class='gt_from_md'><strong>Outcome Variables by Wave</strong></span></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"stat_1\"><span data-qmd-base64=\"PHN0cm9uZz4yMDE4PC9zdHJvbmc+PGJyIC8+Ck4gPSAxNCw0Mzk=\"><span class='gt_from_md'><strong>2018</strong><br />\nN = 14,439</span></span><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"stat_2\"><span data-qmd-base64=\"PHN0cm9uZz4yMDIwPC9zdHJvbmc+PGJyIC8+Ck4gPSAxNCw0Mzk=\"><span class='gt_from_md'><strong>2020</strong><br />\nN = 14,439</span></span><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Kessler Latent Anxiety</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">1.04 (0.65, 1.67)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">1.03 (0.65, 1.67)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">148</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">2,893</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\" style=\"font-weight: bold;\">Kessler Latent Depression</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">0.31 (0.01, 0.96)</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">0.31 (0.01, 0.96)</td></tr>\n    <tr><td headers=\"label\" class=\"gt_row gt_left\">Â Â Â Â Unknown</td>\n<td headers=\"stat_1\" class=\"gt_row gt_center\">152</td>\n<td headers=\"stat_2\" class=\"gt_row gt_center\">2,890</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"3\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span> <span data-qmd-base64=\"TWVkaWFuIChRMSwgUTMp\"><span class='gt_from_md'>Median (Q1, Q3)</span></span></td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n\n### Inspect the distribution of the exposure in treatment wave\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# select 2019 wave\ndt_19 <- dat_long |> dplyr::filter(wave == 2019)\n\n# mean\nmean_exposure <-mean(dt_19$perfectionism, na.rm=TRUE)\n\n# median\nmedian_exposure <-median(dt_19$perfectionism, na.rm=TRUE)\n\n# check if you like\n# median_exposure\n# mean_exposure\n# generate bar plot\ngraph_density_of_exposure_up <- margot::margot_plot_shift(\n  dt_19,\n  shift = \"up\",\n  col_name = \"perfectionism\",\n  binwidth = .25, \n  range_highlight = c(0,mean_exposure)\n)\n\n# show\ngraph_density_of_exposure_up\n```\n\n::: {.cell-output-display}\n![](06-content_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# save\n#margot::here_save(graph_density_of_exposure_up, \"graph_density_of_exposure_up\")\n```\n:::\n\n\n\n\n### Check for change in the treatment (Positivity)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#  select data from wave 18 and 19 \ndt_18_19_positivity <- dat_long |>\n  dplyr::filter(wave == 2018 | wave == 2019) |>\n  dplyr::mutate(perfectionism_round = round(perfectionism, digits = 0)) |>\n  dplyr::select(perfectionism_round, id, wave) |>\n  droplevels()\n\nout <-margot::margot_transition_table(data = dt_18_19_positivity, state_var = \"perfectionism_round\", id_var = \"id\", wave_var = \"wave\")\n\n# table\nout$tables[[1]]\n```\n\n::: {.cell-output-display}\n\n\n|From / To | State 1| State 2| State 3| State 4| State 5| State 6| State 7| Total|\n|:---------|-------:|-------:|-------:|-------:|-------:|-------:|-------:|-----:|\n|State 1   |     893|     484|     194|      40|      16|       3|       2|  1632|\n|State 2   |     657|    1737|     904|     283|      78|       9|       1|  3669|\n|State 3   |     237|    1073|    1368|     768|     245|      40|       5|  3736|\n|State 4   |      66|     335|     803|    1076|     523|     108|      10|  2921|\n|State 5   |      24|      77|     253|     531|     579|     223|      26|  1713|\n|State 6   |       7|       9|      38|     106|     205|     216|      53|   634|\n|State 7   |       2|       1|       5|       8|      25|      45|      48|   134|\n\n\n:::\n\n```{.r .cell-code}\n# for import later\n# margot::here_save(transition_table, \"transition_table\")\n```\n:::\n\n\n\n### Explanation for the table\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncat(out$explanation)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nThese transition matrices capture shifts in states between consecutive waves. Each cell represents the count of individuals transitioning from one state to another. The rows correspond to the initial state (From), and the columns correspond to the subsequent state (To). **Diagonal entries** (in **bold**) correspond to individuals who remained in the same state. **Off-diagonal entries** correspond to individuals who transitioned to a different state.\n\nA higher number on the diagonal relative to off-diagonal entries indicates greater stability in a state. Conversely, higher off-diagonal numbers suggest more frequent shifts between states.\n```\n\n\n:::\n:::\n\n\n\n\n## Lab Part 2: Simulation to Clarify Why The Distribution of Effect Modifiers Matter For Estimating Treatment Effects \n\n\nFirst, we load the `stdReg` library, which obtains marginal effect estimates by simulating counterfactuals under different levels of treatment [@sjÃ¶lander2016]. If a treatment is continuous, the levels can be specified. \n\nWe also load the `parameters` library, which creates nice tables [@parameters2020].\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# to obtain marginal effects\nlibrary(stdReg)\n# to create nice tables\nlibrary(parameters)\n```\n:::\n\n\nNext, we write a function to simulate data for the sample and and target populations. \n\nWe assume the treatment effect is the same in the sample and target population. We will assume that the coefficient for the effect-modifier and the coefficient for interaction are the same.  We assume no unmeasured confounding throughout the study.  We assume only selective attrition of one effect modifier such that the baseline population differs from the sample population at the end of the study.   \n\nThat is: **the distribution of effect modifiers is the only respect in which the sample will differ from the target population.**\n\nThis function will generate data under a range of scenarios.[^margot]\n\n[^margot]: See documentation in the `margot` package: @margot2024\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# function to generate data for the sample and population, \n# along with precise sample weights for the population, there are differences \n# in the distribution of the true effect modifier but no differences in the treatment effect \n# or the effect modification.all that differs between the sample and the population is \n# the distribution of effect-modifiers.\n\n\n# reproducability\nset.seed(123)\n\n# simulate the data -- you can use different parameters\ndata <- margot::simulate_ate_data_with_weights(\n  n_sample = 10000,\n  n_population = 100000,\n  p_z_sample = 0.1,\n  p_z_population = 0.5,\n  beta_a = 1,\n  beta_z = 2.5,\n  noise_sd = 0.5\n)\n\n# view\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ sample_data    :'data.frame':\t10000 obs. of  4 variables:\n  ..$ y_sample: num [1:10000] 1.1854 -0.0834 1.4635 -0.2841 2.6125 ...\n  ..$ a_sample: int [1:10000] 0 0 1 0 0 0 1 1 1 0 ...\n  ..$ z_sample: int [1:10000] 0 0 0 0 1 0 0 0 0 0 ...\n  ..$ weights : num [1:10000] 0.556 0.556 0.556 0.556 5 ...\n $ population_data:'data.frame':\t100000 obs. of  3 variables:\n  ..$ y_population: num [1:100000] 0.331 1.982 -0.446 1.117 0.916 ...\n  ..$ a_population: int [1:100000] 1 0 0 1 1 0 0 1 0 0 ...\n  ..$ z_population: int [1:100000] 0 1 0 0 0 0 0 0 0 0 ...\n```\n\n\n:::\n:::\n\n\nOk, we have generated both sample and population data. \n\nNext, we verify that the distributions of effect modifiers differ in the sample and in the target population:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# obtain the generated data\nsample_data <- data$sample_data\npopulation_data <- data$population_data\n\n\n# check imbalance\ntable(sample_data$z_sample) # type 1 is rare\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n   0    1 \n9055  945 \n```\n\n\n:::\n\n```{.r .cell-code}\ntable(population_data$z_population) # type 1 is common\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n    0     1 \n49916 50084 \n```\n\n\n:::\n:::\n\n\n\n\nGood, the distributions differ. The simulation is working as intended.\n\nNext, consider the question: \"What are the differences in the coefficients that we obtain from the study population at the end of study, as compared with the target population?\"  \n\nFirst, we obtain the coefficients for the sample. They are as follows:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model coefficients sample\nmodel_sample  <-\n  glm(y_sample ~ a_sample * z_sample, data = sample_data)\n\n# summary\nparameters::model_parameters(model_sample, ci_method = \"wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter           | Coefficient |       SE |        95% CI | t(9996) |      p\n-------------------------------------------------------------------------------\n(Intercept)         |   -6.89e-03 | 7.38e-03 | [-0.02, 0.01] |   -0.93 | 0.350 \na sample            |        1.01 |     0.01 | [ 0.99, 1.03] |   95.84 | < .001\nz sample            |        2.47 |     0.02 | [ 2.43, 2.52] |  104.09 | < .001\na sample Ã— z sample |        0.51 |     0.03 | [ 0.44, 0.57] |   14.82 | < .001\n```\n\n\n:::\n:::\n\n\nOk, let's obtain the coefficients for the weighted regression of the sample.   Notice that the coefficients are virtually the same:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model the sample weighted to the population, again note that these coefficients are similar \nmodel_weighted_sample <-\n  glm(y_sample ~  a_sample  * z_sample,\n      data = sample_data,\n      weights = weights)\n\n# summary\nsummary(parameters::model_parameters(model_weighted_sample, ci_method =\n                                       \"wald\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter           | Coefficient |        95% CI |      p\n----------------------------------------------------------\n(Intercept)         |   -6.89e-03 | [-0.03, 0.01] | 0.480 \na sample            |        1.01 | [ 0.98, 1.04] | < .001\nz sample            |        2.47 | [ 2.45, 2.50] | < .001\na sample Ã— z sample |        0.51 | [ 0.47, 0.55] | < .001\n\nModel: y_sample ~ a_sample * z_sample (10000 Observations)\nSigma: 0.494 (df = 9996)\n```\n\n\n:::\n:::\n\n\n\nWe might be tempted to infer that weighting wasn't relevant to the analysis. However, we'll see that such an interpretation would be a mistake.\n\n\nNext, let us obtain model coefficients for the population. Note again there is no difference -- only narrower errors owing to the large sample size. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# model coefficients population -- note that these coefficients are very similar. \nmodel_population <-\n  glm(y_population ~ a_population * z_population, data = population_data)\n\nparameters::model_parameters(model_population, ci_method = \"wald\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParameter                   | Coefficient |       SE |        95% CI | t(99996) |      p\n----------------------------------------------------------------------------------------\n(Intercept)                 |    2.49e-03 | 3.18e-03 | [ 0.00, 0.01] |     0.78 | 0.434 \na population                |        1.00 | 4.49e-03 | [ 0.99, 1.01] |   222.35 | < .001\nz population                |        2.50 | 4.49e-03 | [ 2.49, 2.51] |   556.80 | < .001\na population Ã— z population |        0.50 | 6.35e-03 | [ 0.49, 0.51] |    78.80 | < .001\n```\n\n\n:::\n:::\n\n\n\nAgain, there is no difference. That is, we find that all model coefficients are practically equivalent. The different distribution of effect modifiers does not result in different coefficient values for the treatment effect, the effect-modifier \"effect,\" or the interaction of effect modifier and treatment. \n\nConsider why this is the case: in a large sample where the causal effects are invariant -- as we have simulated them to be -- we will have good replication in the effect modifiers within the sample, so our statistical model can recover the *coefficients* for the population -- no problem. \n\nHowever, **in causal inference, we are interested in obtaining the marginal effect of the treatment**. That is, we seek an estimate for the counterfactual contrast in which everyone in a pre-specified population was subject to one level of treatment compared with a counterfactual condition in which everyone in a population was subject to another level of the same treatment. **When the sample population differs in the distribution of effect modifiers from the target population effect, the marginal effect estimates will typically differ.**\n\nTo see this, we use the `stdReg` package to recover marginal effect estimates, comparing (1) the sample ATE, (2) the true oracle ATE for the population, and (3) the weighted sample ATE.  We will use the outputs of the same models above. The only difference is that we will calculate marginal effects from these outputs. We will contrast a difference from an intervention in which everyone receives treatment = 0 with one in which everyone receives treatment = 1, however, this choice is arbitrary, and the general lessons apply irrespective of the estimand.\n\n\nFirst, consider this ATE for the sample population. \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# What inference do we draw?  We cannot say the models are unbiased for the marginal effect estimates. \n# regression standardisation \nlibrary(stdReg) # to obtain marginal effects \n\n\n# obtain sample ate\nfit_std_sample <-\n  stdReg::stdGlm(model_sample, data = sample_data, X = \"a_sample\")\n\n# summary\nsummary(fit_std_sample,\n        contrast = \"difference\",\n        reference = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: y_sample ~ a_sample * z_sample\nFamily: gaussian \nLink function: identity \nExposure:  a_sample \nReference level:  a_sample = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00     0.0000       0.00       0.00\n1     1.06     0.0101       1.04       1.08\n```\n\n\n:::\n:::\n\n\nThe treatment effect is given as a 1.06 unit change in the outcome across the sample population, with a confidence interval from 1.04 to 1.08. \n\n\nNext, we obtain the true (oracle) treatment effect for the population under the same intervention.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## note the population effect is different\n\n#obtain true ate\nfit_std_population <-\n  stdReg::stdGlm(model_population, data = population_data, X = \"a_population\")\n\n# summary\nsummary(fit_std_population,\n        contrast = \"difference\",\n        reference = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: y_population ~ a_population * z_population\nFamily: gaussian \nLink function: identity \nExposure:  a_population \nReference level:  a_population = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00    0.00000       0.00       0.00\n1     1.25    0.00327       1.24       1.26\n```\n\n\n:::\n:::\n\n\n\nNote, the true treatment effect is a 1.25 unit change in the population, with a confidence bound between 1.24 and 1.26. This is well outside the ATE that we obtain from the sample population!\n\n\n\nNext, consider the ATE in the weighted regression, where the sample was weighted to the target population's true distribution of effect modifiers. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## next try weights adjusted ate where we correctly assign population weights to the sample\nfit_std_weighted_sample_weights <- stdReg::stdGlm( model_weighted_sample, \n    data = sample_data, \n    X = \"a_sample\")\n\n# this gives us the right answer\nsummary(fit_std_weighted_sample_weights, \n    contrast = \"difference\", \n    reference = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nFormula: y_sample ~ a_sample * z_sample\nFamily: gaussian \nLink function: identity \nExposure:  a_sample \nReference level:  a_sample = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00     0.0000       0.00       0.00\n1     1.25     0.0172       1.22       1.29\n```\n\n\n:::\n\n```{.r .cell-code}\n# moral of the story. when we marginalise over the entire sample we need to weight estimates to the target population. \n```\n:::\n\n\n\nWe find that we obtain the population-level causal effect estimate with accurate coverage by weighting the sample to the target population. So with appropriate weights, our results generalise from the sample to the target population.\n\n\n## Lessons from Lab 2\n\n- Regression coefficients do not clarify the problem of sample/target population mismatch -- or selection bias as discussed here.\n- The correct advice to investigators is that they should not rely on regression coefficients when evaluating the biases that arise from sample attrition. This advice applies to both methods that the authors use to investigate threats of bias. That is, to implement this advice, the authors must first take it.\n- Generally, observed data are insufficient for assessing threats. Observed data do not clarify structural sources of bias, nor do they clarify effect-modification across the full counterfactual data conditions, in which (1) all receive the treatment and (2) all do not receive the treatment (at the same level).\n- To properly assess bias, one would need access to the counterfactual outcomeâ€”what would have happened to the missing participants had they not been lost to follow-up or had they responded. Again, the join distributions over \"full data\" are inherently unobservable [@vanderlaan2011]. \n- In simple settings like the one we just simulated, we may address the gap between the sample and target population using methods such as modelling the censoring (e.g., censoring weighting). However, we never know what setting we are in or whether it is simpleâ€”such modelling must be handled with care. There is a large and growing epidemiology literature on this topic (see, for example, @li2023non).\n<!-- - Matters become more complex when there is confounding and selection bias because the problem is not merely one of external validity but also internal validity (i.e. obtaining valid causal effect estimates for the baseline sample). See for example @scharfstein1999adjusting; @laan2003unified; @howe2016selection (note that @howe2016selection, \"selection\" bias is defined as collider stratification bias, a variety of confounding bias and not simple sample and target population mismatch.)   -->\n\n## Appendix A: Simplification of Additive Interaction Formula\n\nWe start with the definition of additive interaction based on comparing the joint effect relative to baseline versus the sum of individual effects relative to baseline:\n\n$$\n\\Big(\\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(0,0)]\\Big) - \\Big[\\Big(\\mathbb{E}[Y(1,0)] - \\mathbb{E}[Y(0,0)]\\Big) + \\Big(\\mathbb{E}[Y(0,1)] - \\mathbb{E}[Y(0,0)]\\Big)\\Big]\n$$\n\nFirst, distribute the negative sign across the terms within the square brackets:\n\n$$\n\\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(0,0)] - \\Big(\\mathbb{E}[Y(1,0)] - \\mathbb{E}[Y(0,0)]\\Big) - \\Big(\\mathbb{E}[Y(0,1)] - \\mathbb{E}[Y(0,0)]\\Big)\n$$\n\nNow remove the parentheses, flipping the signs inside them where preceded by a minus sign:\n\n$$\n\\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(0,0)] - \\mathbb{E}[Y(1,0)] + \\mathbb{E}[Y(0,0)] - \\mathbb{E}[Y(0,1)] + \\mathbb{E}[Y(0,0)]\n$$\n\nNext, combine the $\\mathbb{E}[Y(0,0)]$ terms:\n\n* We have $-\\mathbb{E}[Y(0,0)]$\n* Then $+\\mathbb{E}[Y(0,0)]$ (these two cancel each other out)\n* And another $+\\mathbb{E}[Y(0,0)]$ remains.\n\nThe expression simplifies to:\n\n$$\n\\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(1,0)] - \\mathbb{E}[Y(0,1)] + \\mathbb{E}[Y(0,0)]\n$$\n\nThis is the standard definition of additive interaction, often called the interaction contrast. If this expression equals zero, there is no additive interaction; a non-zero value indicates an interaction effect.\n\n**This shows clearly that interaction is the deviation of the joint effect from the sum of the separate effects, adjusted for the baseline.**\n\n\n## Appendix B:  Evidence for effect-modification is relative to inclusion of other variables in the model\n\nThe 'sharp-null hypothesis' states there is no effect of the exposure on\nthe outcome for any unit in the target population. Unless the 'sharp-null hypothesis' is false, there may be effect-modification. For any study worth conducting, we cannot evaluate whether the sharp-null hypothesis is false. If we could the experiment would be otiose. Therefore, we must assume the possibility of effect-modification. Notably, whether a variable is an effect-modifier also depends on which other variables are included in the model. That is, just as for the concept of a 'confounder', where a variable is an 'effect-modifier' cannot be stated without reference to an assumed causal order and an explicit statement about which other variables will be included in the model [@vanderweele2012].\n\nAs illustrated in  @fig-eff-mod-rel, the marginal association between $A$ and $Y$ is unbiased. Here, exposure $A$ is unconditionally associated with $Y$. Recall our convention <svg width=\"40px\" height=\"40px\"><circle cx=\"20\" cy=\"20\" r=\"18\" fill=\"none\" stroke=\"blue\" stroke-width=\"2\"/><text x=\"20\" y=\"20\" alignment-baseline=\"middle\" text-anchor=\"middle\" fill=\"blue\" font-size=\"16\">G</text></svg> denotes effect-modification with conditioning and <svg width=\"40px\" height=\"40px\"><circle cx=\"20\" cy=\"20\" r=\"18\" fill=\"none\" stroke=\"blue\" stroke-width=\"2\" stroke-dasharray=\"4,4\"/><text x=\"20\" y=\"20\" alignment-baseline=\"middle\" text-anchor=\"middle\" fill=\"blue\" font-size=\"16\">Z</text></svg> indicates effect-modification without conditioning.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Consider a randomised experiment. There is no confounding. Here, the marginal association between A and Y provides an unbiased estimate for the causal effect of A on Y. Does the conditional association of A on Y vary within levels of G? The causal diagram allows for a classification of G as an effect modifier of A on Y by proxy. G modifies A's effect on Y in virtue of G's relationship to Z, which, according to this graph, is a direct effect modifier for the effect of A on Y.](06-content_files/figure-html/fig-eff-mod-rel-1.png){#fig-eff-mod-rel width=80%}\n:::\n:::\n\n\n@fig-dag-effect-modificationb presents the same a randomised experiment as in the previous causal diagram. We again assume that there is no confounding of the marginal association between the exposure, $A$, and the outcome, $Y$. However, suppose we were to adjust for $Z$ and ask, does the conditional association of $A$ on $Y$ vary within levels of $G$, after adjusting for $Z$? That is, does $G$ remain an effect-modifier of the exposure on the outcome? @vanderweele2007 proved that for effect-modification to occur, at least one other arrow besides the treatment must enter into the outcome. According to @fig-dag-effect-modificationb the only arrow into $Y$ other than $A$ arrives from $Z$. Because $Y$ is independent of $G$ conditional on $Z$ we may infer that $G$ is no longer an effect modifier for the effect of $A$ on $Y$. Viewed another way, $G$ no longer co-varies with $Y$\nconditional on $Z$ and so cannot act as an effect-modifier.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Conditioning on Z renders G independent of Y. G is no longer an effect modifier after conditioning on Z because G is independent of Y. Although Z is an unconditional effect modifier, G is not.](06-content_files/figure-html/fig-dag-effect-modificationb-1.png){#fig-dag-effect-modificationb width=80%}\n:::\n:::\n\n\n@fig-dag-effect-modificationc presents the same a randomised experiment as in the previous graph. We assume a true effect of $A \\rightarrow Y$. If we do not condition on $B$, then $G$ will not modify the effect of $A  \\rightarrow Y$ because $G$ will not be associated with $Y$. However, if we were to condition on $B$, then both $B$ (an effect modifier by proxy) and $G$ may become effect-modifiers for the causal effect of $A$ on $Y$. In this setting, both $B$ and $G$ are conditional effect-modifiers.\n\nNote that casual graphs help us to evaluate classifications of conditional and unconditional effect modifiers. They may also help to clarify conditions in which conditioning on unconditional effect-modifiers may remove conditional effect-modification. However we cannot not tell from a causal diagram whether the ancestors of an\nunconditional effect-modifier will be conditional effect-modifiers for the effect of the exposure on the outcome; see: @vanderweele2007, also @suzuki2013counterfactual. Causal diagrams express non-parametric relations. I have adopted an off-label colouring convention to denote instances of effect-modification to highlight possible pathways for effect-modification, which may be relative to other variables in a model.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Blue path denotes effect-modification for G by conditioning on B. Both B and G are conditional effect modifiers.](06-content_files/figure-html/fig-dag-effect-modificationc-1.png){#fig-dag-effect-modificationc width=80%}\n:::\n:::\n\n\n@fig-dag-effect-modificationd reveals the relativity of effect-modification. If investigators do not condition on $B$, then $G$\ncannot be a conditional effect-modifier because $G$ would then be independent of $Z$ because $B$ is a collider. However, as we observed in\n@fig-dag-effect-modificationc, conditioning on $B$, a collider, may open a path for effect-modification of $G$ by $Z$. Both $B$ and $G$ are\nconditional effect modifiers.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Blue path denotes effect-modification. Here G is not an effect modifier because B, a common effect (collider) of G and Z, is not conditioned on. Any conditional effect modification for G would require conditioning on B, and not-conditioning on G. Otherwise G will be d-separated from Y.](06-content_files/figure-html/fig-dag-effect-modificationd-1.png){#fig-dag-effect-modificationd width=80%}\n:::\n:::\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Blue path denotes effect-modification. Neither, G nor B are unconditional effect-modifiers for the effect of A on Y after Z is conditioned upon. If investigators condition on Z, the causal diagram implies they will not find evidence for effect-modification by B or G, which are conditionally independent of Y once Z is conditioned upon.](06-content_files/figure-html/fig-dag-effect-modification5c-1.png){#fig-dag-effect-modification5c width=80%}\n:::\n:::\n\n\n@fig-dag-effect-modification5c considers the implications of\nconditioning on $Z$, which is the only unconditional effect-modifier on\nthe graph. If $Z$ is measured, conditioning on $Z$ will remove\neffect-modification for $B$ and $G$ because $B,G\\coprod Y |Z$. This\nexamples again reveals the context dependency of effect-modification.\nHere, causal diagrams are useful for clarifying features of dependent\nand independent effect modification. For further discussion, see:\n@suzuki2013counterfactual; @vanderweele2009distinction.\n\n### Appendix C: Futher Clarification on Effect Modification Without Statistical Evidence for It.\n\n\nAgain, look at @fig-dag-effect-modification. Suppose the investigator model the effect of $A$ on $Y$.  Suppose G is not associated with $Y$ conditional on $L$.  @fig-dag-effect-modification provides structural clarification for why concluding there is no effect modification by $G$ is incorrect.\n\nTo clarify: \n- We have a DAG structure: $G \\to L$; $L \\to A$, $L \\to Y$\n- We're interested in the conditional average treatment effect (CATE): $\\tau(g) = E[Y(1) - Y(0)| G = g]$\n- To identify the effect of $A$ on $Y$, we must condition on $\\boxed{L}$\n- $G$ is (partially or fully) d-separated from $Y$ conditional on $\\boxed{L}$\n\nEven though $G$ is d-separated from $Y$ given $L$, this doesn't mean $G$ can't modify the effect of $A$ on $Y$. The CATE for a specific value of $G$ can be expressed as:\n\n\n$$\\tau(g) = E[Y(1) - Y(0)| G = g] = E[E[Y(1) - Y(0)| L, G = g]| G = g]$$\n\nSince $G$ is d-separated from $Y$ given $L$:\n\n$$Ï„(g) = E[E[Y(1) - Y(0)| L]| G = g]$$\n\nThis means $Ï„(g)$ is a weighted average of the L-specific treatment effects, where the weights are determined by the distribution of L given $G=g$.\n\nIf two conditions are met:\n1. The effect of $A$ on $Y$ varies across levels of $L$\n2. The distribution of $L$ varies with $G$ (which it does, since $G \\to L$)\n\nThen $\\tau(g)$ will vary with $g$, indicating effect modification by $G$.\n\nThe investigators are would be wrong to equate d-separation with absence of effect modification. Although $G$ doesn't directly affect $Y$ after conditioning on $L$, $G$ can still modify the effect of $A$ on $Y$ through its influence on the distribution of $L$.\n\n\n\n\n### Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreport::cite_packages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 <https://doi.org/10.5281/zenodo.10907724>, R package version 0.3.3.3 Functions to obtain MARGinal Observational Treatment-effects from observational data., <https://go-bayes.github.io/margot/>.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, <https://CRAN.R-project.org/package=janitor>.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - LÃ¼decke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.\n  - MÃ¼ller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, <https://CRAN.R-project.org/package=here>.\n  - MÃ¼ller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - R Core Team (2025). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Rich B (2023). _table1: Tables of Descriptive Statistics in HTML_. R package version 1.4.3, <https://CRAN.R-project.org/package=table1>.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible Summary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580. doi:10.32614/RJ-2021-053 <https://doi.org/10.32614/RJ-2021-053>, <https://doi.org/10.32614/RJ-2021-053>.\n  - Sjolander A, Dahlqwist E (2021). _stdReg: Regression Standardization_. R package version 3.4.1, <https://CRAN.R-project.org/package=stdReg>.\n  - Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022). _skimr: Compact and Flexible Summaries of Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=skimr>.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, FranÃ§ois R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, MÃ¼ller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, FranÃ§ois R, Henry L, MÃ¼ller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n",
    "supporting": [
      "06-content_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}