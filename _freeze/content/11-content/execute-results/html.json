{
  "hash": "3dd1ac739b4966723488bb49a1d16d6e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Hands on Measurement: Exploratory Factor Analysis, Confirmatory Factor Analysis (CFA), Multigroup Confirmatory Factor Analysis, Partial Invariance (Configural, Metric, and Scalar equivalence).\"\ndate: \"2025-MAY-27\"\nbibliography: /Users/joseph/GIT/templates/bib/references.bib\neditor_options: \n  chunk_output_type: console\nformat:\n  html:\n    warnings: FALSE\n    error: FALSE\n    messages: FALSE\n    code-overflow: scroll\n    highlight-style: kate\n    code-tools:\n      source: true\n      toggle: FALSE\nhtml-math-method: katex\nreference-location: margin\ncitation-location: margin\ncap-location: margin\ncode-block-border-left: true\n---\n\n\n\n\n\n::: {.callout-readings}\n### Required Readings\n- [@fischer2019primer] [link](https://www.dropbox.com/scl/fi/1h8slzy3vzscvbtp6yrjh/FischeKarlprimer.pdf?rlkey=xl93d5y7280c1qjhn3k2g8qls&dl=0)\n\n### Optional Readings \n- [@Vijver2021CulturePsychology] [link](https://doi.org/10.1017/9781107415188)\n- [@he2012] [link](https://www.dropbox.com/scl/fi/zuv4odmxbz8dbtdjfap3e/He-BiasandEquivalence.pdf?rlkey=wezprklb4jm6rgvvx0g58nw1n&dl=0ā)\n- [@Harkness2003TRANSALTION] [link](https://www.dropbox.com/scl/fi/hmmje9vbunmcu3oiahaa5/Harkness_CC_translation.pdf?rlkey=6vqq3ap5n52qp7t1e570ubpgt&dl=0)\n:::\n\n::: {.callout-important}\n## Key concepts\n- EFA\n- CFA\n- Multigroup CFA\n- Invariance Testing (configural, metric, scalar)\n:::\n\n::: {.callout-important}\n- You need to know these measurement concepts\n:::\n\n\n#### Readings\n\n- [@fischer2019primer] [link](https://www.dropbox.com/scl/fi/1h8slzy3vzscvbtp6yrjh/FischeKarlprimer.pdf?rlkey=xl93d5y7280c1qjhn3k2g8qls&dl=0)\n\n##### Optional Readings \n\n- [@Vijver2021CulturePsychology] [link](https://doi.org/10.1017/9781107415188)\n- [@he2012] [link](https://www.dropbox.com/scl/fi/zuv4odmxbz8dbtdjfap3e/He-BiasandEquivalence.pdf?rlkey=wezprklb4jm6rgvvx0g58nw1n&dl=0ā)\n- [@Harkness2003TRANSALTION] [link](https://www.dropbox.com/scl/fi/hmmje9vbunmcu3oiahaa5/Harkness_CC_translation.pdf?rlkey=6vqq3ap5n52qp7t1e570ubpgt&dl=0)\n\n#### Lab\n\n- R exercises focusing on measurement theory applications and graphing\n\n\n## Overview\nBy the conclusion of our session, you will gain proficiency in:\n\n- Exploratory Factor Analysis,\n- Confirmatory Factor Analysis (CFA),\n- Multigroup Confirmatory Factor Analysis,\n- Partial Invariance (configural, metric, and scalar equivalence) \n\nWe will learn these concepts by doing an analysis.\n\n## Focus on Kessler-6 Anxiety\n\nThe code below will:\n\n-   Load required packages.\n-   Select the Kessler 6 items\n-   Check whether there is sufficient correlation among the variables to support factor analysis.\n\n#### Select A Scale To Validate: Kessler 6 Distress\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get synthetic data\nlibrary(margot)\nlibrary(tidyverse)\nlibrary(performance)\n\n# update margot\n# uncomment\n# devtools::install_github(\"go-bayes/margot\")\n\n\n# select the columns of the kesser-6 need. \ndt_only_k6 <- df_nz |> \n  filter(wave == 2018) |> \n  select(\n    kessler_depressed,\n    kessler_effort,\n    kessler_hopeless,\n    kessler_worthless,\n    kessler_nervous,\n    kessler_restless\n  )\n\n\n# check factor structure\nperformance::check_factorstructure(dt_only_k6)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Is the data suitable for Factor Analysis?\n\n\n  - Sphericity: Bartlett's test of sphericity suggests that there is sufficient significant correlation in the data for factor analysis (Chisq(15) = 50402.32, p < .001).\n  - KMO: The Kaiser, Meyer, Olkin (KMO) overall measure of sampling adequacy suggests that data seems appropriate for factor analysis (KMO = 0.87). The individual KMO scores are: kessler_depressed (0.85), kessler_effort (0.90), kessler_hopeless (0.86), kessler_worthless (0.85), kessler_nervous (0.90), kessler_restless (0.88).\n```\n\n\n:::\n:::\n\n### Practical Definitions of the Kessler-6 Items\n\n- The `df_nz` is loaded with the `margot` package. It is a synthetic dataset. \n- take items from the Kessler-6 (K6) scale: depressed, effort, hopeless, worthless, nervous, and restless [@kessler2002; @kessler2010].\n-  The Kessler-6 is used as a diagnostic screening tool for depression for physicians in New Zealand \n\n\nThe Kessler-6 (K6) is a widely-used diagnostic screening tool designed to identify levels of psychological distress that may indicate mental health disorders such as depression and anxiety. Physicians in New Zealand to screen patients quickly [@krynen2013measuring]. Each item on the Kessler-6 asks respondents to reflect on their feelings and behaviors over the past 30 days, with responses provided on a five-point ordinal scale: \n\n1. **\"...you feel hopeless\"**\n   - **Interpretation**: This item measures the frequency of feelings of hopelessness. It assesses a core symptom of depression, where the individual perceives little or no optimism about the future.\n\n2. **\"...you feel so depressed that nothing could cheer you up\"**\n   - **Interpretation**: This statement gauges the depth of depressive feelings and the inability to gain pleasure from normally enjoyable activities, a condition known as anhedonia.\n\n3. **\"...you feel restless or fidgety\"**\n   - **Interpretation**: This item evaluates agitation and physical restlessness, which are common in anxiety disorders but can also be present in depressive states.\n\n4. **\"...you feel that everything was an effort\"**\n   - **Interpretation**: This query assesses feelings of fatigue or exhaustion with everyday tasks, reflecting the loss of energy that is frequently a component of depression.\n\n5. **\"...you feel worthless\"**\n   - **Interpretation**: This item measures feelings of low self-esteem or self-worth, which are critical indicators of depressive disorders.\n\n6. **\"...you feel nervous\"**\n   - **Interpretation**: This question is aimed at identifying symptoms of nervousness or anxiety, helping to pinpoint anxiety disorders.\n\n#### Response Options\n\nThe ordinal response options provided for the Kessler-6 are designed to capture the frequency of these symptoms, which is crucial for assessing the severity and persistence of psychological distress:\n\n- **1. \"None of the time\"**: The symptom was not experienced at all.\n- **2. \"A little of the time\"**: The symptom was experienced infrequently.\n- **3. \"Some of the time\"**: The symptom was experienced occasionally.\n- **4. \"Most of the time\"**: The symptom was experienced frequently.\n- **5. \"All of the time\"**: The symptom was constantly experienced.\n\n\nIn clinical practice, higher scores on the Kessler-6 are indicative of greater distress and a higher likelihood of a mental health disorder. Physicians use a sum score of 13 to decide on further diagnostic evaluations or immediate therapeutic interventions. \n\nThe simplicity and quick administration of the Kessler-6 make it an effective tool for primary care settings in New Zealand, allowing for the early detection and management of mental health issues. Let's stop to consider this measure. Do the items in this scale cohere? Do they all relate to depression? Might we quantitatively evaluate \"coherence\" in this scale?  \n\n\n### Exploratory Factor Analysis\n\nWe employ `performance::check_factorstructure()` to evaluate the data's suitability for factor analysis. Two tests are reported:\n\na. **Bartlett's Test of Sphericity**\n\nBartlett's Test of Sphericity is used in psychometrics to assess the appropriateness of factor analysis for a dataset. It tests the hypothesis that the observed correlation matrix of is an identity matrix, which would suggest that all variables are orthogonal (i.e., uncorrelated) and therefore, factor analysis is unlikely to be appropriate. (Appendix A.)\n\nThe outcome:\n\n- **Chi-square (Chisq)**: 50402.32 with **Degrees of Freedom (15)** and a **p-value** < .001\n\nThis highly reliable result (p < .001) confirms that the observed correlation matrix is not an identity matrix, substantiating the factorability of the dataset.\n\nb. **Kaiser-Meyer-Olkin (KMO) Measure**\n\nThe KMO test assesses sampling adequacy by comparing the magnitudes of observed correlation coefficients to those of partial correlation coefficients. A KMO value nearing 1 indicates appropriateness for factor analysis. The results are:\n\n- **Overall KMO**: 0.87\n  - This value suggests good sampling adequacy, indicating that the sum of partial correlations is relatively low compared to the sum of correlations, thus supporting the potential for distinct and reliable factors.\n\nEach item’s KMO value exceeds the acceptable threshold of 0.5,so suitabale for factor analysis.\n\n\n#### Explore Factor Structure \n\nThe following R code allows us to perform exploratory factor analysis (EFA) on the Kessler 6 (K6) scale data, assuming three latent factors. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# exploratory factor analysis\n# explore a factor structure made of 3 latent variables\n\nlibrary(\"psych\")\nlibrary(\"parameters\")\n\n\n# do efa\nefa <- psych::fa(dt_only_k6, nfactors = 3) |>\n  model_parameters(sort = TRUE, threshold = \"max\")\n\nprint( efa )\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Rotated loadings from Factor Analysis (oblimin-rotation)\n\nVariable          |  MR3 |  MR1 |  MR2 | Complexity | Uniqueness\n----------------------------------------------------------------\nkessler_hopeless  | 0.79 |      |      |       1.00 |       0.32\nkessler_worthless | 0.79 |      |      |       1.01 |       0.34\nkessler_depressed |      | 0.99 |      |       1.00 |   4.98e-03\nkessler_restless  |      |      | 0.72 |       1.03 |       0.47\nkessler_nervous   |      |      | 0.43 |       1.91 |       0.57\nkessler_effort    |      |      | 0.38 |       2.00 |       0.53\n\nThe 3 latent factors (oblimin rotation) accounted for 62.94% of the total variance of the original data (MR3 = 28.20%, MR1 = 17.56%, MR2 = 17.18%).\n```\n\n\n:::\n:::\n\n####  Explore Factor Structure\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(psych)\nefa <- psych::fa(dt_only_k6, nfactors = 3) |>\n  model_parameters(sort = TRUE, threshold = \"max\")\nprint(efa)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Rotated loadings from Factor Analysis (oblimin-rotation)\n\nVariable          |  MR3 |  MR1 |  MR2 | Complexity | Uniqueness\n----------------------------------------------------------------\nkessler_hopeless  | 0.79 |      |      |       1.00 |       0.32\nkessler_worthless | 0.79 |      |      |       1.01 |       0.34\nkessler_depressed |      | 0.99 |      |       1.00 |   4.98e-03\nkessler_restless  |      |      | 0.72 |       1.03 |       0.47\nkessler_nervous   |      |      | 0.43 |       1.91 |       0.57\nkessler_effort    |      |      | 0.38 |       2.00 |       0.53\n\nThe 3 latent factors (oblimin rotation) accounted for 62.94% of the total variance of the original data (MR3 = 28.20%, MR1 = 17.56%, MR2 = 17.18%).\n```\n\n\n:::\n:::\n\n#### What is \"Rotation\"?\n\nIn factor analysis, rotation is a mathematical technique applied to the factor solution to make it more interpretable. Rotation is like adjusting the angle of a camera to get a better view. When we rotate the factors, we are not changing the underlying data, just how we are looking at it, to make the relationships between variables and factors clearer and more meaningful.\n\nThe main goal of rotation is to achieve a simpler and more interpretable factor structure. This simplification is achieved by **making the factors as distinct as possible,** by aligning them closer with specific variables, which makes it easier to understand what each factor represents. Think of orthogonal rotation like organising books on a shelf so that each book only belongs to one category. Each category (factor) is completely independent of the others.\n\nThere are two types:\n\n**Orthogonal rotations** (such as Varimax), which assume that the factors are uncorrelated and keep the axes at 90 degrees to each other. This is useful when we assume that the underlying factors are independent.\n\n**Oblique rotations** (such as Oblimin), which allow the factors to correlate. Returning to our analogy, imagine a more complex library system where some categories of books overlap; for example, \"history\" might overlap with \"political science\". Oblique rotation recognises and allows these overlaps.This is more realistic in psychological and social sciences, ... here, we believe that stress and anxiety might naturally correlate with each other, so Oblique rotation is a better option.\n\n#### Results \n\nUsing oblimin rotation, the items loaded as follows on the three factors:\n\n- **MR3**: Strongly associated with 'kessler_hopeless' (0.79) and 'kessler_worthless' (0.79). This factor might be capturing aspects related to feelings of hopelessness and worthlessness, often linked with depressive affect.\n- **MR1**: Mostly linked with 'kessler_depressed' (0.99), suggesting this factor represents core depressive symptoms.\n- **MR2**: Includes 'kessler_restless' (0.72), 'kessler_nervous' (0.43), and 'kessler_effort' (0.38). This factor seems to encompass symptoms related to anxiety and agitation.\n\nThe **complexity** values indicate the number of factors each item loads on \"significantly.\"  A complexity near 1.00 suggests that the item predominantly loads on a single factor, which is seen with most of the items except for 'kessler_nervous' and 'kessler_effort', which show higher complexity and thus share variance with more than one factor.\n\n**Uniqueness** values represent the variance in each item not explained by the common factors. Lower uniqueness values for items like 'kessler_depressed' indicate that the factor explains most of the variance for that item.\n\n#### Variance Explained\n\nThe three factors together account for 62.94% of the total variance in the data, distributed as follows:\n\n- **MR3**: 28.20%\n- **MR1**: 17.56%\n- **MR2**: 17.18%\n\nThis indicates a substantial explanation of the data’s variance by the model, with the highest contribution from the factor associated with hopelessness and worthlessness.\n\n\n#### Consensus View?\n\nThere are different algorithms for assessing the factor structure.  The performance package allows us to consider a 'consensus' view.\n\n\n::: {.cell .column-page-right}\n\n```{.r .cell-code  code-fold=\"true\"}\nn <-n_factors(dt_only_k6)\nn\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Method Agreement Procedure:\n\nThe choice of 1 dimensions is supported by 8 (50.00%) methods out of 16 (Optimal coordinates, Acceleration factor, Parallel analysis, Kaiser criterion, Scree (SE), Scree (R2), VSS complexity 1, Velicer's MAP).\n```\n\n\n:::\n\n```{.r .cell-code  code-fold=\"true\"}\n# plot\nplot(n) + theme_classic()\n```\n\n::: {.cell-output-display}\n![](11-content_files/figure-html/plot_factors-1.png){width=672}\n:::\n:::\n\nOutput: \n\n> The choice of 1 dimensions is supported by 8 (50.00%) methods out of 16 (Optimal coordinates, Acceleration factor, Parallel analysis, Kaiser criterion, Scree (SE), Scree (R2), VSS complexity 1, Velicer's MAP). \n\n\nThe result indicates that a single dimension is supported by half of the methods used (8 out of 16).  However science isn't a matter of voting. Also, does it make sense that there is one latent factor here?  Let's press on...\n\n\n### Confirmatory Factor Analysis (ignoring groups)\n\nCFA to validate the hypothesised factor structures derived from EFA. \n\n- **One-factor model**: assumes all items measure a single underlying construct.\n- **Two-factor model**: assumes two distinct constructs measured by the items.\n- **Three-factor model**: assumes three distinct constructs measured by the items.\n\nSteps are:\n\n#### 1. Data Partition\n\nFirst, we take the dataset (`dt_only_k6`) and partition it into training and testing sets. This division helps in validating the model built on the training data against an unseen test set; this enhances robustness for the factor analysis findings.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\npart_data <- datawizard::data_partition(dt_only_k6, training_proportion = .7, seed = 123)\ntraining <- part_data$p_0.7\ntest <- part_data$test\n```\n:::\n\n#### 2. Model Setup for CFA\n\nBases on the EFA results, we consider three different factor structures\n\n- **One-factor model**: assumes all items measure a single underlying construct.\n- **Two-factor model**: assumes two distinct constructs measured by the items.\n- **Three-factor model**: assumes three distinct constructs measured by the items.\n\nWe fit each model to the training data:\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-factor model\nstructure_k6_one <- psych::fa(training, nfactors = 1) |>\n  efa_to_cfa()\n\n# Two-factor model\nstructure_k6_two <- psych::fa(training, nfactors = 2) |>\n  efa_to_cfa()\n\n# Three-factor model\nstructure_k6_three <- psych::fa(training, nfactors = 3) %>%\n  efa_to_cfa()\n```\n:::\n\n\nThen we split our data for cross-validation\n\n::: {.cell}\n\n```{.r .cell-code}\n# first partition the data \npart_data <- datawizard::data_partition(dt_only_k6, traing_proportion = .7, seed = 123)\n\n\n# set up training data\ntraining <- part_data$p_0.7\ntest <- part_data$test\n\n\n# one factor model\nstructure_k6_one <- psych::fa(training, nfactors = 1) |>\n  efa_to_cfa()\n\n# two factor model model\nstructure_k6_two <- psych::fa(training, nfactors = 2) |>\n  efa_to_cfa()\n\n# three factor model\nstructure_k6_three <- psych::fa(training, nfactors = 3) %>%\n  efa_to_cfa()\n\n# inspect models\nstructure_k6_one\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Latent variables\nMR1 =~ kessler_depressed + kessler_effort + kessler_hopeless + kessler_worthless + kessler_nervous + kessler_restless + .row_id\n```\n\n\n:::\n\n```{.r .cell-code}\nstructure_k6_two\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Latent variables\nMR1 =~ kessler_depressed + kessler_hopeless + kessler_worthless\nMR2 =~ kessler_effort + kessler_nervous + kessler_restless + .row_id\n```\n\n\n:::\n\n```{.r .cell-code}\nstructure_k6_three\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Latent variables\nMR1 =~ kessler_depressed + kessler_hopeless + kessler_worthless\nMR2 =~ kessler_effort\nMR3 =~ kessler_nervous + kessler_restless + .row_id\n```\n\n\n:::\n:::\n\n- **One-Factor Model**: All items are linked to a single factor (`MR1`).\n  \n- **Two-Factor Model**: \n  - `MR1` is linked with `kessler_depressed`, `kessler_hopeless`, and `kessler_worthless`, suggesting these items might represent a more depressive aspect of **distress.**\n  - `MR2` is associated with `kessler_effort`, `kessler_nervous`, and `kessler_restless`, which could indicate a different aspect, perhaps related to **anxiety or agitation.**\n\n- **Three-Factor Model**: \n  - `MR1` includes `kessler_depressed`, `kessler_effort`, `kessler_hopeless`, and `kessler_worthless`, indicating a broad factor possibly encompassing overall distress.\n  - `MR2` consists solely of `kessler_effort`.\n  - `MR3` includes `kessler_nervous` + `kessler_restless`, which might imply these are distinctivene from other distress components.\n  \n\nDo these results make sense?  Note they are different from the Exploratory Factor Analysis. Why might that be? \n  \n  \nNext we perform the confirmatory factor analysis itself...\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit and compare models\n\n# one latent model\none_latent <-\n  suppressWarnings(lavaan::cfa(structure_k6_one, data = test))\n\n# two latents model\ntwo_latents <-\n  suppressWarnings(lavaan::cfa(structure_k6_two, data = test))\n\n# three latents model\nthree_latents <-\n  suppressWarnings(lavaan::cfa(structure_k6_three, data = test))\n\n\n# compare models\ncompare <-\n  performance::compare_performance(one_latent, two_latents, three_latents, verbose = FALSE)\n\n# select cols we want\nkey_columns_df <- compare[, c(\"Model\", \"Chi2\", \"Chi2_df\", \"CFI\", \"RMSEA\", \"RMSEA_CI_low\", \"RMSEA_CI_high\", \"AIC\", \"BIC\")]\n\n# view as html table\nas.data.frame(key_columns_df) |>\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n\n\n|Model  |      Chi2| Chi2_df|       CFI|     RMSEA| RMSEA_CI_low| RMSEA_CI_high|      AIC|      BIC|\n|:------|---------:|-------:|---------:|---------:|------------:|-------------:|--------:|--------:|\n|lavaan | 805.47732|      14| 0.9468004| 0.0985415|    0.0928176|     0.1043876| 195671.0| 195764.3|\n|lavaan | 161.24069|      13| 0.9900359| 0.0442564|    0.0382928|     0.0504917| 195028.7| 195128.8|\n|lavaan |  80.53628|      12| 0.9953933| 0.0313209|    0.0250361|     0.0379798| 194950.0| 195056.7|\n\n\n:::\n:::\n\n####  Metrics:\n\n- **Chi2 (Chi-Square Test)**: A lower Chi2 value indicates a better fit of the model to the data.\n- **df (Degrees of Freedom)**: Reflects the model complexity.\n- **CFI (Comparative Fit Index)**: Values closer to 1 indicate a better fit. A value above 0.95 is generally considered to indicate a good fit.\n- **RMSEA (Root Mean Square Error of Approximation)**: values less than 0.05 indicate a good fit, and values up to 0.08 are acceptable.\n- **AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion)**: lower values are better, indicating a more parsimonious model, with the BIC imposing a penalty for model complexity.\n\n#### Model Selection:\n\nWhat do you think? \n\n- The **Three Latents Model** shows the best fit across all indicators, having the lowest Chi2, RMSEA, and the highest CFI. It also has the lowest AIC and BIC scores, suggesting it not only fits well but is also the most parsimonious among the tested models. \n\nBut... \n\n- **The CFI** for the two-factor model is 0.990, which is close to 1 and suggests a very good fit to the data. This is superior to the one-factor model (CFI = 0.9468) and slightly less than the three-factor model (CFI = 0.9954). A CFI value closer to 1 indicates a better fit of the model to the data.\n\n- **Root Mean Square Error of Approximation (RMSEA):** The two-factor model has an RMSEA of 0.0443, which is within the excellent fit range (below 0.05). It significantly improves upon the one-factor model's RMSEA of 0.0985 and is only slightly worse than the three-factor model's 0.0313.\n\n- **BIC* isn't much different, So\n\nWe might say the two-factor model strikes a balance between simplicity and model fit. It has fewer factors than the three-factor model, making it potentially easier to interpret while still capturing the variance in the data.\n\nLook at the items. What do you think? \n\nDoes Anxiety appear to differ from Depression? \n\n\n\n\n### Measurement Invariance in Multi-group Confirmatory Factor Analysis\n\nWhen we use tools like surveys or tests to measure psychological constructs (like distress, intelligence, satisfaction), we often need to ensure that these tools work similarly across different groups of people. This is crucial for fair comparisons. Think of it as ensuring that a ruler measures inches or centimeters the same way, whether you are in Auckland or Wellington.\n\n#### Levels of Measurement Invariance\n\nMeasurement invariance tests how consistently a measure operates across different groups, such as ethnic or gender groups. Consider how we can understand it through the K6 Distress Scale applied to different demographic groups in New Zealand:\n\n1. **Configural Invariance**\n\n   - **What it means**: The measure's structure is the same across groups. Imagine you have a toolkit; configural invariance means that everyone has the same set of tools (screwdrivers, hammers, wrenches) in their kits.\n   - **Application**: For the K6 Distress Scale, both Māori and New Zealand Europeans use the same six questions to gauge distress. However, how strongly each question predicts distress can vary between the groups. (Not we are using \"prediction\" here -- we are only assessessing associations.)\n\n2. **Metric Invariance**\n   - **What it means**: The strength of the relationship between each tool (question) and the construct (distress) is consistent across groups. If metric invariance holds, turning a screw (answering a question about feeling nervous) tightens the screw by the same amount no matter who uses the screwdriver.\n   - **Application**: A unit change in the latent distress factor affects scores on questions (like feeling nervous or hopeless) equally for Māori and New Zealand Europeans. \n\n3. **Scalar Invariance**\n   - **What it means**: Beyond having the same tools and relationships, everyone starts from the same baseline. If scalar invariance holds. It is like ensuring that every screwdriver is calibrated to the same torque setting before being used.\n   - **Application**: The actual scores on the distress scale mean the same thing across different groups. If a Māori scores 15 and a New Zealander of European descent scores 15, both are experiencing a comparable level of distress.\n\n#### Concept of \"Partial Invariance\"\n\nSometimes, not all conditions for full metric or scalar invariance are met, which could hinder meaningful comparisons across groups. This is where the concept of \"partial invariance\" comes into play.\n\n**Partial Invariance** occurs when invariance holds for some but not all items of the scale across groups. Imagine if most, but not all, tools in the kits behaved the same way across different groups. If sufficient items (tools) exhibit invariance, the measure might still be usable for certain comparisons.\n\n- **Metric Partial Invariance**: This might mean that while most items relate similarly to the underlying factor across groups, one or two do not. Researchers might decide that there’s enough similarity to proceed with comparisons of relationships (correlations) but should proceed with caution.\n\n- **Scalar Partial Invariance**: Here, most but not all items show the same intercepts across groups. It suggests that while comparisons of the construct means can be made, some scores might need adjustments or nuanced interpretation.\n\n\nIn practical terms, achieving partial invariance in your analysis allows for some comparisons but signals a need for careful interpretation and potentially more careful analysis. For instance, if partial scalar invariance is found on the K6 Distress Scale, researchers might compare overall distress levels between Māori and New Zealand Europeans but should acknowledge that differences in certain item responses might reflect measurement bias rather than true differences in distress.\n\n\nThe upshot is that understanding these levels of invariance helps ensure that when we compare mental health or other constructs across different groups, we are making fair and meaningful comparisons. Partial invariance offers a flexible approach to handle real-world data where not all conditions are perfectly met. This approach allows researchers to acknowledge and account for minor discrepancies while still extracting valuable insights from their analyses.\n\nThe following script runs multi-group confirmatory factor analysis (MG-CFA) to assess the invariance of the Kessler 6 (K6) distress scale across two ethnic groups: European New Zealanders and Māori.\n\n::: {.cell}\n\n```{.r .cell-code}\n# select needed columns plus 'ethnicity'\n# filter dataset for only 'euro' and 'maori' ethnic categories\ndt_eth_k6_eth <- df_nz |> \n  filter(wave == 2018) |> \n  filter(eth_cat == \"euro\" | eth_cat == \"maori\") |> \n  select(kessler_depressed, kessler_effort, kessler_hopeless,\n         kessler_worthless, kessler_nervous, kessler_restless, eth_cat)\n\n# partition the dataset into training and test subsets\n# stratify by ethnic category to ensure balanced representation\npart_data_eth <- datawizard::data_partition(dt_eth_k6_eth, training_proportion = .7, seed = 123, group = \"eth_cat\")\n\ntraining_eth <- part_data_eth$p_0.7\ntest_eth <- part_data_eth$test\n\n# configural invariance models\n#run CFA models specifying one, two, and three latent variables without constraining across groups\none_latent_eth_configural <- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", data = test_eth))\ntwo_latents_eth_configural <- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", data = test_eth))\nthree_latents_eth_configural <- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\", data = test_eth))\n\n# compare model performances for configural invariance\ncompare_eth_configural <- performance::compare_performance(one_latent_eth_configural, two_latents_eth_configural, three_latents_eth_configural, verbose = FALSE)\ncompare_eth_configural\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# Comparison of Model Performance Indices\n\nName                         |  Model |    Chi2 | Chi2_df | p (Chi2)\n--------------------------------------------------------------------\none_latent_eth_configural    | lavaan | 612.807 |  28.000 |   < .001\ntwo_latents_eth_configural   | lavaan | 129.992 |  26.000 |   < .001\nthree_latents_eth_configural | lavaan |  85.047 |  24.000 |   < .001\n\nName                         | Baseline(42) | p (Baseline) |   GFI |  AGFI\n--------------------------------------------------------------------------\none_latent_eth_configural    |    13146.709 |       < .001 | 0.987 | 0.967\ntwo_latents_eth_configural   |    13146.709 |       < .001 | 0.997 | 0.993\nthree_latents_eth_configural |    13146.709 |       < .001 | 0.998 | 0.995\n\nName                         |   NFI |  NNFI |   CFI | RMSEA |    RMSEA  CI\n---------------------------------------------------------------------------\none_latent_eth_configural    | 0.953 | 0.933 | 0.955 | 0.089 | [0.08, 0.09]\ntwo_latents_eth_configural   | 0.990 | 0.987 | 0.992 | 0.039 | [0.03, 0.05]\nthree_latents_eth_configural | 0.994 | 0.992 | 0.995 | 0.031 | [0.02, 0.04]\n\nName                         | p (RMSEA) |    RMR |  SRMR |   RFI |  PNFI\n-------------------------------------------------------------------------\none_latent_eth_configural    |    < .001 | 33.223 | 0.037 | 0.930 | 0.636\ntwo_latents_eth_configural   |    0.997  | 30.180 | 0.016 | 0.984 | 0.613\nthree_latents_eth_configural |    > .999 | 28.432 | 0.012 | 0.989 | 0.568\n\nName                         |   IFI |   RNI | Loglikelihood |   AIC (weights)\n------------------------------------------------------------------------------\none_latent_eth_configural    | 0.955 | 0.955 |    -87850.050 | 1.8e+05 (<.001)\ntwo_latents_eth_configural   | 0.992 | 0.992 |    -87608.642 | 1.8e+05 (<.001)\nthree_latents_eth_configural | 0.995 | 0.995 |    -87586.170 | 1.8e+05 (>.999)\n\nName                         |   BIC (weights) | BIC_adjusted\n-------------------------------------------------------------\none_latent_eth_configural    | 1.8e+05 (<.001) |    1.759e+05\ntwo_latents_eth_configural   | 1.8e+05 (<.001) |    1.755e+05\nthree_latents_eth_configural | 1.8e+05 (>.999) |    1.754e+05\n```\n\n\n:::\n\n```{.r .cell-code}\n# metric invariance models\n# run CFA models holding factor loadings equal across groups\none_latent_eth_metric <- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", group.equal = \"loadings\", data = test_eth))\ntwo_latents_eth_metric  <- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", group.equal = \"loadings\", data = test_eth))\nthree_latents_eth_metric  <- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\",group.equal = \"loadings\", data = test_eth))\n\n# compare model performances for metric invariance\ncompare_eth_metric  <- performance::compare_performance(one_latent_eth_metric, two_latents_eth_metric, three_latents_eth_metric, verbose = FALSE)\n\n# scalar invariance models\n# run CFA models holding factor loadings and intercepts equal across groups\none_latent_eth_scalar <- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", group.equal = c(\"loadings\",\"intercepts\"), data = test_eth))\ntwo_latents_eth_scalar  <- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", group.equal =  c(\"loadings\",\"intercepts\"), data = test_eth))\nthree_latents_eth_scalar  <- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\",group.equal =  c(\"loadings\",\"intercepts\"), data = test_eth))\n\n# Compare model performances for scalar invariance\ncompare_eth_scalar <- compare_eth_scalar  <- performance::compare_performance(one_latent_eth_scalar, two_latents_eth_scalar, three_latents_eth_scalar, verbose = FALSE)\n```\n:::\n\n### Configural Invariance Results\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_eth_configural_key <- compare_eth_configural[, c(\"Name\", \"Chi2\", \"Chi2_df\",\"RFI\", \"NNFI\", \"CFI\",\"GFI\",\"RMSEA\", \"RMSEA_CI_low\", \"RMSEA_CI_high\", \"AIC\", \"BIC\")]\n\nas.data.frame(compare_eth_configural_key)|>\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n\n\n|Name                         |      Chi2| Chi2_df|       RFI|      NNFI|       CFI|       GFI|     RMSEA| RMSEA_CI_low| RMSEA_CI_high|      AIC|      BIC|\n|:----------------------------|---------:|-------:|---------:|---------:|---------:|---------:|---------:|------------:|-------------:|--------:|--------:|\n|one_latent_eth_configural    | 612.80668|      28| 0.9300806| 0.9330615| 0.9553743| 0.9866606| 0.0887694|    0.0827342|     0.0949488| 175784.1| 176060.3|\n|two_latents_eth_configural   | 129.99163|      26| 0.9840274| 0.9871812| 0.9920646| 0.9972721| 0.0388462|    0.0323467|     0.0456186| 175305.3| 175594.6|\n|three_latents_eth_configural |  85.04735|      24| 0.9886791| 0.9918477| 0.9953416| 0.9982007| 0.0309787|    0.0239993|     0.0382454| 175264.3| 175566.8|\n\n\n:::\n:::\n\nThe table represents the comparison of three multi-group confirmatory factor analysis (CFA) models conducted to test for configural invariance across different ethnic categories (eth_cat). Configural invariance refers to whether the pattern of factor loadings is the same across groups. It's the most basic form of measurement invariance.\n\nLooking at the results, we can draw the following conclusions:\n\n1.  **Chi2 (Chi-square)**: a lower value suggests a better model fit. In this case, the three looks best \n\n2.  **GFI (Goodness of Fit Index) and AGFI (Adjusted Goodness of Fit Index)**: These values range from 0 to 1, with values closer to 1 suggesting a better fit. All models are close. \n\n3.  **NFI (Normed Fit Index), NNFI (Non-Normed Fit Index, also called TLI), CFI (Comparative Fit Index)**: These range from 0 to 1, with values closer to 1 suggesting a better fit. The two and three factors models have the highest values.\n\n4.  **RMSEA (Root Mean Square Error of Approximation)**: lower values are better, with values below 0.05 considered good and up to 0.08 considered acceptable.Only two and three meet this threshold.\n\n5.  **RMR (Root Mean Square Residual) and SRMR (Standardized Root Mean Square Residual)**: three is best.\n\n6.  **RFI (Relative Fit Index), PNFI (Parsimonious Normed Fit Index), IFI (Incremental Fit Index), RNI (Relative Noncentrality Index)**: These range from 0 to 1, with values closer to 1 suggesting a better fit. Again three is the winner.\n\n7.  **AIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion)**: The three factor model win's again.\n\n### Analysis of the Results:\n- **One Latent Model**: shows the poorest fit among the models with a high RMSEA and the lowest CFI. The model's Chi-squared value is also significantly high, indicating a substantial misfit with the observed data.\n\n- **Two Latents Model**: displays a much improved fit compared to the one latent model, as evident from its much lower Chi-squared value, lower RMSEA, and higher CFI. This suggests that two factors might be necessary to adequately represent the underlying structure in the data.\n\n- **Three Latents Model**: provides the best fit metrics among the three configurations.\n\n### Metric Equivalence\n\n::: {.cell}\n\n```{.r .cell-code}\ncompare_eth_metric <- compare_eth_metric[, c(\"Name\", \"Chi2\", \"Chi2_df\",\"RFI\", \"NNFI\", \"CFI\",\"GFI\",\"RMSEA\", \"RMSEA_CI_low\", \"RMSEA_CI_high\", \"AIC\", \"BIC\")]\n\nas.data.frame(compare_eth_metric)|>\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n\n\n|Name                     |     Chi2| Chi2_df|       RFI|      NNFI|       CFI|       GFI|     RMSEA| RMSEA_CI_low| RMSEA_CI_high|      AIC|      BIC|\n|:------------------------|--------:|-------:|---------:|---------:|---------:|---------:|---------:|------------:|-------------:|--------:|--------:|\n|one_latent_eth_metric    | 631.4181|      34| 0.9406705| 0.9436854| 0.9544120| 0.9862901| 0.0814209|    0.0759304|     0.0870395| 175790.7| 176027.4|\n|two_latents_eth_metric   | 146.8837|      31| 0.9848628| 0.9880193| 0.9911571| 0.9968735| 0.0375549|    0.0315677|     0.0437721| 175312.2| 175568.6|\n|three_latents_eth_metric | 101.6930|      28| 0.9883971| 0.9915649| 0.9943766| 0.9978055| 0.0315116|    0.0250581|     0.0382135| 175273.0| 175549.2|\n\n\n:::\n:::\n\nThis table presents the results of a multi-group confirmatory factor analysis (CFA) conducted to test metric equivalence (also known as weak measurement invariance) across different ethnic categories (eth_cat).  \n\nThe three factor model wins again.\n\n\n### Scalar Equivalence\n\n::: {.cell}\n\n```{.r .cell-code}\n# view as html table\n\ncompare_eth_scalar <- compare_eth_scalar[, c(\"Name\", \"Chi2\", \"Chi2_df\",\"RFI\", \"NNFI\", \"CFI\",\"GFI\",\"RMSEA\", \"RMSEA_CI_low\", \"RMSEA_CI_high\", \"AIC\", \"BIC\")]\n\nas.data.frame(compare_eth_scalar)|>\n  kbl(format = \"markdown\")\n```\n\n::: {.cell-output-display}\n\n\n|Name                     |     Chi2| Chi2_df|       RFI|      NNFI|       CFI|       GFI|     RMSEA| RMSEA_CI_low| RMSEA_CI_high|      AIC|      BIC|\n|:------------------------|--------:|-------:|---------:|---------:|---------:|---------:|---------:|------------:|-------------:|--------:|--------:|\n|one_latent_eth_scalar    | 669.8690|      40| 0.9464990| 0.9495325| 0.9519357| 0.9854887| 0.0770781|    0.0720058|     0.0822646| 175817.2| 176014.4|\n|two_latents_eth_scalar   | 177.4574|      36| 0.9842521| 0.9874065| 0.9892056| 0.9961614| 0.0385033|    0.0329544|     0.0442492| 175332.8| 175556.3|\n|three_latents_eth_scalar | 128.2153|      32| 0.9871996| 0.9903636| 0.9926580| 0.9971838| 0.0336809|    0.0277002|     0.0398839| 175291.5| 175541.4|\n\n\n:::\n:::\n\nOverall, it seems that we have good evidence for the three-factor model of Kessler-6, but two-factor is close.\n\nConsider: when might we prefer a two-factor model?  When might we prefer a three-factor model?  When might we prefer a one-factor model? \n\n\n### Conclusion: Understanding the Limits of Association in Factor Models\n\nThis discussion of measurement invariance across different demographic groups underscores the reliance of factor models on the underlying associations in the data. It is crucial to remember that these models are fundamentally descriptive, not prescriptive; they organize the observed data into a coherent structure based on correlations and assumed relationships among variables.\n\nNext week, we will consider the causal assumptions inherent in these factor models. Factor analysis assumes that the latent variables (factors) causally influence the observed indicators. This is a stron assumption that can profoundly affect the interpretation of the results. Understanding and critically evaluating our assumptions is important when applying factor analysis to real-world scenarios.\n\nThe assumption that latent variables cause the observed indicators, rather than merely being associated with them, suggests a directional relationship that can affect decisions made based on the analysis. For instance, if we believe that a latent construct like psychological distress causally influences responses on the K6 scale, interventions might be designed to target this distress directly. However, if the relationship is more complex or bidirectional, such straightforward interventions might not be as effective.\n\nNext week's session on causal assumptions will provide a deeper insight into how these assumptions shape our interpretations and the strategies we derive from factor models. This understanding is critical for applying these models appropriately and effectively in psychological research and practice.\n\n### Lab assignment\n\nUsing the code above, perform MG-CFA on personality measures using the `df_nz` data set. \n\n\n## Appendix A. What is a Correlation Matrix? \n\nA correlation matrix is a square matrix that contains the Pearson correlation coefficients between each pair of variables within a dataset. Each element in the matrix represents the correlation between two variables.\n\n#### Structure\n- **Dimensions**: the matrix is $p \\times p$ where $p$ is the number of variables.\n- **Diagonal Elements**: all diagonal elements are 1, because each variable has a perfect correlation with itself.\n- **Off-Diagonal Elements**: These elements, denoted as $r_{ij}$, are the Pearson correlation coefficients between the $i^{th}$ and $j^{th}$ variables, ranging from -1 to +1.\n  - $r_{ij} = 1$ indicates a perfect positive linear relationship.\n  - $r_{ij} = -1$ indicates a perfect negative linear relationship.\n  - $r_{ij} = 0$ indicates no linear relationship.\n\n#### Properties\n- **Symmetry**: the matrix is symmetric around the diagonal, meaning $r_{ij} = r_{ji}$.\n- **Real Values**: all entries are real numbers.\n- **Bounded Values**: values are constrained between -1 and 1, inclusive.\n\n####  Use\n- Exploring relationships between variables.\n- Conducting factor analysis to identify latent factors, as here.\n- ... \n\n::: {.cell}\n\n```{.r .cell-code}\n# Compute the correlation matrix\nlibrary(margot)\nlibrary(tidyverse)\ndt_only_k6 <- df_nz |> \n  dplyr::filter(wave == 2018) |> \n  dplyr::select(\n    kessler_depressed,\n    kessler_effort,\n    kessler_hopeless,\n    kessler_worthless,\n    kessler_nervous,\n    kessler_restless\n  )\n\ncor_matrix <- cor(dt_only_k6, use = \"pairwise.complete.obs\", method = \"pearson\")\nprint( \n  round( cor_matrix, 2) \n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                  kessler_depressed kessler_effort kessler_hopeless\nkessler_depressed              1.00           0.50             0.68\nkessler_effort                 0.50           1.00             0.53\nkessler_hopeless               0.68           0.53             1.00\nkessler_worthless              0.68           0.50             0.67\nkessler_nervous                0.42           0.45             0.47\nkessler_restless               0.38           0.46             0.41\n                  kessler_worthless kessler_nervous kessler_restless\nkessler_depressed              0.68            0.42             0.38\nkessler_effort                 0.50            0.45             0.46\nkessler_hopeless               0.67            0.47             0.41\nkessler_worthless              1.00            0.46             0.39\nkessler_nervous                0.46            1.00             0.46\nkessler_restless               0.39            0.46             1.00\n```\n\n\n:::\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyr)\n\n#plot\ncor_matrix_df <- as.data.frame(cor_matrix)  # convert matrix to data frame\ncor_matrix_df$variable <- rownames(cor_matrix_df)  # add a new column for rownames\n\nlong_cor_matrix <- tidyr::pivot_longer(cor_matrix_df, \n                                cols = -variable, \n                                names_to = \"comparison\", \n                                values_to = \"correlation\")\n\nggplot(long_cor_matrix, aes(x = variable, y = comparison, fill = correlation)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", midpoint = 0, limit = c(-1,1)) +\n  theme_minimal() +\n  labs(x = \"Variables\", y = \"Variables\", fill = \"Correlation\") +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](11-content_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n### Packages\n\n::: {.cell}\n\n```{.r .cell-code}\nreport::cite_packages()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  - Barrett M (2021). _ggokabeito: 'Okabe-Ito' Scales for 'ggplot2' and 'ggraph'_. R package version 0.1.0, <https://CRAN.R-project.org/package=ggokabeito>.\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 <https://doi.org/10.5281/zenodo.10907724>, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., <https://go-bayes.github.io/margot/>.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, <https://CRAN.R-project.org/package=extrafont>.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, <https://CRAN.R-project.org/package=janitor>.\n  - Greifer N (2024). _WeightIt: Weighting for Covariate Balance in Observational Studies_. R package version 1.3.2, <https://CRAN.R-project.org/package=WeightIt>.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. <https://www.jstatsoft.org/v40/i03/>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 <https://doi.org/10.21105/joss.02445>.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021). \"performance: An R Package for Assessment, Comparison and Testing of Statistical Models.\" _Journal of Open Source Software_, *6*(60), 3139. doi:10.21105/joss.03139 <https://doi.org/10.21105/joss.03139>.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, <https://CRAN.R-project.org/package=tibble>.\n  - Patil I, Makowski D, Ben-Shachar M, Wiernik B, Bacher E, Lüdecke D (2022). \"datawizard: An R Package for Easy Data Preparation and Statistical Transformations.\" _Journal of Open Source Software_, *7*(78), 4684. doi:10.21105/joss.04684 <https://doi.org/10.21105/joss.04684>.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, <https://CRAN.R-project.org/package=patchwork>.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. <https://www.R-project.org/>.\n  - Rosseel Y (2012). \"lavaan: An R Package for Structural Equation Modeling.\" _Journal of Statistical Software_, *48*(2), 1-36. doi:10.18637/jss.v048.i02 <https://doi.org/10.18637/jss.v048.i02>.\n  - VanderWeele TJ, Ding P (2011). \"Sensitivity analysis in observational research: introducing the E-value.\" _Annals of Internal Medicine_, *167*(4), 268-274. Mathur MB, VanderWeele TJ (2019). \"Sensitivity analysis for unmeasured confounding in meta-analyses.\" _Journal of the American Statistical Association>_. Smith LH, VanderWeele TJ (2019). \"Bounding bias due to selection.\" _Epidemiology_.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, <https://ggplot2.tidyverse.org>.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, <https://CRAN.R-project.org/package=forcats>.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, <https://CRAN.R-project.org/package=stringr>.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 <https://doi.org/10.21105/joss.01686>.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, <https://CRAN.R-project.org/package=dplyr>.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, <https://CRAN.R-project.org/package=purrr>.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, <https://CRAN.R-project.org/package=readr>.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, <https://CRAN.R-project.org/package=tidyr>.\n  - William Revelle (2024). _psych: Procedures for Psychological, Psychometric, and Personality Research_. Northwestern University, Evanston, Illinois. R package version 2.4.12, <https://CRAN.R-project.org/package=psych>.\n  - Xie Y (2024). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.49, <https://yihui.org/knitr/>. Xie Y (2015). _Dynamic Documents with R and knitr_, 2nd edition. Chapman and Hall/CRC, Boca Raton, Florida. ISBN 978-1498716963, <https://yihui.org/knitr/>. Xie Y (2014). \"knitr: A Comprehensive Tool for Reproducible Research in R.\" In Stodden V, Leisch F, Peng RD (eds.), _Implementing Reproducible Computational Research_. Chapman and Hall/CRC. ISBN 978-1466561595.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, <https://github.com/rstudio/tinytex>. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. <https://tug.org/TUGboat/Contents/contents40-1.html>.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0, <https://CRAN.R-project.org/package=kableExtra>.\n```\n\n\n:::\n:::\n\n\n",
    "supporting": [
      "11-content_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}