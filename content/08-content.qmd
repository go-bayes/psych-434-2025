---
title: "Causal Inference: Estimation of ATE and CATE"
date: "2025-APR-29"
format:
  html:
    warnings: false
    error: false
    messages: false
    code-overflow: scroll
    highlight-style: kate
    code-line-numbers: true
    code-fold: false
    code-tools:
      source: true
      toggle: false
html-math-method: katex
reference-location: margin
citation-location: margin
cap-location: margin
code-block-border-left: true
bibliography: /Users/joseph/GIT/templates/bib/references.bib
editor_options: 
  chunk_output_type: console
---

```{r}
#| eval: true
#| include: false
#| echo: false
# for information about this template: https://github.com/mikemahoney218/quarto-arxiv/blob/main/template.qmd

# libraries
library("tinytex")
library(extrafont)
loadfonts(device = "win")
library(margot)
library(here)
library(boilerplate)
library(patchwork)
library(kableExtra)
library(tidyverse)
# set save path
push_mods <- here::here('/Users/joseph/v-project\ Dropbox/data/courses/25-psych-434')

# read (large file)
models_binary_flipped_all <- margot::here_read_qs("models_binary_flipped_all", push_mods)

# names
flipped_names <- here_read("flipped_names", push_mods)

# read labels
label_mapping_all <- here_read("label_mapping_all")

# set boilerplate path (set to your own machine)
master_path <- "/Users/joseph/GIT/templates/boilerplate_data"

# set directory database path
here_data_path = here::here("data")

# data
original_df <- margot::here_read("df_wide", push_mods)

# # import
# master_unified_db <- boilerplate_import(data_path = master_path)

# boilerplate_save(master_unified_db, output_file = "unified_db", data_path  = here_data_path, create_backup = FALSE)

# unified_db <- boilerplate_import(data_path = here_data_path)

# cat(unified_db$appendix$explain$grf)
# set model defaults -----------------------------------------------------
grf_defaults <- list(
  seed = 123, # reproduce results
  stabilize.splits = TRUE, # robustness
  # min.node.size = 5,  # default is five/ requires at least 5 observed in control and treated
  # set higher for greater smoothing
  num.trees = 2000 # grf default = 2000 # set lower or higher depending on storage
)

# set defaults for graphs (see bottom of script for options)
decision_tree_defaults <- list(
  span_ratio = .3,
  text_size = 3.8,
  y_padding = 0.25  # Use full parameter name
  # edge_label_offset = .002,
  # border_size = .05
)

# set defaults for graphs (see bottom of script for options)
# set policy tree defaults
policy_tree_defaults <- list(
  point_alpha = .5,
  title_size = 12,
  subtitle_size = 14,
  axis_title_size = 14,
  legend_title_size = 14,
  split_line_color = "red",
  split_line_alpha = 0.8,
  split_label_color = "red"
)

rate_table_all <- margot_rate(
  models_binary_flipped_all, 
  label_mapping = label_mapping_all, 
  highlight_significant = TRUE
)


# rate_table_all$rate_autoc |> kbl("markdown")
# rate_table_all$rate_qini |> kbl("markdown")


# generate interpretation
rate_interpretation_all <- margot_interpret_rate(
  rate_table_all, 
  flipped_outcomes = flipped_names
)

# view interpretations
cat(rate_interpretation_all$autoc_results)
cat(rate_interpretation_all$qini_results)
cat(rate_interpretation_all$comparison)



# # check out model names
# rate_interpretation_all$either_model_names
# rate_interpretation_all$qini_model_names
# rate_interpretation_all$both_model_names
# rate_interpretation_all$autoc_model_names



# define autoc model names for batch processing
# autoc plots ------------------------------------------------------------
# generate batch rate plots
batch_rate_autoc_plots <- margot_plot_rate_batch(
  models_binary_flipped_all, 
  save_plots = FALSE,
  # just use rate autoc
  model_names = rate_interpretation_all$autoc_model_names  
)

# batch_rate_autoc_plots$model_t2_hlth_fatigue_z
# view selected autoc plots
# batch_rate_autoc_plots$model_t2_log_hours_exercise_z
# batch_rate_autoc_plots$model_t2_hlth_fatigue_z
# batch_rate_autoc_plots$model_t2_self_control_z

# QINI --------------------------------------------------------------------
# batch process heterogeneity results for qini
models_binary_batch_qini <- margot::margot_policy(
  models_binary_flipped_all,
  save_plots = FALSE,
  decision_tree_args = decision_tree_defaults,
  policy_tree_args = policy_tree_defaults,
  model_names = rate_interpretation_all$qini_model_names,
  original_df = original_df,
  label_mapping = label_mapping_all
)

# view models
# first make graphs
plot_qini_exercise <-models_binary_batch_qini$model_t2_log_hours_exercise_z$qini_plot
plot_qini_fatigue <- models_binary_batch_qini$model_t2_hlth_fatigue_z$qini_plot
plot_qini_bodysat <- models_binary_batch_qini$model_t2_bodysat_z$qini_plot
plot_qini_self_control <- models_binary_batch_qini$model_t2_self_control_z$qini_plot
plot_qini_self_esteem <- models_binary_batch_qini$model_t2_self_esteem_z$qini_plot
plot_qini_belong <- models_binary_batch_qini$model_t2_belong_z$qini_plot
# 


# recall the ate
# plot_all_models$plot

# patchwork allows us to group graphs together

# 
# # view plots
# (plot_qini_exercise / plot_qini_fatigue / plot_qini_bodysat) 
# 
# (plot_qini_self_control /plot_qini_self_esteem / plot_qini_t2_belong)

# extract plots for models without reliable heterogeneity

# interpret qini curves
interpretation_qini_curves <- margot::margot_interpret_qini(models_binary_batch_qini,
                                                    model_names =rate_interpretation_all$qini_model_names,,
                                                    label_mapping = label_mapping_all)

# view qini interpretation
cat(interpretation_qini_curves$qini_explanation)

# view summary table
interpretation_qini_curves$summary_table |> kbl("markdown")

# others
# combine qini plots
# qini_plots_combined <- 
#   (plot_qini_exercise + plot_qini_fatigue +  plot_qini_bodysat) / (plot_qini_self_control + plot_qini_self_esteem + plot_qini_t2_belong) + 
#   plot_annotation(
#     title = "Qini Plots: Reliable Priority 'Spending' at Fractional Budgets",
#     tag_levels = "A",
#     theme = theme(legend.position = "top")
#   ) +
#   plot_layout(guides = "collect")
# 
# # view combined qini plots
# qini_plots_combined

# again compare with ate
# plot_all_models$plot 


# policy tree analysis ---------------------------------------------------
# model_names_subset <- c(
#   "model_t2_log_hours_exercise_z",
#   "model_t2_self_control_z", 
#   "model_t2_sexual_satisfaction_z",
#   "model_t2_belong_z",
#   "model_t2_support_z"
# )


plots_policy_trees <- margot::margot_policy(
  models_binary_flipped_all,
  save_plots = FALSE,
  output_dir = here::here(push_mods),
  decision_tree_args = decision_tree_defaults,
  policy_tree_args = policy_tree_defaults,
  model_names = rate_interpretation_all$either_model_names, # defined above
  original_df = original_df,
  label_mapping = label_mapping_all
)

# generate policy tree interpretations
interpretation_policy_trees <- margot::margot_interpret_policy_batch(
  models_binary_flipped_all,
  # use eithre model
  model_names = rate_interpretation_all$either_model_names, # defined above
  train_proportion = 0.8,
  original_df = original_df,
  label_mapping = label_mapping_all
)

# this will give you results
# cat(interpretation_policy_trees)

# # plots
# plots_policy_trees$model_t2_log_hours_exercise_z$decision_tree
# plots_policy_trees$model_t2_log_hours_exercise_z$policy_tree
# plots_policy_trees$model_t2_log_hours_exercise_z$combined_plot
# # 
# plots_policy_trees$model_t2_hlth_fatigue_z$decision_tree
# plots_policy_trees$model_t2_hlth_fatigue_z$policy_tree
# plots_policy_trees$model_t2_hlth_fatigue_z$combined_plot
# # 
# plots_policy_trees$model_t2_self_control_z$decision_tree
# plots_policy_trees$model_t2_self_control_z$policy_tree
# plots_policy_trees$model_t2_self_control_z$combined_plot

# plots_policy_trees$model_t2_meaning_sense_z$decision_tree
# plots_policy_trees$model_t2_meaning_sense_z$policy_tree
# plots_policy_trees$model_t2_meaning_sense_z$combined_plot
# 
# plots_policy_trees$model_t2_bodysat_z$decision_tree
# plots_policy_trees$model_t2_bodysat_z$policy_tree
# plots_policy_trees$model_t2_bodysat_z$combined_plot
# # 
# 
# plots_policy_trees$model_t2_self_esteem_z$decision_tree
# plots_policy_trees$model_t2_self_esteem_z$policy_tree
# plots_policy_trees$model_t2_self_esteem_z$combined_plot

# plots_policy_trees$model_t2_belong_z$decision_tree
# plots_policy_trees$model_t2_belong_z$policy_tree
# plots_policy_trees$model_t2_belong_z$combined_plot

# batch_rate_autoc_plots$model_t2_meaning_sense_z
# models_binary_batch_qini$model_t2_belong_z$qini_plot

```


::: {.callout-note}
**Required**
- [https://grf-labs.github.io/grf/](https://grf-labs.github.io/grf/)



**Optional**
- [@vanderweele2020] [link](https://www.dropbox.com/scl/fi/srpynr0dvjcndveplcydn/OutcomeWide_StatisticalScience.pdf?rlkey=h4fv32oyjegdfl3jq9u1fifc3&dl=0)
- [@suzuki2020] [link](https://www.dropbox.com/scl/fi/4midxwr9ltg9oce02e0ss/suzuki-causal-diagrams.pdf?rlkey=uktzf3nurtgpbj8m4h0xz82dn&dl=0)
- [@Bulbulia2024PracticalGuide] [link](https://osf.io/preprints/psyarxiv/uyg3d)
- [@hoffman2023] [link](https://arxiv.org/pdf/2304.09460.pdf)
:::


::: {.callout-important}
### Key concepts  
The workflow below introduces **heterogeneous-treatment-effect (HTE) analysis** with *causal forests*. By the end of the lecture you should recognise five technical ideas - ATE, CATE, the estimator $\widehat{\tau}(x)$, the RATE statistics drawn from a **Targeting-Operator Characteristic** (TOC) curve, and **policy trees**—and know how each fits into an applied research pipeline.
:::

::: {.callout-important}
### For the lab  

There are **Three** R scripts we will be using over the next few weeks. 

First:

[Script 1](https://raw.githubusercontent.com/go-bayes/psych-434-2025/refs/heads/main/laboratory/01-example-script-data-wrangling.R)

[Script 2](https://raw.githubusercontent.com/go-bayes/psych-434-2025/refs/heads/main/laboratory/02-example-script-data-wrangling-2.R)

[Script 3](https://raw.githubusercontent.com/go-bayes/psych-434-2025/refs/heads/main/laboratory/03-example-script-estimation-results.R)

:::



## Heterogeneous-Treatment-Effect Analysis with **causal forests**

### Why worry about heterogeneity?  


Relying on the average treatment effect (ATE) is a bit like handing out size-nine shoes to an entire student body: on *average* they might fit, but watch the tall students hobble and the small ones trip.  In the same way, a one-hour boost in weekly community socialising could send some students' sense of belonging soaring while leaving others cold—or even wishing they'd stayed home with the cat.  Spotting that spread, measuring how big it really is, and deciding whether it is worth tailoring the 'shoe size' are the three practical goals of HTE analysis.


---

### 1 Start with the average treatment effect (ATE)  

We begin with the most straightforward (and secretly impossible) counterfactual: *run two parallel universes—one where **everyone** gets the treatment, another where **no-one** does—and compare the final scores.  The resulting difference is the **average treatment effect**:  


$$
\text{ATE}=E\!\bigl[Y(1)-Y(0)\bigr].
$$

This gives us the average response -- the shoe size...


---

### 2 Do effects differ across people?  

Variation is captured by the **conditional average treatment effect (CATE)**,  

$$
\tau(x)=E\!\bigl[Y(1)-Y(0)\mid X=x\bigr],
$$

where $X$ gathers pre-treatment covariates -- age, baseline wellbeing, personality, etc... Normally these will be our baseline confounders. 

If $\tau(x)$ turns out to be flat, there is no heterogeneity worth targeting. 

People differ in countless, overlapping ways—think of age, baseline wellbeing, personality traits, study habits, and more. A linear interaction model tests whether the treatment works differently along one straight dimension, such as gender, by fitting a straight line. But real‐world data often twist and turn. If the true relationship bends like a garden hose, a straight line will miss the curve. Causal forests fix this by letting the data place splits wherever the shape changes, so they can follow any bends that appear [@wager2018].  Straight-line models are fine for simple patterns, but causal forests can trace the curves that simple lines overlook.


### 3. From straight lines to trees  

Traditional 'parametric' models (like simple regression) guess a single functional shape -- often a straight line -- before seeing the data.  A **non-parametric** model, by contrast, lets the data decide the shape.  A *regression tree* is the simplest non-parametric learner we will use.  

1. **Regression tree**  

*Idea*: split the covariate space by asking yes/no questions— 'Age ≤ 20?', 'Baseline wellbeing > 0.3?' — until each terminal **leaf** is fairly homogeneous.  Inside a leaf the predicted outcome is just the sample mean, so the tree builds a *piece-wise constant* surface instead of a global line.  

*Analogy*: think of tiling a garden with stepping-stones: each stone is flat, but taken together they follow the ground’s contours.

2. **Regression forest**  
   A single tree is quick and interpretable but unstable: small changes in the data can move the splits and shift predictions.  A **random forest** grows many trees on bootstrap samples and averages their outputs.  Averaging cancels much of the noise [@breiman2001random].  

3. **Causal Forests**  
   To estimate treatment effects rather than outcomes, each tree plays a two-step 'honest' game [@wager2018]:  
   - use one half of its sample to choose splits that separate treated from control units;  
   - use the other half to compute treatment-control differences within every leaf.  

   For a new individual with covariates $x_i$ each tree supplies a noisy leaf-level effect; the forest reports the **average**, written  

$$
  \widehat{\tau}(x)=E[Y(1)-Y(0)\mid X=x].
$$

Because the noisy estimates point in many directions, their average is markedly less variable -- *the wisdom of trees is a wisdom of crowds*.

In sum, a regression tree chops the data into locally flat chunks; a regression forest averages many such trees to smooth away chance idiosyncrasies; a causal forest adds honesty so that its averaged differences, though never directly observable for any one person, give our best data-driven forecast of individual treatment effects.
---

### 4 Built-in protection against over-fitting  

Honesty already separates model selection from estimation, but the forest adds a second safeguard: **out-of-bag (OOB) prediction**. Each $\widehat{\tau}(x_i)$ is averaged only over trees that never used $i$ in their split phase.  Together, honesty and OOB prediction deliver reliable uncertainty estimates even in high-dimensional settings.

---

### 5 Handling missing data  

The `grf` package adopts **Missing Incorporated in Attributes (MIA)** splitting.  'Missing' can itself become a branch, so cases are neither discarded nor randomly imputed.  This pragmatic approach keeps all observations in play while preserving the forest’s interpretability.

---

### 6 Is the heterogeneity *actionable*? — RATE statistics  


Once we have a personalised score $\widehat{\tau}(x)$ for every unit, the practical question is whether *targeting* high scorers delivers a benefit large enough to justify the extra effort.  The tool of choice is the **Targeting-Operator Characteristic (TOC)** curve:

$$
G(q)=\frac{1}{n}\sum_{i=1}^{\lfloor qn\rfloor}\widehat{\tau}_{(i)}, \qquad 0\le q\le1,
$$

where $\widehat{\tau}_{(1)}\ge\widehat{\tau}_{(2)}\ge\cdots$ are the estimated effects sorted from largest to smallest.  The horizontal axis $q$ is the fraction of the population we would treat; the vertical axis $G(q)$ is the cumulative gain we expect from treating that top slice.

Two integrals of the TOC curve summarise how lucrative targeting could be:

* **RATE AUTOC** (Area *Under* the TOC) puts equal weight on every $q$.  This answers: *If benefits are concentrated among the very best prospects, how much can we harvest by cherry-picking them?*  

* **RATE Qini** applies heavier weight to the mid-range of $q$.  This is the go-to metric when investigators face a fixed, moderate-sized budget—say, "we can afford to treat 40 % of individuals; will targeting help?"  [@yadlowsky2021evaluating]. We will evaluate the curve at treatment of 20% and 50% of the population.


To quantify the economic or policy value of heterogeneity, rank units by $\widehat{\tau}(x)$ and draw a **Targeting-Operator Characteristic (TOC)** curve that plots cumulative gain against the fraction $q$ of the population treated.  

---

### 7 RATE AUTOC EXAMPLE

Although OOB predictions are 'out-of-sample' for individual trees, the full forest still reuses information.  A simple remedy is to cut the data in half: **train** the forest on one fold and **test** RATE/Qini on the other.  This explicit split blocks optimistic bias and yields honest test statistics ($p$-values) [@grf2024].

```{r, results='asis'}
#| label: fig-rate-example
#| fig-cap: "RATE AUTOC: Hours Socialising → Sense of Meaning"
#| echo: false
#| column: screen
batch_rate_autoc_plots$model_t2_meaning_sense_z
```

@fig-rate-example depicts a typical RATE AUTOC curve with sample splitting.  A steep initial rise indicates that a small, correctly targeted programme could deliver large gains. Note that the curve begins dipping below zero past about 30%. At that point we might be doing worse than the ATE by targeting the CATE.

---

### 8 Visualising policy value: the Qini curve  

A **Qini curve** displays cumulative benefit on the vertical axis and treatment coverage on the horizontal.  As with the AUTOC curve we are using a held-out test fold to validate the reponse curve.

```{r, results='asis'}
#| label: fig-qini-example
#| fig-cap: "Qini Curve: Hours Socialising → Social Belonging"
#| echo: false
#| column: screen
plot_qini_belong
```




@fig-qini-example: we find that focussing on the top 20 % of individuals nets a gain of 0.08 units (95 % CI 0.04–0.12).  Widening the net to 50 % bumps the haul to 0.13 units (95 % CI 0.07–0.19).  After that the curve flattens -- once you’ve treated everyone who offers a decent return, there are no more 'big fish' left to catch.

---


### 9 From 'a black box' to simple rules: policy trees  

The causal forest hands us a personalised CATE for every individual, mapping a **high-dimensional** covariate vector $X$ to a number $\widehat{\tau}(X)$.  Helpful as that forecast is, it stops short of telling us *what to do*: the function itself is too tangled --- thousands of overlapping splits -- to translate directly into a policy.  

The **policytree** algorithm bridges that gap by collapsing the forest's many $\widehat{\tau}(X)$ values into a single, shallow decision tree whose depth you choose; each split is chosen to maximise expected benefit [@policytree_package_2024].  In this course we cap the depth at **2** for a practical balance:

- at most two yes/no questions per rule, so the logic fits on a slide you can present to policy-makers;
- each leaf still contains enough observations to yield a stable effect estimate;  
- deeper trees increase complexity faster than they improve payoff.

```{r, results='asis'}
#| label: fig-decision-tree
#| fig-cap: "Decision tree for Social Belonging"
#| echo: false
#| column: screen
plots_policy_trees$model_t2_belong_z$decision_tree
```

 
**Policy Tree Findings for Effect of Hour Socialising on Social Belonging:**

Participants are first split by Self Esteem at -0.925 (original scale: 3.958). For those with Self Esteem <= this threshold, the next split is by Neuroticism at 0.642 (original scale: 4.228). Within that subgroup, individuals with Neuroticism <= the threshold are recommended **control**, while those with Neuroticism > the threshold are recommended **treated**.

For participants with Self Esteem > -0.925 (original scale: 3.958), the second split is by Social Belonging at 0.776 (original scale: 5.972). In this subgroup, individuals with Social Belonging <= the threshold are recommended **treated**, while those with Social Belonging > the threshold are recommended **control**.

**Policy Rule**

> If self-esteem ≤ −0.93 and neuroticism ≤ 0.64, do **not** recommend extra socialising; otherwise, recommend it unless current belonging > 0.78.*


```{r, results='asis'}
#| label: fig-policy-map
#| fig-cap: "Predicted treatment assignment (predictions out of training sample)"
#| fig-height: 14   # adjust
#| fig-width: 16  # adjust
#| echo: false
plots_policy_trees$model_t2_belong_z$policy_tree
```



---

### 10 Ethical and practical considerations  

Statistical optimality rarely lines up with social acceptability.  A rule that maximises expected health gains might still be **unaffordable** for a public agency, **unfair** to a protected group, or **opaque** to those asked to trust it.  Typically these trade-offs lie beyond the statistician’s remit (see the caveats in [Lecture 6](https://go-bayes.github.io/psych-434-2025/content/06-content.html#appendix-b-evidence-for-effect-modification-is-relative-to-inclusion-of-other-variables-in-the-model)).  

Yet the very same CATE machinery that powers targeting also helps science move past a *one-size-fits-all* mindset.  By mapping treatment effects across a high-dimensional covariate space, we can test whether our favourite categories -- gender, age group, clinical severity -- actually capture the differences that matter.  Sometimes they do; often they don't, revealing that nature is not carved at the joints of our folk classifications.  Discovering *where* the forest sees meaningful splits can generate fresh psychological hypotheses about who responds, why, and under what circumstances, even when no policy decision is on the table.


<!-- Before deployment we therefore need three extra layers of scrutiny: -->

<!-- 1. **Cost realism**   Will the programme's administrative and opportunity costs erase the forecast benefit?  A cost–effectiveness analysis can reveal when a simpler, less 'optimal' rule actually delivers better value.   -->
<!-- 2. **Fairness auditing**  check whether error rates or treatment probabilities differ by gender, ethnicity, or socioeconomic status.  If gaps appear, consider adjusting the loss function or adding fairness constraints [@mitchell2021algorithmic].   -->
<!-- 3. **Transparency and consent**   Publish the rule, document data sources, and secure stakeholder buy-in.  Transparent governance limits the risk of political backlash and encourages external replication. -->

---

### Summary/next steps  

Our workflow answers three questions in sequence:

1. **Is there substantial heterogeneity?**  Reject $H_0{:}\tau(x)$ constant if RATE AUTOC or RATE Qini is positive and statistically reliable  
2. **Does targeting pay at realistic budgets?**  Inspect the slope of the Qini curve around plausible coverage levels.
3. **Can we express the targeting rule in a few defensible steps?**  fit and validate a shallow policy tree.

In the lab section you will reproduce each stage on a simulated dataset.

---


## Lab: Data Preparation and Analysis Scripts




### Script 1
```{r}
#| include: true
#| eval: false

# Example script 1: data wrangling
# Spring 2025
# example estimation of average treatment effect - script 1
# questions: joseph.bulbulia@vuw.ac.nz

# restart fresh session if needed
#rstudioapi::restartSession()

# set reproducibility
set.seed(123)

# save paths -------------------------------------------------------------------
# create a save path to your on computer.
# this is mine
# push_mods <- here::here('/Users/joseph/v-project\ Dropbox/data/courses/25-psych-434')
# yours might be (after creating a data file)
# push_mods <- here::here("data")

# load libraries ---------------------------------------------------------
# install and load 'margot' package
if (!require(margot, quietly = TRUE)) {
devtools::install_github("go-bayes/margot") # make sure you have at least margot 1.0.21
}

if (!require(boilerplate, quietly = TRUE)) {
  devtools::install_github("go-bayes/boilerplate")
}

# load margot library
library(margot)
library(boilerplate)
library(tidyverse)
library(qs)
library(here)

# import synthetic data ---------------------------------------------------
# link
# url <- "https://www.dropbox.com/scl/fi/ru0ecayju04ja8ky1mhel/df_nz_long.qs?rlkey=prpk9a5v4vcg1ilhkgf357dhd&dl=1"
# 
# # download to a temporary file
# tmp <- tempfile(fileext = ".qs")
# download.file(url, tmp, mode = "wb")
# 
# # read it into R
# library(qs)
# df_nz_long <- qread(tmp)
# 
# # view synthetic data
# head(df_nz_long)
# 
# # save to your director for later use and comment the above
# margot::here_save_qs(df_nz_long,"df_nz_long" ,push_mods)



# comment the above and henceforth read your data: 
# remove old data 
rm(df_nz_long)

# read data
df_nz_long <- margot::here_read_qs("df_nz_long", push_mods)

# define study variables --------------------------------------------------------

# check out var names
glimpse(df_nz_long)

# how many participants? 
length(unique(df_nz_long$id))

# exposure variable
name_exposure <- c("hours_community")
var_labels_exposure = c("hours_community" = "Weekly Hours Community Socialising",
                        "hours_community_binary" = "Weekly Hours Community Socialising (binary)")

# save for manuscript
here_save(var_labels_exposure, "var_labels_exposure")

# define variable names
name_exposure_binary <- paste0(name_exposure, "_binary")
t0_name_exposure_continuous <- paste0("t0_", name_exposure)
t0_name_exposure_binary <- paste0("t0_", name_exposure, "_binary")

# define wide variable name
t0_name_exposure <- paste0("t0_", name_exposure)
t0_name_exposure_continuous <- paste0("t0_", name_exposure)
t0_name_exposure_binary <- paste0("t0_", name_exposure, "_binary")

# variable names for exposures used in models
t1_name_exposure <- paste0("t1_", name_exposure)
t1_name_exposure_binary <- paste0("t1_", name_exposure, "_binary")

# Define study waves -----------------------------------------------------------
baseline_wave <- "2018"
exposure_waves <- c("2019")
outcome_wave <- "2020"

# define wave combinations for analysis
all_waves <- c(baseline_wave, exposure_waves, outcome_wave)
baseline_and_exposure_waves <- c(baseline_wave, exposure_waves)
baseline_and_outcome_waves <- c(baseline_wave, outcome_wave)

# define scale ranges ----------------------------------------------------------
scale_range_exposure <- c(0, 20)  # Used for descriptive graphs
scale_ranges_outcomes <- c(1, 7) # Used for descriptive graphs

# check package versions
packageVersion(pkg = 'margot') # make sure it is 1.0.19 or greater
packageVersion(pkg = 'boilerplate')

# load required packages -------------------------------------------------------
pacman::p_load(
  # Causal inference
  clarify,      # Sensitivity analysis
  cobalt,       # Covariate balance tables and plots
  lmtp,         # Longitudinal targeted maximum likelihood estimation
  margot,       # Functions for causal inference
  MatchIt,      # Matching methods
  MatchThem,    # Matching for multiply imputed datasets
  policytree,   # Causal inference with policy trees
  WeightIt,     # Weighting methods for covariate balancing
  
  # data processing
  data.table,   # Fast data wrangling
  fastDummies,  # Fast creation of dummy variables
  fs,           # Cross-platform file system operations
  here,         # Simple and robust file referencing
  janitor,      # Data cleaning and validation
  naniar,       # Handling and visualization of missing data
  skimr,        # Summary statistics for data frames
  tidyverse,    # Collection of R packages for data science
  
  # Machine learning
  glmnet,       # Lasso and elastic-net regularized models
  grf,          # Generalized random forests
  ranger,       # Fast implementation of random forests
  SuperLearner, # Ensemble learning
  xgboost,      # Extreme gradient boosting
  
  # Visualization
  DiagrammeR,   # Graph and network visualization
  ggbeeswarm,   # Data visualization   
  ggplot2,      # Data visualization
  gt,           # HTML tables for data frames
  gtsummary,    # Summary tables for regression models
  kableExtra,   # Advanced table formatting
  
  # Parallel processing
  doParallel,   # Parallel processing with foreach
  progressr,    # Progress reporting for R
  
  # Analysis
  parameters,   # Parameters and performance metrics
  EValue       # Compute E-values
)

# data preparation -------------------------------------------------------------
# import and prepare data

# get total sample size
n_total <- skimr::n_unique(df_nz_long$id)
n_total <- margot::pretty_number(n_total)
margot::here_save(n_total, "n_total")

# view
n_total

# Define Baseline Variables ----------------------------------------------------
baseline_vars <- c(
  # note all outcomes will be added to baseline vars later. 
  # demographics
  "age",
  "born_nz_binary",
  "education_level_coarsen",
  "employed_binary",
  "eth_cat",
  "male_binary",
  "not_heterosexual_binary",
  "parent_binary",
  "partner_binary",
  "rural_gch_2018_l",
  "sample_frame_opt_in_binary",
  
  # personality traits
  "agreeableness",
  "conscientiousness",
  "extraversion",
  "neuroticism",
  "openness",
  
  # health and lifestyle
  "alcohol_frequency",
  "alcohol_intensity",
  "hlth_disability_binary",
  "log_hours_children",
  "log_hours_commute",
  "log_hours_exercise",
  "log_hours_housework",
  "log_household_inc",
  # "log_hours_community", # commented out because using as exposure
  "short_form_health",
  "smoker_binary",
  
  # social and psychological
  "belong",
  "nz_dep2018",
  "nzsei_13_l",
  "political_conservative",
  "religion_identification_level"
)

# Sort baseline variables
baseline_vars <- sort(baseline_vars)


# baseline vars no log ----------------------------------------------------

baseline_vars_no_log <- c(
  # Demographics
  "age",
  "born_nz_binary",
  "education_level_coarsen",
  "eth_cat",
  "employed_binary",
  "male_binary",
  "not_heterosexual_binary",
  "parent_binary",
  "partner_binary",
  "rural_gch_2018_l",
  "sample_frame_opt_in_binary",
  
  # Personality traits
  "agreeableness",
  "conscientiousness",
  "extraversion",
  "neuroticism",
  "openness",
  
  # Health and lifestyle
  "alcohol_frequency",
  "alcohol_intensity",
  "hlth_disability_binary",
  "log_hours_children",
  "hours_children",
  "log_hours_commute",
  "hours_commute",
  "log_hours_exercise",
  "hours_exercise",
  "log_hours_housework",
  "hours_housework",
  "log_household_inc",
  "household_inc",
  # "log_hours_community",
  "hours_community",
  "short_form_health",
  "smoker_binary",
  
  # Social and psychological
  "belong",
  "nz_dep2018",
  "nzsei_13_l",
  "political_conservative",
  "religion_identification_level"
)

# define outcome variables ----------------------------------------------------
# define outcome variables without log transformation
# outcomes
outcome_vars <- c(
  "alcohol_frequency",
  "alcohol_intensity",
  "belong",
  "bodysat",
  "forgiveness",
  "gratitude",
  "hlth_bmi",
  "hlth_fatigue",
  "hlth_sleep_hours",
  "kessler_latent_anxiety",
  "kessler_latent_depression",
  "lifesat",
  "log_hours_exercise",
  "meaning_purpose", 
  "meaning_sense",
  "neighbourhood_community",
  "perfectionism",
  "pwi", 
  "rumination",
  "self_control",
  "self_esteem",
  "sexual_satisfaction",
  "short_form_health",
  "support"
)

# sort and save outcome variables
outcome_vars <- sort(outcome_vars)
here_save(outcome_vars, "outcome_vars")

# Create standardized outcome variables
t2_outcome_vars_z <- paste0("t2_", outcome_vars, "_z")

# view the result
t2_outcome_vars_z


# define outcome variables without log transformation
# for tables
outcome_vars_no_log <- c(
  "alcohol_frequency",
  "alcohol_intensity",
  "belong",
  "bodysat",
  "forgiveness",
  "gratitude",
  "hlth_bmi",
  "hlth_fatigue",
  "hlth_sleep_hours",
  "hours_exercise", # logged 
  "kessler_latent_anxiety",
  "kessler_latent_depression",
  "lifesat",
  "meaning_purpose",
  "meaning_sense",
  "neighbourhood_community",
  "perfectionism",
  "pwi", 
  "rumination",
  "self_control",
  "self_esteem",
  "sexual_satisfaction",
  "short_form_health",
  "support"
)

# exposure_var
exposure_var = c(name_exposure, name_exposure_binary)

# check
# exposure_var_continuous = exposure_var[[1]]
# exposure_var_continuous
# 
# exposure_var_binary =  exposure_var[[2]]
# exposure_var_binary

# raw outcomes 
raw_outcomes_health <- c(
  "alcohol_frequency",
  "alcohol_intensity",
  "hlth_bmi", 
  "log_hours_exercise", 
  "hlth_sleep_hours", 
  "short_form_health"
)
# sort
raw_outcomes_health <- sort(raw_outcomes_health)

# save 
here_save(raw_outcomes_health, "raw_outcomes_health")

# define psych outcomes
raw_outcomes_psych <- c( 
  "hlth_fatigue", 
  "kessler_latent_anxiety", 
  "kessler_latent_depression",  
  "rumination"
)

# sort
raw_outcomes_psych <- sort(raw_outcomes_psych)

# save
here_save(raw_outcomes_psych, "raw_outcomes_psych")

# define present outcomes
raw_outcomes_present <- c(
  "bodysat",
  "forgiveness",
  "perfectionism", 
  "self_control" , 
  "self_esteem", 
  "sexual_satisfaction" 
)

# sort
raw_outcomes_present <- sort(raw_outcomes_present)

# save
here_save(raw_outcomes_present, "raw_outcomes_present")

# define life outcomes
raw_outcomes_life <- c( 
  "gratitude", 
  "lifesat", 
  "meaning_purpose", 
  "meaning_sense",
  "pwi"  # move personal well-being here if not using individual facents
)

# sort
raw_outcomes_life <- sort(raw_outcomes_life)

# save
here_save(raw_outcomes_life, "raw_outcomes_life")

# define social outcomes
raw_outcomes_social <- c(
  "belong",
  "neighbourhood_community", 
  "support" 
)
# sort
raw_outcomes_social <- sort(raw_outcomes_social)

# save
here_save(raw_outcomes_social, "raw_outcomes_social")

# save for publication
raw_outcomes_all <- c(raw_outcomes_health, 
                      raw_outcomes_psych,
                      raw_outcomes_present, 
                      raw_outcomes_life, 
                      raw_outcomes_social)

# save
here_save(raw_outcomes_all, "raw_outcomes_all")

#table1::table1(~ religion_spiritual_identification |wave, data = dat)
outcome_vars <-sort(outcome_vars)
outcome_vars_no_log<-sort(outcome_vars_no_log)
extra_vars <- c("id", "wave", "year_measured", "not_lost", "sample_weights") 
all_vars <- c(baseline_vars, exposure_var, outcome_vars, extra_vars)

extra_vars_table <- extra_vars
not_all_vars<- c(baseline_vars_no_log, exposure_var, outcome_vars_no_log, extra_vars_table)

# sort
all_vars <- sort(all_vars)
not_all_vars <- sort(not_all_vars)

# define columns that will later be handled in a special way
# define continuous columns that we will not standardise
continuous_columns_keep <- c("t0_sample_weights")


# define ordinal columns that we will expand into binary variables
ordinal_columns <- c("t0_education_level_coarsen", "t0_eth_cat", "t0_rural_gch_2018_l")

# checks
overlap <- intersect(baseline_vars, outcome_vars)
print(overlap)

# read and preprocess data ------------------------------------------------
df_nz_long$hours_community

# prepare initial dataframe -----------------------------------------------
dat_prep <- df_nz_long |>
  arrange(id, wave) |>
  as.data.frame() |>
  margot::remove_numeric_attributes() |>
  mutate(sample_weights = sample_weights) |> 
  mutate(religion_church = round( ifelse(religion_church > 8, 8, religion_church)),1) |>  # to simplify
  arrange(id, wave) |>
  droplevels()

# define variable names using paste0 # *-- needed in this study --*
# name_exposure_cat <- paste0(name_exposure, "_cat")
# name_exposure_binary <- paste0(name_exposure, "_binary")

# define wide variable names
t0_name_exposure <- paste0("t0_", name_exposure)
t1_name_exposure <- paste0("t1_", name_exposure)
here_save(t0_name_exposure , 't0_name_exposure')

# eligibility  ------------------------------------------------------------
# select baseline and exposure ids based on eligibility criteria 
ids_baseline <- dat_prep |>
  filter(year_measured == 1, wave == baseline_wave) |> 
  filter(!is.na(!!sym(name_exposure))) |> # exposure observed at baseline
  pull(id)

# 
n_participants <- length(ids_baseline)
n_participants<- margot::pretty_number(n_participants)

# check
n_participants

# save
here_save(n_participants, "n_participants")


# select ids for baseline cohort ---------------------------------------------------

# eligibility criteria: participated in baseline wave, no missingness in the exposure
# may have been lost to follow up. 
dat_long_1 <- dat_prep |>
  filter(id %in% ids_study & wave %in% c(baseline_wave, exposure_waves, outcome_wave)) |> 
  droplevels()# note that we might have more than one exposure wave

# check
str(dat_long_1$wave)



# aside -------------------------------------------------------------------
# example of censoring with more conditions -------------------------------

# censor exposure if lost
# ids_baseline_2 <- dat_long_censored_0 |>
#   filter(year_measured == 1, wave == baseline_wave, employed == 1, hours_work >= 20) |>
#   pull(id)
# 
# dat_long_censored <- dat_long_censored_0 |>
#   filter(id %in% ids_baseline_2 & wave %in% c(baseline_wave, exposure_waves, outcome_wave)) |> 
#   droplevels()# not

# check
# subset for wave 2021 and extract observations where employed == 0, and now work_hours >20
# subset_vals <- dat_long_censored$year_measured[
#   dat_long_censored$wave == 2021 & dat_long_censored$employed == 0
# ]

# check
# evaluate whether all year_measured are 0 in this subset
# all_zero <- all(subset_vals == 0, na.rm = TRUE)

# view
# all_zero

# data with eligibility criteria
# dat_long_1 <- dat_long_censored


# aside over --------------------------------------------------------------

# evaluate exposure variable/s
dat_long_exposure <- dat_long_1 |> 
  filter(wave == exposure_waves) |> 
  droplevels()


# censor if employed = 0 at wave 2
table(dat_long_exposure$wave)

# check 
table(is.na(dat_long_exposure$religion_church))
name_exposure
# check missing
# naniar::gg_miss_var(dat_long_exposured
# you can check quantile breaks this way
# ********* ENTER VARIABLE MANUALLY ***************
quantile(dat_long_exposure[[name_exposure]], na.rm = TRUE, probs = seq(0, 1, .25))
mean(dat_long_exposure[[name_exposure]], na.rm = TRUE)
median(dat_long_exposure[[name_exposure]], na.rm = TRUE)
max(dat_long_exposure[[name_exposure]], na.rm = TRUE)
sd(dat_long_exposure[[name_exposure]], na.rm = TRUE)

# make break at one
sum(dat_long_exposure[[name_exposure]] >= 1, na.rm = TRUE)
sum(dat_long_exposure[[name_exposure]] < 1, na.rm = TRUE)

# binary graph ------------------------------------------------------------
#graph binary break at lower quartile (5)
graph_exposure_binary <- margot::margot_plot_categorical(
  dat_long_exposure,
  col_name = name_exposure,
  cutpoint_inclusive = "lower",
  #n_divisions = 2,
  custom_breaks = c(0,1),
  binwidth = .5)

# view
print(graph_exposure_binary)

# check size
margot_size(graph_exposure_binary)

# save for manuscript
margot::here_save_qs(graph_exposure_binary, "graph_exposure_binary", push_mods)

# resume wrangling --------------------------------------------------------
# create categorical variable (if desired) ------------------------------
# view name
name_exposure

dat_long_2 <- margot::create_ordered_variable(
  dat_long_1,  # make sure this is correct
  var_name = name_exposure,
  cutpoint_inclusive = "lower",
  custom_breaks = c(0,1),
)

# view name
name_exposure_binary

# view binary exposure variable
table(is.na(
  dat_long_2[[name_exposure_binary]]
))

# convert binary factors to 0, 1 -----------------------------------------
# we do this using a custom function
dat_long_3 <- margot_process_binary_vars(dat_long_2)


# make 'not lost' variable ------------------------------------------------
# used later for dealing with attrition
dat_long_4 <- dat_long_3 |>
  arrange(id, wave) |> 
  mutate(
    not_lost = ifelse(lead(year_measured) == 1, 1, 0),
    not_lost = ifelse(is.na(not_lost) & year_measured == 1, 1, not_lost),
    not_lost = ifelse(is.na(not_lost), 0, not_lost)
  ) |> 
  droplevels()

# log-transform 'hours_' variables ----------------------------------------
dat_long_table <- margot_log_transform_vars(
  dat_long_4,
  vars = c(starts_with("hours_"), "household_inc"),
  exceptions = name_exposure,
  # always
  prefix = "log_",
  keep_original = TRUE ## set to TRUE for tables
)  |> select(all_of(not_all_vars)) |> droplevels()

# make wave a factor
dat_long_table$wave <- as.factor(dat_long_table$wave)



# summary tables ----------------------------------------------------------
# IMPORTANT FUNCTION  creates summary tables in one place
summary_tables  <- margot_summary_tables(
  data = dat_long_table,
  baseline_wave = baseline_wave,
  exposure_waves = exposure_waves,
  outcome_wave = outcome_wave,
  name_exposure = name_exposure,
  baseline_vars = baseline_vars_no_log,
  outcome_vars = outcome_vars,
  extra_vars = extra_vars
)

# show details
summary_tables$baseline_table
summary_tables$exposure_table
summary_tables$outcome_table
summary_tables$n_participants


# newer tables (for manuscript) -------------------------------------------
# sort
var_labels_health <- list(
  "alcohol_frequency" = "Alcohol Frequency",
  "alcohol_intensity" = "Alcohol Intensity",
  "hlth_bmi" = "Body Mass Index", 
  "hlth_sleep_hours" = "Sleep", 
  "hours_exercise" = "Hours of Exercise",   #logged in models
  "short_form_health" = "Short Form Health" 
)

# define psych outcomes 
var_labels_psych<- list(
  "hlth_fatigue" = "Fatigue", 
  "kessler_latent_anxiety" = "Anxiety", 
  "kessler_latent_depression" = "Depression",  
  "rumination" = "Rumination"
)

# define present outcomes
var_labels_present <- c(
  "bodysat" = "Body Satisfaction",
  "foregiveness" = "Forgiveness",
  "perfectionism" = "Perfectionism",
  "self_control" = "Self Control",
  "self_esteem" = "Self Esteem",
  "sexual_satisfaction" = "Sexual Satisfaction"
)

# define life outcomes
var_labels_life <- list(
  "gratitude" = "Gratitude", 
  "lifesat" = "Life Satisfaction", 
  "meaning_purpose" = "Meaning: Purpose", # exposure variable
  "meaning_sense" = "Meaning: Sense",
  "pwi" = "Personal Well-being Index"
)

# define social outcome names
var_labels_social <- list(
  "belong" = "Belonging",
  "neighbourhood_community" = "Neighbourhood Belonging", 
  "support" = "Support" 
)

# make labels
var_labels_baseline <- c(
  "sdo" = "Social Dominance Orientation",
  "belong" = "Social Belonging",
  "born_nz_binary" = "Born in New Zealand (binary)",
  "rural_gch_2018_l" = "Rural Gch 2018 Levels",
  "education_level_coarsen" = "Education Level",
  "employed_binary" = "Employed (binary)",
  "eth_cat" = "Ethnicity",
  "household_inc" = "Household Income",
  "log_household_inc" = "Log Household Income",
  "male_binary" = "Male (binary)",
  "nz_dep2018" = "NZ Deprevation Index 2018",
  "nzsei_13_l" = "NZSEI (Occupational Prestige Index)",
  "parent_binary" = "Parent (binary)",
  "rwa" = "Right Wing Authoritarianism",
  "sample_frame_opt_in_binary" = "Sample Frame Opt-In (binary)",
  "sdo" = "Social Dominance Orientation",
  "smoker_binary" = "Smoker (binary)",
  "support" = "Social Support (perceived)",
  "hours_community" = "Hours Community Socialising"
)

# labels for factors
rural_labels <- c(
  "High Urban Accessibility",
  "Medium Urban Accessibility",
  "Low Urban Accessibility",
  "Remote",
  "Very Remote"
)

# save labels -------------------------------------------------------------
here_save(var_labels_baseline, "var_labels_baseline")
here_save(var_labels_health, "var_labels_health")
here_save(var_labels_psych, "var_labels_psych")
here_save(var_labels_present, "var_labels_present")
here_save(var_labels_life, "var_labels_life")
here_save(var_labels_social, "var_labels_social")


# combine all variable labels
var_labels_measures = c(
  var_labels_baseline,
  var_labels_health,
  var_labels_psych,
  var_labels_present,
  var_labels_life,
  var_labels_social
)

# save
here_save(var_labels_measures, "var_labels_measures")

# new df for table
dat_long_table_x <- dat_long_table
dat_long_table_x$rural_gch_2018_l <- factor(
  dat_long_table_x$rural_gch_2018_l,
  levels = 1:5,
  labels = rural_labels,
  ordered = TRUE  # Optional: if the levels have an inherent order
)

# nicer for church attendance -- if you use it
# dat_long_table_x$religion_church <- factor(
#   dat_long_table_x$religion_church,
#   levels = 0:8,
#   ordered = TRUE  
# )

dat_long_table_baseline = dat_long_table_x |> 
  filter(wave %in% c(baseline_wave, exposure_waves, outcome_wave))

dat_long_table_exposure_waves = dat_long_table_x |> 
  filter(wave %in% c(baseline_wave, exposure_waves))

dat_long_table_outcome_waves = dat_long_table_x |> 
  filter(wave %in% c(baseline_wave, outcome_wave))

# make tables
markdown_table_baseline <- margot_make_tables(
  data = dat_long_table_baseline,
  vars = baseline_vars_no_log,
  by = "wave",
  labels = var_labels_baseline,
  factor_vars = c("rural_gch_2018_l", "eth_cat"),
  table1_opts = list(overall = FALSE, transpose = FALSE),
  format = "markdown"
)

# view
markdown_table_baseline

# save
margot::here_save(markdown_table_baseline, "markdown_table_baseline")

# make exposure table
markdown_table_exposures <-margot_make_tables(
  data = dat_long_table_exposure_waves,
  vars = name_exposure,
  by = "wave",
  labels = var_labels_exposure,
  table1_opts = list(overall = FALSE, transpose = FALSE),
  format = "markdown"
)

# view
markdown_table_exposures

# save
here_save(markdown_table_exposures, "markdown_table_exposures")


# names of outcome vars for health no logs
raw_outcomes_health_no_log <- c(
  "alcohol_intensity",
  "alcohol_frequency",
  "hlth_bmi", 
  "hlth_sleep_hours", 
  "hours_exercise",
  "short_form_health"
)

# make tables
markdown_table_outcomes_all <- margot_make_tables(
  data = dat_long_table_outcome_waves,
  vars = raw_outcomes_all,
  by = "wave",
  labels = var_labels_measures,
  table1_opts = list(overall = FALSE, transpose = FALSE),
  format = "markdown",
  quarto_label = "tbl-sample-outcomes"  # This is the key addition!
)

# view
markdown_table_outcomes_all

# save
here_save(markdown_table_outcomes_all, "markdown_table_outcomes_all")


# data for study, remove originals ----------------------------------------
## create gender weights if needed
dat_long_selected<- dat_long_4


# aside -------------------------------------------------------------------
# only if gender weights
# dat_long_selected$gender_weights <- margot_compute_gender_weights_by_wave(
#   dat_long_selected,
#   male_col = "male_binary",
#   wave_col = "wave",
#   target_wave = baseline_wave,
#   target_male_prop = 0.52 # source https://www.stats.govt.nz/news/women-in-paid-work
# )

# end aside  --------------------------------------------------------------
# checks
table(dat_long_selected$sample_weights[dat_long_selected$wave == baseline_wave])
# hist(dat_long_selected$g_sample_weights)
# hist(dat_long_selected$gender_weights)

# prepare data
dat_long_prepare <- margot::margot_log_transform_vars(
  dat_long_selected,
  vars = c(starts_with("hours_"), "household_inc"),
  exceptions = name_exposure,
  prefix = "log_",
  keep_original = TRUE ## Set to FALSE
) |> 
  # uncomment if using gender weights
  # select(-sample_weights) |>
  # dplyr::rename(sample_weights = gender_weights)|> 
  select(all_of(all_vars)) |>
  # make binary exposure variable |> 
  droplevels()

# view hist
hist(dat_long_selected$sample_weights)
table(is.na((dat_long_selected$sample_weights)))
table(is.na((dat_long_selected$male_binary)))


# finally save baseline variables (if as needed)
dat_baseline <- dat_long_prepare |>
  filter(wave == baseline_wave)
table(is.na(dat_baseline$sample_weights))
table(is.na(dat_baseline$male_binary))

# ordinary sample weights
t0_sample_weights <- dat_baseline$sample_weights # use age/gender/ethnicity
hist(dat_baseline$sample_weights)
hist(t0_sample_weights)

# if not using ethicity gender age
#t0_sample_weights <- dat_baseline$gender_weights

margot::here_save(t0_sample_weights, "t0_sample_weights")

# create tables -----------------------------------------------------------
exposure_waves

# create transition matrix ------------------------------------------------
dt_positivity <- dat_long_selected |>
  filter(wave == baseline_wave | wave %in% exposure_waves) |>
  select(!!sym(name_exposure), id, wave) |>
  mutate(exposure= as.numeric(!!sym(name_exposure))) |>
  mutate(exposure = round(ifelse(exposure > 5, 5, exposure), 0)) |> 
  droplevels()

# view
transition_tables <- margot_transition_table(dt_positivity, "exposure", "id", wave_var = "wave")

# explanation
cat(transition_tables$explanation)

# view
transition_tables$tables[[1]]


# run this to put into your quarto document
# (just copy and past the output)
transition_tables$quarto_code()

# save the transition_tables, and import them into your document if/as needed
here_save(transition_tables, "transition_tables")


# create transition matrix ------------------------------------------------
dt_positivity_binary <- dat_long_selected |>
  filter(wave == baseline_wave | wave %in% exposure_waves) |>
  select(!!sym(name_exposure_binary), id, wave) |>
  mutate(exposure_binary= as.numeric(!!sym(name_exposure_binary))) |>
  droplevels()

# make binary table
transition_tables_binary <- margot_transition_table(dt_positivity_binary, 
                                                    "exposure_binary", 
                                                    "id", 
                                                    wave_var = "wave")
# table
transition_tables_binary$tables[[1]]


# transition_tables_cat
cat(transition_tables_binary$explanation)

# view
transition_tables_binary$quarto_code()

# save
margot::here_save(transition_tables_binary, "transition_tables_binary")


# check missing values ---------------------------------------------------
# and look for other problems
naniar::miss_var_summary(dat_long_prepare) |> print(n = 100)

# get baseline wave for perc missing
dat_baseline <- dat_long_prepare |> filter(wave == baseline_wave)

# get
percent_missing_baseline <- naniar::pct_miss(dat_baseline)

# view
percent_missing_baseline

# save for manuscript
here_save(percent_missing_baseline, "percent_missing_baseline")

# view missingness
naniar::vis_miss(dat_baseline, warn_large_data = FALSE)

# view missingness # lots of missingness in employed at current job
naniar::gg_miss_var(dat_baseline)

# If everything looks OK, save the data -----------------------------------
# save the selected data
margot::here_save(dat_long_prepare, "dat_long_prepare")
margot::here_save(name_exposure, "name_exposure")

# save variable names
margot::here_save(baseline_vars, "baseline_vars")
margot::here_save(exposure_var, "exposure_var")
margot::here_save(outcome_vars, "outcome_vars")
margot::here_save(baseline_wave, "baseline_wave")
margot::here_save(exposure_waves, "exposure_waves")
margot::here_save(outcome_wave, "outcome_wave")
margot::here_save(continuous_columns_keep, "continuous_columns_keep")
margot::here_save(ordinal_columns, "ordinal_columns")

# graphs ------------------------------------------------------------------
# individual plot ---------------------------------------------------------
# exposure plot
individual_plot_exposure <- margot_plot_individual_responses(
  dat_long_1,
  y_vars = name_exposure,
  id_col = "id",
  waves = c(2018:2019), # only there for two waves
  theme = theme_classic(),
  random_draws =80,
  title = NULL,
  y_label = NULL,
  x_label = NULL,
  color_palette = NULL,
  include_timestamp = FALSE,
  # save_path = here::here(push_mods), # uncomment to save
  width = 16,
  height = 8,
  seed = 123,
  full_response_scale = TRUE,
  scale_range = scale_range_exposure
)


# view
individual_plot_exposure

# size
margot_size( individual_plot_exposure )
```


### Script 2: Second Level of Data Preparation
```{r}
#| include: true
#| eval: false
# 02-data-wrangling-grf-model
# get data into wide format and ready for modelling using grf
# joseph.bulbulia@gmail.com
# april 2025

# restart fresh session
# rstudioapi::restartSession()
# set reproducibility
set.seed(123)

# save paths -------------------------------------------------------------------
# create a save path to your on computer.
# this is mine
# push_mods <- here::here('/Users/joseph/v-project\ Dropbox/data/courses/25-psych-434')
# yours might be (after creating a data file)
# push_mods <- here::here("data")

# load libraries ---------------------------------------------------------
# install and load 'margot' package
# make sure you have at least margot 1.0.21
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}

if (!require(boilerplate, quietly = TRUE)) {
  devtools::install_github("go-bayes/boilerplate")
}

# load margot library
library(margot)

# load necessary libraries
pacman::p_load(
  clarify,
  # sensitivity analysis for causal inference
  cobalt,
  # covariate balance tables and plots
  DiagrammeR,
  # graph and network visualization
  doParallel,
  # parallel processing with foreach
  fastDummies,
  # fast creation of dummy variables
  fs,
  # cross-platform file system operations
  ggbeeswarm,
  # data visualisation
  ggplot2,
  # data visualisation
  glmnet,
  # lasso and elastic-net regularized models
  grf,
  # generalized random forests
  gt,
  # html tables for data frames
  gtsummary,
  # summary tables for regression models
  here,
  # simple and robust file referencing
  janitor,
  # data cleaning and validation
  kableExtra,
  # advanced table formatting
  lmtp,
  # longitudinal targeted maximum likelihood estimation
  # margot,
  # functions for casual inference
  MatchIt,
  # matching methods for causal inference
  MatchThem,
  # matching methods for multiply imputed datasets
  naniar,
  # handling and visualization of missing data
  parameters,
  # parameters and performance metrics
  policytree,
  # causal inference with policy trees
  progressr,
  # progress reporting for R
  ranger,
  # fast implementation of random forests
  skimr,
  # summary statistics for data frames
  SuperLearner,
  # ensemble learning
  tidyverse,
  # collection of R packages for data science
  WeightIt,
  # weighting methods for covariate balancing
  xgboost,
  # extreme gradient boosting
  EValue,
  # compute Evalues
  data.table,
  # fast data wrangling
  maq,
  # qini curves
  purrr,
  # data wrangling
  patchwork,
  # multiple plots
  labelled,
  purrr,
  boilerplate
)
# library(tidyr)
# library(dplyr)


#check
push_mods

# read data in
dat_long_prepare <- margot::here_read("dat_long_prepare")
name_exposure <- margot::here_read("name_exposure") #

# check
name_exposure_binary = paste0(name_exposure, "_binary")
name_exposure_continuous = name_exposure

#check
name_exposure_binary
name_exposure_continuous

# get vars
baseline_vars <- margot::here_read("baseline_vars")
outcome_vars <- margot::here_read("outcome_vars")

# baseline_exposure_cat <- margot::here_read("baseline_exposure_cat")
baseline_wave <- margot::here_read("baseline_wave")
exposure_waves <- margot::here_read("exposure_waves")
outcome_wave <- margot::here_read("outcome_wave")
t0_sample_weights <- margot::here_read("t0_sample_weights")

# define wide variable names
t0_name_exposure_binary <- paste0("t0_", name_exposure_binary)

# make exposure names (continuous not genreally used)
t1_name_exposure_binary <- paste0("t1_",name_exposure_binary)
t1_name_exposure_binary

t0_name_exposure_continuous <- paste0("t0_", name_exposure)
t0_name_exposure_continuous
# make exposure names (continuous not genreally used)
t1_name_exposure_continuous <- paste0("t1_",name_exposure)
t1_name_exposure_continuous
# ordinal use
ordinal_columns <- c(
  "t0_education_level_coarsen",
  "t0_eth_cat",
  "t0_rural_gch_2018_l",
  "t0_gen_cohort"
)

# for
continuous_columns_keep <- c("t0_sample_weights")

# prepare data for analysis ----------------------
dat_long_prepare <- margot::remove_numeric_attributes(dat_long_prepare)

dat_long_prepare_updated <- dat_long_prepare %>%
  mutate(wave = as.numeric(factor(wave, levels = sort(unique(wave)))))

# make both
name_exposure_both <- c(name_exposure_binary,name_exposure_continuous)

#check
name_exposure_both

# wide data
df_wide <- margot::margot_wide(
  dat_long_prepare_updated,
  baseline_vars = baseline_vars,
  exposure_var = name_exposure_both,
  outcome_vars = outcome_vars
)

# check
head(df_wide)

# check
# remove baseline binary
t0_sample_weights

# add weights back to data
df_wide$t0_sample_weights <- t0_sample_weights

# make sure that rural is a factor
df_wide$t0_rural_gch_2018_l <- as.factor(df_wide$t0_rural_gch_2018_l)

# save the wide data
margot::here_save(df_wide, "df_wide")

# naniar::vis_miss(df_wide, warn_large_data = FALSE)
# read back if needed
#df_wide <- margot::here_read("df_wide")

# check
colnames(df_wide)

# this will order the data correctly
# see margot documentation
# standardixe outcomes, create not-lost indicator
df_wide_encoded  <- margot::margot_process_longitudinal_data_wider(
  df_wide,
  ordinal_columns = ordinal_columns,
  continuous_columns_keep = continuous_columns_keep,
  not_lost_in_following_wave = "not_lost_following_wave",
  lost_in_following_wave = "lost_following_wave",
  remove_selected_columns = TRUE,
  exposure_var = name_exposure_both,
  scale_continuous = TRUE,
  censored_if_any_lost = FALSE # not relevant here
)

# check
colnames(df_wide_encoded)

# check
table(df_wide_encoded$t0_not_lost_following_wave)

# make the binary variable numeric! 
df_wide_encoded[[t0_name_exposure_binary]] <- as.numeric(df_wide_encoded[[t0_name_exposure_binary]]) - 1
df_wide_encoded[[t1_name_exposure_binary]] <- as.numeric(df_wide_encoded[[t1_name_exposure_binary]]) - 1

# check
table(df_wide_encoded[[t0_name_exposure_binary]])
table(df_wide_encoded[[t1_name_exposure_binary]])

# save data for models
here_save_qs(df_wide_encoded, "df_wide_encoded", push_mods)

# save data for models
# make exposure numeric

# check
colnames(df_wide_encoded)
table(is.na(df_wide_encoded[[t1_name_exposure_binary]]))
table(df_wide_encoded$t0_lost_following_wave)

# check
stopifnot(
  all(
    is.na(df_wide_encoded[[t1_name_exposure_binary]]) |
      df_wide_encoded[["t0_not_lost_following_wave"]] == 1
  )
)

# naniar::vis_miss(df_wide_encoded, warn_large_data = FALSE)
naniar::gg_miss_var(df_wide_encoded)

df_wide_encoded$t0_sample_weights

# predict attrition and create censoring weights --------------------------
# step 1: prepare baseline covariates
E <- df_wide_encoded %>%
  select(
    - all_of(t0_name_exposure_binary), # inserted by function but irrelevant
    -"t0_sample_weights") %>%
  select(starts_with("t0_"),
         -ends_with("_lost"),
         -ends_with("lost_following_wave")) %>%
  colnames() %>%
  sort()

# Note for baseline confounding we use the continuous var
E # we use the continuous variable

# save baseline covariates
margot::here_save(E, "E")

# view
print(E)

# step 2: calculate weights for t0
D_0 <- as.factor(df_wide_encoded$t0_lost_following_wave)

# get covariates
cen_0 <- df_wide_encoded[, E]

# probability forest for censoring
cen_forest_0 <- probability_forest(cen_0, D_0)

# save if needed, very large!
# here_save_qs(cen_forest_0, "cen_forest_0", push_mods)

predictions_grf_0 <- predict(cen_forest_0, newdata = cen_0, type = "response")
pscore_0 <- predictions_grf_0$pred[, 2]

# view
hist(pscore_0)

# check corrrect sample weights
hist(t0_sample_weights)

# use margot_adjust_weights for t0
t0_weights <- margot_adjust_weights(
  pscore = pscore_0,
  trim = TRUE,
  normalize = TRUE,
  # lower trimming
  lower_percentile = 0.01,
  upper_percentile = 0.99,
  # upper trimming
  censoring_indicator = df_wide_encoded$t0_lost_following_wave,
  sample_weights = df_wide_encoded$t0_sample_weights 
)

# view
length(t0_weights$adjusted_weights)
length(df_wide_encoded$t0_sample_weights)

# assign
nrow(df_wide_encoded)
hist(t0_weights$adjusted_weights)

# assign weights
df_wide_encoded$t0_adjusted_weights <- t0_weights$adjusted_weights

# just fyi
# df_wide_encoded$t0_propensity_score_model_weights <- t0_weights$censoring_weights

#check
naniar::vis_miss(df_wide_encoded, warn_large_data = FALSE)

# view
head(df_wide_encoded)
colnames(df_wide_encoded)

# remove lost next wave (censored)
df_wide_encoded_1 <- df_wide_encoded %>%
  filter(t0_lost_following_wave == 0) %>%
  droplevels()

# step 4: calculate weights for t1
E_and_exposure <- c(E, t1_name_exposure_continuous)
D_1 <- as.factor(df_wide_encoded_1$t1_lost_following_wave)
cen_1 <- df_wide_encoded_1[, E_and_exposure]

# probability forest for censoring
cen_forest_1 <- probability_forest(cen_1, D_1, sample.weights = df_wide_encoded_1$t0_adjusted_weights)

# save if needed, very large
# here_save(cen_forest_1, "cen_forest_1")

predictions_grf_1 <- predict(cen_forest_1, newdata = cen_1, type = "response")
pscore_1 <- predictions_grf_1$pred[, 2]

# check
hist(pscore_1)

# use margot_adjust_weights for t1
t1_weights <- margot_adjust_weights(
  pscore = pscore_1,
  trim = TRUE,
  normalize = TRUE,
  lower_percentile = 0.01,
  upper_percentile = 0.99,
  # upper trimming
  censoring_indicator = df_wide_encoded_1$t1_lost_following_wave,
  sample_weights = df_wide_encoded_1$t0_adjusted_weights # combine with weights
)

# check
hist(t1_weights$adjusted_weights)

# add weights -- these will be the weights we use
df_wide_encoded_1$t1_adjusted_weights <- t1_weights$adjusted_weights


# calculate summary statistics
t0_adjusted_weight_summary <- summary(df_wide_encoded$t0_adjusted_weights)
t1_adjusted_weight_summary <- summary(df_wide_encoded_1$t1_adjusted_weights)

# view summaries
t0_adjusted_weight_summary
t1_adjusted_weight_summary

#check
naniar::vis_miss(df_wide_encoded_1, warn_large_data = FALSE)

# save
here_save(df_wide_encoded_1, "df_wide_encoded_1")

# read if needed
# df_wide_encoded_1 <- here_read("df_wide_encoded_1")

# check names
colnames(df_wide_encoded_1)

# check
df_wide_encoded_1[[t1_name_exposure_binary]]

# step 5: prepare final dataset
nrow(df_wide_encoded_1)
table(df_wide_encoded_1$t1_lost_following_wave)

# arrange
df_grf <- df_wide_encoded_1 |>
  filter(t1_lost_following_wave == 0) |>
  # rename(t0_adjusted_weights = t1_adjusted_weights) |> # do this later
  # if you have not previously made a binary variable, make it here
  # mutate(
  #   # use the dynamically created binary variable name
  #   !!t1_name_exposure_binary := ifelse(
  #     get(t1_name_exposure_continuous) > 0, ### THINK ABOUT THIS
  #     1,
  #     0
  #   )
  # ) |>
  # mutate(across(
  #   where(is.factor),
  #   ~ factor(as.character(.), levels = levels(.), ordered = is.ordered(.))
  # )) |>
  select(
    where(is.factor),
    ends_with("_binary"),
    ends_with("_lost_following_wave"),
    ends_with("_z"),
    ends_with("_weights"),
    starts_with("t0_"),
    starts_with("t1_"),
    starts_with("t2_"),
  ) |>
  relocate(starts_with("t0_"), .before = starts_with("t1_")) |>
  relocate(starts_with("t1_"), .before = starts_with("t2_")) |>
  relocate("t0_not_lost_following_wave", .before = starts_with("t1_")) |>
  relocate(all_of(t1_name_exposure_binary), .before = starts_with("t2_")) |>
  droplevels()

# save final data
margot::here_save(df_grf, "df_grf")

# check final dataset
#check
colnames(df_grf)

# visualise missing
naniar::vis_miss(df_grf, warn_large_data = FALSE)

# check weights
df_grf$t1_adjusted_weights

#checks
colnames(df_grf)
str(df_grf)

# check exposures
table(df_grf[[t1_name_exposure_binary]])

# check
hist(df_grf$t1_adjusted_weights)

# calculate summary statistics
t0_weight_summary <- summary(df_wide_encoded)

# check
glimpse(df_grf$t0_adjusted_weights)

# visualise weight distributions
hist(df_grf$t0_adjusted_weights, main = "t0_stabalised weights", xlab = "Weight")

# visualise and check missing values
naniar::vis_miss(df_grf, warn_large_data = FALSE)
naniar::gg_miss_var(df_grf)
naniar::miss_var_summary(dat_long_prepare) |> print(n = 100)

# check n
n_observed_grf <- nrow(df_grf)

# view
n_observed_grf

# save
margot::here_save(n_observed_grf, "n_observed_grf")


# inspect propensity scores -----------------------------------------------
# get data # read in if needed
# df_grf <- here_read('df_grf')

# assign weights var name
weights_var_name = "t0_adjusted_weights"

# baseline covariates  # E already exists and is defined
E

# must be a data frame, no NA in exposure

# df_grf is a data frame - we must process this data frame in several steps
# user to specify which columns are outcomes, default to 'starts_with("t2_")'
df_propensity_org <- df_grf |> select(!starts_with("t2_"))

# Remove NAs and print message that this has been done
df_propensity <- df_propensity_org |> drop_na() |> droplevels()


# if running a baseline model - exclude outcome
E
# E_propensity_names
# first run model for baseline propensity if this is selected.  The default should be to not select it.
propensity_model_and_plots <- margot_propensity_model_and_plots(
  df_propensity = df_propensity,
  exposure_variable = t1_name_exposure_binary,
  baseline_vars = E,
  weights_var_name = weights_var_name,
  estimand = "ATE",
  method = "ebal",
  focal = NULL
)

# visualise
summary(propensity_model_and_plots$match_propensity)

# key plot
propensity_model_and_plots$love_plot

# other diagnostic plots
propensity_model_and_plots$summary_plot
propensity_model_and_plots$balance_table
propensity_model_and_plots$diagnostics


# check size
size_bytes <- object.size(propensity_model_and_plots)
print(size_bytes, units = "auto") # Mb

# use qs to save only if you have space
here_save_qs(propensity_model_and_plots,
             "propensity_model_and_plots",
             push_mods)

```


### Script 3: Estimation 

```{r}
#| include: true
#| eval: false

# 03-estimating-models-grf
# joseph.bulbulia@vuw.ac.nz
# april 2025
# devtools::load_all("/Users/joseph/GIT/margot/") # use version >= 1.0.21 
# for information on causal forests see: 
# https://grf-labs.github.io/grf/

# ** NOTE THESE DATA ARE SIMULATED SO RESULTS ARE NOT INTERPRETABLE **

# restart fresh session
#rstudioapi::restartSession()

# set reproducibility
set.seed(123)



# save paths -------------------------------------------------------------------
# create a save path to your on computer.
# this is mine
# push_mods <- here::here('/Users/joseph/v-project\ Dropbox/data/courses/25-psych-434')
# yours might be (after creating a data file)
# push_mods <- here::here("data")


# load libraries ---------------------------------------------------------
# install and load 'margot' package
if (!require(margot, quietly = TRUE)) {
  devtools::install_github("go-bayes/margot")
}

# if (!require(boilerplate, quietly = TRUE)) {
#   devtools::install_github("go-bayes/boilerplate")
# }

# load margot library
library(margot)

# load necessary libraries
# load necessary libraries
pacman::p_load(
  clarify,      # sensitivity analysis for causal inference
  cobalt,       # covariate balance tables and plots
  DiagrammeR,   # graph and network visualization
  doParallel,   # parallel processing with foreach
  fastDummies,  # fast creation of dummy variables
  fs,           # cross-platform file system operations
  ggbeeswarm,   # data visualisation   
  ggplot2,      # data visualisation
  glmnet,       # lasso and elastic-net regularized models
  grf,          # generalized random forests
  gt,           # html tables for data frames
  gtsummary,    # summary tables for regression models
  here,         # simple and robust file referencing
  janitor,      # data cleaning and validation
  kableExtra,   # advanced table formatting
  lmtp,         # longitudinal targeted maximum likelihood estimation
  margot,       # functions for casual inference
  MatchIt,      # matching methods for causal inference
  MatchThem,    # matching methods for multiply imputed datasets
  naniar,       # handling and visualization of missing data
  parameters,   # parameters and performance metrics
  policytree,   # causal inference with policy trees
  progressr,    # progress reporting for R
  ranger,       # fast implementation of random forests
  skimr,        # summary statistics for data frames
  SuperLearner, # ensemble learning
  tidyverse,    # collection of R packages for data science
  WeightIt,     # weighting methods for covariate balancing
  xgboost,      # extreme gradient boosting
  EValue,       # compute Evalues
  data.table,   # fast data wrangling
  maq,          # qini curves
  purrr,        # data wrangling
  patchwork,     # multiple plots
  labelled,
  purrr, 
  cli,
  crayon,
  rlang,
  kableExtra
)


# variable names and labels -----------------------------------------------
# import exposure variable (binary) 
name_exposure <- margot::here_read("name_exposure")
name_exposure

# make exposure names
t1_name_exposure_binary <- paste0("t1_", name_exposure, "_binary")

# check exposure name
t1_name_exposure_binary

# read health outcomes 
raw_outcomes_health <- here_read("raw_outcomes_health")
t2_outcome_health_z <- paste0("t2_", raw_outcomes_health, "_z")
t2_outcome_health_z <- sort(t2_outcome_health_z)

# read raw outcomes 
raw_outcomes_psych <- here_read("raw_outcomes_psych")
t2_outcome_psych_z <- paste0("t2_", raw_outcomes_psych, "_z")
t2_outcome_psych_z <- sort(t2_outcome_psych_z)

# read raw outcomes
raw_outcomes_present <- here_read("raw_outcomes_present")
t2_outcome_present_z <- paste0("t2_", raw_outcomes_present, "_z")
t2_outcome_present_z <- sort(t2_outcome_present_z)

# read raw outcomes
raw_outcomes_life <- here_read("raw_outcomes_life")
t2_outcome_life_z <- paste0("t2_", raw_outcomes_life, "_z")
t2_outcome_life_z <- sort(t2_outcome_life_z)

# read raw outcomes
raw_outcomes_social <- here_read("raw_outcomes_social")
t2_outcome_social_z <- paste0("t2_", raw_outcomes_social, "_z")
t2_outcome_social_z <- sort(t2_outcome_social_z)

# combine all raww outcome names
raw_outcomes_all <- c(raw_outcomes_health, 
                      raw_outcomes_psych,
                      raw_outcomes_present, 
                      raw_outcomes_life, 
                      raw_outcomes_social)

# save all outcomes
here_save(raw_outcomes_all, "raw_outcomes_all")


# label mappings for health outcomes
label_mapping_health <- list(
  "t2_alcohol_frequency" = "Alcohol Frequency",
  "t2_alcohol_intensity" = "Alcohol Intensity",
  "t2_hlth_bmi_z" = "BMI", 
  "t2_hlth_sleep_hours_z" = "Sleep", 
  "t2_log_hours_exercise_z" = "Hours of Exercise (log)",
  "t2_short_form_health_z" = "Short Form Health" 
)

# label mappings for psychological well-being outcomes
label_mapping_psych <- list(
  "t2_hlth_fatigue_z" = "Fatigue", 
  "t2_kessler_latent_anxiety_z" = "Anxiety", 
  "t2_kessler_latent_depression_z" = "Depression",  
  "t2_rumination_z" = "Rumination"
)

# label mappings for present reflective outcomes
label_mapping_present <- list(
  "t2_bodysat_z" = "Body Satisfaction",
  "t2_foregiveness_z" = "Forgiveness",  
  "t2_perfectionism_z" = "Perfectionism",  
  "t2_self_control_z" = "Self Control",  
  "t2_sexual_satisfaction_z" = "Sexual Satisfaction"
)

# label mappings for life reflective outcomes
label_mapping_life <- list(
  "t2_gratitude_z" = "Gratitude", 
  "t2_lifesat_z" = "Life Satisfaction", 
  "t2_meaning_purpose_z" = "Meaning: Purpose",  
  "t2_meaning_sense_z" = "Meaning: Sense", 
  "t2_pwi_z" = "Personal Well-being Index"
)

# label mappings for social outcomes
label_mapping_social <- list(
  "t2_belong_z" = "Social Belonging",
  "t2_neighbourhood_community_z" = "Neighbourhood Community", 
  "t2_support_z" = "Social Support" 
)

# n participants (can be useful for graphs)
n_participants <- here_read("n_participants")

# label mapping all -------------------------------------------------------
label_mapping_all <- c(
  label_mapping_health,
  label_mapping_psych,
  label_mapping_present,
  label_mapping_life,
  label_mapping_social
)



# save label mappings -----------------------------------------------------
here_save(label_mapping_health, "label_mapping_health")
here_save(label_mapping_psych, "label_mapping_psych")
here_save(label_mapping_present, "label_mapping_present")
here_save(label_mapping_life, "label_mapping_life")
here_save(label_mapping_social, "label_mapping_social")
here_save(label_mapping_all, "label_mapping_all")

# start analysis here ----------------------------------------------------
# import data
df_grf <- margot::here_read('df_grf')

# check
colnames(df_grf)

# read original dataframe / used to get measures on data scale
original_df <- margot::here_read("df_wide", push_mods)

# check missing values (baseline missingness is handled by grf)
# takes a long time to render so commented out
# naniar::vis_miss(df_grf, warn_large_data = FALSE)

# check another way
naniar::gg_miss_var(df_grf)

# import names of baseline covariates
E <- margot::here_read("E")
# check
E

# exposure variable (we use the GRF convention where W is the exposure)
# *****SET ***************
# make binary

# *********************************
# check that variables are 0 or 1
df_grf[[t1_name_exposure_binary]]
# *********************************


# needs to be a matrix
W <- as.vector(df_grf[[t1_name_exposure_binary]])


# check that these values are 0 or 1
W

# set weights
weights <- df_grf$t1_adjusted_weights 

# view/ check none too extreme
hist(weights)

# remove attributes of baseline co-variaties
X <-  margot::remove_numeric_attributes(df_grf[E]) 

# set parameters ----------------------------------------------------------
# set model defaults -----------------------------------------------------
grf_defaults <- list(
  seed = 123, # reproduce results
  stabilize.splits = TRUE, # robustness
  # min.node.size = 5,  # default is five/ requires at least 5 observed in control and treated
  # set higher for greater smoothing
  num.trees = 2000 # grf default = 2000 # set lower or higher depending on storage
)

# set defaults for graphs (see bottom of script for options)
decision_tree_defaults <- list(
  span_ratio = .3,
  text_size = 3.8,
  y_padding = 0.25  # Use full parameter name
  # edge_label_offset = .002,
  # border_size = .05
)

# set defaults for graphs (see bottom of script for options)
# set policy tree defaults
policy_tree_defaults <- list(
  point_alpha = .5,
  title_size = 12,
  subtitle_size = 14,
  axis_title_size = 14,
  legend_title_size = 14,
  split_line_color = "red",
  split_line_alpha = 0.8,
  split_label_color = "red"
)

# test --------------------------------------------------------------------
n <- nrow(X) # n in sample

# define training sample
toy <- sample(1:n, n / 4) # get half sample

# test data
toy_data = df_grf[toy, ]

# check
nrow(toy_data)

# test covariates
X_toy = X[toy, ]

# check
str(X_toy)

# test exposure
W_toy = W[toy]

# test weights
weights_toy = weights[toy]

# # test model
# ignore warnings
cf.test <- margot::margot_causal_forest(
  data          = toy_data,
  outcome_vars  = "t2_log_hours_exercise_z",
  covariates    = X_toy,
  W             = W_toy,
  weights       = weights_toy,
  top_n_vars = 15,
  save_models = TRUE # save the models
)

# test plots
models_binary_batch_test <- margot::margot_policy(
  cf.test,
  save_plots = FALSE,
  output_dir = here::here(push_mods),
  decision_tree_args = decision_tree_defaults,
  policy_tree_args = policy_tree_defaults,
  model_names = "model_t2_log_hours_exercise_z",
  original_df = original_df,
  label_mapping = label_mapping_psych
)

# test plots
models_binary_batch_test$model_t2_log_hours_exercise_z$qini_plot
models_binary_batch_test$model_t2_log_hours_exercise_z$decision_tree
models_binary_batch_test$model_t2_log_hours_exercise_z$policy_tree


# run binary model --------------------------------------------------------
# health models -----------------------------------------------------------
models_binary_health <- margot::margot_causal_forest(
  data = df_grf,
  outcome_vars = t2_outcome_health_z,
  covariates = X,
  W = W,
  weights = weights,
  grf_defaults = grf_defaults,
  top_n_vars = 15,
  save_models = TRUE,
  train_proportion = 0.7
)

# check size if needed
margot::margot_size(models_binary_health)

# save model
margot::here_save_qs(models_binary_health, "models_binary_health", push_mods)

# psych models ------------------------------------------------------------
models_binary_psych <- margot::margot_causal_forest(
  data = df_grf,
  outcome_vars = t2_outcome_psych_z,
  covariates = X,
  W = W,
  weights = weights,
  grf_defaults = grf_defaults,
  top_n_vars = 15,
  save_models = TRUE,
  train_proportion = 0.7
)

# save model
margot::here_save_qs(models_binary_psych, "models_binary_psych", push_mods)


# present models ----------------------------------------------------------
models_binary_present <- margot::margot_causal_forest(
  data = df_grf,
  outcome_vars = t2_outcome_present_z,
  covariates = X,
  W = W,
  weights = weights,
  grf_defaults = grf_defaults,
  top_n_vars = 15,
  save_models = TRUE,
  train_proportion = 0.7
)
# save model
margot::here_save_qs(models_binary_present, "models_binary_present", push_mods)


# life models -------------------------------------------------------------
models_binary_life <- margot::margot_causal_forest(
  data = df_grf,
  outcome_vars = t2_outcome_life_z,
  covariates = X,
  W = W,
  weights = weights,
  grf_defaults = grf_defaults,
  top_n_vars = 15,
  save_models = TRUE,
  train_proportion = 0.7
)

# save model
margot::here_save_qs(models_binary_life, "models_binary_life", push_mods)


# social models -----------------------------------------------------------
models_binary_social <- margot::margot_causal_forest(
  data = df_grf,
  outcome_vars = t2_outcome_social_z,
  covariates = X,
  W = W,
  weights = weights,
  grf_defaults = grf_defaults,
  top_n_vars = 15,
  save_models = TRUE,
  train_proportion = 0.7
)

# save model
margot::here_save_qs(models_binary_social, "models_binary_social", push_mods)

# graphs ------------------------------------------------------------------
# plot defaults -----------------------------------------------------------
title_binary = "Community Socialising (binary)"
filename_prefix = "grf_extraversion_wb"

# titles
subtitle_health = "Health"
subtitle_psych = "Psychological Well-being"
subtitle_present = "Present-Focussed Well-being"
subtitle_life = "Life-Focussed Well-being"
subtitle_social = "Social Well-being"


# defaults
base_defaults_binary  <- list(
  type = "RD",
  title = title_binary,
  #interpret_all_E_gt1 = TRUE,
  e_val_bound_threshold = 1.1,
  colors = c(
    "positive" = "#E69F00",
    "not reliable" = "grey50",
    "negative" = "#56B4E9"
  ),
  x_offset = -.275,
  # will be set based on type
  x_lim_lo = -.275,
  # will be set based on type
  x_lim_hi = .275,
  text_size = 4,
  linewidth = 0.5,
  estimate_scale = 1,
  base_size = 18,
  point_size = 2,
  title_size = 19,
  subtitle_size = 16,
  legend_text_size = 10,
  legend_title_size = 10,
  include_coefficients = FALSE
)


# set options for graphs
# health graph options
outcomes_options_health <- margot_plot_create_options(
  title = subtitle_health,
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)

# psych graph options
outcomes_options_psych <- margot_plot_create_options(
  title = subtitle_psych,
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)


# present graph options ---------------------------------------------------
outcomes_options_present <- margot_plot_create_options(
  title = subtitle_present,
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)


# life graph options ------------------------------------------------------
outcomes_options_life <- margot_plot_create_options(
  title =  subtitle_life,
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)


# social graph options ----------------------------------------------------
outcomes_options_social <- margot_plot_create_options(
  title =  subtitle_social,
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)

# all graph options ----------------------------------------------------
options_all_models <- margot_plot_create_options(
  title =  "Outcomewide Wellbeing",
  base_defaults = base_defaults_binary,
  subtitle = "",
  filename_prefix = filename_prefix)




# make graphs -----------------------------------------------------------
# read results
# warning reading models will take time
# import
models_binary_health <- margot::here_read_qs("models_binary_health", push_mods)
models_binary_psych <- margot::here_read_qs("models_binary_psych", push_mods)
models_binary_present <- margot::here_read_qs("models_binary_present", push_mods)
models_binary_life <- margot::here_read_qs("models_binary_life", push_mods)
models_binary_social <- margot::here_read_qs("models_binary_social", push_mods)

# check size (example)
margot::margot_size(models_binary_health)

# make ATE plots ----------------------------------------------------------
# health plots ------------------------------------------------------------
binary_results_health <- margot_plot(
  models_binary_health$combined_table,
  options = outcomes_options_health,
  label_mapping = label_mapping_health,
  include_coefficients = FALSE,
  save_output = FALSE, 
  order = "evaluebound_asc",
  original_df = original_df,
  e_val_bound_threshold = 1.1
)

# view
binary_results_health$transformed_table |> rename(
  "E-Value" = "E_Value",
  "E-Value bound" = "E_Val_bound"
) |>
  kbl(format = 'markdown')

# check
cat(binary_results_health$interpretation)

# interpretation
cat(binary_results_health$interpretation)

# plot psych
binary_results_psych_asc <- margot_plot(
  models_binary_psych$combined_table,
  options = outcomes_options_psych,
  label_mapping = label_mapping_psych,
  include_coefficients = FALSE,
  save_output = FALSE,
  original_df = original_df,
  e_val_bound_threshold = 1.1,
  order = "evaluebound_asc")


# order
binary_results_psych_asc$plot

# reorder for descriptions
binary_results_psych <- margot_plot(
  models_binary_psych$combined_table,
  options = outcomes_options_psych,
  label_mapping = label_mapping_psych,
  include_coefficients = FALSE,
  save_output = FALSE,
  e_val_bound_threshold = 1.1,
  original_df = original_df,
  order = "evaluebound_asc"
)

# table
binary_results_psych$transformed_table|> rename(
  "E-Value" = "E_Value",
  "E-Value bound" = "E_Val_bound"
) |>
  kbl(format = 'markdown')

# interpretation
cat(binary_results_psych$interpretation)

# plot present
#order
binary_results_present <- margot_plot(
  models_binary_present$combined_table,
  options = outcomes_options_present,
  label_mapping = label_mapping_present,
  include_coefficients = FALSE,
  save_output = FALSE,
  original_df = original_df,
  order = "evaluebound_asc"
  
)

# plot
binary_results_present$plot


# interpretation
cat(binary_results_present$interpretation)
(binary_results_present$transformed_table)


# plot life
binary_results_life <- margot_plot(
  models_binary_life$combined_table,
  options = outcomes_options_life,
  label_mapping = label_mapping_life,
  include_coefficients = FALSE,
  save_output = FALSE,
  order = "evaluebound_asc",
  original_df = original_df
)


# table
binary_results_life$transformed_table|> rename(
  "E-Value" = "E_Value",
  "E-Value bound" = "E_Val_bound"
) |>
  kbl(format = 'markdown')

# plot
binary_results_life$transformed_table

# interpretation
cat(binary_results_life$interpretation)

# plot social
binary_results_social <- margot_plot(
  models_binary_social$combined_table,
  options = outcomes_options_social,
  label_mapping = label_mapping_social,
  include_coefficients = FALSE,
  save_output = FALSE,
  original_df = original_df,
  order = "evaluebound_asc",
  
)

# table
binary_results_social$transformed_table |> rename(
  "E-Value" = "E_Value",
  "E-Value bound" = "E_Val_bound"
) |>
  kbl(format = 'markdown')

# interpretation
cat(binary_results_social$interpretation)


# combine ate plots ------------------------------------------------------
# plot_ate_health <- binary_results_health_asc$plot
# plot_ate_psych <- binary_results_psych_asc$plot
# plot_ate_present <- binary_results_present_asc$plot
# plot_ate_life <- binary_results_life_asc$plot
# plot_ate_social <- binary_results_social_asc$plot
# 
# 
# 
# # create combined plot with annotations
# ate_plots_combined <- plot_ate_health + 
#   plot_ate_psych + 
#   plot_ate_present + 
#   plot_ate_life + 
#   plot_ate_social +
#   plot_annotation(
#     title = title_binary,
#     tag_levels = "A",
#     theme = theme(
#       plot.title = element_text(size = 20),
#       legend.position = "top"
#     )
#   ) +
#   plot_layout(guides = "collect")
# 
# # view combined plot
# ate_plots_combined

# combine all models -----------------------------------------------------
# merge all domain models into single object
all_models <- margot_bind_models(
  models_binary_health,
  models_binary_psych,
  models_binary_present,
  models_binary_life,
  models_binary_social
)


# graph
plot_all_models <- margot_plot(
  all_models$combined_table,
  options =  options_all_models,
  save_output = FALSE,
  e_val_bound_threshold = 1.1,
  label_mapping = label_mapping_all,
  save_path = here::here(push_mods),
  original_df = original_df,
  include_coefficients = FALSE,
  order = "evaluebound_asc"
)

# view plot
plot_all_models$plot

# interpretation
cat(plot_all_models$interpretation)

# table
plot_all_models$transformed_table

# nice table
tables_list <- list(
  Health = binary_results_health$transformed_table,
  Psych = binary_results_psych$transformed_table,
  Present = binary_results_present$transformed_table,
  Life = binary_results_life$transformed_table,
  Social = binary_results_social$transformed_table
)

margot_bind_tables_markdown <- margot_bind_tables(
  tables_list         =   tables_list, #list(all_models$combined_table),
  sort_E_val_bound    = "desc",
  e_val_bound_threshold = 1.1,
  highlight_color     = NULL,
  bold                = TRUE,
  rename_cols         = TRUE,
  col_renames         = list(
    "E-Value"       = "E_Value",
    "E-Value bound" = "E_Val_bound"
  ),
  rename_ate          = TRUE,
  threshold_col       = "E_Val_bound",
  output_format       = "markdown",
  kbl_args            = list(
    booktabs = TRUE,
    caption  = NULL,
    align    = NULL
  )
)

# view markdown table
margot_bind_tables_markdown

# save for publication
here_save(margot_bind_tables_markdown, "margot_bind_tables_markdown")


# count models by category
cat("Number of original models:\n")
cat("Social models:", length(models_binary_social$results), "\n")
cat("Psych models:", length(models_binary_psych$results), "\n")
cat("Health models:", length(models_binary_health$results), "\n")
cat("Present models:", length(models_binary_present$results), "\n")
cat("Life models:", length(models_binary_life$results), "\n")
cat("\nTotal models in combined object:", length(all_models$results), "\n")


# flip negatively oriented outcomes --------------------------------------
models_binary_flipped_all <- margot_flip_forests(
  all_models,
  flip_outcomes = c(
    "t2_alcohol_frequency",
    "t2_alcohol_intensity",
    "t2_hlth_bmi_z", 
    "t2_hlth_fatigue_z",
    "t2_kessler_latent_anxiety_z",
    "t2_kessler_latent_depression_z",
    "t2_rumination_z",
    "t2_perfectionism_z"
  )
)

# omnibus heterogeneity tests --------------------------------------------
result_ominbus_hetero_all <- margot::margot_omnibus_hetero_test(models_binary_flipped_all, label_mapping = label_mapping_all)

# view results table
result_ominbus_hetero_all$summary_table |> kbl("markdown")

# view test interpretation
cat(result_ominbus_hetero_all$brief_interpretation)


# rate test analysis -----------------------------------------------------
# define flipped outcome names for interpretation
flipped_names <- c("Alcohol Frequency", "Alcohol Intensity", "BMI", "Fatigue", "Anxiety", "Depression", "Perfectionism", "Rumination")

# save for publication
here_save(flipped_names, "flipped_names")
# create rate analysis table

rate_table_all <- margot_rate(
  models_binary_flipped_all, 
  label_mapping = label_mapping_all, 
  highlight_significant = TRUE
)

# view rate tables
rate_table_all$rate_autoc |> kbl("markdown")
rate_table_all$rate_qini |> kbl("markdown")


# generate interpretation
rate_interpretation_all <- margot_interpret_rate(
  rate_table_all, 
  flipped_outcomes = flipped_names
)

# view interpretations
cat(rate_interpretation_all$autoc_results)
cat(rate_interpretation_all$qini_results)
cat(rate_interpretation_all$comparison)



# check out model names
rate_interpretation_all$either_model_names
rate_interpretation_all$qini_model_names
rate_interpretation_all$both_model_names
rate_interpretation_all$autoc_model_names



# define autoc model names for batch processing
# autoc plots ------------------------------------------------------------
# generate batch rate plots
batch_rate_autoc_plots <- margot_plot_rate_batch(
  models_binary_flipped_all, 
  save_plots = FALSE,
  # just use rate autoc
  model_names = rate_interpretation_all$autoc_model_names  
)

rate_interpretation_all$autoc_model_names
# view selected autoc plots
batch_rate_autoc_plots$model_t2_log_hours_exercise_z
batch_rate_autoc_plots$model_t2_hlth_fatigue_z
batch_rate_autoc_plots$model_t2_self_control_z
batch_rate_autoc_plots$model_t2_meaning_sense_z

# for instruction
batch_rate_qini_plots <- margot_plot_rate_batch(
  models_binary_flipped_all, 
  save_plots = FALSE,
  rate_interpretation_all$qini_model_names  #just use a
)

# for instruction -- note that initial heterogeneity dips below zero
batch_rate_qini_plots$model_t2_bodysat_z
batch_rate_qini_plots$model_t2_self_esteem_z
batch_rate_qini_plots$model_t2_belong_z



# QINI --------------------------------------------------------------------
# batch process heterogeneity results for qini
models_binary_batch_qini <- margot_policy(
  models_binary_flipped_all,
  save_plots = FALSE,
  output_dir = here::here(push_mods),
  decision_tree_args = decision_tree_defaults,
  policy_tree_args = policy_tree_defaults,
  model_names = rate_interpretation_all$qini_model_names,
  original_df = original_df,
  label_mapping = label_mapping_all
)



# view models
# first make graphs
plot_qini_exercise <-models_binary_batch_qini$model_t2_log_hours_exercise_z$qini_plot
plot_qini_fatigue <- models_binary_batch_qini$model_t2_hlth_fatigue_z$qini_plot
plot_qini_bodysat <- models_binary_batch_qini$model_t2_bodysat_z$qini_plot
plot_qini_self_control <- models_binary_batch_qini$model_t2_self_control_z$qini_plot
plot_qini_self_esteem <- models_binary_batch_qini$model_t2_self_esteem_z$qini_plot
plot_qini_belong <- models_binary_batch_qini$model_t2_belong_z$qini_plot


# recall the ate
plot_all_models$plot

# patchwork allows us to group graphs together
library(patchwork)

# view plots
(plot_qini_exercise / plot_qini_fatigue / plot_qini_bodysat) 

(plot_qini_self_control /plot_qini_self_esteem / plot_qini_t2_belong)

# extract plots for models without reliable heterogeneity

# interpret qini curves
interpretation_qini_curves <- margot_interpret_qini(models_binary_batch_qini,
                                                    model_names = rate_interpretation_all$qini_model_names,
                                                    label_mapping = label_mapping_all)

# view qini interpretation
cat(interpretation_qini_curves$qini_explanation)

# view summary table
interpretation_qini_curves$summary_table |> kbl("markdown")

# others
# combine qini plots
qini_plots_combined <- 
  (plot_qini_exercise + plot_qini_fatigue +  plot_qini_bodysat) / (plot_qini_self_control + plot_qini_self_esteem + plot_qini_t2_belong) + 
  plot_annotation(
    title = "Qini Plots: Reliable Priority 'Spending' at Fractional Budgets",
    tag_levels = "A",
    theme = theme(legend.position = "top")
  ) +
  plot_layout(guides = "collect")

# view combined qini plots
qini_plots_combined

# again compare with ate
plot_all_models$plot 


# policy tree analysis ---------------------------------------------------
# model_names_subset <- c(
#   "model_t2_log_hours_exercise_z",
#   "model_t2_self_control_z", 
#   "model_t2_sexual_satisfaction_z",
#   "model_t2_belong_z",
#   "model_t2_support_z"
# )


plots_policy_trees <- margot_policy(
  models_binary_flipped_all,
  save_plots = FALSE,
  output_dir = here::here(push_mods),
  decision_tree_args = decision_tree_defaults,
  policy_tree_args = policy_tree_defaults,
  model_names = rate_interpretation_all$either_model_names, # defined above
  original_df = original_df,
  label_mapping = label_mapping_all
)

# generate policy tree interpretations
interpretation_policy_trees <- margot_interpret_policy_batch(
  models_binary_flipped_all,
  # use eithre model
  model_names = rate_interpretation_all$either_model_names, # defined above
  train_proportion = 0.8,
  original_df = original_df,
  label_mapping = label_mapping_all
)

# this will give you results
cat(interpretation_policy_trees)

# plots
plots_policy_trees$model_t2_log_hours_exercise_z$decision_tree
plots_policy_trees$model_t2_log_hours_exercise_z$policy_tree
plots_policy_trees$model_t2_log_hours_exercise_z$combined_plot

plots_policy_trees$model_t2_hlth_fatigue_z$decision_tree
plots_policy_trees$model_t2_hlth_fatigue_z$policy_tree
plots_policy_trees$model_t2_hlth_fatigue_z$combined_plot

plots_policy_trees$model_t2_self_control_z$decision_tree
plots_policy_trees$model_t2_self_control_z$policy_tree
plots_policy_trees$model_t2_self_control_z$combined_plot

plots_policy_trees$model_t2_meaning_sense_z$decision_tree
plots_policy_trees$model_t2_meaning_sense_z$policy_tree
plots_policy_trees$model_t2_meaning_sense_z$combined_plot

plots_policy_trees$model_t2_bodysat_z$decision_tree
plots_policy_trees$model_t2_bodysat_z$policy_tree
plots_policy_trees$model_t2_bodysat_z$combined_plot


plots_policy_trees$model_t2_self_esteem_z$decision_tree
plots_policy_trees$model_t2_self_esteem_z$policy_tree
plots_policy_trees$model_t2_self_esteem_z$combined_plot

plots_policy_trees$model_t2_belong_z$decision_tree
plots_policy_trees$model_t2_belong_z$policy_tree
plots_policy_trees$model_t2_belong_z$combined_plot


#############################################################################
# theoretical comparisons ---------------------------------------------------
# individual theoretical comparisons (if relevant)
# need to get values for wealth if wealth is compared


# step 1 get information for wealth for conditonal comparisons
head(df_grf$t0_log_household_inc_z)

# get mean on original data scale
log_mean_inc <- mean(original_df$t0_log_household_inc, na.rm = TRUE)

# get sd on original data scale
log_sd_inc <- sd(original_df$t0_log_household_inc, na.rm = TRUE)

# function to get 
margot_back_transform_log_z(log_mean = log_mean_inc, 
                            log_sd = log_sd_inc,
                            z_scores = c(-1, 0, 1),
                            label = "data_scale")


# if we have specific groups to compare
complex_condition_political <- X[, "t0_political_conservative_z"] > -1 &
  X[, "t0_political_conservative_z"] < 1

complex_condition_wealth <- X[, "t0_log_household_inc_z"] > -1 & 
  X[, "t0_log_household_inc_z"] < 1

subsets_standard_wealth  <- list(
  Poor = list(
    var = "t0_log_household_inc_z",
    value = -1,
    operator = "<",
    description = "HShold income < -1 SD (NZD ~41k)"
    # label = "Conservative"  # label remains as is, but could be changed if desired
  ),
  MiddleIncome = list(
    subset_condition = complex_condition_wealth,
    description = "HShold income within +/-1SD (> NZD 41k < NZD 191k)"
  ),
  Rich = list(
    var = "t0_log_household_inc_z",
    value = 1,
    operator = ">",
    description = "HShold income > +1 SD (NZD 191k)",
    label = "Rich"  # label remains as is, but could be changed if desired
  )
)

subsets_standard_political  <- list(
  Liberal = list(
    var = "t0_political_conservative_z",
    value = -1,
    operator = "<",
    description = "< -1 SD in political conservativism"
  ),
  Moderates = list(
    var = "t0_political_conservative_z",
    # operator = "<",
    subset_condition = complex_condition_political,
    description = "Effects among those > -1 SD and < +1 in political conservativism",
    label = "Centrist"  # label remains as is, but could be changed if desired
  ),
  Conservative = list(
    var = "t0_political_conservative_z",
    value = 1,
    operator = ">",
    description = "> +1 SD in political conservativism",
    label = "Conservative"  # label remains as is, but could be changed if desired
  )
)

subsets_standard_gender  <- list(
  Female = list(
    var = "t0_male_binary",
    value = 0,
    description = "Females"
  ),
  Male = list(
    var = "t0_male_binary",
    value = 1,
    description = "Males"
  )) 


subsets_standard_ethnicity<- list(
  Asian = list(
    var = "t0_eth_cat_asian_binary",
    value = 1,
    description = "Asians"
  ),
  Euro = list(
    var = "t0_eth_cat_euro_binary",
    value = 1,
    description = "Europeans (Pakeha)"
  ),
  Pacific = list(
    var = "t0_eth_cat_pacific_binary",
    value = 1,
    description = "Pacific Peoples"
  ),
  Maori = list(
    var = "t0_eth_cat_maori_binary",
    value = 1,
    description = "Māori"
  )
)
# 
# subsets_standard_cohort <- list(
#   boomers = list(
#     var = "t0_gen_cohort_gen_Boomers_binary",
#     value = 1,
#     description = "Baby Boomers",
#     label = "Boomers"  # label remains as is, but could be changed if desired
#   ),
#   gen_X = list(
#     var = "t0_gen_cohort_gen_X_binary",
#     value = 1,
#     description = "Generation X",
#     label = "Generation_X"  # label remains as is, but could be changed if desired
#   ),
#   gen_Y = list(
#     var = "t0_gen_cohort_gen_Y_binary",
#     value = 1,
#     description = "Generation Y",
#     label = "Generation_Y"  # label remains as is, but could be changed if desired
#   ),
#   gen_Z = list(
#     var = "t0_gen_cohort_gen_Z_binary",
#     value = 1,
#     description = "Generation Z",
#     label = "Generation_Z"  # label remains as is, but could be changed if desired
#   )
# )


# check
mean(original_df$t0_age) - sd(original_df$t0_age) # 36.44773


# if we have specific groups to compare
complex_condition_age_under_neg_1_sd  <- X[, "t0_age_z"] < -1 
complex_condition_age_gr_eq_neg_1_sd  <- X[, "t0_age_z"] >= -1 


subsets_standard_cohort <- list(
  under_37 = list(
    value = complex_condition_age_under_neg_1_sd,
    description = "under_37"
  ),
  over_37 = list(
    value = complex_condition_age_gr_eq_neg_1_sd,
    description = "37 and over"
  )
)


# batch planned subgroup analysis -----------------------------------------
# set up lists of models, names, and subtitles
domain_models <- list(
  models_binary_health,
  models_binary_psych,
  models_binary_present,
  models_binary_life,
  models_binary_social
)

domain_names <- c("health", "psych", "present", "life", "social")

subtitles <- c(
  subtitle_health,
  subtitle_psych,
  subtitle_present,
  subtitle_life,
  subtitle_social
)

# set up subset types in a list
subset_types <- list(
  wealth = subsets_standard_wealth,
  ethnicity = subsets_standard_ethnicity,
  political = subsets_standard_political,
  gender = subsets_standard_gender#,
  # cohort = subsets_standard_cohort
)

# run the batch processing for all domains and subsets
planned_subset_results <- margot_planned_subgroups_batch(
  domain_models = domain_models,
  X = X,
  base_defaults = base_defaults_binary,
  subset_types = subset_types,
  original_df = original_df,
  domain_names = domain_names,
  subtitles = subtitles,
  push_mods = push_mods
)

# results
# health subgroup
cat(planned_subset_results$health$wealth$explanation)
cat(planned_subset_results$health$ethnicity$explanation) #* 
cat(planned_subset_results$health$political$explanation) # 
cat(planned_subset_results$health$gender$explanation) # 
cat(planned_subset_results$health$cohort$explanation) #*


cat(planned_subset_results$psych$wealth$explanation) #*
cat(planned_subset_results$psych$ethnicity$explanation) #*
cat(planned_subset_results$psych$political$explanation) # *
cat(planned_subset_results$psych$gender$explanation) # *
cat(planned_subset_results$psych$cohort$explanation) #*


cat(planned_subset_results$present$wealth$explanation) #*
cat(planned_subset_results$present$ethnicity$explanation) #*
cat(planned_subset_results$present$political$explanation) # *
cat(planned_subset_results$present$gender$explanation) # *
cat(planned_subset_results$present$cohort$explanation) #*


cat(planned_subset_results$life$wealth$explanation) #*
cat(planned_subset_results$life$ethnicity$explanation) #*
cat(planned_subset_results$life$political$explanation) # *
cat(planned_subset_results$life$gender$explanation) # *
cat(planned_subset_results$life$cohort$explanation) #*

cat(planned_subset_results$social$wealth$explanation) #*
cat(planned_subset_results$social$ethnicity$explanation) #*
cat(planned_subset_results$social$political$explanation) # *
cat(planned_subset_results$social$gender$explanation) # *
cat(planned_subset_results$social$cohort$explanation) #*


# combine tables ----------------------------------------------------------
# wrap each domain’s table in a list:


# wealth subgroups --------------------------------------------------------
tables_list_poor <- list(
  Health = planned_subset_results$health$wealth$results$Poor$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$Poor$transformed_table,
  Life   = planned_subset_results$life$wealth$results$Poor$transformed_table,
  Social = planned_subset_results$social$wealth$results$Poor$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_poor,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Poor"),
                           highlight_color = NULL, output_format = "html")


# margot_bind_tables(tables_list = tables_list,
#                    bold = TRUE,
#                    highlight_color = NULL, output_format = "latex")
tables_list_middleincome <- list(
  Health = planned_subset_results$health$wealth$results$MiddleIncome$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$MiddleIncome$transformed_table,
  Life   = planned_subset_results$life$wealth$results$MiddleIncome$transformed_table,
  Social = planned_subset_results$social$wealth$results$MiddleIncome$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_middleincome,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Middle Income"),
                           highlight_color = NULL, output_format = "html")


planned_subset_results$health$wealth$results$Rich$transformed_table

tables_list_rich <- list(
  Health = planned_subset_results$health$wealth$results$Rich$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$Rich$transformed_table,
  Life   = planned_subset_results$life$wealth$results$Rich$transformed_table,
  Social = planned_subset_results$social$wealth$results$Rich$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_rich,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Rich"),
                           highlight_color = NULL, output_format = "html")




# Age subgroups -----------------------------------------------------------

# wealth subgroups --------------------------------------------------------
planned_subset_results$health$cohort$results$Generation_X$transformed_table

planned_subset_results$health$cohort$results$Boomers$transformed_table
tables_list_boomers <- list(
  Health = planned_subset_results$health$cohort$results$Boomers$transformed_table,
  Psych  = planned_subset_results$psych$cohort$results$Boomers$transformed_table,
  Life   = planned_subset_results$psych$cohort$results$Boomers$transformed_table,
  Social = planned_subset_results$psych$cohort$results$Boomers$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_boomers,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, 
                                          caption = "Cohort Subgroup Analysis: Boomers"),
                           highlight_color = "yellow", output_format = "html")


# margot_bind_tables(tables_list = tables_lisblue()# margot_bind_tables(tables_list = tables_list,
#                    bold = TRUE,
#                    highlight_color = NULL, output_format = "latex")
tables_list_genZ <- list(
  Health = planned_subset_results$health$cohort$results$Generation_Z$transformed_table,
  Psych  = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table,
  Life   = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table,
  Social = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_genZ,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Cohort Subgroup Analysis: Generation Z"),
                           highlight_color = NULL, output_format = "html")




# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_rich,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Rich"),
                           highlight_color = NULL, output_format = "html")






# plots -------------------------------------------------------------------
# Results Plots
# health
plots_subgroup_wealth_health <- wrap_plots(
  list(
    planned_subset_results$health$wealth$results$Poor$plot,
    planned_subset_results$health$wealth$results$MiddleIncome$plot,
    planned_subset_results$health$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_health)

plots_subgroup_ethnicity_health<- wrap_plots(
  list(
    planned_subset_results$health$ethnicity$results$Asian$plot,
    planned_subset_results$health$ethnicity$results$Euro$plot,
    planned_subset_results$health$ethnicity$results$Maori$plot,
    planned_subset_results$health$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_health)

plots_subgroup_political_health <- wrap_plots(
  list(
    planned_subset_results$health$political$results$Conservative$plot,
    planned_subset_results$health$political$results$Centrist$plot,
    planned_subset_results$health$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_health)

# plots
plots_subgroup_gender_health<- wrap_plots(
  list(
    planned_subset_results$health$gender$results$Female$plot,
    planned_subset_results$health$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_health)

# plots
plots_subgroup_cohort_health<- wrap_plots(
  list(
    planned_subset_results$health$cohort$results$Boomers$plot,
    planned_subset_results$health$cohort$results$Generation_X$plot,
    planned_subset_results$health$cohort$results$Generation_Y$plot,
    planned_subset_results$health$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_health)

# psychological well-being
plots_subgroup_wealth_psych <- wrap_plots(
  list(
    planned_subset_results$psych$wealth$results$Poor$plot,
    planned_subset_results$psych$wealth$results$MiddleIncome$plot,
    planned_subset_results$psych$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_psych)

plots_subgroup_ethnicity_psych<- wrap_plots(
  list(
    planned_subset_results$psych$ethnicity$results$Asian$plot,
    planned_subset_results$psych$ethnicity$results$Euro$plot,
    planned_subset_results$psych$ethnicity$results$Maori$plot,
    planned_subset_results$psych$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_psych)


plots_subgroup_political_psych <- wrap_plots(
  list(
    planned_subset_results$psych$political$results$Conservative$plot,
    planned_subset_results$psych$political$results$Centrist$plot,
    planned_subset_results$psych$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_psych)

# plots
plots_subgroup_gender_psych<- wrap_plots(
  list(
    planned_subset_results$psych$gender$results$Female$plot,
    planned_subset_results$psych$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_psych)

# plots
plots_subgroup_cohort_psych<- wrap_plots(
  list(
    planned_subset_results$psych$cohort$results$Boomers$plot,
    planned_subset_results$psych$cohort$results$Generation_X$plot,
    planned_subset_results$psych$cohort$results$Generation_Y$plot,
    planned_subset_results$psych$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_psych)



# present focussed well-being
plots_subgroup_wealth_present <- wrap_plots(
  list(
    planned_subset_results$present$wealth$results$Poor$plot,
    planned_subset_results$present$wealth$results$MiddleIncome$plot,
    planned_subset_results$present$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_present)

plots_subgroup_ethnicity_present<- wrap_plots(
  list(
    planned_subset_results$present$ethnicity$results$Asian$plot,
    planned_subset_results$present$ethnicity$results$Euro$plot,
    planned_subset_results$present$ethnicity$results$Maori$plot,
    planned_subset_results$present$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_present)


plots_subgroup_political_present <- wrap_plots(
  list(
    planned_subset_results$present$political$results$Conservative$plot,
    planned_subset_results$present$political$results$Centrist$plot,
    planned_subset_results$present$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_present)

# plots
plots_subgroup_gender_present<- wrap_plots(
  list(
    planned_subset_results$present$gender$results$Female$plot,
    planned_subset_results$present$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_present)

# plots
plots_subgroup_cohort_present<- wrap_plots(
  list(
    planned_subset_results$present$cohort$results$Boomers$plot,
    planned_subset_results$present$cohort$results$Generation_X$plot,
    planned_subset_results$present$cohort$results$Generation_Y$plot,
    planned_subset_results$present$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_present)


## life focussed well-being
plots_subgroup_wealth_life <- wrap_plots(
  list(
    planned_subset_results$life$wealth$results$Poor$plot,
    planned_subset_results$life$wealth$results$MiddleIncome$plot,
    planned_subset_results$life$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_life)

plots_subgroup_ethnicity_life<- wrap_plots(
  list(
    planned_subset_results$life$ethnicity$results$Asian$plot,
    planned_subset_results$life$ethnicity$results$Euro$plot,
    planned_subset_results$life$ethnicity$results$Maori$plot,
    planned_subset_results$life$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_life)


plots_subgroup_political_life <- wrap_plots(
  list(
    planned_subset_results$life$political$results$Conservative$plot,
    planned_subset_results$life$political$results$Centrist$plot,
    planned_subset_results$life$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_life)

# plots
plots_subgroup_gender_life<- wrap_plots(
  list(
    planned_subset_results$life$gender$results$Female$plot,
    planned_subset_results$life$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_life)

# plots
plots_subgroup_cohort_life<- wrap_plots(
  list(
    planned_subset_results$life$cohort$results$Boomers$plot,
    planned_subset_results$life$cohort$results$Generation_X$plot,
    planned_subset_results$life$cohort$results$Generation_Y$plot,
    planned_subset_results$life$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_life)

# social well-being
plots_subgroup_wealth_social <- wrap_plots(
  list(
    planned_subset_results$social$wealth$results$Poor$plot,
    planned_subset_results$social$wealth$results$MiddleIncome$plot,
    planned_subset_results$social$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_social)

plots_subgroup_ethnicity_social<- wrap_plots(
  list(
    planned_subset_results$social$ethnicity$results$Asian$plot,
    planned_subset_results$social$ethnicity$results$Euro$plot,
    planned_subset_results$social$ethnicity$results$Maori$plot,
    planned_subset_results$social$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_social)


plots_subgroup_political_social <- wrap_plots(
  list(
    planned_subset_results$social$political$results$Conservative$plot,
    planned_subset_results$social$political$results$Centrist$plot,
    planned_subset_results$social$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_social)

# plots
plots_subgroup_gender_social<- wrap_plots(
  list(
    planned_subset_results$social$gender$results$Female$plot,
    planned_subset_results$social$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_social)

# plots
plots_subgroup_cohort_social<- wrap_plots(
  list(
    planned_subset_results$social$cohort$results$Boomers$plot,
    planned_subset_results$social$cohort$results$Generation_X$plot,
    planned_subset_results$social$cohort$results$Generation_Y$plot,
    planned_subset_results$social$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_social)











# ol ----------------------------------------------------------------------


# wealth subgroups --------------------------------------------------------
tables_list_poor <- list(
  Health = planned_subset_results$health$wealth$results$Poor$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$Poor$transformed_table,
  Life   = planned_subset_results$life$wealth$results$Poor$transformed_table,
  Social = planned_subset_results$social$wealth$results$Poor$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_poor,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Poor"),
                           highlight_color = NULL, output_format = "html")


# margot_bind_tables(tables_list = tables_list,
#                    bold = TRUE,
#                    highlight_color = NULL, output_format = "latex")
tables_list_middleincome <- list(
  Health = planned_subset_results$health$wealth$results$MiddleIncome$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$MiddleIncome$transformed_table,
  Life   = planned_subset_results$life$wealth$results$MiddleIncome$transformed_table,
  Social = planned_subset_results$social$wealth$results$MiddleIncome$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_middleincome,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Middle Income"),
                           highlight_color = NULL, output_format = "html")


planned_subset_results$health$wealth$results$Rich$transformed_table

tables_list_rich <- list(
  Health = planned_subset_results$health$wealth$results$Rich$transformed_table,
  Psych  = planned_subset_results$psych$wealth$results$Rich$transformed_table,
  Life   = planned_subset_results$life$wealth$results$Rich$transformed_table,
  Social = planned_subset_results$social$wealth$results$Rich$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_rich,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Rich"),
                           highlight_color = NULL, output_format = "html")




# Age subgroups -----------------------------------------------------------

# wealth subgroups --------------------------------------------------------
planned_subset_results$health$cohort$results$Generation_X$transformed_table

planned_subset_results$health$cohort$results$Boomers$transformed_table
tables_list_boomers <- list(
  Health = planned_subset_results$health$cohort$results$Boomers$transformed_table,
  Psych  = planned_subset_results$psych$cohort$results$Boomers$transformed_table,
  Life   = planned_subset_results$psych$cohort$results$Boomers$transformed_table,
  Social = planned_subset_results$psych$cohort$results$Boomers$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_boomers,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, 
                                          caption = "Cohort Subgroup Analysis: Boomers"),
                           highlight_color = "yellow", output_format = "html")


# margot_bind_tables(tables_list = tables_lisblue()# margot_bind_tables(tables_list = tables_list,
#                    bold = TRUE,
#                    highlight_color = NULL, output_format = "latex")
tables_list_genZ <- list(
  Health = planned_subset_results$health$cohort$results$Generation_Z$transformed_table,
  Psych  = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table,
  Life   = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table,
  Social = planned_subset_results$psych$cohort$results$Generation_Z$transformed_table
)


# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_genZ,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Cohort Subgroup Analysis: Generation Z"),
                           highlight_color = NULL, output_format = "html")




# new function bind tables
margot::margot_bind_tables(tables_list = tables_list_rich,
                           bold = TRUE,
                           kbl_args= list(booktabs = TRUE, caption = "Wealth Subgroup Analysis: Rich"),
                           highlight_color = NULL, output_format = "html")






# plots -------------------------------------------------------------------
# Results Plots
# health
plots_subgroup_wealth_health <- wrap_plots(
  list(
    planned_subset_results$health$wealth$results$Poor$plot,
    planned_subset_results$health$wealth$results$MiddleIncome$plot,
    planned_subset_results$health$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_health)

plots_subgroup_ethnicity_health<- wrap_plots(
  list(
    planned_subset_results$health$ethnicity$results$Asian$plot,
    planned_subset_results$health$ethnicity$results$Euro$plot,
    planned_subset_results$health$ethnicity$results$Maori$plot,
    planned_subset_results$health$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_health)

plots_subgroup_political_health <- wrap_plots(
  list(
    planned_subset_results$health$political$results$Conservative$plot,
    planned_subset_results$health$political$results$Centrist$plot,
    planned_subset_results$health$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_health)

# plots
plots_subgroup_gender_health<- wrap_plots(
  list(
    planned_subset_results$health$gender$results$Female$plot,
    planned_subset_results$health$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_health)

# plots
plots_subgroup_cohort_health<- wrap_plots(
  list(
    planned_subset_results$health$cohort$results$Boomers$plot,
    planned_subset_results$health$cohort$results$Generation_X$plot,
    planned_subset_results$health$cohort$results$Generation_Y$plot,
    planned_subset_results$health$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_health,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_health)

# psychological well-being
plots_subgroup_wealth_psych <- wrap_plots(
  list(
    planned_subset_results$psych$wealth$results$Poor$plot,
    planned_subset_results$psych$wealth$results$MiddleIncome$plot,
    planned_subset_results$psych$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_psych)

plots_subgroup_ethnicity_psych<- wrap_plots(
  list(
    planned_subset_results$psych$ethnicity$results$Asian$plot,
    planned_subset_results$psych$ethnicity$results$Euro$plot,
    planned_subset_results$psych$ethnicity$results$Maori$plot,
    planned_subset_results$psych$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_psych)


plots_subgroup_political_psych <- wrap_plots(
  list(
    planned_subset_results$psych$political$results$Conservative$plot,
    planned_subset_results$psych$political$results$Centrist$plot,
    planned_subset_results$psych$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_psych)

# plots
plots_subgroup_gender_psych<- wrap_plots(
  list(
    planned_subset_results$psych$gender$results$Female$plot,
    planned_subset_results$psych$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_psych)

# plots
plots_subgroup_cohort_psych<- wrap_plots(
  list(
    planned_subset_results$psych$cohort$results$Boomers$plot,
    planned_subset_results$psych$cohort$results$Generation_X$plot,
    planned_subset_results$psych$cohort$results$Generation_Y$plot,
    planned_subset_results$psych$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_psych,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_psych)



# present focussed well-being
plots_subgroup_wealth_present <- wrap_plots(
  list(
    planned_subset_results$present$wealth$results$Poor$plot,
    planned_subset_results$present$wealth$results$MiddleIncome$plot,
    planned_subset_results$present$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_present)

plots_subgroup_ethnicity_present<- wrap_plots(
  list(
    planned_subset_results$present$ethnicity$results$Asian$plot,
    planned_subset_results$present$ethnicity$results$Euro$plot,
    planned_subset_results$present$ethnicity$results$Maori$plot,
    planned_subset_results$present$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_present)


plots_subgroup_political_present <- wrap_plots(
  list(
    planned_subset_results$present$political$results$Conservative$plot,
    planned_subset_results$present$political$results$Centrist$plot,
    planned_subset_results$present$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_present)

# plots
plots_subgroup_gender_present<- wrap_plots(
  list(
    planned_subset_results$present$gender$results$Female$plot,
    planned_subset_results$present$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_present)

# plots
plots_subgroup_cohort_present<- wrap_plots(
  list(
    planned_subset_results$present$cohort$results$Boomers$plot,
    planned_subset_results$present$cohort$results$Generation_X$plot,
    planned_subset_results$present$cohort$results$Generation_Y$plot,
    planned_subset_results$present$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_present,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_present)


## life focussed well-being
plots_subgroup_wealth_life <- wrap_plots(
  list(
    planned_subset_results$life$wealth$results$Poor$plot,
    planned_subset_results$life$wealth$results$MiddleIncome$plot,
    planned_subset_results$life$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_life)

plots_subgroup_ethnicity_life<- wrap_plots(
  list(
    planned_subset_results$life$ethnicity$results$Asian$plot,
    planned_subset_results$life$ethnicity$results$Euro$plot,
    planned_subset_results$life$ethnicity$results$Maori$plot,
    planned_subset_results$life$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_life)


plots_subgroup_political_life <- wrap_plots(
  list(
    planned_subset_results$life$political$results$Conservative$plot,
    planned_subset_results$life$political$results$Centrist$plot,
    planned_subset_results$life$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_life)

# plots
plots_subgroup_gender_life<- wrap_plots(
  list(
    planned_subset_results$life$gender$results$Female$plot,
    planned_subset_results$life$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_life)

# plots
plots_subgroup_cohort_life<- wrap_plots(
  list(
    planned_subset_results$life$cohort$results$Boomers$plot,
    planned_subset_results$life$cohort$results$Generation_X$plot,
    planned_subset_results$life$cohort$results$Generation_Y$plot,
    planned_subset_results$life$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_life,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_life)

# social well-being
plots_subgroup_wealth_social <- wrap_plots(
  list(
    planned_subset_results$social$wealth$results$Poor$plot,
    planned_subset_results$social$wealth$results$MiddleIncome$plot,
    planned_subset_results$social$wealth$results$Rich$plot
  ),
  ncol = 1
) +
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_wealth_social)

plots_subgroup_ethnicity_social<- wrap_plots(
  list(
    planned_subset_results$social$ethnicity$results$Asian$plot,
    planned_subset_results$social$ethnicity$results$Euro$plot,
    planned_subset_results$social$ethnicity$results$Maori$plot,
    planned_subset_results$social$ethnicity$results$Pacific$plot
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_ethnicity_social)


plots_subgroup_political_social <- wrap_plots(
  list(
    planned_subset_results$social$political$results$Conservative$plot,
    planned_subset_results$social$political$results$Centrist$plot,
    planned_subset_results$social$political$results$Conservative$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_political_social)

# plots
plots_subgroup_gender_social<- wrap_plots(
  list(
    planned_subset_results$social$gender$results$Female$plot,
    planned_subset_results$social$gender$results$Male$plot
  ),
  ncol = 1
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

# view
print(plots_subgroup_gender_social)

# plots
plots_subgroup_cohort_social<- wrap_plots(
  list(
    planned_subset_results$social$cohort$results$Boomers$plot,
    planned_subset_results$social$cohort$results$Generation_X$plot,
    planned_subset_results$social$cohort$results$Generation_Y$plot,
    planned_subset_results$social$cohort$results$Generation_Z$plot
    
  ),
  ncol = 2
)+
  patchwork::plot_annotation(
    title = subtitle_social,
    theme = theme(plot.title = element_text(size = 18,  face = "bold"))
  )

print(plots_subgroup_cohort_social)



# individual plot options: showcased ---------------------------------------------
# default
margot_plot_decision_tree(
  models_binary_social,
  "model_t2_support_z",
)
# tighten branches for easier viewing in single graphs
margot::margot_plot_decision_tree(
  models_binary_social,
  "model_t2_support_z",
  span_ratio = .30,
  text_size = 3.8,
  border_size = .1,
  #  title = "none",
  original_df = original_df
)
# colour decision node
margot::margot_plot_decision_tree(
  models_binary_social,
  "model_t2_support_z",
  span_ratio = .3,
  text_size = 4, 
  title = "New Title",
  non_leaf_fill =  "violet",
  original_df = original_df
)
# make new title
margot::margot_plot_decision_tree(
  models_binary_social,
  "model_t2_support_z",
  span_ratio = .2,
  text_size = 3, 
  title = "New Title",
  non_leaf_fill =  "white",
  original_df = original_df
)

# remove title
margot::margot_plot_decision_tree(
  models_binary_social,
  "model_t2_support_z",
  text_size = 5, 
  title = 'none', # set title to none
  original_df = original_df
)

# policy tree options 
# select only plot 1 change alpha
margot::margot_plot_policy_tree(
  models_binary_social,
  "model_t2_support_z",
  point_alpha = .25, 
  plot_selection = "p1"
)
# select only plot 2 change size of axis_text
# change colours, modify etc... 
margot::margot_plot_policy_tree(
  models_binary,
  "model_t2_agreeableness_z",
  plot_selection = "p2",
  axis_title_size = 30,
  split_label_size = 20,
  split_label_color = "red",
  split_line_color = "red",
)


# just the alpha
margot::margot_plot_policy_tree(
  models_binary,
  "model_t2_agreeableness_z",
  point_alpha = .1
)

```


## HOMEWORK: Prepare A Fresh Set of Analysis Scripts With A Different Exposure

- E.g. Ask: what are the effects of a shift in religious service `religion_church` on multi-dimensional well-being. 
- Consider what variables you need for confounding control at baseline. 
- Think about how to make the exposure variable binary.
- You may consider different outcome(s) as well as a different exposure. 




### Packages

```{r}
report::cite_packages()
```



## Appendix 

## Review: The Fundamental Problem of Causal Inference as a Missing Data Problem

Recall the fundamental problem of causal inference, returning to the question of whether bilingualism improves cognitive abilities:

-   $Y_i^{a = 1}$: The cognitive ability of child $i$ if they were bilingual. This is the counterfactual outcome when A = 1.
-   $Y_i^{a = 0}$:: The cognitive ability of child $i$ if they were monolingual. This is the counterfactual outcome when A = 0.

The causal effect of bilingualism on cognitive ability for individual $i$ is then defined as the difference between these potential outcomes:

$$
\text{Causal Effect}_i = Y_i^{a=1} - Y_i^{a=0} 
$$

We say there is a causal effect if:

$$
Y_i^{a=1} - Y_i^{a=0}  \neq 0
$$

However, we only observe one of the potential outcomes for each child. The other outcome is not observed because physics prevents a child from both receiving and not receiving bilingual exposure.

The fact that causal contrasts are not observed in individuals is called "The fundamental problem of causal inference."

Although we typically cannot observe individual causal effects, we can obtain average causal effects when certain assumptions are satisfied.

```{=tex}
\begin{align}
E(\delta) = E(Y^{a=1} - Y^{a=0})\\
          ~  = E(Y^{a=1}) - E(Y^{a=0}) \\
          ~  = ATE
\end{align}
```
We may identify average causal effects from the data when the following assumptions are met:

-   **Causal Consistency:** The exposure values under comparisons correspond to well-defined interventions that, in turn, correspond to the treatment versions in the data.[]
-   **Positivity:** The probability of receiving every value of the exposure within all strata of co-variates is greater than zero []
-   **Exchangeability:** The conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates []

Further assumptions:

-   **No Interference,** also known as the **Stable Unit Treatment Value Assumption** (SUTVA), requires that the treatment given to one unit (e.g., person, group, organization) does not interfere with the potential outcomes of another unit. Put differently, there are no "spillover" effects. Note: this assumption may be thought to be part of causal consistency, namely individual has only one potential outcome under each treatment condition.
-   **Correctly specified model**: the requirement that the underlying statistical model used to estimate causal effects accurately represents the true relationships between the variables of interest. We say the model should be able to capture "the functional form" of the relationship between the treatment, the outcome, and any covariates. The model's functional form should be flexible enough to capture the true underlying relationship. The estimated causal effects may be biased if the model's functional form is incorrect. Additionally, the model must handle omitted variable bias by including all relevant confounders and should correctly handle missing data from non-response or loss-to follow up. We will return to the bias arising from missing data in the weeks ahead. For now, it is important to note that causal inference assumes that our model is correctly specified.


## Subgroup analysis

Redcall, **Effect Modification** (also known as "heterogeneity of treatment effects", and "Effect-measure modification") occurs when the causal effect of intervention $A$ varies across different levels of another variable $R$:

$$E(Y^{a=1}|G=g_1, L=l) - E(Y^{a=0}|G=g_1, L=l) \neq E(Y^{a=1}|G=g_2, L=l) - E(Y^{a=0}|G=g_2, L=l)$$

Effect modification indicates that the magnitude of the causal effect of intervention $A$ is related to the modifier variable $G$ level. As discussed last week, effect modification can be observed even when there is no direct causal interaction between the treatment and the modifier variable. We noted that **interaction in causal inference refers to a situation where the combined effect of two interventions is not equal to the sum of their individual effects**. **Effect modification, on the other hand, occurs when the causal effect of one intervention varies across different levels of another variable.**


We also noted that 

> **For comparative research, we are typically interested in effect-modification, which requires subgroup analysis.**


### Causal Estimand, Statistical Estimand, Statistical Estimator

Let's set subgroup analysis to the side for a moment and begin focussing on statistical estimation.  

Suppose a researcher wants to understand the causal effect of marriage on individual happiness. Participants in the study are surveyed for their marital status ("married" or "not married") and their self-reported happiness on a scale from 1 to 10.

#### Causal Estimand

- **Definition**: The causal estimand is the specific quantity or parameter that we aim to estimate to understand the causal effect of an intervention or treatment on an outcome.

- **Example**: Here, the **Causal Estimand** would be the Average Treatment Effect (ATE) of being married on happiness. Specifically, we define the ATE as the difference in the potential outcomes of happiness if all individuals were married versus if no individuals were married:

  $$
  \text{ATE} = E[Y^{a=1} - Y^{a=0}]
  $$


  Here, $Y^{a=1}$ represents the potential happiness score if an individual is married, and $Y^{a=0}$ if they are not married.


#### Next step: Are Causal Assumptions Met? 

- Identification (Exchangeability): balance in the confounders across the treatments to be compared

- Consistency: well-defined interventions

- Positivity: treatments occur within levels of covariates $L$


#### Statistical Estimand (next step)

- **The problem**: how do we bridge the gap between potential outcomes and data? 

- **Definition**: the statistical estimand is the parameter or function that summarises the relationship between variables as described by a statistical model applied to data. 

- **Example**: for our study, the **Statistical Estimand** might be the mean difference in happiness scores between individuals who are married and those who are not, as derived from a linear regression model:

  $$
  \text{Happiness} = \beta_0 + \beta_1 \times \text{Married} + \epsilon
  $$

  In this equation, $\beta_1$ represents the estimated difference in happiness scores between the married and non-married groups.

#### Statistical Estimator

- **Definition**: a statistical estimator is a rule or method by which a numerical estimate of a statistical estimand is calculated from the data.

- **Example**: in our marriage study, the **Statistical Estimator** for $\beta_1$ is the ordinary least squares (OLS) estimator. This estimator is used to calculate $\beta_1$ from the sample data provided by the survey. It provides an estimate of the impact of being married on happiness, calculated using:
  $$
  \hat{\beta}_1 = \frac{\sum_{i=1}^n (X_i - \bar{X})(Y_i - \bar{Y})}{\sum_{i=1}^n (X_i - \bar{X})^2}
  $$
  where $X_i$ is a binary indicator for being married (1 for married, 0 for not married), $Y_i$ is the observed happiness score, and $\bar{X}$, $\bar{Y}$ are the sample means of $X$ and $Y$, respectively.

The upshot, we anchor our causal inquiries within a multi-step framework of data analysis. This involves: 

1. clearly defining our causal estimand within a specified *target population,*
2. clarifying assumptions, & especially identification assumptions, 
3. describing a statistical strategy for extracting this estimand from the data, and then 
4. applying an algorithm that embodies this statistical method.


<!-- ## Methods for Statistical Estimation in Causal Inference: Inverse Probability of Treatment Weights Using Propensity Scores -->

<!-- Last week, we discussed confounding control using regression adjustment. Recall the formula for the average treatment effect (ATE) when conditioning on a set of covariates $L$: -->

<!-- $$ -->
<!-- \begin{aligned} -->
<!-- \text{ATE} = E[Y^{a=1} \mid L = l] - E[Y^{a=0} \mid L = l] \quad \text{for any value of } l -->
<!-- \end{aligned} -->
<!-- $$ -->

<!-- > "We say that a set $L$ of measured non-descendants of $L$ is a sufficient set for confounding adjustment when conditioning on $L$ blocks all backdoor paths—that is, the treated and the untreated are exchangeable within levels of $L$" (Hernán & Robins, *Causal Inference*, p. 86). -->

<!-- This formula calculates the expected outcome difference between treated ($a=1$) and untreated ($a=0$) groups, given a specific value of the covariates $l$. -->

<!-- Inverse Probability of Treatment Weighting (IPTW) takes a different approach. We create a pseudo-population where the treatment assignment is independent of the observed covariates by assigning weights to each individual based on their propensity scores. -->

<!-- **We do this by modelling the treatment** -->

<!-- Denote the treatment indicator by $A$, where $A = 1$ if an individual receives treatment and $A = 0$ otherwise. $L$ represents the vector of observed covariates, and $Y^a$ the potential outcomes. The propensity score, $e(L)$, is defined as the probability of receiving the treatment given the observed covariates: -->

<!-- $$ -->
<!-- \hat{e}(L) = P(A = 1 \mid L) -->
<!-- $$ -->

<!-- To obtain IPTW weights, compute the inverse probability of treatment: -->

<!-- $$ -->
<!-- v_i = \frac{A_i}{\hat{e}(L_i)} + \frac{1 - A_i}{1 - \hat{e}(L_i)} -->
<!-- $$ -->

<!-- Which simplifies to  -->

<!-- $$ -->
<!-- v_i =  -->
<!-- \begin{cases}  -->
<!-- \frac{1}{\hat{e}} & \text{if } A_i = 1 \\ -->
<!-- \frac{1}{1-\hat{e}} & \text{if } A_i = 0  -->
<!-- \end{cases} -->
<!-- $$ -->

<!-- where $v_i$ is the IPTW weight for individual $i$, $A_i$ is the treatment indicator for individual $i$, and $\hat{e}(L_i)$ is the estimated propensity score for individual $i$.    -->

<!-- How might we use these weights to obtain causal effect estimates? -->



<!-- ## Marginal Structural Models (MSMs) -->

<!-- Marginal Structural Models (MSMs) estimate causal effects without requiring an "outcome model" that stratifies on covariates. Rather, MSMs employ weights derived from the inverse probability of treatment weighting (IPTW) to create a pseudo-population in which the distribution of covariates is independent of treatment assignment over time. -->

<!-- The general form of an MSM can be expressed as follows: -->

<!-- $$ -->
<!-- E[Y^a] = \beta_0 + \beta_1a -->
<!-- $$ -->

<!-- where $E[Y^a]$ is the expected outcome under treatment $a$  and $\beta_0$ and $\beta_1$ are parameters estimated by fitting the weighted model. Again, the weights used in the MSM, typically derived from the IPTW (or another treatment model), adjust for the confounding, allowing the model to estimate the unbiased effect of the treatment on the outcome without requiring covariates in the model. -->

<!-- Where do weights fit in?   Note, we have $E[Y^a]$ in please of $E[Y|A=a]$.  When applying propensity score weights in the linear regression model $E[Y^a] = \beta_0 + \beta_1a$, each observation is weighted by $v_i$, such that $v_i(\beta_0 + \beta_1a)$. This changes the estimation process to focus on a weighted sum of outcomes, where each individual's contribution is adjusted to reflect their probability of receiving the treatment, given their covariates. -->


<!-- ## Interpretation of $\beta_0$ and $\beta_1$  in a Marginal Structural Model -->

<!-- ### Binary Treatment -->

<!-- In models where the treatment $a$ is binary (e.g., $a = 0$ or $a = 1$), such as in many causal inference studies: -->

<!-- - **$\beta_0$**: the expected value of the outcome $Y$ when the treatment is not applied ($a = 0$). This is the baseline level of the outcome in the absence of treatment. -->
<!-- - **$\beta_1$**: the change in the expected outcome when the treatment status changes from 0 to 1. In logistic regression, $\beta_1$ represents the log-odds ratio of the outcome for the treatment group relative to the control group. In linear regression, $\beta_1$ quantifies the difference in the average outcome between the treated and untreated groups. -->

<!-- ### Continuous Treatment -->

<!-- When the treatment $a$ is continuous, the interpretation of $\beta_0$ and $\beta_1$ adjusts slightly: -->

<!-- - **$\beta_0$**: represents the expected value of the outcome $Y$ when the treatment $a$ is at its reference value (often zero).  -->
<!-- - **$\beta_1$**: represents the expected change in the outcome for each unit increase in the treatment. In this case, $\beta_1$ measures the gradient or slope of the relationship between the treatment and the outcome. For every one-unit increase in treatment, the outcome changes by $\beta_1$ units, assuming all other factors remain constant. -->


<!-- ###  How can we apply marginal structural models in subgroups?  -->


<!-- ### Assumptions -->

<!-- - **Model assumptions**: the treatment model is correctly specified. -->
<!-- - **Causal assumptions**: all confounders are appropriately controlled, positivity and consistency assumptions hold. -->


<!-- ### Calculating Treatment Weights (Propensity Scores) and Confounding Control in Subgroups -->

<!-- We may often achieve greater balance when conducting weighted analyses in subgroups by estimating propensity scores *within* these subgroups. The propensity score $ e(L, G) $ is the conditional probability of receiving the exposure $ A = 1 $, given the covariates $ L $ and subgroup indicator $ G $. This is often modelled using logistic regression or other methods that ensure covariate balance -->
<!-- We define the estimated propensity score as follows: -->

<!-- $$ -->
<!-- \hat{e} = P(A = 1 \mid L, G) = f_A(L, G; \theta_A) -->
<!-- $$ -->

<!-- Here, $ f_A(L, G; \theta_A) $ is the statistical model estimating the probability of exposure $A = 1$ given covariates $L$ and subgroup $G$. We then calculate the weights for each individual, denoted $v$, using the estimated propensity score: -->

<!-- $\theta_A$ encapsulates all the coefficients (parameters) in this model, including intercepts, slopes, and potentially other parameters depending on the model complexity (e.g., interaction terms, non-linear effects...etc). -->

<!-- These weights $v$ depend on $A$ and are calculated as the inverse of the propensity score for exposed individuals and as the inverse of $ 1-\hat{e} $ for unexposed individuals. -->

<!-- Propensity scores are estimated *separately* within strata of the subgroup to control for potential confounding tailored to each subgroup. These weights $v$ are specific to each individual in subgroup $G$. In the lab, we will clarify how to fit models to estimate contrasts for the causal effects within groups $\hat{\delta}_{g}, \hat{\delta}_{g'}$, etc., and how to obtain estimates for group-wise differences: -->

<!-- $$ -->
<!-- \hat{\gamma} = \overbrace{\big( \hat{E}[Y^a \mid G=g] - \hat{E}[Y^{a'} \mid G=g] \big)}^{\hat{\delta}_g} - \overbrace{\big( \hat{E}[Y^{a'} \mid G=g'] - \hat{E}[Y^a \mid G=g'] \big)}^{\hat{\delta}_{g'}} -->
<!-- $$ -->


<!-- - **$\hat{E}[Y^a \mid G=g]$**: Estimated expected outcome when treatment $a$ is applied to subgroup $G=g$. -->
<!-- - **$\hat{E}[Y^{a'} \mid G=g]$**: Estimated expected outcome when a different treatment or control $a'$ is applied to the same subgroup $G=g$. -->
<!-- - **$\hat{\delta}_g$**: Represents the estimated treatment effect within subgroup $G=g$, computed as the difference in expected outcomes between treatment $a$ and $a'$ within this subgroup. -->

<!-- - **$\hat{E}[Y^{a'} \mid G=g']$**: Estimated expected outcome when treatment $a'$ is applied to a different subgroup $G=g'$. -->
<!-- - **$\hat{E}[Y^a \mid G=g']$**: Estimated expected outcome when treatment $a$ is applied to subgroup $G=g'$. -->
<!-- - **$\hat{\delta}_{g'}$**: Represents the estimated treatment effect within subgroup $G=g'$, computed as the difference in expected outcomes between treatment $a'$ and $a$ within this subgroup. -->

<!-- - **$\hat{\gamma}$**: The overall measure calculated from your formula represents the difference in treatment effects between two subgroups, $G=g$ and $G=g'$. It quantifies how the effect of switching between treatments $a$ and $a'$ differs across the two subgroups. -->


<!-- ### Considerations -->

<!-- - **Estimation**: to estimate the expected outcomes $\hat{E}[Y^a \mid G]$ and $\hat{E}[Y^{a'} \mid G]$, we require statistical models. If we use regression, we include interaction terms between treatment and subgroup indicators to directly estimate subgroup-specific treatment effects. Our use depends on correct model specification. -->
<!-- - **Confidence intervals**: we may compute confidence intervals for $\hat{\gamma}$ using bootstrap, the delta method, or -- in our excercises -- simulation based methods. -->
<!-- - **Causal assumptions**: again, a causal interpretation of $\hat{\gamma}$ relies on satisfying both causal assumptions and modelling assumptions.  Here, we have described estimation using propensity scores. -->


<!-- ## Doubly Robust Estimation -->

<!-- We can combine regression-based estimation with propensity score estimation to obtain *doubly robust* estimation. I will walk you through the steps in the lab. The TL;DR is this: doubly robust estimation reduces reliance on correct model specification. If either the PS model or the regression model is correctly specified, the model will be unbiased -- if the other causal inference assumptions are met. -->

<!-- We cannot know whether these assumptions are met, we will need to do a sensitivity analysis, the topic of next week. -->

<!-- I'll show you in lab how to employ simulation-based inference methods to compute standard errors and confidence intervals, following the approaches suggested by Greifer (2023)[]. -->

<!-- ## Extra Readings n on Propensity Scores: -->

<!-- Noah Griefer's Software and Blogs: [https://ngreifer.github.io/blog/subgroup-analysis-psm/](https://ngreifer.github.io/blog/) -->