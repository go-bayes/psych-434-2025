---
title: "Causal Inference: Effect Modification, Interaction, and Conditional Average Treatment Effects"
date: "2025-APR-01"
bibliography: /Users/joseph/GIT/templates/bib/references.bib
editor_options: 
  chunk_output_type: console
format:
  html:
    warnings: FALSE
    error: FALSE
    messages: FALSE
    code-overflow: scroll
    highlight-style: kate
    code-tools:
      source: true
      toggle: FALSE
html-math-method: katex
reference-location: margin
citation-location: margin
cap-location: margin
code-block-border-left: true
---


```{=html}
<style>
  .boxedblue {
      border: 2px solid blue;
      border-radius: 4px; /* slight roundness */
      padding: 3px 6px; /* vertical | horizontal */
      display: inline-block;
      color: blue;
   }
  .circleblue {
      border: 2px dashed blue;
      border-radius: 50%;
      padding: 3px 6px;
      display: inline-block;
      color: blue;
   }
</style>
```


```{r setup, include=FALSE}
#| include: false
# libraries and functions
# Ensure necessary packages like tinytex, extrafont might be loaded if needed globally or per-project.
# library("tinytex")
# library(extrafont)
# loadfonts(device = "win") # Adjust device based on OS if using extrafont

# read functions if any external functions are used
# source("/Users/joseph/GIT/templates/functions/funs.R") 
```

::: {.callout-note}
**Required Reading**
- [@hernan2024WHATIF] Chapters 4-5 [link](https://www.dropbox.com/scl/fi/9hy6xw1g1o4yz94ip8cvd/hernanrobins_WhatIf_2jan24.pdf?rlkey=8eaw6lqhmes7ddepuriwk5xk9&dl=0)

**Optional Reading**
- [@vanderweele2007FOURTYPESOFEFFECT] [link](https://www.dropbox.com/scl/fi/drytp2ui2b8o9jplh4bm9/four_types_of_effect_modification__a.6.pdf?rlkey=mb9nl599v93m6kyyo69iv5nz1&dl=0)
- [@vanderweele2009distinction] [link](https://www.dropbox.com/scl/fi/srpynr0dvjcndveplcydn/OutcomeWide_StatisticalScience.pdf?rlkey=h4fv32oyjegdfl3jq9u1fifc3&dl=0)
:::

::: {.callout-important}
## Key Concepts for Assessment
  - Causal Estimand
  - Statistical Estimand
  - Interaction
  - Effect Modification
  - Heterogeneous Treatment Effects (HTE)
  - Conditional Average Treatment Effect (CATE) $\tau(x)$
  - Estimated Conditional Average Treatment Effect $\hat{\tau}(X)$ # Added estimator for clarity
:::


## If you learn nothing else from this course...

To answer a psychological question scientifically, we must first state it precisely. Causal inference provides the framework for doing so.


## Causal inference begins by stating a counterfactual contrast

In the simplest case, we define a contrast between potential outcomes under two or more alternative conditions, often called "treatments" or "exposures" (denoted $A$). For an outcome $Y$, we might compare the potential outcome if everyone received treatment level $a^*$ versus if everyone received treatment level $a$. The average difference in the population is the Average Treatment Effect (ATE):

$$
\text{ATE} = \mathbb{E}[Y(a^*) - Y(a)]
$$

Understanding causal inference involves comparing what actually happened with what *could have happened* (counterfactuals) on average, under different specified conditions, within a defined target population. A crucial part of this process involves identifying and accounting for factors (confounders) that could distort the comparison and lead to incorrect conclusions about the causal question asked.


## In Causal Inference, What do 'Interaction' and 'Effect Modification' mean? 

We often encounter terms like 'moderation' and 'interaction' used loosely in psychological science. Causal inference demands greater precision. We will set aside the ambiguous term 'moderation' and focus on clearly distinguishing two specific concepts using the counterfactual framework: 

1.  **Interaction**
2.  **Effect Modification**


## Interaction: The Effect of Joint Interventions

In the framework of causal inference, **interaction** specifically relates to evaluating a **joint intervention**. We are interested in the combined causal effect when we simultaneously intervene on *two (or more) distinct treatments* or exposures.

Let these distinct treatments be $A$ and $B$, and the outcome be $Y$.

Recall the potential outcome under a single intervention setting $A$ to level $\tilde{a}$ is $Y(\tilde{a})$. We typically aim to identify this from observational data using assumptions such as consistency ($Y_i(\tilde{a}) = (Y_i |A_i = \tilde{a})$ for individual $i$) and conditional exchangeability (no unmeasured confounding) given a set of measured covariates $L$: $Y(\tilde{a}) \perp\kern-5pt\perp A | L$. The set $L$ must be sufficient to block all non-causal (backdoor) paths between $A$ and $Y$.

When considering a joint intervention on both $A$ and $B$, we extend the notation to $Y(\tilde{a}, \tilde{b})$. This represents the potential outcome if treatment $A$ were set to $\tilde{a}$ *and* treatment $B$ were set to $\tilde{b}$ for an individual or population.

Identification of $Y(\tilde{a}, \tilde{b})$ requires analogous assumptions for both interventions. In addition to needing $L$ for the $A \to Y$ relationship ($Y(\tilde{a}) \perp\kern-5pt\perp A | L$), we also need a set of covariates $Q$ sufficient to ensure conditional exchangeability for the $B \to Y$ relationship: $Y(\tilde{b}) \perp\kern-5pt\perp B | Q$. Consistency must also hold for $B$.

The sets of required covariates $L$ and $Q$ may overlap ($L \cap Q \not\equiv \emptyset$). Critically, identifying causal interaction requires sufficient data to control for *all* variables in the union of these sets, $L \cup Q$.


### Defining Interaction with a Counterfactual Contrast

Let's use an educational example. Consider the effect of a new teaching method (treatment $A$: 1=New, 0=Old) on student test scores (outcome $Y$). Suppose we are also interested in the effect of providing extra tutoring (treatment $B$: 1=Yes, 0=No). We want to assess the individual and combined effects of $A$ and $B$ on test scores, perhaps on the difference scale (additive scale).

Using counterfactuals, we define **causal interaction on the additive scale** as occurring when the effect of intervening on both $A$ and $B$ simultaneously differs from the sum of the effects of intervening on each one individually (always relative to a common baseline, usually $A=0, B=0$). The interaction is non-zero if:

$$
\bigg(\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint intervention}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither intervention}}\bigg) - \bigg[ \bigg(\underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A intervention}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither intervention}}\bigg) + \bigg(\underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B intervention}} - \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither intervention}} \bigg)\bigg] \neq 0
$$

This expression simplifies to the standard definition of additive interaction (see appendix):

$$
\underbrace{\mathbb{E}[Y(1,1)]}_{\text{joint}} - \underbrace{\mathbb{E}[Y(1,0)]}_{\text{only A}} - \underbrace{\mathbb{E}[Y(0,1)]}_{\text{only B}} + \underbrace{\mathbb{E}[Y(0,0)]}_{\text{neither}} \neq 0
$$

This specific quantity is the causal estimand for additive interaction. It captures the extent to which the joint effect deviates from additivity. A positive value implies synergy (superadditivity); a negative value implies antagonism (subadditivity). Note the definition is symmetric regarding $A$ and $B$: $Y(\tilde{a}, \tilde{b}) \equiv Y(\tilde{b}, \tilde{a})$.

*(Other scales, like the multiplicative/ratio scale, can define interaction, potentially leading to different conclusions. The choice of scale should always be justified.)*

#### Identification of Causal Interaction

To estimate this causal interaction from data, we must identify all four potential outcome means: $\mathbb{E}[Y(0,0)]$, $\mathbb{E}[Y(1,0)]$, $\mathbb{E}[Y(0,1)]$, and $\mathbb{E}[Y(1,1)]$. This requires controlling for confounding factors for *both* the $A \to Y$ relationship and the $B \to Y$ relationship. The causal diagram in @fig-dag-interaction illustrates this requirement.


```{tikz}
#| label: fig-dag-interaction
#| fig-cap: "Diagram illustrating causal interaction. Assessing the joint effect of two interventions, A (e.g., teaching method) and B (e.g., tutoring), on outcome Y (e.g., test score). L represents confounders of the A-Y relationship, and Q represents confounders of the B-Y relationship. Red arrows indicate biasing backdoor paths requiring adjustment. Assumes A and B are decided independently here."
#| out-width: 100%
#| echo: false

\usetikzlibrary{positioning, shapes.geometric, arrows, decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=white] (LA) at (0, .5) {$L_{0}$};
\node [rectangle, draw=white] (LB) at (0, -.5) {$Q_{0}$};
\node [rectangle, draw=white] (A) at (2, .5) {$A_{1}$};
\node [rectangle, draw=white] (B) at (2, -.5) {$B_{1}$};
\node [rectangle, draw=white] (Y) at (5, 0) {$Y_{2}$};
\draw [-latex, draw=red] (LA) to (A);
\draw [-latex, draw=red] (LB) to (B);
\draw [-latex, draw=red, bend left] (LA) to (Y);
\draw [-latex, draw=red, bend right] (LB) to (Y);
\draw [-latex, draw=black] (A) to (Y); 
\draw [-latex, draw=black] (B) to (Y); 
\end{tikzpicture}
```

As shown in @fig-dag-interaction-solved, identifying the causal interaction requires conditioning on (adjusting for) *both* sets of confounders, $L_0$ and $Q_0$, blocking the backdoor paths.

```{tikz}
#| label: fig-dag-interaction-solved
#| fig-cap: "Identification of causal interaction requires adjusting for all confounders of A-Y (L) and B-Y (Q). Boxes around L and Q indicate conditioning, closing backdoor paths."
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning, shapes.geometric, arrows, decorations}
\tikzstyle{Arrow} = [->, thin, preaction = {decorate}]
\tikzset{>=latex}
\begin{tikzpicture}[{every node/.append style}=draw]
\node [rectangle, draw=black] (LA) at (0, .5) {$L_{0}$}; 
\node [rectangle, draw=black] (LB) at (0, -.5) {$Q_{0}$}; 
\node [rectangle, draw=white] (A) at (2, .5) {$A_{1}$};
\node [rectangle, draw=white] (B) at (2, -.5) {$B_{1}$};
\node [rectangle, draw=white] (Y) at (5, 0) {$Y_{2}$};
\draw [-latex, draw=black] (LA) to (A);
\draw [-latex, draw=black] (LB) to (B);
\draw [-latex, draw=black, bend left] (LA) to (Y);
\draw [-latex, draw=black, bend right] (LB) to (Y);
\draw [-latex, draw=black] (A) to (Y);
\draw [-latex, draw=black] (B) to (Y);
\end{tikzpicture}
```

In our education example:
**L (confounders of Teaching Method -> Score):** Prior student achievement, student motivation, socioeconomic status (SES), school resources, teacher experience/quality (if method not randomly assigned across teachers).

**Q (confounders of Tutoring -> Score):** Prior student achievement, student motivation, parental
involvement/SES (influencing access/payment for tutoring), student time availability, specific learning needs.

Here, $L \cap Q$ clearly includes prior achievement and student motivation. Therefore, $L \cup Q$ is a potentially large set of variables requiring measurement and adjustment. Failure to adequately control for $L \cup Q$ leads to biased estimates of causal interaction.



## Effect Modification: Variation in a Single Effect

Distinct from **interaction** (which involves joint interventions), **effect modification** examines whether the causal effect of a *single* intervention ($A$) on an outcome ($Y$) differs across subgroups within a population. These subgroups are typically defined by baseline characteristics ($G$ or $X$), which may or may not be modifiable themselves. Understanding effect modification helps identify for whom an intervention is most (or least) effective. We explore this potential variability using concepts like Heterogeneous Treatment Effects (HTE) and Conditional Average Treatment Effects (CATE).


### Heterogeneous Treatment Effects (HTE): The Phenomenon of Variability

**Heterogeneous Treatment Effects (HTE)** refers to the *phenomenon* where the causal effect of an intervention ($A$ on $Y$) is not constant across all individuals or subgroups. This *is* effect modification. The variability might stem from differences in observed characteristics (like age, sex, or prior conditions captured in measured covariates $X$) or unobserved factors (like genetics, unmeasured environmental factors, or personal history). HTE reflects the reality that interventions rarely affect everyone identically.

Identifying the full extent of HTE, especially variation due to unobserved factors, is challenging because individual causal effects are generally not point identifiable.


### Conditional Average Treatment Effect (CATE): A Specific Measure $\tau(x)$

To investigate HTE using observable data, we focus on estimating the **Conditional Average Treatment Effect (CATE)**. CATE is a specific causal *estimand*: the average treatment effect *conditional on observed covariates* $X$ taking a specific value or set of values $x$.

$$
\tau(x) = \text{CATE}(x) = \mathbb{E}[Y(1) - Y(0) | X = x]
$$

Estimating $\text{CATE}(x)$ (denoted $\tau(x)$) for different values of $x$ allows us to quantify effect modification by the *measured* characteristics $X$. It is a primary tool for studying the broader HTE phenomenon, answering: How does the average effect of $A$ differ for individuals with specific observed characteristics $X=x$?


### Comparing Effect Heterogeneity Across Groups

A direct way to assess effect modification by a categorical variable $G$ (e.g., comparing effects between males and females, or across different study sites) is to compare the average treatment effect (ATE) estimated *within* each level of $G$. This involves comparing CATEs where the conditioning variable $X$ is simply the group indicator $G$.

We define the causal estimand that compares two conditional average treatment effects between levels $g$ and $g'$ of variable $G$:

$$
{\gamma} = \overbrace{\big( \mathbb{E}[Y(a^*)|G=g] - \mathbb{E}[Y(a)|G=g] \big)}^{{\delta_g=\text{CATE}(G=g)}} - \overbrace{\big(\mathbb{E}[Y(a^*)|G=g^{\prime}]- \mathbb{E}[Y(a)|G=g']\big)}^{{\delta_{g^{\prime}}=\text{CATE}(G=g')}}
$$

Let $A$ be the treatment (e.g., $a=0$ to $a^*=1$), $G$ the potential effect-modifier (e.g., sex: $g=$female, $g'=$male), and $Y$ the outcome. The analysis assesses whether $\delta$, the effect of $A$ on $Y$, differs across levels of $G$.

For example, comparing the causal effect of an intervention for females ($G=g_1$) versus males ($G=g_2$):

1.  **Causal effect within females ($G=g_1$):**
    $$
    \delta_{g_1} = \mathbb{E}[Y(1)|G= g_1] - \mathbb{E}[Y(0)|G = g_1]
    $$ 

2.  **Causal effect within males ($G=g_2$):**
    $$
    \delta_{g_2} = \mathbb{E}[Y(1)|G=g_2] - \mathbb{E}[Y(0)|G=g_2]
    $$

3.  **Comparing causal effects across groups:**
    $$
    {\gamma} = {\delta}_{g_1} - {\delta}_{g_2}
    $$ 
    A non-zero estimate $\hat{\gamma}$ indicates effect modification by $G$. The intervention's effect differs between females and males. Note that $\hat{\gamma} \neq 0$ can occur even if one group's effect ($\hat{\delta}_{g_1}$ or $\hat{\delta}_{g_2}$) is near zero.

#### Identification of Effect Modification

To identify group-specific effects ($\delta_g, \delta_{g'}$) and their difference ($\gamma$), we need to ensure exchangeability for $A$ holds *within* each stratum defined by $G$. That is, we must control for confounders ($L$) of the $A \to Y$ relationship, potentially allowing $L$ itself to be associated with $G$. Crucially, since $G$ defines the subpopulations of interest and is not (usually) the intervention itself, we do *not* necessarily need to control for factors ($Q$) that cause $G$, unless those factors also confound the $A \to Y$ relationship (i.e., if $Q \subseteq L$).

Referencing @fig-dag-effect-modification: To estimate the $A \to Y$ effect within levels of $G$, we must adjust for $L_0$. Adjusting for $Q$ (causes of G) is necessary only if $Q$ is also in $L_0$.


```{tikz}
#| label: fig-dag-effect-modification
#| fig-cap: "Imagine A is an experiment. How shall we investigate effect modification of A on Y by Z? Can you see why regression coefficients will not work?"
#| out-width: 80%
#| echo: false

\usetikzlibrary{positioning, shapes.geometric, arrows.meta, decorations.pathmorphing}

\tikzset{
  Arrow/.style={->, >=latex, line width=0.4pt},  % Defines a generic arrow style
  emod/.style={rectangle, fill=blue!10, draw=blue, thick, minimum size=6mm},
  emoddot/.style={circle, fill=blue!10, draw=blue, dotted, thick, minimum size=6mm}
}

\begin{tikzpicture}

\node [rectangle, draw=white, thick] (Q) at (-4,0) {Q};
\node [black] (G) at (-2,0) {G};
\node [rectangle, draw=black,thick] (L) at (0,0) {L$_{0}$};
\node [rectangle, draw=white, thick] (A) at (2,0) {A$_{1}$};

\node [emoddot] (Z) at (0, -1) {Z};

\node [rectangle, draw=white, thick] (Y) at (4,0) {Y$_{2}$};

\draw[Arrow, draw=black] (Q) to (G);
\draw[Arrow, draw=black] (G) to (L);
\draw[Arrow, draw=black] (L) to (A);
\draw[Arrow, draw=black, bend left = 30] (L) to (Y);
\draw[Arrow, draw=black, bend right = 40] (Q) to (Y);
\draw [-latex, draw=black] (A) to (Y);
\draw[-{Circle[open, fill=none]}, line width=0.25pt, draw=blue, bend right = 10] (Z) to (Y); Circle-ended arrow
\end{tikzpicture}
```


The primary identification challenge for effect modification lies in adequately controlling for the $A \to Y$ confounders ($L$) within each subgroup defined by $G$ or $X$. Next week, we turn our focus to statistical estimation.

## Estimating Conditional Average Treatment Effects: $\hat{\tau}(X)$

In the previous section, we defined the Conditional Average Treatment Effect (CATE), $\tau(x)$, as a key causal estimand for understanding effect modification by observed covariates $X$:

$$
\tau(x) = \mathbb{E}[Y(1) - Y(0) | X = x]
$$

This represents the *true* average treatment effect within the specific subpopulation where individuals share the covariate profile $X=x$. It quantifies how the average effect of intervention $A$ varies according to baseline characteristics $X$.

Our focus now shifts to *estimating* this CATE function from observed data. We denote the statistical estimate, derived from our sample, as $\hat{\tau}(X)$. For any individual $i$ in our study with observed baseline covariates $X_i$, the value $\hat{\tau}(X_i)$ represents our data-driven prediction of the average treatment effect *for the subgroup of individuals possessing characteristics like $X_i$*.

### Clarifying "Individualised" Treatment Effects vs. Individual Effects

You might recall our earlier discussion highlighting that *true individual causal effects*—the effect of treatment for a single specific person, $Y_i(1) - Y_i(0)$—are generally impossible to identify from data. This might seem contradictory to the goal of estimating "individualised" treatment effects.

The essential distinction lies in the interpretation:

- **Individual Causal Effect (Unobservable):** $Y_i(1) - Y_i(0)$ is the precise effect for person $i$. We cannot observe both potential outcomes for the same person simultaneously.

- **Estimated Conditional Average Treatment Effect (CATE estimate):** $\hat{\tau}(X_i)$ is an estimate of the *average* effect $\mathbb{E}[Y(1) - Y(0) | X = X_i]$ within the stratum, or subgroup, of the population who share the observable characteristics $X_i$.

The term "individualised" or "personalised" treatment effect, in this context, acknowledges that our *prediction* $\hat{\tau}(X_i)$ is tailored to the *specific covariate profile $X_i$* of an individual. However, it crucially represents an **estimated average effect for a subgroup**, not the unique causal effect for that one person. It is our best estimate of the average response for the *type* of individual defined by $X_i$, based on the observed data and the chosen model.

### The Multidimensional Nature of Individual Characteristics

An important reality is that individuals do not belong to just one group; they simultaneously belong to many overlapping groups defined by their multidimensional characteristics. For example, a student might be:

* Female (gender)
* 14 years old (age)
* From a low-income household (socioeconomic status)
* High-achieving in previous assessments (prior performance)
* Attending a rural school (location)
* Highly motivated (psychological trait)

Each of these characteristics, and their combinations, might influence how the student responds to an intervention. The challenge becomes estimating treatment effects that account for this multidimensional reality.

Traditional approaches using regression with manually specified interaction terms quickly become unwieldy when trying to model all relevant combinations (e.g., `A*gender*age*income*prior_performance*location*motivation`). With even a modest number of covariates, we face problems including:

* Insufficient data within many specific covariate combinations (strata).
* Inflated risks of false positives due to multiple testing.
* Difficulties in model specification, complexity, and interpretation.
* An inability to discover unexpected interaction patterns without pre-specifying them.

Modern methods like causal forests address this challenge by:

1.  **Considering the full covariate space simultaneously:** Instead of requiring researchers to pre-specify interaction terms, causal forests automatically search for patterns of effect heterogeneity across the multidimensional covariate space ($X$).

2.  **Adaptive complexity:** The algorithm adapts to the data, splitting on variables and combinations that best differentiate treatment effects, while using regularisation techniques to avoid overfitting.

3.  **Local averaging:** Causal forests effectively perform a weighted local averaging. For each individual $i$, the estimate $\hat{\tau}(X_i)$ is derived by considering the outcomes of similar individuals (i.e., "neighbours" in the covariate space $X$).

4.  **Honest estimation:** By employing techniques like sample splitting (using separate parts of the data for building the tree structure and estimating the effects within the leaves) or out-of-bag estimation, causal forests aim to provide statistically valid ("honest") estimates with appropriate confidence intervals.

The result is that for each individual $i$ with covariates $X_i$, we obtain an estimate $\hat{\tau}(X_i)$ reflecting the predicted treatment effect given their particular combination of characteristics. While still not a true individual causal effect, this approach acknowledges and leverages the multidimensional nature of individual differences.

### Why Estimate CATEs ($\hat{\tau}(X)$)?

Estimating the CATE function $\hat{\tau}(X)$ is the primary statistical approach for investigating the phenomenon of Heterogeneous Treatment Effects (HTE) using measured baseline variables $X$. By examining how the estimated effect $\hat{\tau}(X)$ changes across different covariate profiles $X$, we aim to:

1.  **Explore Effect Heterogeneity:** Move beyond the single summary statistic of the Average Treatment Effect (ATE) to understand if, how, and potentially by which observed factors the intervention's impact varies across the population.

2.  **Identify Potential Subgroups:** Discover if specific subgroups, defined by their baseline characteristics $X$, experience substantially different benefits (or harms) from the intervention.

3.  **Inform Potential Targeting:** Use the predictions $\hat{\tau}(X_i)$ as a basis for exploring whether tailoring treatment decisions could lead to better overall outcomes. This involves evaluating whether strategies based on $\hat{\tau}(X_i)$ outperform uniform treatment approaches, assessed using tools like RATE and Qini curves (discussed later).

### Methods for Estimation: Introducing `grf`

While traditional regression models incorporating interaction terms (e.g., `lm(Y ~ A * X1 + A * X2)`) can estimate CATEs under specific assumptions (like linearity and correct model specification), they often struggle with complex scenarios involving many potential effect modifiers ($X$) or non-linear relationships.

Modern machine learning methods, particularly **causal forests** as implemented in the R package `grf` [@grf2024], are specifically designed for estimating CATEs ($\hat{\tau}(X)$) flexibly and robustly. Causal forests adapt the random forest algorithm for causal inference. Instead of building trees simply to predict the outcome $Y$, they construct trees that explicitly maximise the heterogeneity in estimated treatment effects between leaves. This design allows them to:

* Handle a large number of potential covariates ($X$) simultaneously.
* Capture complex, non-linear interactions between covariates and the treatment effect without pre-specification.
* Avoid strong parametric assumptions about the functional form of $\tau(X)$.

The output of a causal forest is typically a prediction $\hat{\tau}(X_i)$ for each individual $i$ in the dataset (ideally, an evaluation dataset distinct from the training data to prevent overfitting). We will demonstrate these methods after the mid-term break and clarify how they facilitate the development of treatment prioritisation rules. Such rules, often assuming fixed budgets, help determine policy regarding whether and when assigning treatment based on pre-treatment covariates is advantageous.

### Summary: Key Distinctions

This lecture has introduced several interconnected but distinct concepts:

* **Interaction:** Concerns the *joint causal effect* of *two or more distinct interventions* ($A$ and $B$) on an outcome ($Y$). It asks if the effect of intervening on both differs from the sum of their individual intervention effects. The estimand involves joint potential outcomes like $\mathbb{E}[Y(a,b)]$. Identification requires controlling confounders for *all* involved interventions ($L \cup Q$).


- **Effect Modification:** Concerns how the causal effect of a *single intervention* ($A$) on an outcome ($Y$) *varies* across subgroups defined by a baseline characteristic ($G$ or $X$). It asks if the effect, $\mathbb{E}[Y(1) - Y(0)]$, changes depending on the level of $G$ or $X$.
-  **HTE** is the general *phenomenon* of such effect variability.
-  **CATE** ($\tau(x) = \mathbb{E}[Y(1) - Y(0) | X=x]$) is the specific *causal estimand* used to *quantify* this variability based on *observed* covariates $X$. Comparing CATEs across levels of $G$ or $X$ assesses effect modification by measured factors.

- **Estimated Individualised Treatment Effects ($\hat{\tau}(X_i)$):** Refers to our data-derived *estimates* of treatment effects tailored to individuals' specific combinations of observed characteristics ($X_i$).

    * These are **not** true individual causal effects ($Y_i(1) - Y_i(0)$), which remain fundamentally unobservable. They estimate the CATE for the subgroup defined by $X = X_i$.
    * Modern methods like causal forests generate these predictions $\hat{\tau}(X_i)$ by considering the multidimensional covariate profile $X_i$ without requiring pre-specification of effect modifiers.
    * These estimates acknowledge that individuals exist at the intersection of many characteristics simultaneously.
    * They form the basis for evaluating whether personalised treatment strategies might outperform uniform approaches (using RATE, Qini curves, etc.).

Clearly distinguishing between these concepts is vital for precisely formulating research questions (defining causal estimands) and selecting valid methods for identification and estimation. In future lectures, we will explore the practical implementation of these methods in R using `grf` and related packages.


## Course Review So Far

Imagine you are trying to determine if something causes something else. For example, does a new teaching method (let's call it 'treatment A') actually cause better test scores (the 'outcome Y')? Causal inference provides the set of tools researchers use to answer these kinds of questions rigorously.

### The Core Idea: What If?

At its heart, causal inference compares what actually happened to what *would have happened* under different circumstances. This "what if" scenario is called a counterfactual.

What would a student's score $(Y)$ be if they received the new teaching method $(A=1)$? 
We write this potential outcome as $Y(1)$.

What would that same student's score $(Y)$ be if they received the old method $(A=0)$? 
We write this potential outcome as $Y(0)$.

The Average Treatment Effect (ATE) is the average difference between these "what if" scenarios across a whole population or group: $\text{ATE} = \mathbb{E}[Y(1) - Y(0)]$. This tells us, on average, how much the new teaching method changes the score.

### This Lecture: Interaction vs. Effect Modification vs. Individualised Treatment Effects

#### Interaction (Think: Teamwork Effects)

**What it is:** Interaction is about whether the combined effect of *two different interventions* (say, treatment A and treatment B) is different from simply adding up their individual effects.
**Example:** Does using the new teaching method (A) *and* having extra tutoring (B) improve scores (Y) more (or less) than you would expect by combining the improvement from only teaching method A and only extra tutoring B?
**How it's defined:** We use counterfactuals: Is the outcome with both A and B, $\mathbb{E}[Y(1, 1)]$, different from what you would predict based on having neither $\mathbb{E}[Y(0, 0)]$, only A $\mathbb{E}[Y(1, 0)]$, and only B $\mathbb{E}[Y(0, 1)]$? Specifically, if $[\mathbb{E}[Y(1,1)] - \mathbb{E}[Y(1,0)] - \mathbb{E}[Y(0,1)] + \mathbb{E}[Y(0,0)]] \neq 0$, then there is interaction on the additive scale.
**Challenge:** To study interaction properly, you need to control for confounding factors for *both* intervention A and intervention B (confounders $L$ for A-Y and $Q$ for B-Y).

#### Effect Modification (Think: Different Effects for Different Groups)

**What it is:** Effect modification is about whether the effect of *one intervention* (A) differs depending on some pre-existing *characteristic* (G or X) of the individuals. This characteristic is observed, not intervened upon.
**Example:** Does the new teaching method (A) improve scores (Y) more for students who already have high prior grades (Group G=high) compared to students with low prior grades (Group G=low)? Here, G (prior grades) is the "effect modifier". This phenomenon is called Heterogeneous Treatment Effects (HTE).
**How it's defined:** You compare the treatment effect (A's effect on Y) across different groups defined by G or X. The Conditional Average Treatment Effect (CATE) quantifies this: $\tau(x) = \mathbb{E}[Y(1) - Y(0) | X=x]$. If $\tau(x)$ varies for different values of $x$, then $X$ modifies the effect of $A$.
**Challenge:** To study effect modification, you need to control for confounding factors ($L$) of the relationship between the single intervention A and the outcome Y, potentially within each subgroup G or X.

#### Estimated Individualised Treatment Effects (Think: Personal Profiles Matter)

**What it is:** In reality, people belong to many groups simultaneously based on multiple characteristics (age, gender, prior performance, motivation, etc.). "Individualised treatment effects" typically refer to the *estimated* CATE, $\hat{\tau}(X_i)$, which predicts the average treatment response based on an individual's complex combination of characteristics $X_i$.

**Example:** We want to predict whether the new teaching method will help a specific student who is female, 14 years old, from a low-income background, with high prior achievement and high motivation. We use all this information ($X_i$) for the prediction $\hat{\tau}(X_i)$.

**How it's estimated:** Modern methods like causal forests process all characteristics ($X$) simultaneously to generate predictions $\hat{\tau}(X_i)$ for each individual. These are **not** true individual causal effects (which remain unobservable) but are our best estimates of the *average effect for people like individual i*, given the available data.

**Why it matters:** These predictions $\hat{\tau}(X_i)$ allow us to explore whether tailoring treatments based on individual profiles ($X_i$) could be more effective than treating everyone uniformly. This involves further evaluation (e.g., using RATE, Qini curves).

**In Simple Terms:**

* **Interaction:** Do two treatments work together synergistically or antagonistically? (Requires analysing effects of $A$, $B$, and $A+B$).
* **Effect Modification (HTE/CATE):** Does a single treatment's effect change depending on who receives it (based on their characteristics $X$)? (Requires analysing effect of $A$ within levels of $X$).
* **Estimated Individualised Effects ($\hat{\tau}(X_i)$):** How can we *predict* treatment responses based on the complex combination of an individual's characteristics $X_i$? (Requires flexible models like causal forests trained on $A$, $Y$, and $X$).

Understanding these distinctions helps formulate precise research questions, choose appropriate methods, and potentially develop more effective intervention strategies that acknowledge individual differences.

## Appendix: Simplification of Additive Interaction Formula

We start with the definition of additive interaction based on comparing the joint effect relative to baseline versus the sum of individual effects relative to baseline:

$$
\Big(\mathbb{E}[Y(1,1)] - \mathbb{E}[Y(0,0)]\Big) - \Big[\Big(\mathbb{E}[Y(1,0)] - \mathbb{E}[Y(0,0)]\Big) + \Big(\mathbb{E}[Y(0,1)] - \mathbb{E}[Y(0,0)]\Big)\Big]
$$

First, distribute the negative sign across the terms within the square brackets:

$$
\mathbb{E}[Y(1,1)] - \mathbb{E}[Y(0,0)] - \Big(\mathbb{E}[Y(1,0)] - \mathbb{E}[Y(0,0)]\Big) - \Big(\mathbb{E}[Y(0,1)] - \mathbb{E}[Y(0,0)]\Big)
$$

Now remove the parentheses, flipping the signs inside them where preceded by a minus sign:

$$
\mathbb{E}[Y(1,1)] - \mathbb{E}[Y(0,0)] - \mathbb{E}[Y(1,0)] + \mathbb{E}[Y(0,0)] - \mathbb{E}[Y(0,1)] + \mathbb{E}[Y(0,0)]
$$

Next, combine the $\mathbb{E}[Y(0,0)]$ terms:

* We have $-\mathbb{E}[Y(0,0)]$
* Then $+\mathbb{E}[Y(0,0)]$ (these two cancel each other out)
* And another $+\mathbb{E}[Y(0,0)]$ remains.

The expression simplifies to:

$$
\mathbb{E}[Y(1,1)] - \mathbb{E}[Y(1,0)] - \mathbb{E}[Y(0,1)] + \mathbb{E}[Y(0,0)]
$$

This is the standard definition of additive interaction, often called the interaction contrast. If this expression equals zero, there is no additive interaction; a non-zero value indicates an interaction effect.

**This shows clearly that interaction is measured as the deviation of the joint effect from the sum of the separate effects, adjusted for the baseline.**



