[
  {
    "objectID": "content/course-outline.html",
    "href": "content/course-outline.html",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Introduce course objectives and outline\nR setup\n\n\n\n\n\nGetting started with R/R-studio: installation and package management\n\n\n\n\n\n\n\n(Joseph A. Bulbulia 2023) link\n\n\n\n\n\n\n\n\n\nUnderstanding causal diagrams: definitions and applications\nIntroduction to five elementary structures and four rules in causal inference\nIntroduction to R interface and data simulation\n\n\n\n\n\nBarrett M (2023). ggdag: Analyze and Create Elegant Directed Acyclic Graphs. R package version 0.2.7.9000, https://github.com/malcolmbarrett/ggdag\n“An Introduction to Directed Acyclic Graphs”, https://r-causal.github.io/ggdag/articles/intro-to-dags.html\n“Common Structures of Bias”, https://r-causal.github.io/ggdag/articles/bias-structures.html\n\n\n\n\n\nPractical exercises in R: Using the interface and simulating data\n\n\n\n\n\n\n\n\nConfounding bias using causal diagrams\nApplication of regression and simulation in R\n\n\n\n\n\nPractical exercises in R: regression and ggdag\n\n\n\n\n\n(Hernan and Robins 2024) Chapter 6 link\n\n\n\n\n(Suzuki, Shinozaki, and Yamamoto 2020) link\n(J. A. Bulbulia 2024b) link\n(Neal 2020) Chapter 3 link\n\n\n\n\n\n\n\n\n\nKey concepts of interaction, measurement bias, and selection bias understood through causal diagrams\nBoth External and Internal Validity clarified by Causal Graphs\nAdvanced regression and simulation exercises in R\n\n\n\n\n\nContinuation of regression and simulation exercises in R\n\n\n\n\n\n(Hernan and Robins 2024) Chapter 6-9 link\n\n\n\n\n(Miguel A. Hernán, Hernández-Díaz, and Robins 2004) link\n(M. A. Hernán 2017) link\n(Miguel A. Hernán and Cole 2009) link\n(Tyler J. VanderWeele and Hernán 2012) link\n\n\n\n\n\n\n\n\n\nAssessment covering key terms and concepts taught so far\n\n\n\n\n\n\n\n\n\n\n\n\nKey concepts of Average Treatment Effect (ATE)\nApplication of regression and simulation in R to obtain ATE estimation\n\n\n\n\n\n(Hernan and Robins 2024) Chapters 1-3 link\n\n\n\n\n(Neal 2020) Chapter 1-2 link\n\n\n\n\n\n\nRegression and simulation exercises in R focussed on estimating the ATE\n\n\n\n\n\n\n(Hernan and Robins 2024) Chapters 4-5 link\n\n\n\n\n(Tyler J. VanderWeele and Robins 2007) link\n(Tyler J. VanderWeele 2009) link\n\n\n\n\n\nEffect Modification: Definine your Causal Estimand\nDistinguishing Cultural Effect-Modification from the confused and conflated concepts of “Moderation”, “Mediation”, “Interaction.”\nDetour into Causal Mediation\n\n\n\n\n\nAnalysis step 1: data wrangling and descriptive tables/graphs\n\n\n\n\n\n\n\n\nWorkflow for causal question formulation, population statement, and causal diagram creation\nMarginal Structural Models: propensity scores and Inverse Probability of Treatment Weighting (IPTW)\nIPTW when estimating conditional causal effects\nEstimation techniques evaluating evidence for group-wise effect modification using R.\n\n\n\n\n\n(Greifer 2023) link\n(Tyler J. VanderWeele, Mathur, and Chen 2020) link\n\n\n\n\n(J. A. Bulbulia 2024a) link\n(Hoffman et al. 2023) link\n\n\n\n\n\n\nEstimation ATE; CATE\n\n\n\n\n\n\n\n\nSecond assessment covering advanced topics in causal inference\nTopics include ATE, Effect-Modification, fundamental assumptions of causal inference, experiments, and real-world confounding\n\n\n\n\n\nPreparing your analysis: Hands On Study!\n\n\n\n\n\n\nNo readings, do your take-home assignment (see course details).\n\n\n\n\n\nCreating and managing Quarto documents for publication quality research workflows\n\n\n\n\n\n\n\nFactor analysis, confirmatory factor analysis (CFA), multigroup CFA, partial invariance\nWorked example on configural, metric, and scalar equivalence\n\n\n\n\n\n(Fischer and Karl 2019) link\n\n\n\n\n(Vijver et al. 2021) link\n(He and Vijver 2012) link\n(J. [et. al]. Harkness 2003) link\n\n\n\n\n\n\nR exercises focusing on measurement theory applications and graphing\n\n\n\n\n\n\n\n\nUnderstanding causal assumptions of measurement theory\nGuidance on your final assessment.\n\n\n\n\n\n(Tyler J. VanderWeele 2022) link\n\n\n\n\n(J. A. Harkness, Van de Vijver, and Johnson 2003) link\n\n\n\n\n\n\nR programming using causal inference to examine failure modes in measurement models\n\n\n\n\n\n\nYou assess a questions: do cultural groups vary in response to interventions on well-beings?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAbstract. Psychosocial constructs can only be assessed indirectly, and measures are typically formed by a combination of indicators that are thought to relate to the construct. Reflective and formative measurement models offer different conceptualizations of the relation between the indicators and what is sometimes conceived of as a univariate latent variable supposedly corresponding to the construct. I argue that the empirical implications of these models will often be violated by data since the causally relevant constituents will generally be multivariate, not univariate. In fact, the assumption of an underlying univariate structural latent variable is so strong that it has empirically testable implications, even though the latent is unobserved. Formal statistical tests can be developed to reject this assumption, but factor analysis, as typically practiced, is not adequate to do so. Factor analysis also suffers from the inability to distinguish associations arising from causal versus conceptual relations. I put forward an outline for a new model of the process of measure construction and propose a causal interpretation of associations between constructed measures and subsequent outcomes that is applicable even if the usual assumptions of reflective and formative models fail. I discuss the practical implications of these observations and proposals for the provision of definitions, the selection of items, item-by-item analyses, the construction of measures, and the causal interpretation of regression analyses.\n\n\n\n\n\n\n\n\n\n\nAbstract: Causal inference research has shifted from being primarily descriptive (describing the data-generating mechanism using statistical models) to being primarily prescriptive (evaluating the effects of specific interventions). The focus has thereby moved from being centered on statistical models to being centered on causal estimands. This evolution has been driven by the increasing need for practical solutions to real-world problems, such as designing effective interventions, making policy decisions, and identifying effective treatment strategies. It has brought enormous progress, not solely in terms of delivering more useful answers to the scientific questions at stake, but also in providing a more hygienic inference that targets a well-understood causal estimand. However, many causal questions are not readily translated into the effects of specific interventions, and even if they can, scientists may be reliant on help from an expert statistician to make that translation, may not find the considered interventions feasible or of immediate interest, or may find too little information in the data about the considered estimand. In this talk, I will reflect on this and argue that hygienic causal inference thinking therefore comes with a price. I will next propose a compromise solution at the intersection of descriptive and prescriptive causal inference. It borrows the flexibility of statistical modeling, while tying model parameters to causal estimands in order to ensure that we understand what is being estimated and obtain valid (data-adaptive) inference for it, even when the model is wrong. Examples on structural (nested) mean models, instrumental variables estimation, target trials, … will be used to provide insight."
  },
  {
    "objectID": "content/course-outline.html#week-1---course-introduction---introduction-to-r",
    "href": "content/course-outline.html#week-1---course-introduction---introduction-to-r",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Introduce course objectives and outline\nR setup\n\n\n\n\n\nGetting started with R/R-studio: installation and package management\n\n\n\n\n\n\n\n(Joseph A. Bulbulia 2023) link"
  },
  {
    "objectID": "content/course-outline.html#week-2---causal-diagrams-five-elementary-causal-structures",
    "href": "content/course-outline.html#week-2---causal-diagrams-five-elementary-causal-structures",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Understanding causal diagrams: definitions and applications\nIntroduction to five elementary structures and four rules in causal inference\nIntroduction to R interface and data simulation\n\n\n\n\n\nBarrett M (2023). ggdag: Analyze and Create Elegant Directed Acyclic Graphs. R package version 0.2.7.9000, https://github.com/malcolmbarrett/ggdag\n“An Introduction to Directed Acyclic Graphs”, https://r-causal.github.io/ggdag/articles/intro-to-dags.html\n“Common Structures of Bias”, https://r-causal.github.io/ggdag/articles/bias-structures.html\n\n\n\n\n\nPractical exercises in R: Using the interface and simulating data"
  },
  {
    "objectID": "content/course-outline.html#week-3-march-11---causal-diagrams-the-structures-of-confounding-bias",
    "href": "content/course-outline.html#week-3-march-11---causal-diagrams-the-structures-of-confounding-bias",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Confounding bias using causal diagrams\nApplication of regression and simulation in R\n\n\n\n\n\nPractical exercises in R: regression and ggdag\n\n\n\n\n\n(Hernan and Robins 2024) Chapter 6 link\n\n\n\n\n(Suzuki, Shinozaki, and Yamamoto 2020) link\n(J. A. Bulbulia 2024b) link\n(Neal 2020) Chapter 3 link"
  },
  {
    "objectID": "content/course-outline.html#week-4---causal-diagrams-the-structures-of-interactioneffect-modification-measurement-bias-selection-bias",
    "href": "content/course-outline.html#week-4---causal-diagrams-the-structures-of-interactioneffect-modification-measurement-bias-selection-bias",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Key concepts of interaction, measurement bias, and selection bias understood through causal diagrams\nBoth External and Internal Validity clarified by Causal Graphs\nAdvanced regression and simulation exercises in R\n\n\n\n\n\nContinuation of regression and simulation exercises in R\n\n\n\n\n\n(Hernan and Robins 2024) Chapter 6-9 link\n\n\n\n\n(Miguel A. Hernán, Hernández-Díaz, and Robins 2004) link\n(M. A. Hernán 2017) link\n(Miguel A. Hernán and Cole 2009) link\n(Tyler J. VanderWeele and Hernán 2012) link"
  },
  {
    "objectID": "content/course-outline.html#week-5---quiztest-in-class-25",
    "href": "content/course-outline.html#week-5---quiztest-in-class-25",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Assessment covering key terms and concepts taught so far"
  },
  {
    "objectID": "content/course-outline.html#week-6---causal-inference-average-treatment-marginal-effects",
    "href": "content/course-outline.html#week-6---causal-inference-average-treatment-marginal-effects",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Key concepts of Average Treatment Effect (ATE)\nApplication of regression and simulation in R to obtain ATE estimation\n\n\n\n\n\n(Hernan and Robins 2024) Chapters 1-3 link\n\n\n\n\n(Neal 2020) Chapter 1-2 link\n\n\n\n\n\n\nRegression and simulation exercises in R focussed on estimating the ATE"
  },
  {
    "objectID": "content/course-outline.html#week-7---causal-inference-and-effect-modification",
    "href": "content/course-outline.html#week-7---causal-inference-and-effect-modification",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "(Hernan and Robins 2024) Chapters 4-5 link\n\n\n\n\n(Tyler J. VanderWeele and Robins 2007) link\n(Tyler J. VanderWeele 2009) link\n\n\n\n\n\nEffect Modification: Definine your Causal Estimand\nDistinguishing Cultural Effect-Modification from the confused and conflated concepts of “Moderation”, “Mediation”, “Interaction.”\nDetour into Causal Mediation\n\n\n\n\n\nAnalysis step 1: data wrangling and descriptive tables/graphs"
  },
  {
    "objectID": "content/course-outline.html#week-8---causal-inference-marginal-structural-models-inverse-probability-of-treatment-weighting-conditional-average-treatment-effects-iptw-when-groups-are-compared.",
    "href": "content/course-outline.html#week-8---causal-inference-marginal-structural-models-inverse-probability-of-treatment-weighting-conditional-average-treatment-effects-iptw-when-groups-are-compared.",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Workflow for causal question formulation, population statement, and causal diagram creation\nMarginal Structural Models: propensity scores and Inverse Probability of Treatment Weighting (IPTW)\nIPTW when estimating conditional causal effects\nEstimation techniques evaluating evidence for group-wise effect modification using R.\n\n\n\n\n\n(Greifer 2023) link\n(Tyler J. VanderWeele, Mathur, and Chen 2020) link\n\n\n\n\n(J. A. Bulbulia 2024a) link\n(Hoffman et al. 2023) link\n\n\n\n\n\n\nEstimation ATE; CATE"
  },
  {
    "objectID": "content/course-outline.html#week-9---hands-on-analysis-and-take-home-assessment-25",
    "href": "content/course-outline.html#week-9---hands-on-analysis-and-take-home-assessment-25",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Second assessment covering advanced topics in causal inference\nTopics include ATE, Effect-Modification, fundamental assumptions of causal inference, experiments, and real-world confounding\n\n\n\n\n\nPreparing your analysis: Hands On Study!"
  },
  {
    "objectID": "content/course-outline.html#week-10-may-13---hands-on-working-with-quarto-manuscript",
    "href": "content/course-outline.html#week-10-may-13---hands-on-working-with-quarto-manuscript",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "No readings, do your take-home assignment (see course details)."
  },
  {
    "objectID": "content/course-outline.html#labs",
    "href": "content/course-outline.html#labs",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Creating and managing Quarto documents for publication quality research workflows"
  },
  {
    "objectID": "content/course-outline.html#week-11-may-20---measurement-matters",
    "href": "content/course-outline.html#week-11-may-20---measurement-matters",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Factor analysis, confirmatory factor analysis (CFA), multigroup CFA, partial invariance\nWorked example on configural, metric, and scalar equivalence\n\n\n\n\n\n(Fischer and Karl 2019) link\n\n\n\n\n(Vijver et al. 2021) link\n(He and Vijver 2012) link\n(J. [et. al]. Harkness 2003) link\n\n\n\n\n\n\nR exercises focusing on measurement theory applications and graphing"
  },
  {
    "objectID": "content/course-outline.html#week-12-may-27---measurement-external-validity-in-causal-inference",
    "href": "content/course-outline.html#week-12-may-27---measurement-external-validity-in-causal-inference",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Understanding causal assumptions of measurement theory\nGuidance on your final assessment.\n\n\n\n\n\n(Tyler J. VanderWeele 2022) link\n\n\n\n\n(J. A. Harkness, Van de Vijver, and Johnson 2003) link\n\n\n\n\n\n\nR programming using causal inference to examine failure modes in measurement models"
  },
  {
    "objectID": "content/course-outline.html#week-13-june-3-no-seminar-comparative-report-due-40",
    "href": "content/course-outline.html#week-13-june-3-no-seminar-comparative-report-due-40",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "You assess a questions: do cultural groups vary in response to interventions on well-beings?"
  },
  {
    "objectID": "content/course-outline.html#appendix-optional-videos",
    "href": "content/course-outline.html#appendix-optional-videos",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Abstract. Psychosocial constructs can only be assessed indirectly, and measures are typically formed by a combination of indicators that are thought to relate to the construct. Reflective and formative measurement models offer different conceptualizations of the relation between the indicators and what is sometimes conceived of as a univariate latent variable supposedly corresponding to the construct. I argue that the empirical implications of these models will often be violated by data since the causally relevant constituents will generally be multivariate, not univariate. In fact, the assumption of an underlying univariate structural latent variable is so strong that it has empirically testable implications, even though the latent is unobserved. Formal statistical tests can be developed to reject this assumption, but factor analysis, as typically practiced, is not adequate to do so. Factor analysis also suffers from the inability to distinguish associations arising from causal versus conceptual relations. I put forward an outline for a new model of the process of measure construction and propose a causal interpretation of associations between constructed measures and subsequent outcomes that is applicable even if the usual assumptions of reflective and formative models fail. I discuss the practical implications of these observations and proposals for the provision of definitions, the selection of items, item-by-item analyses, the construction of measures, and the causal interpretation of regression analyses.\n\n\n\n\n\n\n\n\n\n\nAbstract: Causal inference research has shifted from being primarily descriptive (describing the data-generating mechanism using statistical models) to being primarily prescriptive (evaluating the effects of specific interventions). The focus has thereby moved from being centered on statistical models to being centered on causal estimands. This evolution has been driven by the increasing need for practical solutions to real-world problems, such as designing effective interventions, making policy decisions, and identifying effective treatment strategies. It has brought enormous progress, not solely in terms of delivering more useful answers to the scientific questions at stake, but also in providing a more hygienic inference that targets a well-understood causal estimand. However, many causal questions are not readily translated into the effects of specific interventions, and even if they can, scientists may be reliant on help from an expert statistician to make that translation, may not find the considered interventions feasible or of immediate interest, or may find too little information in the data about the considered estimand. In this talk, I will reflect on this and argue that hygienic causal inference thinking therefore comes with a price. I will next propose a compromise solution at the intersection of descriptive and prescriptive causal inference. It borrows the flexibility of statistical modeling, while tying model parameters to causal estimands in order to ensure that we understand what is being estimated and obtain valid (data-adaptive) inference for it, even when the model is wrong. Examples on structural (nested) mean models, instrumental variables estimation, target trials, … will be used to provide insight."
  },
  {
    "objectID": "content/09-content.html",
    "href": "content/09-content.html",
    "title": "Causal inference: a step by step guide",
    "section": "",
    "text": "Note\n\n\n\nRequired - nil\nOptional - (Bulbulia 2024a) link - (Hoffman et al. 2023) link - (Tyler J. VanderWeele, Mathur, and Chen 2020) link"
  },
  {
    "objectID": "content/09-content.html#lab",
    "href": "content/09-content.html#lab",
    "title": "Causal inference: a step by step guide",
    "section": "LAB",
    "text": "LAB\n\nWe start with our lab this week.\nHere is a link to the workbook:\n\nlink to template for option 2 assignment 3"
  },
  {
    "objectID": "content/09-content.html#what-you-will-learn",
    "href": "content/09-content.html#what-you-will-learn",
    "title": "Causal inference: a step by step guide",
    "section": "What You Will Learn",
    "text": "What You Will Learn\n\nModified Treatment Policies\nSetting up your analysis:\nData wrangling (review):\nDemographic Tables (review):\nExploratory Tables and Graphs (review)\nComputing inverse probability of censoring weights (IPCW) to handle attrition/missingness\nSensitivity Analysis: E-values\nCausal Analysis using machine learning ensembles (Targeted Maximum Likelihood)"
  },
  {
    "objectID": "content/09-content.html#part-1-new-content",
    "href": "content/09-content.html#part-1-new-content",
    "title": "Causal inference: a step by step guide",
    "section": "Part 1: New Content",
    "text": "Part 1: New Content\n\nModified Treatment Policies and E-values\nA modified treatment policy is a flexible intervention of the following form:\n\n\\mathbf{d}^\\lambda (a_1) = \\begin{cases} 4 & \\text{if } a_1 &lt; 4 \\\\\na_1 & \\text{otherwise} \\end{cases}\n \n\\mathbf{d}^\\phi (a_1) = \\begin{cases} 0 & \\text{if } a_1 &gt; 0 \\\\\na_1 & \\text{otherwise} \\end{cases}\n\n g' = \\text{Intervention 1 - Intervention 2} = E[Y(\\mathbf{d}^\\lambda) - Y(\\mathbf{d}^\\phi)] \n g'' = \\text{Intervention 1 - Intervention 2} = E[Y(\\mathbf{d}^\\lambda) - Y(\\mathbf{d}^\\phi)] \n\n{\\delta}(g) ={g'} - {g''}\n\nRather than shifting an entire population into one of two states, the estimand flexibly shifts a population according to a pre-specified function.\nsee: Hoffman et al. (2023)\n\n\nSensitivity Analysis using E-values\n\nThe minimum strength of association on the risk ratio scale that an unmeasured confounder would need to have with both the exposure and the outcome, conditional on the measured covariates, to fully explain away a specific exposure-outcome association\n\nSee: Mathur et al. (2018); Linden, Mathur, and VanderWeele (2020); Tyler J. VanderWeele and Ding (2017).\n\nMathur, Maya B, Peng Ding, Corinne A Riddell, and Tyler J VanderWeele. 2018. “Website and r Package for Computing E-Values.” Epidemiology (Cambridge, Mass.) 29 (5): e45.\nFor example, suppose that the lower bound of the the E-value was 1.3 with the lower bound of the confidence interval = 1.12, we might then write:\n\nWith an observed risk ratio of RR=1.3, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 1.3-fold each (or 30%), above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 1.12-fold (or 12%) each could do so, but weaker joint confounder associations could not.\n\nThe equations are as follows (for risk ratios)\n\nE-value_{RR} = RR + \\sqrt{RR \\times (RR - 1)}\n \nE-value_{LCL} = LCL + \\sqrt{LCL \\times (LCL - 1)}\n\nHere is an R function that will calculate E-values\n\n# evalue for risk ratio\ncalculate_e_value &lt;- function(rr, lcl) {\n  e_value_rr = rr + sqrt(rr*(rr - 1))\n  e_value_lcl = lcl + sqrt(lcl*(lcl - 1))\n  \n  list(e_value_rr = e_value_rr, e_value_lcl = e_value_lcl)\n}\n\n# e.g. smoking causes cancer\n# finding   RR = 10.73 (95% CI: 8.02, 14.36)\nevalue_computed &lt;- calculate_e_value(10.73, 8.02)\n\n#print\nevalue_computed\n\n$e_value_rr\n[1] 20.94777\n\n$e_value_lcl\n[1] 15.52336\n\n\nWe write:\n\nWith an observed risk ratio of RR=10.7, an unmeasured confounder that was associated 20.9477737-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of e_value_rr$e_value_lcl-fold each could do so, but weaker joint confounder associations could not.\n\nNote that in this class, most of the outcomes will be (standardised) continuous outcomes. Here’s a function and LaTeX code to describe the approximation.\nThis function takes a linear regression coefficient estimate (est), its standard error (se), the standard deviation of the outcome (sd), a contrast of interest in the exposure (delta, which defaults to 1), and a “true” standardized mean difference (true, which defaults to 0). It calculates the odds ratio using the formula from Chinn (2000) and VanderWeele (2017), and then uses this to calculate the E-value.\n\n#evalue for ols\ncompute_evalue_ols &lt;- function(est, se, delta = 1, true = 0) {\n  # rescale estimate and SE to get a contrast of size delta\n  est &lt;- est / delta\n  se &lt;- se / delta\n\n  # compute transformed odds ratio and ci's\n  odds_ratio &lt;- exp(0.91 * est)\n  lo &lt;- exp(0.91 * est - 1.78 * se)\n  hi &lt;- exp(0.91 * est + 1.78 * se)\n\n  # compute E-Values based on the RR values\n  evalue_point_estimate &lt;- odds_ratio * sqrt(odds_ratio + 1)\n  evalue_lower_ci &lt;- lo * sqrt(lo + 1)\n\n  # return the e-values\n  return(list(EValue_PointEstimate = evalue_point_estimate,\n              EValue_LowerCI = evalue_lower_ci))\n}\n\n\n# example:\n# suppose we have an estimate of 0.5, a standard error of 0.1, and a standard deviation of 1.\n# this would correspond to a half a standard deviation increase in the outcome per unit increase in the exposure.\nresults &lt;- compute_evalue_ols(est = 0.5, se = 0.1, delta = 1)\npoint_round &lt;- round(results$EValue_PointEstimate, 3)\nci_round &lt;- round(results$EValue_LowerCI, 3)\n\n# print results\nprint(point_round)\n\n[1] 2.53\n\nprint(ci_round)\n\n[1] 2.009\n\n\nWe write:\n\nWith an observed risk ratio of 2.53, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 2.53-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 2.009-fold each could do so, but weaker joint confounder associations could not.\n\nNote the E-values package will do the computational work for us and this is what we use in the margot package to obtain E-values for sensitivity analysis."
  },
  {
    "objectID": "content/09-content.html#part-2-guide-for-preparing-your-study",
    "href": "content/09-content.html#part-2-guide-for-preparing-your-study",
    "title": "Causal inference: a step by step guide",
    "section": "Part 2 Guide For Preparing Your Study",
    "text": "Part 2 Guide For Preparing Your Study\nRecall that psychology begins with two questions.\n\nWhat do I want to know about thought and behaviour? What is the target population?\n\nIn cross-cultural psychology, these questions relate to differences, and similarities, between groups.\nSuppose we have asked a question. How can we address it using observational data?\nToo fast.\nOur question must be made precise.\nToday we will consider how to make psychological questions precise, and how to answer them, using 3-wave panel designs (Tyler J. VanderWeele, Mathur, and Chen 2020).\nThe order is as follows:\n\nMotivate Three Wave Longitudinal Designs Using Causal Graphs\nChecklist For Causal Estimation in Three Wave Longitudinal Designs\nExplanation of the the Checklist"
  },
  {
    "objectID": "content/09-content.html#motivations-for-a-three-wave-longitudinal-design-for-observational-causal-inference.",
    "href": "content/09-content.html#motivations-for-a-three-wave-longitudinal-design-for-observational-causal-inference.",
    "title": "Causal inference: a step by step guide",
    "section": "Motivations for a Three-Wave Longitudinal Design for Observational Causal Inference.",
    "text": "Motivations for a Three-Wave Longitudinal Design for Observational Causal Inference.\nREVIEW: Causal Diagrammes (DAGS) are a remarkably powerful and simple tool for understanding confounding See here\n\nCommon cause of exposure and outcome.\nOur question: does visiting a clinical psychologist reduce the 10 year incidence of heart attacks?\n\n\n\n\n\n\n\n\nFigure 1: Common cause of exposure and outcome: example\n\n\n\n\n\n\n\nSolution: Adjust for Confounder\n\n\n\n\n\n\n\n\nFigure 2: Solution to this problem.\n\n\n\n\n\n\n\nBias: exposure at baseline is a common cause of the exposure at t1 and outcome at t2\n\n\n\n\n\n\n\n\nFigure 3: Causal graph reveals bias from pre-exosure indicator\n\n\n\n\n\n\n\nSolution: adjust for confounder at baseline\n\n\n\n\n\n\n\n\nFigure 4: Solution to this problem\n\n\n\n\n\n\n\nA more thorough confounding control\n\n\n\n\n\n\n\n\nFigure 5: Causal graph:more general panel design\n\n\n\n\n\n\n\nGeneric 3-wave panel design (VanderWeeele 2020)\n\n\n\n\n\n\n\n\nFigure 6: Causal graph: three-wave panel design"
  },
  {
    "objectID": "content/09-content.html#sensitivity-analysis",
    "href": "content/09-content.html#sensitivity-analysis",
    "title": "Causal inference: a step by step guide",
    "section": "Sensitivity analysis",
    "text": "Sensitivity analysis"
  },
  {
    "objectID": "content/09-content.html#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study.",
    "href": "content/09-content.html#comprehensive-checklist-for-detailed-reporting-of-a-causal-inferenctial-study.",
    "title": "Causal inference: a step by step guide",
    "section": "Comprehensive Checklist for Detailed Reporting of a Causal Inferenctial Study.",
    "text": "Comprehensive Checklist for Detailed Reporting of a Causal Inferenctial Study."
  },
  {
    "objectID": "content/09-content.html#step-1-formulate-the-research-question",
    "href": "content/09-content.html#step-1-formulate-the-research-question",
    "title": "Causal inference: a step by step guide",
    "section": "STEP 1 Formulate the Research Question",
    "text": "STEP 1 Formulate the Research Question\n\nState your question: is my question clearly stated? If not, state it.\nRelevance: have I explained its importance? If not, explain.\nEthics how might this question affect people? How might not investigating this question affect people?\nCausality: Is my question causal? If not, refine your question.\nSubgroup analysis: does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.\nExplain the Framework: can I explain the causal inference framework and convey the gist to non-specialists? If not, review course materials.\n\n\nDetermine Data Requirements\n\nData types: are my data experimental? If yes, your project may not fit this course.\nTime-series data: are my data time-series? If not, reconsider your causal question.\nData waves: do I have at least three waves of data? If not, beware of confounding control issues.\nData source: are my data from the NZAVS simulated data set? If not, consult with me.\n\n\n\nDetermine the Outcome\n\nOutcome variable: is the outcome variable Y defined? If not, define it.\nMultiple outcomes: are there multiple outcomes? If yes, explain and define them.\nOutcome relevance: can I explain how the outcome variable/s relate to my question? If not, clarify.\nOutcome type: is my outcome binary and rare? If yes, consider logistic regression. If my outcome is continuous, consider z-transforming it or categorising it (consult an expert).\nOutcome timing: does the outcome appear after the exposure? It should.\n\n\n\nDetermine the Exposure\n\nExposure variable: is the exposure variable A defined? If not, define it.\nMultiple exposures: are there multiple exposures? If yes, reassess; if only one exposure, proceed.\nExposure relevance: can I explain how the exposure variable relates to my question? If not, clarify.\nPositivity: can we intervene on the exposure at all levels of the covariates? We should be able to.\nConsistency: can I interpret what it means to intervene on the exposure? I should be able to.\nExchangeability: are different versions of the exposure conditionally exchangeable given measured baseline confounders? They should be.\nExposure type: is the exposure binary or continuous?\nShift intervention: Am I contrasting static interventions or modified treatment policies?\nExposure timing: Does the exposure appear before the outcome? It should.\n\n\n\nAccount for Confounders\n\nBaseline confounders: Have I defined my baseline confounders L? I should have.\nJustification: Can I explain how the baseline confounders could affect both A and Y? I should be able to.\nTiming: Are the baseline confounders measured before the exposure? They should be.\nInclusion: Is the baseline measure of the exposure and the baseline outcome included in the set of baseline confounders? They should be.\nSufficiency: Are the baseline confounders sufficient to ensure balance on the exposure, such that A is independent of Y given L? If not, plan a sensitivity analysis.\nConfounder type: Are the confounders continuous or binary? If so, consider converting them to z-scores. If they are categorical with three or more levels, do not convert them to z-scores.\n\n\n\nDraw a Causal Diagram with Unmeasured Confounders\n\nUnmeasured confounders: Does previous science suggest the presence of unmeasured confounders? If not, expand your understanding.\nCausal diagram: Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding? I should have.\nMeasurement error: Have I described potential biases from measurement errors? If not, we’ll discuss later.\nTemporal order: Does my DAG have time indicators to ensure correct temporal order? It should.\nTime consistency: Is my DAG organized so that time follows in a consistent direction? It should.\n\n\n\nIdentify the Estimand\n\nCausal Estimand: Is my causal estimand one of the following:\n\nATE_{G,(A,A')} = E[Y(1) - Y(0)|G, L]\nATE_{G,(A/A')} = \\frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}\nA modified treatment policy, e.g.\n\n\\mathbf{d}^\\lambda (a_1) = \\begin{cases} 4 & \\text{if } a_1 &lt; 4 \\\\\na_1 & \\text{otherwise} \\end{cases}\n \n\\mathbf{d}^\\phi (a_1) = \\begin{cases} 0 & \\text{if } a_1 &gt; 0 \\\\\na_1 & \\text{otherwise} \\end{cases}\n\n g' = \\text{Intervention 1 - Intervention 2} = E[Y(\\mathbf{d}^\\lambda) - Y(\\mathbf{d}^\\phi)] \n g'' = \\text{Intervention 1 - Intervention 2} = E[Y(\\mathbf{d}^\\lambda) - Y(\\mathbf{d}^\\phi)] \n\n{\\gamma}(g) ={g'} - {g''}\n\nIf yes, you’re on the right track.\n\n\nUnderstanding Source and Target Populations\n\nPopulations identified: Have I explained how my sample relates to my target populations? I should have.\nGeneralisability and transportability: Have I considered whether my results generalise different populations? I should have.\n\n\n\nSet Eligibility Criteria\n\nCriteria stated: Have I stated the eligibility criteria for the study? I should have.\n\n\n\nDescribe Sample Characteristics\n\nDescriptive statistics: have I provided descriptive statistics for demographic information taken at baseline? I should have.\nExposure change: Have I demonstrated the magnitudes of change in the exposure from baseline to the exposure interval? I should have.\nReferences: Have I included references for more information about the sample? I should have.\n\n\n\nAddressing Missing Data\n\nMissing data checks: Have I checked for missing data? I should have.\nMissing data plan: If there is missing data, have I described how I will address it? I should have.\n\n\n\nSelecting the Model Approach: If Not Using Machine Learning (Lecture 7)\n\nApproach decision: Have I decided on using G-computation, IPTW, or Doubly-Robust Estimation? I should have.\nInteractions: If not using machine learning, have I included the interaction of the exposure and baseline covariates? I should have.\nBig data: If I have a large data set, should I include the interaction of the exposure, group, and baseline confounders? I should consider it.\nModel specification: have I double-checked the model specification? I should.\nOutcome assessment: If the outcome is rare and binary, have I specified logistic regression? If it’s continuous, have I considered converting it to z-scores?\nSensitivity analysis: am I planning a sensitivity analysis using simulation? If yes, describe it (e.g. E-values.)\n\n\n\nIf Machine Learing\n\nMachine Learning: have I explained how semi-parametric ensemble machine learning works? (see example below).\n\n\n\nd. Highlight unmeasured pre-treatment covariates\nLet U denoted unmeasured pre-treatment covariates that may potentially bias the statistical association between A and Y independently of the measured covariates.\n\nConsider:\n\nTo affect Y and A, U must occur before A.\nIt is useful to draw a causal diagramme to illustrate all potential sources of bias.\nCausal diagrammes are qualitative tools that require specialist expertise. We cannot typically obtain a causal graph from the data.\nA causal diagramme should include only as much information as is required to assess confounding. See Figure 7 for an example.\nBecause we cannot ensure the absence of unmeasured confounders in observational settings, it is vital to conduct sensitivity analyses for the results. For sensitivity analyeses, we use E-values.\n\n\n\n\n\n\n\n\n\nFigure 7: Causal graph: three-wave panel design.\n\n\n\n\n\n\n\n\ne. Choose the scale for a causal contrast\nAverage causal effects can be inferred by contrasting the expected outcome when a population is exposed to an exposure level, E[Y(A = a)], with the expected outcome under a different exposure level, E[Y(A=a')].\nFor a binary treatment with levels A=0 and A=1, the Average Treatment Effect (ATE), on the difference scale, is expressed:\nATE_{\\text{risk difference}} = E[Y(1)|L] - E[Y(0)|L]\nOn the risk ratio scale, the ATE is expressed:\nATE_{\\text{risk ratio}} = \\frac{E[Y(1)|L]}{E[Y(0)|L]}\nOther effect scales, such as the incidence rate ratio, incidence rate difference, or hazard ratio, might also be of interest. We can also define the Average Treatment Effect on the Treated (ATT) :\nATT_{\\text{risk difference}} = E[Y(1) - Y(0)|A=1,L]\nATT_{\\text{risk ratio}} = \\frac{E[Y(1)|A=1,L]}{E[Y(0)|A=1, L]}\nAnother common estimand is the Population Average Treatment Effect (PATE), which denotes the effect the treatment would have on the entire population if applied universally to that population. This quantity can be expressed:\nPATE_{\\text{risk difference}} = f(E[Y(1) - Y(0)|L], W)\nPATE_{\\text{risk ratio}} = f\\left(\\frac{E[Y(1)|L]}{E[Y(0)|L]}, W\\right)\nwhere f is a function that incorporates weights W into the estimation of the expected outcomes. These weights are given from census estimates for the wider population. Note: I will show you how to use weights in future seminars.\nWe might also be interested in identifying effects specific to certain strata, such as risk differences or risk ratios, as they are modified by baseline indicators. Denote a stratum of interest by G. We may then compute:\nATE_{G,\\text{risk difference}} = E[Y(1) - Y(0)|G, L]\nATE_{G,\\text{risk ratio}} = \\frac{E[Y(1)|G, L]}{E[Y(0)|G, L]}\n\nConsider:\n\nIn this course, we are interested in stratum specific comparisons\nIn the causal inference literature, the concept we use to make sense of stratum specific comparisons is called “effect modification.”\nBy inferring effects within strata, we may evaluate whether the effects of different exposures or treatments on some well-defined outcome (measured in some well-defined time-period after the exposure) differ depending on group measurement.\nThe logic of effect modification differs slightly from that of interaction.\n\n\n\nAside: extensions\nFor continuous exposures, we must stipulate the level of contrast for the exposure (e.g. weekly versus monthly church attendance):\nATE_{A,A'} = E[Y(A) - Y(A')| L]\nThis essentially denotes an average treatment effect comparing the outcome under treatment level A to the outcome under treatment level A'.\nLikewise:\nATE_{A/A'} = \\frac{E[Y(A)| L]}{E[Y(A')| L]}\nThis defines the contrast of A and A' on a ratio scale.\n\n\nf. Describe the population(s) for whom the intended study is meant to generalise by distinguishing between source and target populations.\nConsider the following concepts:\n\nSource population: a source population is where we gather our data for a study. We pull our specific sample from this group. It needs to mirror the broader group for our conclusions to be valid and widely applicable.\nTarget population: the target population is the larger group we aim to apply our study’s results to. It could be defined by location, demographics, or specific conditions. The closer the source matches the target in ways that are relevant to our causal questions, the stronger our causal inferences about the target population will be.\n\nGeneralisability refers to the ability to apply the causal effects estimated from a sample to the population it was drawn from. In simpler terms, it deals with the extrapolation of causal knowledge from a sample to the broader population. This concept is also called “external validity”.\n\n\n\\text{Generalisability} = PATE \\approx ATE_{\\text{sample}}\n\nTransportability refers to the ability to extrapolate causal effects learned from a source population to a target population when certain conditions are met. It deals with the transfer of causal knowledge across different settings or populations.\n\n\\text{Transportability} = ATE_{\\text{target}} \\approx f(ATE_{\\text{source}}, T)\nwhere f is a function and T is a function that maps the results from our source population to another population. To achieve transportability, we need information about the source and target populations and an understanding of how the relationships between treatment, outcome, and covariates differ between the populations. Assessing transportability requires scientific knowledge.\n\n\n\nSummary Step 1: Consider how much we need to do when asking a causal question!\nWe discover that asking a causal question is a multifaceted task. It demands careful definition of the outcome, including its timing, the exposure, and covariates. It also requires selecting the appropriate scale for causal contrast, controlling for confounding, and potentially adjusting for sample weights or stratification. Finally, when asking a causal question, we must consider for whom the results apply. Only after following these steps can we then ask: “How may we answer this causal question?”"
  },
  {
    "objectID": "content/09-content.html#step-2-answer-a-causal-question",
    "href": "content/09-content.html#step-2-answer-a-causal-question",
    "title": "Causal inference: a step by step guide",
    "section": "STEP 2: ANSWER A CAUSAL QUESTION",
    "text": "STEP 2: ANSWER A CAUSAL QUESTION\n\nObtain longitudinal data\nNote that causal inference from observational data turns on the appropriate temporal ordering of the key variables involved in the study.\nRecall we have defined.\n\nA: Our exposure or treatment variable, denoted as A. Here we consider the example of ‘Church attendance’.\nY: The outcome variable we are interested in, represented by Y, is psychological distress. We operationalise this variable through the ‘Kessler-6’ distress scale.\nL: The confounding variables, collectively referred to as L, represent factors that can independently influence both A and Y. For example, socio-economic status could be a confounder that impacts both the likelihood of church attendance and the levels of psychological distress.\n\nGiven the importance of temporal ordering, we must now define time:\n\nt \\in T: Let t denote within a multiwave panel study with T measurement intervals.\n\nWhere t/\\text{{exposure}} denotes the measurement interval for the exposure. Longitudinal data collection provides us the ability to establish a causal model such that:\nt_{confounders} &lt; t_{exposure}&lt; t_{outcome}\nTo minimise the posibility of time-varying confounding and obtain the clearest effect estimates, we should acquire the most recent values of \\mathbf{L} preceding A and the latest values of A before Y.\nNote in Figure 7, We use the prefixes “t0, t1, and t2” to denote temporal ordering. We include in the set of baseline confounders the pre-exposure measurement of A and Y. This allows for more substantial confounding control. For unmeasured confounder to affect both the exposure and the outcome, it would need to do so independently of the pre-exposure confounders. Additionally, including the baseline exposure gives us an effect estimate for the incidence exposure, rather than the prevelance of the exposure. This helps us to assess the expected change in the outcome were we to initate a change in the exposure.\n\n\nInclude the measured exposure with baseline covariates\nControlling for prior exposure enables the interpretation of the effect estimate as a change in the exposure in a manner akin to a randomised trial. We propose that the effect estimate with prior control for the exposure estimates the “incidence exposure” rather than the “prevalence exposure” (Danaei, Tavakkoli, and Hernán 2012). It is crucial to estimate the incidence exposure because if the effects of an exposure are harmful in the short term such that these effects are not subsequently measured, a failure to adjust for prior exposure will yield the illusion that the exposure is beneficial. Furthermore, this approach aids in controlling for unmeasured confounding. For such a confounder to explain away the observed exposure-outcome association, it would need to do so independently of the prior level of the exposure and outcome.\n\nDanaei, Goodarz, Mohammad Tavakkoli, and Miguel A. Hernán. 2012. “Bias in observational studies of prevalent users: lessons for comparative effectiveness research from a meta-analysis of statins.” American Journal of Epidemiology 175 (4): 250–62. https://doi.org/10.1093/aje/kwr301.\n\n\nState the eligibility criteria for participation\nThis step is invaluable for assessing whether we are answering the causal question that we have asked.\n\nConsider:\n\nGeneralisability: we cannot evaluate inferences to a target group from the source population if we do not describe the source population\nEligibility criteria will help us to ensure whether we have correctly evaluated potential measurement bias/error in our instruments.\n\nFor example, the New Zealand Attitudes and Values Study is a National Probability study of New Zealanders. The details provided in the supplementary materials describe how individuals were randomly selected from the country’s electoral roll. From these invitations there was typically less than 15% response rate. How might this process of recruitment affect generalisability and transportability of our results?\n\nAside: discuss per protocol effects/ intention to treat effects\n\n\n\n\nDetermine how missing data will be handled\n\nAs we will consider in the upcoming weeks, loss to follow up and non-response opens sources for bias. We must develop a strategy for handling missing data.\n\n\n\nState a statistical model\nThe models we have considered in this course are G-computation, Inverse Probability of Treatement Weighting, and Doubly-Robust estimation.\n\n\nReporting\nConsider the following ideas about how to report one’s model:\n\nEstimator: Doubly robust where possible.\nPropensity Score Reporting: Detail the process of propensity score derivation, including the model used and any variable transformations.\nWeightIt Package: Explicitly mention the use of the ‘WeightIt’ package in R, including any specific options or parameters used in the propensity score estimation process.\nMethod Variations: Report if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as ‘ebal’, ‘energy’, and ‘ps’.\nContinuous Exposures: Highlight that for continuous exposures, only the ‘energy’ option was used for propensity score estimation.\nSubgroup Estimation: Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.\nCovariate Balance: Include a Love plot to visually represent covariate balance on the exposure both before and after weighting.\nWeighting Algorithm Statistics: Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit.\nOutcome Regression Model: Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation.\nSubgroup Interaction: Address whether the subgroup was included separately as an interaction in the outcome model, and if the model successfully converged.\nMachine Learning Using lmtp If using the lmtp package, do a stratified analysis. (see today’s lab)\nModel coefficients: note that the model coefficients should not be interpreted, as they are not meaningful in this context.\nConfidence intervals and standard errors: Describe the methods used to derive confidence intervals and standard errors, noting the use of the ‘clarify’ package in R for simulation based inference.\n\n\n\nExample of how to report a doubly robust method in your report\nThe Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:\nStep 1 involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.\nStep 2 focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.\nStep 3 entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.\nStep 4 is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.\nStep 5 involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods (Greifer et al. 2023). This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.\n\n\nInference\nConsider the following ideas about what to discuss in one’s findings: Consider the following ideas about what to discuss in one’s findings. The order of exposition might be different.\n\nSummary of results: What did you find?\nInterpretation of E-values: Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.\nCausal Effect Interpretation: What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.\nComparison of Subgroups: Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.\nUncertainty and Confidence Intervals: Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.\nGeneralisability and Transportability: Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)\nAssumptions and Limitations: Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.\nTheoretical Relevance: How are these findings relevant to existing theories.\nReplication and Future Research: Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.\nReal-world Implications: Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research."
  },
  {
    "objectID": "content/09-content.html#appendix-a-details-of-estimation-approaches",
    "href": "content/09-content.html#appendix-a-details-of-estimation-approaches",
    "title": "Causal inference: a step by step guide",
    "section": "Appendix A: Details of Estimation Approaches",
    "text": "Appendix A: Details of Estimation Approaches\n\nG-computation for Subgroup Analysis Estimator\nStep 1: Estimate the outcome model. Fit a model for the outcome Y, conditional on the exposure A, the covariates L, and subgroup indicator G. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, confounders, and subgroups.\n \\hat{E}(Y|A,L,G) = f_Y(A,L,G; \\theta_Y) \nThis equation represents the expected value of the outcome Y given the exposure A, covariates L, and subgroup G, as modelled by the function f_Y with parameters \\theta_Y. This formulation allows for the prediction of the average outcome Y given certain values of A, L, and G.\nStep 2: Simulate potential outcomes. For each individual in each subgroup, predict their potential outcome under the intervention A=a using the estimated outcome model:\n\\hat{E}(Y(a)|G=g) = \\hat{E}[Y|A=a,L,G=g; \\hat{\\theta}_Y]\nWe also predict the potential outcome for everyone in each subgroup under the causal contrast, setting the intervention for everyone in that group to A=a':\n\\hat{E}(Y(a')|G=g) = \\hat{E}[Y|A=a',L,G=g; \\hat{\\theta}_Y]\nIn these equations, Y represents the potential outcome, A is the intervention, L are the covariates, G=g represents the subgroup, and \\theta_Y are the parameters of the outcome model.\nStep 3: Calculate the estimated difference for each subgroup g:\n\\hat{\\delta}_g = \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g]\nThis difference \\hat{\\delta}_g represents the average causal effect of changing the exposure from level a' to level a within each subgroup g.\nWe use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023).\nStep 4: Compare differences in causal effects by subgroups:\n\\hat{\\gamma} = \\hat{\\delta}_g - \\hat{\\delta}_{g'}\nwhere,\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a^{\\prime})|G=g] \\big)}^{\\hat{\\delta_g}} - \\overbrace{\\big(\\hat{E}[Y(a^{\\prime})|G=g^{\\prime}]- \\hat{E}[Y(a)|G=g^{\\prime}]\\big)}^{\\hat{\\delta_{g^{\\prime}}}}\nThis difference \\hat{\\gamma} represents the difference in the average causal effects between the subgroups g and g'. It measures the difference in effect of the exposure A within subgroup G on the outcome Y.\n1\n1 A and G on Y might not be additive. We assume that the potential confounders L are sufficient to control for confounding. See AppendixWe again use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023).\n\n\nInverse Probability of Treatment Weighting (IPTW) for Subgroup Analysis Estimator\nStep 1: Estimate the propensity score. The propensity score e(L, G) is the conditional probability of the exposure A = 1, given the covariates L and subgroup indicator G. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.\n\\hat{e} = P(A = 1 | L, G) = f_A(L, G; \\theta_A)\nHere, f_A(L, G; \\theta_A) is a function (statistical model) that estimates the probability of the exposure A = 1 given covariates L and subgroup G. Then, we calculate the weights for each individual, denoted as v, using the estimated propensity score:\n\nv =\n\\begin{cases}\n\\frac{1}{\\hat{e}} & \\text{if } A = 1 \\\\\n\\frac{1}{1-\\hat{e}} & \\text{if } A = 0\n\\end{cases}\n\nStep 2: Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome Y, conditional on the exposure A and subgroup G. This can be represented as:\n \\hat{E}(Y|A, G; V) = f_Y(A, G ; \\theta_Y, V) \nIn this model, f_Y is a function (such as a weighted regression model) with parameters θ_Y.\nStep 3: Simulate potential outcomes. For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention A=a regardless of their actual exposure level:\n\\hat{E}(Y(a)|G=g) = \\hat{E}[Y|A=a,G=g; \\hat{\\theta}_Y, v]\nAnd also under the hypothetical scenario where everyone is exposed to intervention A=a':\n\\hat{E}(Y(a')|G=g) = \\hat{E}[Y|A=a',G=g; \\hat{\\theta}_Y, v]\nStep 4: Estimate the average causal effect for each subgroup as the difference in the predicted outcomes:\n\\hat{\\delta}_g = \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g]\nThe estimated difference \\hat{\\delta}_g represents the average causal effect within group g.\nStep 5: Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:\n\\hat{\\gamma} = \\hat{\\delta}_g - \\hat{\\delta}_{g'}\nwhere,\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g] \\big)}^{\\hat{\\delta_g}} - \\overbrace{\\big(\\hat{E}[Y(a')|G=g']- \\hat{E}[Y(a)|G=g']\\big)}^{\\hat{\\delta_{g'}}}\nThis \\hat{\\gamma} represents the difference in the average causal effects between the subgroups g and g'.\nWe again use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023).\n\n\nDoubly Robust Estimation for Subgroup Analysis Estimator\nIt appears that the Doubly Robust Estimation explanation for subgroup analysis is already clear and correct, covering all the necessary steps in the process. Nevertheless, there’s a slight confusion in step 4. The difference \\delta_g is not defined within the document. I assume that you intended to write \\hat{\\delta}_g. Here’s the corrected version:\n\n\nDoubly Robust Estimation for Subgroup Analysis Estimator\nDoubly Robust Estimation is a powerful technique that combines the strengths of both the IPTW and G-computation methods. It uses both the propensity score model and the outcome model, which makes it doubly robust: it produces unbiased estimates if either one of the models is correctly specified.\nStep 1 Estimate the propensity score. The propensity score \\hat{e}(L, G) is the conditional probability of the exposure A = 1, given the covariates L and subgroup indicator G. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.\n\\hat{e} = P(A = 1 | L, G) = f_A(L, G; \\theta_A)\nHere, f_A(L, G; \\theta_A) is a function (statistical model) that estimates the probability of the exposure A = 1 given covariates L and subgroup G. Then, we calculate the weights for each individual, denoted as v, using the estimated propensity score:\n\nv =\n\\begin{cases}\n\\frac{1}{\\hat{e}} & \\text{if } A = 1 \\\\\n\\frac{1}{1-\\hat{e}} & \\text{if } A = 0\n\\end{cases}\n\nStep 2 Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome Y, conditional on the exposure A, covariates L, and subgroup G.\n \\hat{E}(Y|A, L, G; V) = f_Y(A, L, G ; \\theta_Y, V) \nStep 3 For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention A=a regardless of their actual exposure level:\n\\hat{E}(Y(a)|G=g) = \\hat{E}[Y|A=a,G=g; L,\\hat{\\theta}_Y, v]\nAnd also under the hypothetical scenario where everyone in each subgroup is exposed to intervention A=a':\n\\hat{E}(Y(a')|G=g) = \\hat{E}[Y|A=a',G=g; L; \\hat{\\theta}_Y, v]\nStep 4 Estimate the average causal effect for each subgroup. Compute the estimated expected value of the potential outcomes under each intervention level for each subgroup:\n\\hat{\\delta}_g = \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g]\nThe estimated difference \\hat{\\delta}_g represents the average causal effect of changing the exposure from level a' to level a within each subgroup.\nStep 5 Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:\n\\hat{\\gamma} = \\hat{\\delta}_g - \\hat{\\delta}_{g'}\nwhere,\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g] \\big)}^{\\hat{\\delta_g}} - \\overbrace{\\big(\\hat{E}[Y(a')|G=g']- \\hat{E}[Y(a)|G=g']\\big)}^{\\hat{\\delta_{g'}}}\nWe again use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023)."
  },
  {
    "objectID": "content/09-content.html#appendix-b-g-computation-for-subgroup-analysis-estimator-with-non-additive-effects",
    "href": "content/09-content.html#appendix-b-g-computation-for-subgroup-analysis-estimator-with-non-additive-effects",
    "title": "Causal inference: a step by step guide",
    "section": "Appendix B: G-computation for Subgroup Analysis Estimator with Non-Additive Effects",
    "text": "Appendix B: G-computation for Subgroup Analysis Estimator with Non-Additive Effects\nStep 1: Estimate the outcome model. Fit a model for the outcome Y, conditional on the exposure A, the covariates L, subgroup indicator G, and interactions between A and G. This model can be a linear regression, logistic regression, or another statistical model. The goal is to capture the relationship between the outcome, exposure, confounders, subgroups, and their interactions.\n \\hat{E}(Y|A,L,G,AG) = f_Y(A,L,G,AG; \\theta_Y) \nThis equation represents the expected value of the outcome Y given the exposure A, covariates L, subgroup G, and interaction term AG, as modeled by the function f_Y with parameters \\theta_Y.\nStep 2: Simulate potential outcomes. For each individual in each subgroup, predict their potential outcome under the intervention A=a using the estimated outcome model:\n\\hat{E}(Y(a)|G=g) = \\hat{E}[Y|A=a,L,G=g,AG=ag; \\hat{\\theta}_Y]\nWe also predict the potential outcome for everyone in each subgroup under the causal contrast, setting the intervention for everyone in that group to A=a':\n\\hat{E}(Y(a')|G=g) = \\hat{E}[Y|A=a',L,G=g,AG=a'g; \\hat{\\theta}_Y]\nStep 3: Calculate the estimated difference for each subgroup g:\n\\hat{\\delta}_g = \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g]\nStep 4: Compare differences in causal effects by subgroups:\n\\hat{\\gamma} = \\hat{\\delta}_g - \\hat{\\delta}_{g'}\nwhere,\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a^{\\prime})|G=g] \\big)}^{\\hat{\\delta_g}} - \\overbrace{\\big(\\hat{E}[Y(a^{\\prime})|G=g^{\\prime}]- \\hat{E}[Y(a)|G=g^{\\prime}]\\big)}^{\\hat{\\delta_{g^{\\prime}}}}\nThis difference \\hat{\\gamma} represents the difference in the average causal effects between the subgroups g and g', taking into account the interaction effect of the exposure A and the subgroup G on the outcome Y.\nNote that the interaction term AG (or ag and a'g in the potential outcomes) stands for the interaction between the exposure level and the subgroup. This term is necessary to accommodate the non-additive effects in the model. As before, we must ensure that potential confounders L are sufficient to control for confounding."
  },
  {
    "objectID": "content/09-content.html#appendix-c-doubly-robust-estimation-for-subgroup-analysis-estimator-with-interaction",
    "href": "content/09-content.html#appendix-c-doubly-robust-estimation-for-subgroup-analysis-estimator-with-interaction",
    "title": "Causal inference: a step by step guide",
    "section": "Appendix C: Doubly Robust Estimation for Subgroup Analysis Estimator with Interaction",
    "text": "Appendix C: Doubly Robust Estimation for Subgroup Analysis Estimator with Interaction\nAgain, Doubly Robust Estimation combines the strengths of both the IPTW and G-computation methods. It uses both the propensity score model and the outcome model, which makes it doubly robust: it produces unbiased estimates if either one of the models is correctly specified.\nStep 1 Estimate the propensity score. The propensity score e(L, G) is the conditional probability of the exposure A = 1, given the covariates L and subgroup indicator G. This can be modeled using logistic regression or other suitable methods, depending on the nature of the data and the exposure.\ne = P(A = 1 | L, G) = f_A(L, G; \\theta_A)\nHere, f_A(L, G; \\theta_A) is a function (statistical model) that estimates the probability of the exposure A = 1 given covariates L and subgroup G. Then, we calculate the weights for each individual, denoted as v, using the estimated propensity score:\n\nv =\n\\begin{cases}\n\\frac{1}{\\hat{e}} & \\text{if } A = 1 \\\\\n\\frac{1}{1-\\hat{e}} & \\text{if } A = 0\n\\end{cases}\n\nStep 2 Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome Y, conditional on the exposure A, covariates L, subgroup G and the interaction between A and G.\n \\hat{E}(Y|A, L, G, AG; V) = f_Y(A, L, G, AG ; \\theta_Y, V) \nStep 3 For each individual in each subgroup, simulate their potential outcome under the hypothetical scenario where everyone in the subgroup is exposed to the intervention A=a regardless of their actual exposure level:\n\\hat{E}(Y(a)|G=g) = \\hat{E}[Y|A=a,G=g, AG=ag; L,\\hat{\\theta}_Y, v]\nAnd also under the hypothetical scenario where everyone in each subgroup is exposed to intervention A=a':\n\\hat{E}(Y(a')|G=g) = \\hat{E}[Y|A=a',G=g, AG=a'g; L; \\hat{\\theta}_Y, v]\nStep 4 Estimate the average causal effect for each subgroup. Compute the estimated expected value of the potential outcomes under each intervention level for each subgroup:\n\\hat{\\delta}_g = \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g]\nThe estimated difference \\hat{\\delta}_g represents the average causal effect of changing the exposure from level a' to level a within each subgroup.\nStep 5 Compare differences in causal effects by groups. Compute the differences in the estimated causal effects between different subgroups:\n\\hat{\\gamma} = \\hat{\\delta}_g - \\hat{\\delta}_{g'}\nwhere,\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y(a)|G=g] - \\hat{E}[Y(a')|G=g] \\big)}^{\\hat{\\delta_g}} - \\overbrace{\\big(\\hat{E}[Y(a')|G=g']- \\hat{E}[Y(a)|G=g']\\big)}^{\\hat{\\delta_{g'}}}\nWe again use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023)."
  },
  {
    "objectID": "content/09-content.html#appendix-d-marginal-structural-models-for-estimating-population-average-treatment-effect-with-interaction-doubly-robust",
    "href": "content/09-content.html#appendix-d-marginal-structural-models-for-estimating-population-average-treatment-effect-with-interaction-doubly-robust",
    "title": "Causal inference: a step by step guide",
    "section": "Appendix D: Marginal Structural Models for Estimating Population Average Treatment Effect with Interaction (Doubly Robust)",
    "text": "Appendix D: Marginal Structural Models for Estimating Population Average Treatment Effect with Interaction (Doubly Robust)\nSometimes we will only wish to estimate a marginal effect. In that case.\nStep 1 Estimate the propensity score. The propensity score e(L) is the conditional probability of the exposure A = 1, given the covariates L which contains the subgroup G. This can be modelled using logistic regression or other functions as described in Greifer et al. (2023)\n\\hat{e} = P(A = 1 | L) = f_A(L; \\theta_A)\nHere, f_A(L; \\theta_A) is a function (a statistical model) that estimates the probability of the exposure A = 1 given covariates L. Then, we calculate the weights for each individual, denoted as v, using the estimated propensity score:\n\nv =\n\\begin{cases}\n\\frac{1}{e} & \\text{if } A = 1 \\\\\n\\frac{1}{1-e} & \\text{if } A = 0\n\\end{cases}\n\nStep 2 Fit a weighted outcome model. Using the weights calculated from the estimated propensity scores, fit a model for the outcome Y, conditional on the exposure A and covariates L.\n \\hat{E}(Y|A, L; V) = f_Y(A, L; \\theta_Y, V) \nThis model should include terms for both the main effects of A and L and their interaction AL.\nStep 3 For the entire population, simulate the potential outcome under the hypothetical scenario where everyone is exposed to the intervention A=a regardless of their actual exposure level:\n\\hat{E}(Y(a)) = \\hat{E}[Y|A=a; L,\\hat{\\theta}_Y, v]\nAnd also under the hypothetical scenario where everyone is exposed to intervention A=a':\n\\hat{E}(Y(a')) = \\hat{E}[Y|A=a'; L; \\hat{\\theta}_Y, v]\nStep 4 Estimate the average causal effect for the entire population. Compute the estimated expected value of the potential outcomes under each intervention level for the entire population:\n\\hat{\\delta} = \\hat{E}[Y(a)] - \\hat{E}[Y(a')]\nThe estimated difference \\hat{\\delta} represents the average causal effect of changing the exposure from level a' to level a in the entire population.\nWe again use simulation-based inference methods to compute standard errors and confidence intervals (Greifer et al. 2023).\n\nGreifer, Noah, Steven Worthington, Stefano Iacus, and Gary King. 2023. Clarify: Simulation-Based Inference for Regression Models. https://iqss.github.io/clarify/.\n\nMachine Learning\nExample from https://osf.io/cnphs\n\nWe perform statistical estimation using semi-parametric Targeted Learning, specifically a Targeted Minimum Loss-based Estimation (TMLE) estimator. TMLE is a robust method that combines machine learning techniques with traditional statistical models to estimate causal effects while providing valid statistical uncertainty measures for these estimates (Laan and Gruber 2012; Van der Laan 2014).\n\nLaan, Mark J van der, and Susan Gruber. 2012. “Targeted Minimum Loss Based Estimation of Causal Effects of Multiple Time Point Interventions.” The International Journal of Biostatistics 8 (1).\n\nVan der Laan, Mark J. 2014. “Targeted Estimation of Nuisance Parameters to Obtain Valid Statistical Inference.” The International Journal of Biostatistics 10 (1): 29–57.\n\n\nTMLE operates through a two-step process that involves modelling both the outcome and treatment (exposure). Initially, TMLE employs machine learning algorithms to flexibly model the relationship between treatments, covariates, and outcomes. This flexibility allows TMLE to account for complex, high-dimensional covariate spaces without imposing restrictive model assumptions; (Van Der Laan and Rose 2011, 2018). The outcome of this step is a set of initial estimates for these relationships.\n\nVan Der Laan, Mark J., and Sherri Rose. 2011. Targeted Learning: Causal Inference for Observational and Experimental Data. Springer Series in Statistics. New York, NY: Springer. https://link.springer.com/10.1007/978-1-4419-9782-1.\n\n———. 2018. Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies. Springer Series in Statistics. Cham: Springer International Publishing. http://link.springer.com/10.1007/978-3-319-65304-4.\n\n\nThe second step of TMLE involves ``targeting’’ these initial estimates by incorporating information about the observed data distribution to improve the accuracy of the causal effect estimate. TMLE achieves this precision through an iterative updating process, which adjusts the initial estimates towards the true causal effect. This updating process is guided by the efficient influence function, ensuring that the final TMLE estimate is as close as possible, given the measures and data, to the targeted causal effect while still being robust to model-misspecification in either the outcome or the treatment model (Laan, Luedtke, and Dı́az 2014).\n\nLaan, Mark J van der, Alexander R Luedtke, and Iván Dı́az. 2014. “Discussion of Identification, Estimation and Approximation of Risk Under Interventions That Depend on the Natural Value of Treatment Using Observational Data, by Jessica Young, Miguel Hernán, and James Robins.” Epidemiologic Methods 3 (1): 21–31.\n\n\nAgain, a central feature of TMLE is its double-robustness property. If either the treatment model or the outcome model is correctly specified, the TMLE estimator will consistently estimate the causal effect. Additionally, we used cross-validation to avoid over-fitting, following the pre-stated protocols in Bulbulia (Bulbulia 2024c). The integration of TMLE and machine learning technologies reduces the dependence on restrictive modelling assumptions and introduces an additional layer of robustness. For further details of the specific targeted learning strategy we favour, see Hoffman et al. (2023). We perform estimation using the package (Williams and Díaz 2021). We used the library for semi-parametric estimation with the predefined libraries , , and (Chen et al. 2023; Polley et al. 2023; Wright and Ziegler 2017). We created graphs, tables and output reports using the package (Bulbulia 2024b).\n\n———. 2024c. “A Practical Guide to Causal Inference in Three-Wave Panel Studies.” PsyArXiv Preprints, February. https://doi.org/10.31234/osf.io/uyg3d.\n\nHoffman, Katherine L., Diego Salazar-Barreto, Kara E. Rudolph, and Iván Díaz. 2023. “Introducing Longitudinal Modified Treatment Policies: A Unified Framework for Studying Complex Exposures,” April. https://doi.org/10.48550/arXiv.2304.09460.\n\nWilliams, Nicholas T., and Iván Díaz. 2021. lmtp: Non-Parametric Causal Effects of Feasible Interventions Based on Modified Treatment Policies. https://doi.org/10.5281/zenodo.3874931.\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2023. Xgboost: Extreme Gradient Boosting. https://CRAN.R-project.org/package=xgboost.\n\nPolley, Eric, Erin LeDell, Chris Kennedy, and Mark van der Laan. 2023. SuperLearner: Super Learner Prediction. https://CRAN.R-project.org/package=SuperLearner.\n\nWright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” Journal of Statistical Software 77 (1): 1–17. https://doi.org/10.18637/jss.v077.i01.\n\n———. 2024b. Margot: MARGinal Observational Treatment-Effects. https://doi.org/10.5281/zenodo.10907724.\n\n\nSensitivity Analysis Using the E-value\n\nTo assess the sensitivity of results to unmeasured confounding, we report VanderWeele and Ding’s ``E-value’’ in all analyses (Tyler J. VanderWeele and Ding 2017). The E-value quantifies the minimum strength of association (on the risk ratio scale) that an unmeasured confounder would need to have with both the exposure and the outcome (after considering the measured covariates) to explain away the observed exposure-outcome association (Linden, Mathur, and VanderWeele 2020; Tyler J. VanderWeele, Mathur, and Chen 2020). To evaluate the strength of evidence, we use the bound of the E-value 95% confidence interval closest to 1.\n\nVanderWeele, Tyler J., and Peng Ding. 2017. “Sensitivity Analysis in Observational Research: Introducing the E-Value.” Annals of Internal Medicine 167 (4): 268–74. https://doi.org/10.7326/M16-2607.\n\nLinden, Ariel, Maya B Mathur, and Tyler J VanderWeele. 2020. “Conducting Sensitivity Analysis for Unmeasured Confounding in Observational Studies Using e-Values: The Evalue Package.” The Stata Journal 20 (1): 162–75.\n\nVanderWeele, Tyler J, Maya B Mathur, and Ying Chen. 2020. “Outcome-Wide Longitudinal Designs for Causal Inference: A New Template for Empirical Studies.” Statistical Science 35 (3): 437–66.\n\n\n\n\nPackages\n\nreport::cite_packages()\n\n  - Barrett M (2021). _ggokabeito: 'Okabe-Ito' Scales for 'ggplot2' and 'ggraph'_. R package version 0.1.0, &lt;https://CRAN.R-project.org/package=ggokabeito&gt;.\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 &lt;https://doi.org/10.5281/zenodo.10907724&gt;, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., &lt;https://go-bayes.github.io/margot/&gt;.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, &lt;https://CRAN.R-project.org/package=janitor&gt;.\n  - Greifer N (2024). _WeightIt: Weighting for Covariate Balance in Observational Studies_. R package version 1.3.2, &lt;https://CRAN.R-project.org/package=WeightIt&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, &lt;https://CRAN.R-project.org/package=patchwork&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - VanderWeele TJ, Ding P (2011). \"Sensitivity analysis in observational research: introducing the E-value.\" _Annals of Internal Medicine_, *167*(4), 268-274. Mathur MB, VanderWeele TJ (2019). \"Sensitivity analysis for unmeasured confounding in meta-analyses.\" _Journal of the American Statistical Association&gt;_. Smith LH, VanderWeele TJ (2019). \"Bounding bias due to selection.\" _Epidemiology_.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2024). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.49, &lt;https://yihui.org/knitr/&gt;. Xie Y (2015). _Dynamic Documents with R and knitr_, 2nd edition. Chapman and Hall/CRC, Boca Raton, Florida. ISBN 978-1498716963, &lt;https://yihui.org/knitr/&gt;. Xie Y (2014). \"knitr: A Comprehensive Tool for Reproducible Research in R.\" In Stodden V, Leisch F, Peng RD (eds.), _Implementing Reproducible Computational Research_. Chapman and Hall/CRC. ISBN 978-1466561595.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0, &lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "content/01-content.html",
    "href": "content/01-content.html",
    "title": "Asking questions in cross-cultural psychology",
    "section": "",
    "text": "Figure 1: Causal graph: we will refer to this image in the lecture and begin reviewing causal graphs in Week 2"
  },
  {
    "objectID": "content/01-content.html#slides",
    "href": "content/01-content.html#slides",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Slides",
    "text": "Slides\nPREVIEW\n\n\n\nOpen in browser here"
  },
  {
    "objectID": "content/01-content.html#slide-deck",
    "href": "content/01-content.html#slide-deck",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Slide deck:",
    "text": "Slide deck:"
  },
  {
    "objectID": "content/01-content.html#slides-1",
    "href": "content/01-content.html#slides-1",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Slides",
    "text": "Slides\nPREVIEW\n\n\n\nOpen in browser here"
  },
  {
    "objectID": "content/01-content.html#why-learn-r",
    "href": "content/01-content.html#why-learn-r",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Why learn R?",
    "text": "Why learn R?\n\nYou’ll need it for your final report.\nSupports your psychology coursework.\nEnhances your coding skills. Presently all buzz is about AI. Amateur coders can greatly accelerate their abilities – but you still need to have some coding. If you have no coding skills, you will lose out to those that do.\nCoding can become as enjoyable as music or languages, really!"
  },
  {
    "objectID": "content/01-content.html#installing-r",
    "href": "content/01-content.html#installing-r",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Installing R",
    "text": "Installing R\n\nVisit the Comprehensive R Archive Network (CRAN) at https://cran.r-project.org/.\nSelect the version of R suitable for your operating system (Windows, Mac, or Linux).\nDownload and install it by following the on-screen instructions."
  },
  {
    "objectID": "content/01-content.html#installing-rstudio",
    "href": "content/01-content.html#installing-rstudio",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Installing RStudio",
    "text": "Installing RStudio\nAfter downloading R…\nSee Johannes Karl’s Video\n\nStep 1: Install R-Studio\nIf you have already downloaded and installed R from the Comprehensive R Archive Network (CRAN):\n\nGo to the RStudio download page at https://www.rstudio.com/products/rstudio/download/\nChoose the free version of RStudio Desktop, and download it for your operating system.\nDownload and install RStudio Desktop.\nOpen RStudio to begin setting up your project environment.\n\n\n\nStep 2: Create a new project\n\nIn RStudio, go to File &gt; New Project.\nChoose New Directory for a new project or Existing Directory if you have a folder where you want to initialise an RStudio project.\nFor a new project, select New Project, then provide a directory name. This name will also be the name of your project.\nSpecify the location where the project folder will be created.\nClick Create Project.\n\n\n\n\n\n\n\nOrder your R-studio/R workflow\n\n\n\n\nClear folder structure\nIf you are using GitHub (or similar) create a location on your machine (i.d. not dropbox)\nIf you are not using GitHub choose the cloud (Dropbox or similar).\nWhen creating new files and scripts, use clear labels that anyone could understand.\nThat “anyone” will be your future self, trying to make sense.\n\n\n\n\n\nStep 3: Give project structure\n\nOrganising Files and Folders:\n\nWithin your project, create folders to organise your scripts and data.\nCommon folder names include R/ for R scripts, data/ for datasets, and doc/ for documentation.\nYou can create these folders using RStudio’s Files pane or through your operating system’s file explorer.\n\nCreating and Managing R Scripts:\n\nTo create a new R script, go to File &gt; New File &gt; R Script.\nSave the script in your project directory’s R/ folder to keep your work organised. Use meaningful file names that describe the script’s purpose.\n\nVersion Control:\n\nIf you are familiar with version control, you can initialise a Git repository within your project by selecting the Version Control option when creating a new project.\nThis allows for better tracking of changes and collaboration if working with others.\nIf you are not familiar with version control (or have not installed git on your machine), do not worry about initialising a Git repository.\n\n\n\n\nStep 4: Working with R-scripts\n\nWriting and executing Code:\n\nWrite your R code in the script editor.\nExecute code by selecting lines and pressing Ctrl + Enter (Windows/Linux) or Cmd + Enter (Mac).\n\nCommenting and documentation:\n\nUse comments (preceded by #) to document your code for clarity and future reference.\n\nSaving and organising scripts:\n\nRegularly save your scripts (Ctrl + S or Cmd + S).\nOrganise scripts into folders within your project for different analyses or data processing tasks.\n\n\n\n\nStep 5: When you exit R-studio\n\nBefore concluding your work, save your workspace or clear it to start fresh in the next session (Session &gt; Restart R).\n\n\n\n\n\n\n\nOrder your R-studio/R workflow\n\n\n\n\nAgain, use clearly defined script names\nAnnotate your code\nSave your scripts often (Ctrl + S or Cmd + S).\n\n\n\n\n\n\n\n\n\nExercise 1: Install the tidyverse package\n\n\n\nFollow these instructions to install the tidyverse package in RStudio:\n\nOpen RStudio: launch RStudio on your computer.\nAccess package installation:\n\nNavigate to the menu at the top of RStudio and click on Tools &gt; Install Packages.... This opens the Install Packages dialogue box.\n\nInstall tidyverse:\n\nIn the Install Packages dialogue box, you will see a field labelled “Packages (separate multiple with space or comma):”. Click in this field and type tidyverse.\nBelow the packages field, ensure the checkbox for Install dependencies is checked. This ensures all packages that tidyverse depends on are also installed.\n\nBegin installation:\n\nClick on the Install button to start the installation process.\n\n\nThe installation might take a few minutes. Monitor the progress in the “Console” pane. Once the installation is complete, you will see a message in the console indicating that the process has finished.\n\nLoad tidyverse: After successful installation, you can load the tidyverse package into your R session by typing library(tidyverse) in the console and pressing Enter."
  },
  {
    "objectID": "content/01-content.html#basic-r-commands",
    "href": "content/01-content.html#basic-r-commands",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Basic R Commands",
    "text": "Basic R Commands\n\n\n\n\n\n\nHow to copy the code on this page\n\n\n\n\nR Script &gt; New File &gt; R\nName your new R script and save it in a folder.\nHover your cursor over the top right of the code panel, and click the copy tab.\nCopy the text into your script.\nSave: Ctrl + S or Cmd + S.\n\n\n\n\nAssignment (&lt;-)\nAssignment in R is done using the ‘&lt;-’ operator, which on my machine renders &lt;-. This operator assigns values to variables:\n\nx &lt;- 10 # assigns the value 10 to x\ny &lt;- 5 # assigns the value 5 to y\n\n# this does the same\nx &lt;- 10\ny &lt;- 5\n\n# note what happens when we do this\n# 10 = 5 # not run\n\n# but we can do this\n# 10 == 5 # considered below\n\n\n\n\n\n\n\nRStudio Assignment Operator Shortcut\n\n\n\n\nFor macOS: Option + - (minus key) inserts &lt;-.\nFor Windows and Linux: Alt + - (minus key) inserts &lt;-.\n\nConsult the latest RStudio documentation or access the Keyboard Shortcuts Help (Tools -&gt; Keyboard Shortcuts Help) for up-to-date shortcuts.\n\n\n\n\nConcatenation (c())\nThe c() function combines multiple elements into a vector.\n\nnumbers &lt;- c(1, 2, 3, 4, 5) # a vector of numbers\nprint(numbers)\n\n[1] 1 2 3 4 5\n\n\n\n\nOperations (+, -)\nBasic arithmetic operations include addition (+) and subtraction (-).\n\n# this does the same\nx &lt;- 10\ny &lt;- 5\n\nsum &lt;- x + y # adds x and y\n\nprint(sum)\n\n[1] 15\n\ndifference &lt;- x - y # subtracts y from x\n\n# note we did not need to use the `print()` function\ndifference\n\n[1] 5\n\n\n\n\n\n\n\n\nExecuting code\n\n\n\n\nCtrl + Enter (Windows/Linux) or Cmd + Enter (Mac).\n\n\n\nIn addition to assignment, multiplication and division are fundamental arithmetic operations in R that allow you to manipulate numeric data. Here is how you can incorporate these operations into your basic R commands documentation:\n\n\nMultiplication (*) and Division (/)\nMultiplication and division in R are performed using the * and / operators, respectively. These operators allow for element-wise operations on vectors, as well as operations on individual numeric values.\n\n# multiplication\nproduct &lt;- x * y # multiplies x by y\nproduct\n\n[1] 50\n\n# division\nquotient &lt;- x / y # divides x by y\nquotient\n\n[1] 2\n\n# element-wise multiplication on vectors\nvector1 &lt;- c(1, 2, 3)\nvector2 &lt;- c(4, 5, 6)\n# multiplies each element of vector1 by the corresponding element of vector2\nvector_product &lt;- vector1 * vector2\nvector_product\n\n[1]  4 10 18\n\n# element-wise division on vectors\n# divides each element of vector1 by the corresponding element of vector2\nvector_division &lt;- vector1 / vector2\nvector_division\n\n[1] 0.25 0.40 0.50\n\n\n\nMultiplication and division can be used for scalar (single values) and vector (multiple values) operations. When applied to vectors, these operations are performed element-wise.\nBe mindful of division by zero, as this will result in Inf (infinity) or NaN (not a number) depending on the context.\n\n\n# example of division by zero\nresult &lt;- 10 / 0 # results in Inf\nzero_division &lt;- 0 / 0 # results in NaN\n\n\nR also supports integer division using the %/% operator and modulo operation using %% to find the remainder.\n\n\n# integer division\ninteger_division &lt;- 10 %/% 3 # results in 3\n\n# modulo operation\nremainder &lt;- 10 %% 3 # results in 1\n\n\n\nrm() Remove Object\n\n# `rm()` remove object ----------------------------------------------------\ndevil_number &lt;- 666 # results in 1\n\n# view\ndevil_number\n\n[1] 666\n\n# remove the devil number\nrm(devil_number)\n\n# check\n# devil_number\n\n\n\nLogic (!, !=, ==)\nLogical operations include NOT (!), NOT EQUAL (!=), and EQUAL (==).\n\nx_not_y &lt;- x != y # checks if x is not equal to y\nx_not_y\n\n[1] TRUE\n\nx_equal_10 &lt;- x == 10 # checks if x is equal to 10\nx_equal_10\n\n[1] TRUE\n\n\nLogical operations are fundamental in R for controlling the flow of execution and making decisions based on conditions. In addition to NOT (!), NOT EQUAL (!=), and EQUAL (==), there are several other logical operators you should know:\n\n\nOR (| and ||)\n\nThe | operator performs element-wise logical OR operation. It evaluates each pair of elements in two logical vectors to see if at least one is TRUE.\nThe || operator performs a logical OR operation but only evaluates the first element of each vector – mainly used in if statements and not for vectorised operations.\n\n\n# element-wise OR\nvector_or &lt;- c(TRUE, FALSE) | c(FALSE, TRUE) # returns c(TRUE, TRUE)\nvector_or\n\n[1] TRUE TRUE\n\n# single OR (only looks at first element)\nsingle_or &lt;- TRUE || FALSE # returns TRUE\nsingle_or\n\n[1] TRUE\n\n\n\n\nAND (& and &&)\n\nThe & operator performs element-wise logical AND operations. It checks if both elements in the corresponding positions of two logical vectors are TRUE.\nThe && operator performs a logical AND operation but only evaluates the first element of each vector. Like ||, used in conditions that do not require vectorised operations.\n\n\n# element-wise AND\nvector_and &lt;- c(TRUE, FALSE) & c(FALSE, TRUE) # returns c(FALSE, FALSE)\n\n# single AND (only looks at first element)\nsingle_and &lt;- TRUE && FALSE # returns FALSE\n\n\n\n\n\n\n\nRStudio Workflow Shortcuts\n\n\n\nShortcuts bring order and boost creativity\n\nExecute Code Line: Cmd + Return (Mac) or Ctrl + Enter (Windows/Linux)\nInsert Section Heading: Cmd + Shift + R (Mac) or Ctrl + Shift + R (Windows/Linux)\nAlign Code: Cmd + Shift + A (Mac) or Ctrl + Shift + A (Windows/Linux)\nComment/Uncomment: Cmd/Ctrl + Shift + C\nSave All: Cmd/Ctrl + Shift + S\nFind/Replace: Cmd/Ctrl + F, Cmd/Ctrl + Shift + F\nNew File: Cmd/Ctrl + Shift + N\nAuto-complete: Tab\n\nFor more commands, explore the Command Palette available under Tools -&gt; Command Palette or Shift + Cmd + P (Mac) or Shift + Ctrl + P (Windows/Linux)."
  },
  {
    "objectID": "content/01-content.html#data-types-in-r",
    "href": "content/01-content.html#data-types-in-r",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Data Types in R",
    "text": "Data Types in R\nUnderstanding data types in R is essential. R supports several fundamental data types, including integers, characters, factors, and ordered factors. Each type has its specific use case and functions associated with it.\n\nIntegers\nIntegers are whole numbers without decimal points. In R, integers can be explicitly defined by adding an L suffix to the number.\n\n# define an integer\nx &lt;- 42L\n\nx\n\n[1] 42\n\n# check\nstr(x) # is integer\n\n int 42\n\n# convert to numeric\ny &lt;- as.numeric(x)\n\nstr(y)\n\n num 42\n\n\nIntegers are particularly useful when dealing with counts or indices that do not require fractional values.\n\n\nCharacters\nCharacter data types are used to represent text. In R, text strings are enclosed in quotes, either single (') or double (\").\n\n# define a character string\nname &lt;- \"Alice\"\n\nCharacters are essential for categorical data that does not fit into numerical categories, such as names, labels, and descriptions.\n\n\nFactors\nFactors are used to represent categorical data that can take on a limited number of values, known as levels. Factors are useful for statistical modeling as they explicitly define categories in the data.\n\n# Define a factor\ncolors &lt;- factor(c(\"red\", \"blue\", \"green\"))\n\nFactors can improve efficiency and memory usage when dealing with categorical data, especially in large datasets. And they are useful when dealing with categorical variables (naturally).\n\nOrdered Factors\nOrdered factors are a special type of factor where the levels have an inherent order. They are defined similarly to factors but with an additional argument to denote the order.\n\n# ordered factors ---------------------------------------------------------\n# factors ordinary\neducation_levels &lt;- c(\"high school\", \"bachelor\", \"master\", \"ph.d.\")\neducation_factor_no_order &lt;- factor(education_levels, ordered = FALSE)\nstr(education_factor_no_order)\n\n Factor w/ 4 levels \"bachelor\",\"high school\",..: 2 1 3 4\n\n# factors with inherent order\neducation_factor &lt;- factor(education_levels, ordered = TRUE)\neducation_factor\n\n[1] high school bachelor    master      ph.d.      \nLevels: bachelor &lt; high school &lt; master &lt; ph.d.\n\n# another way to do the same\neducation_ordered_explicit &lt;- factor(education_levels, levels = education_levels, ordered = TRUE)\n\nOrdered factors allow for logical comparisons based on their order, which is particularly useful in analyses where the order of categories matters, such as ordinal regression.\n\n\nOperations with Ordered Factors\nOrdered factors support logical comparisons that consider the order of the levels.\n\n# comparison of ordered factors\nedu1 &lt;- ordered(\"bachelor\", levels = education_levels)\nedu2 &lt;- ordered(\"master\", levels = education_levels)\nedu2 &gt; edu1 # logical comparison\n\n[1] TRUE\n\n# modifying ordered factors\nnew_levels &lt;- c(\"primary school\", \"high school\", \"bachelor\", \"master\", \"ph.d.\")\neducation_updated &lt;- factor(education_levels, levels = new_levels, ordered = TRUE)\nstr(education_updated)\n\n Ord.factor w/ 5 levels \"primary school\"&lt;..: 2 3 4 5\n\n\n\n\nChecking Data with Ordered Factors\nYou can view the structure and summary of ordered factors just as with regular factors, but the output will indicate the order.\n\n# view the structure\nstr(education_ordered_explicit)\n\n Ord.factor w/ 4 levels \"high school\"&lt;..: 1 2 3 4\n\n# summary to see the distribution\nsummary(education_ordered_explicit)\n\nhigh school    bachelor      master       ph.d. \n          1           1           1           1 \n\n\n\n\nModifying Ordered Factors\nIf you need to change the order of levels or add new levels, you can re-factor the variable using factor() or ordered() and specify the new levels.\n\n# modifying ordered factors\nnew_levels &lt;- c(\"primary school\", \"high school\", \"bachelor\", \"master\", \"ph.d.\")\neducation_updated &lt;- factor(education_levels, levels = new_levels, ordered = TRUE)\nstr(education_updated)\n\n Ord.factor w/ 5 levels \"primary school\"&lt;..: 2 3 4 5\n\nstr(education_updated)\n\n Ord.factor w/ 5 levels \"primary school\"&lt;..: 2 3 4 5"
  },
  {
    "objectID": "content/01-content.html#strings",
    "href": "content/01-content.html#strings",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Strings",
    "text": "Strings\nStrings are sequences of characters.\n\n# sequences of characters\nyou &lt;- \"world!\"\ngreeting &lt;- paste(\"hello,\", you)\n# hello world\ngreeting\n\n[1] \"hello, world!\""
  },
  {
    "objectID": "content/01-content.html#vectors",
    "href": "content/01-content.html#vectors",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Vectors",
    "text": "Vectors\nVectors are one of R’s most fundamental data structures, essential for storing and manipulating a sequence of data elements.\nVectors are homogenous, meaning all elements in a vector must be of the same type (e.g., all numeric, all character, etc.).\nVectors in R can be created using the c() function, which stands for concatenate or combine:\n\n# numeric vector\nnumeric_vector &lt;- c(1, 2, 3, 4, 5)\n\n# character vector\ncharacter_vector &lt;- c(\"apple\", \"banana\", \"cherry\")\n\n# logical vector\nlogical_vector &lt;- c(TRUE, FALSE, TRUE, FALSE)\n\n\nManipulating Vectors\nR allows you to perform operations on vectors in a very intuitive way. Operations are vectorised, meaning they are applied element-wise:\n\n# arithmetic operations\nvector_sum &lt;- numeric_vector + 10 # Adds 10 to each element\n# show\nvector_sum\n\n[1] 11 12 13 14 15\n\n# vector mutliplication\nvector_multiplication &lt;- numeric_vector * 2 # Multiplies each element by 2\n# show\nvector_multiplication\n\n[1]  2  4  6  8 10\n\n# logical operations\nvector_greater_than_three &lt;- numeric_vector &gt; 3 # Returns a logical vector\n\n# show\nvector_greater_than_three\n\n[1] FALSE FALSE FALSE  TRUE  TRUE\n\n\nYou can access elements of a vector by using square brackets [ ] with an index or a vector of indices:\n\n#  the first element of numeric_vector\nfirst_element &lt;- numeric_vector[1]\n\n# show\nfirst_element\n\n[1] 1\n\n# multiple elements\nsome_elements &lt;- numeric_vector[c(2, 4)] # Gets the 2nd and 4th elements\n\n# show\nfirst_element\n\n[1] 1\n\n\n\n\nFunctions with vectors\nR provides a rich set of functions for statistical computations and manipulations that work with vectors:\n\n# statistical summary\nvector_mean &lt;- mean(numeric_vector)\nvector_mean\n\n[1] 3\n\nvector_sum &lt;- sum(numeric_vector)\nvector_sum\n\n[1] 15\n\n# sorting\nsorted_vector &lt;- sort(numeric_vector)\nsorted_vector\n\n[1] 1 2 3 4 5\n\n# unique values\nunique_vector &lt;- unique(character_vector)\nunique_vector\n\n[1] \"apple\"  \"banana\" \"cherry\""
  },
  {
    "objectID": "content/01-content.html#data-frames",
    "href": "content/01-content.html#data-frames",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Data Frames",
    "text": "Data Frames\n\nCreate Data Frames\nData frames can be created using the data.frame() function, specifying each column and its values. Here’s a simple example:\n\n# clear any previous `df` object\nrm(df)\ndf &lt;- data.frame(\n    name = c(\"alice\", \"bob\", \"charlie\"),\n    age = c(25, 30, 35),\n    gender = c(\"female\", \"male\", \"male\")\n)\n# check structure\nhead(df)\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\nstr(df)\n\n'data.frame':   3 obs. of  3 variables:\n $ name  : chr  \"alice\" \"bob\" \"charlie\"\n $ age   : num  25 30 35\n $ gender: chr  \"female\" \"male\" \"male\"\n\ntable(df$gender)\n\n\nfemale   male \n     1      2 \n\ntable(df$age)\n\n\n25 30 35 \n 1  1  1 \n\ntable(df$name)\n\n\n  alice     bob charlie \n      1       1       1 \n\n\nIn this example, df is a data frame with three columns (name, age, gender) and three rows, each representing a different individual.\n\n\nAccess Data Frame Elements\nThere are often several ways to do the same thing in R. You can access the elements of a data frame in several ways:\n\nBy column name: use the $ operator followed by the column name.\n\n\nnames &lt;- df$name # extracts the `name` column\nnames\n\n[1] \"alice\"   \"bob\"     \"charlie\"\n\n\n\nBy row and column: Use the [row, column] indexing. Rows or columns can be specified by number or name.\n\n\n# access data frame elements\nnames &lt;- df$name\nnames\n\n[1] \"alice\"   \"bob\"     \"charlie\"\n\nsecond_person &lt;- df[2, ]\nsecond_person\n\n  name age gender\n2  bob  30   male\n\nage_column &lt;- df[, \"age\"]\nage_column\n\n[1] 25 30 35\n\n\n\nUsing subset() Function: To extract subsets of the data frame based on conditions.\n\n\n# use subset()\nvery_old_people &lt;- subset(df, age &gt; 25) # extracts rows where `age` is greater than 18\nvery_old_people\n\n     name age gender\n2     bob  30   male\n3 charlie  35   male\n\nsummary(very_old_people$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  30.00   31.25   32.50   32.50   33.75   35.00 \n\nmean(very_old_people$age)\n\n[1] 32.5\n\nmin(very_old_people$age)\n\n[1] 30\n\n\n\n\nExplore Your Data Frames\nFunctions such as head(), tail(), and str() help you explore the first few rows, last few rows, and the structure of the data frame, respectively.\n\nhead(df) # first six rows\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\ntail(df) # last six rows\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\nstr(df) # structure of the data frame\n\n'data.frame':   3 obs. of  3 variables:\n $ name  : chr  \"alice\" \"bob\" \"charlie\"\n $ age   : num  25 30 35\n $ gender: chr  \"female\" \"male\" \"male\"\n\n\n\n\nManipulating Data Frames\nData frames can be manipulated in various ways:\n\nAdding Columns: You can add new columns using the $ operator.\n\n\n# adds a new column \"employed\"\ndf$employed &lt;- c(TRUE, TRUE, FALSE)\n\n# show\nhead(df)\n\n     name age gender employed\n1   alice  25 female     TRUE\n2     bob  30   male     TRUE\n3 charlie  35   male    FALSE\n\n\n\nAdding rows: Use the rbind() function to add new rows.\n\n\nnew_person &lt;- data.frame(name = \"diana\", age = 28, gender = \"female\", employed = TRUE)\ndf &lt;- rbind(df, new_person)\n\n# show\nhead(df)\n\n     name age gender employed\n1   alice  25 female     TRUE\n2     bob  30   male     TRUE\n3 charlie  35   male    FALSE\n4   diana  28 female     TRUE\n\n\n\nModifying values: Access the element or column and assign it a new value.\n\n\n# note brackets\n# changes diana's age to 26\ndf[4, \"age\"] &lt;- 26\n\n# view row\ndf[4, ]\n\n   name age gender employed\n4 diana  26 female     TRUE\n\n\n\nRemoving columns or rows: set columns to NULL to remove them, or use - with row or column indices.\n\n\nhead(df)\n\n     name age gender employed\n1   alice  25 female     TRUE\n2     bob  30   male     TRUE\n3 charlie  35   male    FALSE\n4   diana  26 female     TRUE\n\n# remove employed column\ndf$employed &lt;- NULL\n\n# check\ndf\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n4   diana  26 female\n\n# remove fourth row (Diana)\ndf &lt;- df[-4, ] # removes the fourth row\n\n# show\ndf\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\n\n\n\nAdd Rows with rbind()\nThe rbind() function in R stands for “row bind”. It is used to combine data frames or matrices by rows. This function is particularly useful when you want to add new observations or records to an existing data frame.\n\n#  adding a new row\nnew_person &lt;- data.frame(name = \"eve\", age = 32, gender = \"female\")\ndf &lt;- rbind(df, new_person)\n\n# verify the row addition\nhead(df)\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n4     eve  32 female\n\n\nWhen using rbind(), ensure that the columns in the data frames being combined match in both name and order. If they do not match, you may encounter errors or unexpected results.\n\n\nAdding Columns with cbind()\nConversely, the cbind() function in R stands for “column bind”. It is used to combine data frames or matrices by columns. This function allows you to add new variables to an existing data frame.\n\n# example of adding a new column\ndf$occupation &lt;- c(\"engineer\", \"doctor\", \"artist\", \"doctor\") # direct assignment\n\n# or using cbind for a separate vector\noccupation_vector &lt;- c(\"engineer\", \"doctor\", \"artist\", \"doctor\")\ndf &lt;- cbind(df, occupation_vector)\n\n# verify the column addition\nhead(df)\n\n     name age gender occupation occupation_vector\n1   alice  25 female   engineer          engineer\n2     bob  30   male     doctor            doctor\n3 charlie  35   male     artist            artist\n4     eve  32 female     doctor            doctor\n\n\nAs with rbind(), when using cbind(), it is crucial that the data frames or vectors being combined have compatible dimensions. For cbind(), the number of rows must match.\n\n\nConsiderations for rbind() and cbind()\nWhile rbind() and cbind() are straightforward and powerful functions for combining data, they have some limitations:\n\nMatching Column or Row Names: for rbind(), the column names between the data frames need to match exactly. For cbind(), the row numbers must be equal.\nFactor Levels: when binding factors with different levels, R will unify the levels, which can sometimes lead to unexpected results. Be mindful of factor levels when using these functions.\nPerformance: we will use a different approach next week (and following), draing on thedplyr package, which will connect more easily to our workflows.\n\nBy understanding and utilizing rbind() and cbind(), you can efficiently manipulate the structure of your data frames, adding flexibility to your data analysis workflows in R.\n\n\nView Data Structure (summary(), str(), head(), tail())\n\nsummary(): Provides a summary of an object’s structure.\nstr(): Displays the structure of an object.\nhead(): Shows the first few rows of a data frame or the first elements of a vector.\ntail(): Shows the last few rows of a data frame or the last elements of a vector.\n\n\n# iris is a preloaded dataset\nstr(iris) # displays structure of scores_df\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(iris) # summary statistics\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nhead(iris) # first few rows\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris) # last few rows\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica\n\n\n\n\nmean()\n\nCalculates the arithmetic mean of a numerical object.\n\n\nset.seed(12345)\n\n# we will cover R’s powerful simulation functions like `rnorm()`next week\nvector &lt;- rnorm(n = 40, mean = 0, sd = 1)\nmean(vector) # note the sampling error here\n\n[1] 0.2401853\n\n\n\n\nsd()\n\nComputes the standard deviation, which measures the amount of variation or dispersion of a set of values.\n\n\nsd(vector) # replace 'vector' with your numerical vector\n\n[1] 1.038425\n\n\n\n\nmin() and max()\n\nThese functions return a numerical object’s minimum and maximum values, respectively.\n\n\nmin(vector) # minimum value\n\n[1] -1.817956\n\nmax(vector) # maximum value\n\n[1] 2.196834\n\n\n\n\ntable()\n\nGenerates a frequency table of an object, useful for categorical data. It counts the number of occurrences of each unique element.\n\n\n#  seed for reproducibility\nset.seed(12345)\nstudent_data &lt;- data.frame(\n    name = c(\"alice\", \"bob\", \"charlie\", \"diana\", \"ethan\", \"fiona\", \"george\", \"hannah\"),\n    score = sample(80:100, 8, replace = TRUE),\n    stringsasfactors = FALSE\n)\n\n# determine pass/fail\nstudent_data$passed &lt;- ifelse(student_data$score &gt;= 90, \"passed\", \"failed\")\n# convert 'passed' to factor\nstudent_data$passed &lt;- factor(student_data$passed, levels = c(\"failed\", \"passed\"))\n\n# simulate study hours\nstudent_data$study_hours &lt;- sample(5:15, 8, replace = TRUE)\n# table for categorical data analysis\ngender &lt;- sample(c(\"male\", \"female\"), size = 100, replace = TRUE, prob = c(0.5, 0.5))\neducation_level &lt;- sample(c(\"high school\", \"bachelor\", \"master\"), size = 100, replace = TRUE, prob = c(0.4, 0.4, 0.2))\ndf_table_example &lt;- data.frame(gender, education_level)\ntable(df_table_example)\n\n        education_level\ngender   bachelor high school master\n  female       14          18     11\n  male         23          20     14\n\n\n\n\nCross-Tabulation with table()\n\ntable() can also be used for cross-tabulation, providing a way to analyse the relationship between two or more factors.\n\n\ntable(df_table_example$gender, df_table_example$education_level) # crosstab\n\n        \n         bachelor high school master\n  female       14          18     11\n  male         23          20     14\n\n\nThis produces a contingency table showing the counts at each combination of factor1 and factor2 levels.\n\n\nSummary Statistics\nUse summary() to get a summary of each column.\n\n# show\nsummary(df)\n\n     name                age           gender           occupation       \n Length:4           Min.   :25.00   Length:4           Length:4          \n Class :character   1st Qu.:28.75   Class :character   Class :character  \n Mode  :character   Median :31.00   Mode  :character   Mode  :character  \n                    Mean   :30.50                                        \n                    3rd Qu.:32.75                                        \n                    Max.   :35.00                                        \n occupation_vector \n Length:4          \n Class :character  \n Mode  :character"
  },
  {
    "objectID": "content/01-content.html#first-data-visualisation-with-ggplot2",
    "href": "content/01-content.html#first-data-visualisation-with-ggplot2",
    "title": "Asking questions in cross-cultural psychology",
    "section": "First Data Visualisation with ggplot2",
    "text": "First Data Visualisation with ggplot2\nggplot2 is a powerful and flexible R package for creating elegant data visualisations. It is based on the Grammar of Graphics, allowing users to build plots layer by layer, making it versatile for creating a wide range of plots.\n\nInstalling and Loading ggplot2\nBefore using ggplot2, ensure the package is installed and loaded into your R session:\n\n# load ggplot2\nif (!require(ggplot2)) install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# seed for reproducibility\nset.seed(12345)\n\n# simulate student data (more on simulation next week)\nstudent_data &lt;- data.frame(\n    name = c(\"alice\", \"bob\", \"charlie\", \"diana\", \"ethan\", \"fiona\", \"george\", \"hannah\"),\n    score = sample(80:100, 8, replace = TRUE), # random scores between 80 and 100\n    stringsasfactors = FALSE\n)\n\n# determine pass/fail based on score\n# we will cover the ifelse() operator in detail in upcoming weeks\nstudent_data$passed &lt;- ifelse(student_data$score &gt;= 90, \"passed\", \"failed\")\n\n# convert 'passed' to factor for colour coding in ggplot2\nstudent_data$passed &lt;- factor(student_data$passed, levels = c(\"failed\", \"passed\"))\n\n# view the first few rows of the data frame\nhead(student_data)\n\n     name score stringsasfactors passed\n1   alice    93            FALSE passed\n2     bob    98            FALSE passed\n3 charlie    95            FALSE passed\n4   diana    90            FALSE passed\n5   ethan    81            FALSE failed\n6   fiona    90            FALSE passed\n\n# simulate study hours\nstudent_data$study_hours &lt;- sample(5:15, 8, replace = TRUE)\n\n\n\nBasic Components of a ggplot2 Plot\n\nData: the dataset you want to visualise.\nAesthetics (aes): defines how data are mapped to colour, size, shape, and other visual properties.\nGeometries (geom_ functions): the type of plot or layer you want to add (e.g., points, lines, bars).\n\n\nCreate a Basic Plot\nStart by creating a simple bar plot:\n\nggplot(student_data, aes(x = name, y = score)) +\n    geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\nThis code plots score for each name in the student_data dataframe. The stat = \"identity\" argument tells ggplot2 to use the score values directly to determine the height of the bars.\n\n\nCustomising the plot\nTo enhance your plot, you can add titles, change axis labels, and modify colours:\n\nggplot(student_data, aes(x = name, y = score, fill = passed)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(values = c(\"true\" = \"blue\", \"FALSE\" = \"red\")) +\n    labs(title = \"student scores\", x = \"student name\", y = \"score\") +\n    theme_minimal()\n\n\n\n\n\n\n\n\n\naes(fill = passed): maps the passed variable to the colour fill of the bars, allowing for colour differentiation based on whether students passed or failed.\nscale_fill_manual(): customizes the colours used for the true and FALSE values of the passed variable.\nlabs(): adds a main title and axis labels.\ntheme_minimal(): applies a minimalistic theme to the plot for a cleaner appearance.\n\n\n\n\nScatter Plot with ggplot2\nA scatter plot is useful for examining the relationship between two continuous variables.\nWe next simulate a scenario where we compare student scores against study hours.\n\n# create scatter plot\nggplot(student_data, aes(x = study_hours, y = score, color = passed)) +\n    geom_point(size = 4) +\n    labs(title = \"student scores vs. study hours\", x = \"study hours\", y = \"score\") +\n    theme_minimal() +\n    scale_color_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))\n\n\n\n\n\n\n\n\n\n\nBox Plot with ggplot2\nBox plots are excellent for visualising the distribution of scores by pass/fail status, showing medians, quartiles, and potential outliers.\n\n# create box plot\nggplot(student_data, aes(x = passed, y = score, fill = passed)) +\n    geom_boxplot() +\n    labs(title = \"score distribution by pass/fail status\", x = \"status\", y = \"score\") +\n    theme_minimal() +\n    scale_fill_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))\n\n\n\n\n\n\n\n\n\n\nHistogram with ggplot2\nHistograms are helpful for understanding the distribution of a single continuous variable, such as scores.\n\n# create a histogram\nggplot(student_data, aes(x = score, fill = passed)) +\n    geom_histogram(binwidth = 5, color = \"black\", alpha = 0.7) +\n    labs(title = \"histogram of scores\", x = \"score\", y = \"count\") +\n    theme_minimal() +\n    scale_fill_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))\n\n\n\n\n\n\n\n\n\n\nLine Plot with ggplot2 (Time Series)\nFor demonstrating a line plot, we simulate monthly study hours over a semester for a student.\n\n# simulate monthly study hours\nmonths &lt;- factor(month.abb[1:8], levels = month.abb[1:8])\nstudy_hours &lt;- c(0, 3, 15, 30, 35, 120, 18, 15)\n\n# make data frame\nstudy_data &lt;- data.frame(month = months, study_hours = study_hours)\n\n# create a line plot\nggplot(study_data, aes(x = month, y = study_hours, group = 1)) +\n    geom_line(linewidth = 1, color = \"blue\") +\n    geom_point(color = \"red\", size = 1) +\n    labs(title = \"monthly study hours\", x = \"month\", y = \"study hours\") +\n    theme_minimal()"
  },
  {
    "objectID": "content/01-content.html#base-r-graphs",
    "href": "content/01-content.html#base-r-graphs",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Base R Graphs",
    "text": "Base R Graphs\nAlthough ggplot2 is renowned for its flexibility and aesthetic appeal, Base R graphics remain a staple for straightforward and quick visualisations.\nBase R provides a set of plotting functions that are readily available without the need for additional packages, and it is speedy.\n\nBasic Plotting Functions\n\nplot(): the workhorse of Base R for creating scatter plots, line graphs, and more, with extensive customisation options.\nhist(): generates histograms to explore the distribution of a single continuous variable.\nboxplot(): useful for comparing distributions across groups, showing medians, quartiles, and outliers.\nbarplot(): Creates bar graphs for visualising categorical data.\n\n\n\nCreating a Basic Scatter Plot with Base R\nConsider simple scatter plot using the data we have just simulated\n\n# basic scatter plot with Base R\nplot(student_data$study_hours, student_data$score,\n    main = \"Scatter Plot of Scores vs. Study Hours\",\n    xlab = \"Study Hours\", ylab = \"Score\",\n    pch = 19, col = ifelse(student_data$passed == \"passed\", \"blue\", \"red\")\n)\n\n\n\n\n\n\n\n\nThis plot uses the plot function to create a scatter plot, with study hours on the x-axis and scores on the y-axis. The pch parameter specifies the symbol type, and col changes the colour based on whether the student passed or failed.\n\n\nGenerating a Histogram with Base R\nTo visualise the distribution of student scores:\n\n# histogram with Base R\nhist(student_data$score,\n    breaks = 5,\n    col = \"skyblue\",\n    main = \"Histogram of Student Scores\",\n    xlab = \"Scores\",\n    border = \"white\"\n)\n\n\n\n\n\n\n\n\nThis histogram provides a quick overview of the scores’ distribution, using the hist function with specified breaks, col for colour, and border for the colour of the histogram borders.\n\n\nGenerate Line Plot with Base R\n\n# must be numeric\nmonths_num &lt;- 1:length(study_data$month) # Simple numeric sequence\n\n# plot points with suppressed x-axis\nplot(months_num, study_data$study_hours,\n    type = \"p\", # Points\n    pch = 19, # Type of point\n    col = \"red\",\n    xlab = \"Month\",\n    ylab = \"Study Hours\",\n    main = \"Monthly Study Hours\",\n    xaxt = \"n\"\n) # Suppress the x-axis\n\n# add lines between points\nlines(months_num, study_data$study_hours,\n    col = \"blue\",\n    lwd = 1\n) # Line width\n\n# add custom month labels to the x-axis at appropriate positions\naxis(1, at = months_num, labels = study_data$month, las = 2) # `las=2` makes labels perpendicular to axis\n\n# Optional: adding a box around the plot for a minimalistic look\nbox()\n\n\n\n\n\n\n\n\n\n\nComparing Distributions with Box Plots\nBox plots in Base R can compare the score distributions across the pass/fail status:\n\n# Box plot with Base R\nboxplot(score ~ passed,\n    data = student_data,\n    main = \"Score Distribution by Pass/Fail Status\",\n    xlab = \"Status\", ylab = \"Scores\",\n    col = c(\"red\", \"blue\")\n)\n\n\n\n\n\n\n\n\nThis code uses the boxplot function to create box plots for scores, grouped by the pass/fail status, with custom colours for each group."
  },
  {
    "objectID": "content/01-content.html#summary-of-todays-lab",
    "href": "content/01-content.html#summary-of-todays-lab",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Summary of Today’s Lab",
    "text": "Summary of Today’s Lab\nCongratulations on completing Lab 1!\nThis session has laid the groundwork. We have covered a lot, but we’ll have a good deal of practice throughout the course to reinforce the learning.\n\nWhat We Have Learned\n\nHow to install and setup R:\n\nYou’ve successfully installed R and RStudio, setting up your workstation for statistical analysis.\n\nHow to install and use R-Studio:\n\nYou’ve familiarised yourself with the RStudio interface, including the console, source editor, environment tab, and other utilities for effective data analysis.\n\nBasic R operations:\n\nYou’ve practided using R for basic arithmetic operations, understanding how to execute simple commands in the console.\n\nBasic R Data Structures such as:\n\nVectors and Matrices: You have learned to create and manipulate vectors and matrices, the simplest forms of data storage in R, which are crucial for handling numeric, character, and logical data types in a structured manner.\nData Frames: You’ve been introduced to data frames, a key data structure in R for storing tabular data. Data frames accommodate columns of different data types, making them highly versatile for data analysis and manipulation.\nFactors and Ordered Factors: Understanding factors and ordered factors has provided you with the tools to handle categorical data effectively, including the ability to manage and analyse data involving categorical variables with both unordered and ordered levels.\n\nBasics of ggplot2:\n\nYou’ve been equipped with the fundamentals of data visualisation using ggplot2, including how to create basic plots like bar charts, scatter plots, and line graphs. You’ve learned about the importance of aesthetics (aes) and geometries (geom_ functions) in creating visually appealing and informative graphics.\n\nCustomizing Plots:\n\nTechniques for enhancing plots with titles, axis labels, and custom colour schemes have been covered. You’ve practised making your visualisations more informative and engaging by customising plot aesthetics.\n\n\nHow to Build Skills?\n\nPractical Application:\n\nDo the hands-on exercises at home. They’ll help you apply what you have learned here.\n\n\nWhere to Get Help\nAs sure as night follows day, you will need help coding. Good resources:\n\nLarge Language Models (LLMs): LLMs are trained on extensive datasets. They are extremely good coding tutors. Open AI’s GPT-4 considerably outperforms GPT-3.5. However GPT 3.5 should be good enough. Gemini has a two-month free trial. LLM’s are rapidly evolving. However, presently, to use these tools, and to spot their errors, you will need to know how to code. Which is fortunate because coding makes you smarter!\n\nNote: you will not be assessed for R-code. Help from LLM’s for coding does not consitute a breach of academic integrity in this course. Your tests are in-class; no LLM’s allowed. For your final report, you will need to cite all sources, and how you used them, including LLMs.\n\nStack Overflow:: an outstanding resource for most problems. Great community.\nCross-validated the best place to go for stats advice. (LLM’s are only safe for standard statistics. They do not perform well for causal inference.)\nDeveloper Websites and GitHub Pages: Tidyverse\nYour tutors and course coordinator. We care. We’re here to help you!\n\n\n\nRecommended Reading\n\nWickham, H., & Grolemund, G. (2016). R for Data Science. O’Reilly Media. [Available online](https://r4ds.had.co.nz\nA helpful resource for learning R is Megan Hall’s lecture available at: https://meghan.rbind.io/talk/neair/.\nRStudio has compiled numerous accessible materials for learning R, which can be found here: https://education.rstudio.com/learn/beginner/.\nMaterials from a previous course on learning R can be accessed here. https://go-bayes.github.io/psych-447/\nJohannes Karl’s Video\n\n\n\nJohannas Karl on Getting Started In R\n\n\n\nPackages\n\nreport::cite_packages()\n\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;."
  },
  {
    "objectID": "content/01-content.html#appendix-a-at-home-exercises",
    "href": "content/01-content.html#appendix-a-at-home-exercises",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Appendix A: At Home Exercises",
    "text": "Appendix A: At Home Exercises\n\n\n\n\n\n\nExercise 1: Install the tidyverse package\n\n\n\nFollow these instructions to install the tidyverse package in RStudio:\n\nOpen RStudio: launch RStudio on your computer.\nAccess package installation:\n\nNavigate to the menu at the top of RStudio and click on Tools &gt; Install Packages.... This opens the Install Packages dialogue box.\n\nInstall tidyverse:\n\nIn the Install Packages dialogue box, you will see a field labelled “Packages (separate multiple with space or comma):”. Click in this field and type tidyverse.\nBelow the packages field, ensure the checkbox for Install dependencies is checked. This ensures all packages that tidyverse depends on are also installed.\n\nBegin installation:\n\nClick on the Install button to start the installation process.\n\n\nThe installation might take a few minutes. Monitor the progress in the “Console” pane. Once the installation is complete, you will see a message in the console indicating that the process has finished.\n\nLoad tidyverse: After successful installation, you can load the tidyverse package into your R session by typing library(tidyverse) in the console and pressing Enter.\n\n\n\n\n\n\n\n\n\nExercise 2: Install the parameters and report packages\n\n\n\nTo install the parameters and report packages in RStudio, follow these instructions:\n\nOpen RStudio: start by launching the RStudio application on your computer.\nAccess Package Installation:\n\nGo to the RStudio menu bar at the top of the screen and click on Tools &gt; Install Packages.... This action opens the Install Packages dialogue box.\n\nInstall parameters and report:\n\nIn the Install Packages dialogue box, locate the field labelled “Packages (separate multiple with space or comma):”. Click in this field and type parameters, report, separating the package names with a comma.\nMake sure the checkbox for Install dependencies is selected. This ensures that any additional packages needed by parameters and report are also installed.\nClick the Install button to initiate the installation of both packages and their dependencies.\n\n\n\n\n\n\n\n\n\n\nExercise 3: Basic Operations and Data Structure Manipulation\n\n\n\nObjective: Practice creating vectors and performing basic arithmetic operations.\n\nCreate two numeric vectors, vector_a and vector_b, with the following values:\n\nvector_a: 2, 4, 6, 8\nvector_b: 1, 3, 5, 7\n\nPerform the following operations and store the results in new variables:\n\nAdd vector_a and vector_b.\nSubtract vector_b from vector_a.\nMultiply vector_a by 2.\nDivide vector_b by 2.\n\nCalculate the mean and standard deviation of both vector_a and vector_b.\n\n\n\n\n\n\n\n\n\nExercise 4: Working with Data Frames\n\n\n\nObjective: Gain familiarity with data frame creation, manipulation, and basic data exploration functions.\n\nCreate a data frame student_data with the following columns:\n\nid: 1, 2, 3, 4\nname: alice, bob, charlie, diana\nscore: 88, 92, 85, 95\nEnsure you set stringsAsFactors = FALSE.\n\nAdd a new column passed to student_data indicating whether the student passed. Assume a pass mark of 90.\nExtract the name and score of students who passed into a new data frame.\nUse summary(), head(), and str() functions to explore student_data.\n\n\n\n\n\n\n\n\n\nExercise 5 Logical Operations and Subsetting\n\n\n\nObjective: Practice using logical operations to subset data frames.\n\nUsing the student_data data frame from Exercise 2, subset the data to find students who scored above the mean score of the class.\nCreate a vector attendance with values (present, absent, present, present) corresponding to each student’s attendance.\nAdd attendance as a new column to student_data and then subset the data frame to select only the rows where students were present.\n\n\n\n\n\n\n\n\n\nExercise 6: Cross-Tabulation and Analysis\n\n\n\nObjective: Understand the use of table() function for cross-tabulation and analysis.\n\nCreate two-factor variables:\n\nfruit: apple, banana, apple, orange, banana\ncolour: red, yellow, green, orange, green\n\nConvert fruit and colour into factors and then into a data frame named fruit_data.\nUse the table() function to perform a cross-tabulation of fruit by colour.\nInterpret the results. Which fruit has the most colour variety?\n\n\n\n\n\n\n\n\n\nExercise 7: Visualization with ggplot2\n\n\n\nObjective: (If ggplot2 was introduced) Create a simple plot to visualise the data.\n\nInstall and load the ggplot2 package if not already done.\nUsing student_data, create a bar plot showing the scores of students. Use name for the x-axis and score for the y-axis.\nEnhance the plot by adding a title, x and y-axis labels, and use different colours for passed and failed students.\n\nThese exercises are designed to be progressively challenging, ensuring that students apply what they’ve learned about basic operations, data frame manipulation, logical operations, and simple data analysis and visualisation in R."
  },
  {
    "objectID": "content/01-content.html#appendix-b-solutions",
    "href": "content/01-content.html#appendix-b-solutions",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Appendix B: Solutions",
    "text": "Appendix B: Solutions\n\nSolutions 1 and 2\n\nExercises 1 and 2 have no solutions. Installation worked or it did not! If you have trouble, please see your tutor or instructor.\n\n\n\nSolution Exercise 3: Basic Operations and Data Structure Manipulation\n\n# e.g. create vectors\nvector_a &lt;- c(2, 4, 6, 8)\nvector_b &lt;- c(1, 3, 5, 7)\n\n# operations\nsum_vector &lt;- vector_a + vector_b\ndiff_vector &lt;- vector_a - vector_b\ndouble_vector_a &lt;- vector_a * 2\nhalf_vector_b &lt;- vector_b / 2\n\n# view\nsum_vector\n\n[1]  3  7 11 15\n\ndiff_vector\n\n[1] 1 1 1 1\n\ndouble_vector_a\n\n[1]  4  8 12 16\n\nhalf_vector_b\n\n[1] 0.5 1.5 2.5 3.5\n\n# Mean and Standard Deviation\nmean_a &lt;- mean(vector_a)\nsd_a &lt;- sd(vector_a)\nmean_b &lt;- mean(vector_b)\nsd_b &lt;- sd(vector_b)\n\n# view\nmean_a\n\n[1] 5\n\nsd_a\n\n[1] 2.581989\n\nmean_b\n\n[1] 4\n\nsd_b\n\n[1] 2.581989\n\n\n\n\nSolution 4: Working with Data Frames\n\n# create data frame\nstudent_data &lt;- data.frame(\n    id = 1:4,\n    name = c(\"alice\", \"bob\", \"charlie\", \"diana\"),\n    score = c(88, 92, 85, 95),\n    stringsAsFactors = FALSE\n)\n\n# add `passed` column\nstudent_data$passed &lt;- student_data$score &gt;= 90\n\n# subset students who passed\npassed_students &lt;- student_data[student_data$passed == TRUE, ]\n\n# explore data frame\nsummary(student_data)\n\n       id           name               score         passed       \n Min.   :1.00   Length:4           Min.   :85.00   Mode :logical  \n 1st Qu.:1.75   Class :character   1st Qu.:87.25   FALSE:2        \n Median :2.50   Mode  :character   Median :90.00   TRUE :2        \n Mean   :2.50                      Mean   :90.00                  \n 3rd Qu.:3.25                      3rd Qu.:92.75                  \n Max.   :4.00                      Max.   :95.00                  \n\nhead(student_data)\n\n  id    name score passed\n1  1   alice    88  FALSE\n2  2     bob    92   TRUE\n3  3 charlie    85  FALSE\n4  4   diana    95   TRUE\n\nstr(student_data)\n\n'data.frame':   4 obs. of  4 variables:\n $ id    : int  1 2 3 4\n $ name  : chr  \"alice\" \"bob\" \"charlie\" \"diana\"\n $ score : num  88 92 85 95\n $ passed: logi  FALSE TRUE FALSE TRUE\n\n\n\n\nSolution 5: Logical Operations and Subsetting\n\n# subset data based on score\nmean_score &lt;- mean(student_data$score)\nstudents_above_mean &lt;- student_data[student_data$Score &gt; mean_score, ]\n\n# add attendance and subset\nattendance &lt;- c(\"present\", \"absent\", \"present\", \"present\")\nstudent_data$Attendance &lt;- attendance\npresent_students &lt;- student_data[student_data$Attendance == \"present\", ]\n\n\n\nSolution 6: Cross-Tabulation and Analysis\n\n# create factor variables\nfruit &lt;- factor(c(\"apple\", \"banana\", \"apple\", \"orange\", \"banana\"))\ncolour &lt;- factor(c(\"red\", \"yellow\", \"green\", \"orange\", \"green\"))\n\n# create data frame\nfruit_data &lt;- data.frame(fruit, colour)\n\n# cross-tabulation\nfruit_color_table &lt;- table(fruit_data$fruit, fruit_data$colour)\nprint(fruit_color_table)\n\n        \n         green orange red yellow\n  apple      1      0   1      0\n  banana     1      0   0      1\n  orange     0      1   0      0\n\n# interpretation: Apple has the most colour variety with 2 colours (Red, Green).\n\n\n\nSolution 7: Visualization with ggplot2\n\n# install and load ggplot2\nif (!require(ggplot2)) install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# create bar plot\nggplot(student_data, aes(x = name, y = score, fill = passed)) +\n    geom_bar(stat = \"identity\") +\n    scale_fill_manual(values = c(\"TRUE\" = \"blue\", \"FALSE\" = \"red\")) +\n    labs(title = \"Student Scores\", x = \"Name\", y = \"Score\") +\n    theme_minimal()"
  },
  {
    "objectID": "content/01-content.html#appendix-b-other-data-types-you-may-encounter",
    "href": "content/01-content.html#appendix-b-other-data-types-you-may-encounter",
    "title": "Asking questions in cross-cultural psychology",
    "section": "Appendix B: Other Data Types You May Encounter",
    "text": "Appendix B: Other Data Types You May Encounter\n\nArrays and Matrices\nArrays are multi-dimensional data structures, while matrices are two-dimensional.\n\nmatrix_1 &lt;- matrix(1:9, nrow = 3) # creates a 3x3 matrix\narray_1 &lt;- array(1:12, dim = c(2, 3, 2)) # creates a 2x3x2 array\n\n\n\nConvert Matrix to Data Frame\nA data.frame is used for storing tabular data.\n\n# change matrix to array:\ndf_matrix_1 &lt;- data.frame(matrix_1)\n\nstr(df_matrix_1)\n\n'data.frame':   3 obs. of  3 variables:\n $ X1: int  1 2 3\n $ X2: int  4 5 6\n $ X3: int  7 8 9\n\nhead(df_matrix_1)\n\n  X1 X2 X3\n1  1  4  7\n2  2  5  8\n3  3  6  9\n\n# change colnames\nnew_colnames &lt;- c(\"col_1\", \"col_2\", \"col_3\")\n\ncolnames(df_matrix_1) &lt;- new_colnames\n\n# check\nstr(df_matrix_1)\n\n'data.frame':   3 obs. of  3 variables:\n $ col_1: int  1 2 3\n $ col_2: int  4 5 6\n $ col_3: int  7 8 9\n\nhead(df_matrix_1)\n\n  col_1 col_2 col_3\n1     1     4     7\n2     2     5     8\n3     3     6     9\n\n\n\n\nWorking with Lists in R\n\nCreating lists\nTo create a list, you use the list() function.\n\n# Creating a simple list\nmy_list &lt;- list(name = \"John Doe\", age = 30, scores = c(90, 80, 70))\n\n# A list containing various types of elements, including another list\ncomplex_list &lt;- list(id = 1, name = \"Jane Doe\", preferences = list(color = \"blue\", hobby = \"reading\"))\n\n\n\nAccessing list elements\nList elements can be accessed using the [[ ]] notation for single elements, or the $ notation if you’re accessing named elements:\n\n# Accessing elements\nname &lt;- my_list$name # or my_list[[\"name\"]]\n\npreference_color &lt;- complex_list$preferences$color\n\n\n\nModifying lists\nLists can be modified by adding new elements, changing existing elements, or removing elements:\n\n# Adding a new element\nmy_list$gender &lt;- \"Male\"\n\n# Changing an existing element\nmy_list$age &lt;- 31\n\n# Removing an element\nmy_list$scores &lt;- NULL\n\n\n\nLists in Functions\nLists are often used as return values for functions that need to provide multiple pieces of data:\n\n# Function returning a list\ncalculate_stats &lt;- function(numbers) {\n    mean_val &lt;- mean(numbers)\n    sum_val &lt;- sum(numbers)\n    return(list(mean = mean_val, sum = sum_val))\n}\n\n# Using the function\nresults &lt;- calculate_stats(c(1, 2, 3, 4, 5))"
  },
  {
    "objectID": "content/03-content.html",
    "href": "content/03-content.html",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "",
    "text": "Note\n\n\n\nRequired - (Hernan and Robins 2024) Chapter 6 link\nOptional\n\n(Suzuki, Shinozaki, and Yamamoto 2020) link\n(J. A. Bulbulia 2024) link\n(Neal 2020) Chapter 3 link"
  },
  {
    "objectID": "content/03-content.html#learning-outcomes",
    "href": "content/03-content.html#learning-outcomes",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nYou will learn how to use causal diagrams to evaluate the “no unmeasured confounding” assumption of causal inference.\nYou will understand how time-series data-collection may address common confounding problems.\nYou will understand why time-series data-collection are insufficient for addressing other common confounding problems."
  },
  {
    "objectID": "content/03-content.html#confounding-problems-resolved-by-time-series-data",
    "href": "content/03-content.html#confounding-problems-resolved-by-time-series-data",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Confounding problems resolved by time-series data",
    "text": "Confounding problems resolved by time-series data\nFigure 3 presents the structural features of seven confounding problems. We shall discuss examples of each, and how longitudinal data collection resolves each problem.\n\n\n\n\n\n\nFigure 1: This figure is adapted from (J. A. Bulbulia 2024)\n\nBulbulia, J. A. 2024. “Methods in Causal Inference Part 1: Causal Diagrams and Confounding.” Evolutionary Human Sciences 6: e40. https://doi.org/10.1017/ehs.2024.35."
  },
  {
    "objectID": "content/03-content.html#confounding-problems-not-resolved-by-time-series-data-alone",
    "href": "content/03-content.html#confounding-problems-not-resolved-by-time-series-data-alone",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Confounding problems not resolved by time-series data alone",
    "text": "Confounding problems not resolved by time-series data alone\nFigure 2 presents six examples of time-series data that are not resolved by longitudinal data collection. Before seminar, consider why time series data are insufficient to address confounding in each of the six scenarios described in this figure.\n\n\n\n\n\n\nFigure 2: This figure is adapted from (J. A. Bulbulia 2024)\n\nBulbulia, J. A. 2024. “Methods in Causal Inference Part 1: Causal Diagrams and Confounding.” Evolutionary Human Sciences 6: e40. https://doi.org/10.1017/ehs.2024.35."
  },
  {
    "objectID": "content/03-content.html#worked-example-the-assumptions-in-causal-mediation",
    "href": "content/03-content.html#worked-example-the-assumptions-in-causal-mediation",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Worked Example: The Assumptions in Causal Mediation",
    "text": "Worked Example: The Assumptions in Causal Mediation\n\n\n\n\n\n\nFigure 3: This figure is adapted from (J. A. Bulbulia 2024)\n\nBulbulia, J. A. 2024. “Methods in Causal Inference Part 1: Causal Diagrams and Confounding.” Evolutionary Human Sciences 6: e40. https://doi.org/10.1017/ehs.2024.35."
  },
  {
    "objectID": "content/03-content.html#learning-outcomes-1",
    "href": "content/03-content.html#learning-outcomes-1",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy learning regression, you will be better equipped to do psychological science and to evaluate psychological research."
  },
  {
    "objectID": "content/03-content.html#what-is-regression",
    "href": "content/03-content.html#what-is-regression",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "What is Regression?",
    "text": "What is Regression?\nBroadly speaking, a regression model is a method for inferring the expected average features of a population and its variance conditional on other features of the population as measured in a sample.\nWe’ll see that regression encompasses more than this definition; however, this definition makes a start.\nTo understand regression, then, we need to understand the following jargon words: population, sample, measurement, and inference.\n\nWhat is a population?\nIn science, a population is a hypothetical construct. It is the set of all potential members of a set of things. In psychological science, that set is typically a collection of individuals. We want to understand “The population of all human beings?” or “The New Zealand adult population”; or “The population of undergraduates who may be recruited for IPRP in New Zealand.”\n\n\nWhat is a sample?\nA sample is a randomly realised sub-population from the larger abstract population that a scientific community hopes to generalise about.\nThink of selecting balls randomly from an urn. When pulled at random, the balls may inform us about the urn’s contents. For example, if we select one white ball and one black ball, we may infer that the balls in the urn are not all white or all black.\n\n\nWhat is “measurement”?\nA measure is a tool or method for obtaining numerical descriptions of a sample. We often call measures “scales.”\nA measurement is the numerical description we obtain from sensors such as statistical surveys, census data, twitter feeds, & etc.\nIn the course, we have encountered numerical scales, ordinal scales, and factors. The topic of measurement in psychology is very broad. As we shall see, the trail of the serpent of measurement runs across comparative psychological research.\nIt is essential to remember that measures can be prone to error.\nError-prone scales may nevertheless be helpful. However, we need to investigate their utility against the backdrop of specific interests and purposes.\n\n\nWhat is a parameter?\nIn regression, we combine measurements on samples with probability theory to guess about the properties of a population we will never observe. We call these properties “parameters.”\n\n\nWhat is statistical inference?\nThe bulk of statistical inference consists of educated guessing about population parameters.\n\n\nProbability distributions and statistical guessing\nInference is possible because the parameters of naturally occurring populations are structured by data-generating processes that are approximated by probability distributions. A probability distribution is a mathematical function describing a random event’s probability. Today we will be focusing on height.1\n1 The relationship of probability distributions and data-generating processes is complex, intriguing, and both historically and philosophically rich \\dots. Because our interests are applied, we will hardly touch up this richness in this course.Today we will discuss the “normal” or “Gaussian distribution.” A large number of data-generating processes in nature conform the normal distribution.\nLet’s consider some examples of randomly generated samples, which we will obtain using R’s rnorm function.\n\n\n10-person sample of heights\n\n# seed\nset.seed(123)\n\n# generate 10 samples, average 170, sd = 20\ndraws_10 &lt;- rnorm(10, mean = 170, sd = 20)\n\n# ggplot quick-histogram\nggplot2::qplot(draws_10, binwidth = 2)\n\n\n\n\n\n\n\n\n\n\n100-person sample of heights\n\n# reproducibility \nset.seed(123)\n\n# generate 100 samples, average 170, sd = 20\ndraws_100 &lt;-rnorm(100, mean = 170, sd = 20)\n\n# graph\nggplot2::qplot(\n  draws_100, binwidth = 2\n  )\n\n\n\n\n\n\n\n\n\n\n10000-person sample of heights\n\n# reproducibility\nset.seed(123)\n\n# N = 10,000\ndraws_10000 &lt;- rnorm(1e5, mean = 170, sd = 20)\n\n# plot\nggplot2::qplot(draws_10000, binwidth = 2)\n\n\n\n\n\n\n\n\n\n\nHow can I use regression to infer a population parameter?\nWe can use R to investigate the average height of our imaginary population from which the preceding samples were randomly drawn. We do this in R by writing an “intercept-only” model as follows:\n\n# syntax for an intercept-only model\nmodel &lt;- lm(outcome ~ 1, data = data)\n\n# base R summary\nsummary(model)\n\nUsing the previous simulations:\nN = 10 random draws\n\n#|code-fold: false\n\n#write the model and get a nice table for it\nsjPlot::tab_model(lm(draws_10 ~ 1))\n\n\n\n\n \nDependent variable\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n171.49\n157.85 – 185.14\n&lt;0.001\n\n\nObservations\n10\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n\n\n\n\n\n\n\nN = 100 random draws\n\nsjPlot::tab_model(lm(draws_100 ~ 1))\n\n\n\n\n \nDependent variable\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n171.81\n168.19 – 175.43\n&lt;0.001\n\n\nObservations\n100\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n\n\n\n\n\n\n\nN = 10,000 random draws\n\nsjPlot::tab_model(lm(draws_10000 ~ 1))\n\n\n\n\n \nDependent variable\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n170.02\n169.90 – 170.14\n&lt;0.001\n\n\nObservations\n100000\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n\n\n\n\n\n\n\nWhat do we notice about the relationship between sample size the estimated population average?\n\nsjPlot::tab_model(lm(draws_10 ~ 1),\n                  lm(draws_100 ~ 1),\n                  lm(draws_10000 ~ 1))\n\n\n\n\n \nDependent variable\nDependent variable\nDependent variable\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n171.49\n157.85 – 185.14\n&lt;0.001\n171.81\n168.19 – 175.43\n&lt;0.001\n170.02\n169.90 – 170.14\n&lt;0.001\n\n\nObservations\n10\n100\n100000\n\n\nR2 / R2 adjusted\n0.000 / 0.000\n0.000 / 0.000\n0.000 / 0.000\n\n\n\n\n\n\n\n\n\nRegression with a single co-variate\nDo mothers’s heights predict daughter height? If so, what is the magnitude of the relationship?\nFrancis Galton is credited with inventing regression analysis. Galton observed that offspring’s heights tend to fall between parental height and the population average, which Galton termed “regression to the mean.” Galton sought a method for educated guessing about heights, and this led to fitting a line of regression by a method called “least squares” (For a history, see: here).\nThe following dataset is from “The heredity of height” by Karl Pearson and Alice Lee (1903)(Pearson and Lee 1903). I obtained it from (Gelman, Hill, and Vehtari 2020). Let’s use this dataset to investigate the relationship between mothers’ and daughters’ heights.\n\nPearson, Karl, and Alice Lee. 1903. “On the Laws of Inheritance in Man: I. Inheritance of Physical Characters.” Biometrika 2 (4): 357–462.\n\n# import data\ndf_pearson_lee &lt;-\n  data.frame(read.table(\n    url(\n      \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/PearsonLee/data/MotherDaughterHeights.txt\"\n    ),\n    header = TRUE\n  ))\n\n# save\n# saveRDS(df_pearson_lee, here::here(\"data\", \"df_pearson_lee\"))\n\n# Center mother's height for later example\ndf_pearson_lee_centered &lt;- df_pearson_lee |&gt;\n  dplyr::mutate(mother_height_c = as.numeric(scale(\n    mother_height, center = TRUE, scale = FALSE\n  )))\n\nskimr::skim(df_pearson_lee_centered)\n\n\n\n\n\nName\ndf_pearson_lee_centered\n\n\nNumber of rows\n5524\n\n\nNumber of columns\n3\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n3\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nData summaryVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndaughter_height\n0\n1\n63.86\n2.62\n52.5\n62.5\n63.5\n65.5\n73.5\n▁▂▇▅▁\n\n\nmother_height\n0\n1\n62.50\n2.41\n52.5\n60.5\n62.5\n64.5\n70.5\n▁▂▇▇▁\n\n\nmother_height_c\n0\n1\n0.00\n2.41\n-10.0\n-2.0\n0.0\n2.0\n8.0\n▁▂▇▇▁\n\n\n\n\n\nPearson and Lee collected 5,524 observations from mother/daughter height pairs. Let’s examine the data, first by plotting the relationship.\nWhat is happening here?\n\n# explore pearson lee data\nexplore_md &lt;-\n  ggplot2::ggplot(data = df_pearson_lee_centered, aes(y = daughter_height, x = mother_height)) +\n  geom_jitter(alpha = .2) +\n  labs(title = \"The relationship between mothers height and daughter's height\") +\n  ylab(\"Daughter's height\") +\n  xlab(\"Mother's height\") + theme_classic()\n\n# print\nprint( explore_md )\n\n\n\n\n\n\n\n\nIs there a linear predictive relationship between these two parameters? In regression we examine the line of best fit.\n\n# regression \nm1 &lt;-\n  lm(daughter_height ~ mother_height, data = df_pearson_lee_centered)\n\n# graph\nsjPlot::tab_model(m1)\n\n\n\n\n \ndaughter height\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n29.80\n28.25 – 31.35\n&lt;0.001\n\n\nmother height\n0.54\n0.52 – 0.57\n&lt;0.001\n\n\nObservations\n5524\n\n\nR2 / R2 adjusted\n0.252 / 0.252\n\n\n\n\n\n\n\nWe can plot the coefficient, but in a model with one predictor, this isn’t very informative. However, as we continue in the course, we’ll see that plotting coefficients can be easier than deciphering the numbers in tables. Here are two methods for plotting.\n\n# get model parameters\nt_m1&lt;-parameters::model_parameters(m1,  \n                                   ci = 0.95)\n# plot \nplot(t_m1) +\n  labs(title = \"The relationship between mothers height and daughter's height\") + \n  ylab(\"Daughter's height\")"
  },
  {
    "objectID": "content/03-content.html#how-do-we-interpret-the-regression-model",
    "href": "content/03-content.html#how-do-we-interpret-the-regression-model",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "How do we interpret the regression model?",
    "text": "How do we interpret the regression model?\nLet’s write the equation out in mathematics. How do we read this? [^2] [^2]: Later, we’ll prefer a different way of writing regression equations in math. (Note: writing math isn’t math - it’s just encoding the model that we’ve written).\n\nlibrary(\"equatiomatic\")\n# extract equation\n#extract_eq(m1, use_coefs = FALSE)\n\n\n\\operatorname{daughter\\_height} = \\alpha + \\beta_{1}(\\operatorname{mother\\_height}) + \\epsilon\n\nThe math says that the expected daughter’s height in a population is predicted by the average height of the population when mothers’ heights are set to zero units (note, this is impossible - we’ll come back to this) plus \\beta ~\\times units of daughter’s height (inches) for each additional unit of mother’s height (inches)\nWe can plug the output of the model directly into the equation as follows:\n\n# extract equation\n#extract_eq(m1, use_coefs = TRUE)\n\n\n\\operatorname{\\widehat{daughter\\_height}} = 29.8 + 0.54(\\operatorname{mother\\_height})\n\n\nGraph the relationship between mother’s and daughter’s heights\n\nlibrary(ggeffects)\npredictions &lt;- ggeffects::ggpredict(m1, terms = \"mother_height\",    \n    add.data = TRUE,\n    dot.alpha = .1,\n    jitter = TRUE)\n\n\nplot_predictions &lt;-\n  plot(predictions) +   theme_classic() + labs(title = \"Predicted values of daughter's height from the Pearson/Fox 1903 dataset\")\nplot_predictions\n\n\n\n\n\n\n\n\n\n\nRegression to predict beyond the range of a dataset\nJoyte Amge is the world’s shortest woman at 25 inches. Sandy Allen was the world’s tallest woman at 91 inches. What are the expected heights of their daughter and of every intermediary woman in between?\n\n# use the `expand.grid` command to create a sequence of points for mother's height\ndf_expand_grid &lt;- expand.grid(mother_height = c(25:91))\n\n# use the `predict` function to create a new response\ndf_predict &lt;-\n  predict(m1,\n          type = \"response\",\n          interval = \"confidence\",\n          newdata = df_expand_grid)\n\n# have a look at the object\n#dplyr::glimpse(df_predict)\n\n# create a new dataframe for the new sequence of points for mother's height and the predicted data\nnewdata &lt;- data.frame(df_expand_grid, df_predict)\nhead(newdata)\n\n  mother_height      fit      lwr      upr\n1            25 43.42183 42.49099 44.35266\n2            26 43.96676 43.06065 44.87288\n3            27 44.51170 43.63030 45.39310\n4            28 45.05664 44.19995 45.91332\n5            29 45.60157 44.76960 46.43355\n6            30 46.14651 45.33924 46.95378\n\n\nGraph the predicted results\n\n# graph the expected results\npredplot &lt;- ggplot(data = newdata,\n                   aes(x = mother_height, y = fit))  +\n  geom_point() +  geom_errorbar(aes(ymin = lwr, ymax = upr), width = .1) +\n  expand_limits(x = c(20, 91), y = c(0, 81))  + theme_classic() +\n  labs(title = \"Predicted values for a broader population\")\n\n# plot the two graphs together (making the x and y axis at the same scale \nlibrary(\"patchwork\")\n# rescale heightplot\n\n# old plot with the new axis and y-axis scales, and remove points\n\nplot_height &lt;- plot(predplot, add.data = FALSE) +   theme_classic()\n\n\n\n\n\n\n\nplot_height_title &lt;-\n  plot_height +  expand_limits(x = c(20, 91), y = c(0, 81)) +  labs(title = \"Predicted values of daughter's height from the Pearson/Fox 1903 dataset\")\n\n# double graph\nplot_height_title / predplot  + plot_annotation(title = \"What do you notice about these relationships?\", tag_levels = \"a\")\n\n\n\n\n\n\n\n\nA simple method for obtaining the predicted values from your fitted model is to obtain the effects output without producing a graph.\n\n# prediction plots\nlibrary(ggeffects)\n# predicted values of mother height on daughter height\nggeffects::ggpredict(m1, terms = \"mother_height\")\n\n# Predicted values of daughter_height\n\nmother_height | Predicted |       95% CI\n----------------------------------------\n        52.50 |     58.41 | 58.15, 58.66\n        54.50 |     59.50 | 59.29, 59.70\n        57.50 |     61.13 | 60.99, 61.27\n        59.50 |     62.22 | 62.13, 62.32\n        61.50 |     63.31 | 63.25, 63.38\n        63.50 |     64.40 | 64.34, 64.47\n        65.50 |     65.49 | 65.40, 65.59\n        70.50 |     68.22 | 68.01, 68.42\n\n\n\n\nNon-linear relationships\nLinear regression assumes linearity conditional on a model. Often your data will not be linear!\nConsider the following example:\n\n# simulate nonlinear relationship between x and y\nb &lt;- c(2, 0.75)\nset.seed(12)\nx &lt;- rnorm(100)\nset.seed(12)\ny &lt;- rnorm(100, mean = b[1] * exp(b[2] * x))\ndat1 &lt;- data.frame(x, y)\n\not1 &lt;- lm(y ~ x, data  = dat1)\n# performance::check_model(ot1)\n\n# plot linear effect\nplot(ggeffects::ggpredict(ot1, terms = \"x\",\n     add.data = TRUE,\n     dot.alpha = .4))\n\n\n\n\n\n\n\n\nNon-linear relationship as modelled by a polynomial regression:\n\n# model: quadratic\nfit_non_linear &lt;- lm(y ~ x + I(x ^ 2), data  = dat1)\n\n# predictive plot\nplot(ggeffects::ggpredict(fit_non_linear, terms = \"x\",\n     add.data = TRUE,\n     dot.alpha = .4))\n\n\n\n\n\n\n\n\nHere is another approach:\n\n# non-linear regression \nlibrary(splines)\n\n# fit model \nfit_non_linear_b &lt;- lm(y ~ x + poly(x, 2), data  = dat1)\n\n# graph model\nplot(\n  ggeffects::ggpredict(fit_non_linear_b, terms = \"x\",\n  add.data = TRUE,\n  dot.alpha = .4\n))\n\n\n\n\n\n\n\n\nNon-linear relationship as modelled by a general additive model (spline)\n\n# fit spline: not specified\nfit_non_linear_c &lt;-lm(y ~ bs(x), data  = dat1)\n\n# model parameters: coefficients are not interpretable\nparameters::model_parameters(\n  fit_non_linear_c\n)\n\nParameter      | Coefficient |   SE |         95% CI |  t(96) |      p\n----------------------------------------------------------------------\n(Intercept)    |       -1.90 | 0.03 | [-1.95, -1.84] | -70.74 | &lt; .001\nx [1st degree] |        2.60 | 0.06 | [ 2.48,  2.72] |  43.47 | &lt; .001\nx [2nd degree] |        3.00 | 0.03 | [ 2.94,  3.06] |  96.12 | &lt; .001\nx [3rd degree] |       13.33 | 0.04 | [13.26, 13.40] | 368.37 | &lt; .001\n\n#performance::check_model(ot2)\nplot(\n  ggeffects::ggpredict(fit_non_linear_c, terms = \"x\",\n  add.data = TRUE,\n  dot.alpha = .4\n))\n\n\n\n\n\n\n\n\n\n\nCentering\nAny linear transformation of a predictor is OK. Often we centre (or centre and scale) all indicators, which gives us an interpretable intercept (the expected population average when the other indicators are set their average).\n\nlibrary(ggeffects)\n\n# fit raw data \nfit_raw &lt;- lm(daughter_height ~ mother_height, data = df_pearson_lee_centered)\n\n# fit centred data\nfit_centered &lt;-\n  lm(daughter_height ~ mother_height_c, data = df_pearson_lee_centered)\n\n# compare the models\nsjPlot::tab_model(fit_raw, fit_centered)\n\n\n\n\n \ndaughter height\ndaughter height\n\n\nPredictors\nEstimates\nCI\np\nEstimates\nCI\np\n\n\n(Intercept)\n29.80\n28.25 – 31.35\n&lt;0.001\n63.86\n63.80 – 63.92\n&lt;0.001\n\n\nmother height\n0.54\n0.52 – 0.57\n&lt;0.001\n\n\n\n\n\nmother height c\n\n\n\n0.54\n0.52 – 0.57\n&lt;0.001\n\n\nObservations\n5524\n5524\n\n\nR2 / R2 adjusted\n0.252 / 0.252\n0.252 / 0.252\n\n\n\n\n\n\n\nGraph model\n\n# graph centred model\nplot(\n  ggeffects::ggpredict(fit_centered, terms = \"mother_height_c\",\n  add.data = TRUE,\n  dot.alpha = .4\n))\n\n\n\n\n\n\n\n\nNote: when fitting a polynomial or any interaction, it is important to center your indicators. We’ll come back to this point in later lectures.\n\n\nModel evaluation\nReviewers will sometime ask you to assess model fit.\nA simple, but flawed way to assess accuracy of your model fit is to compare a model with one covariate with a simple intercept-only model and to assess improvement in either the AIC statistic or the BIC statistic. The BIC is similar to the AIC but adds a penalty for extra predictors. An absolute improvement in either statistic of n &gt; 10 is considered to be a “better” model.\nWe can use the performance package to generate a table that compares model fits.\n\n# load library \nlibrary(performance)\n# intercept only\nfig_intercept_only &lt;- lm(daughter_height ~ 1, data = df_pearson_lee)\n\n# covariate added\nfig_covariate &lt;- lm(daughter_height ~ mother_height, data = df_pearson_lee)\n\n# evaluate\nperformance::compare_performance(fig_intercept_only, fig_covariate)\n\n# Comparison of Model Performance Indices\n\nName               | Model |   AIC (weights) |  AICc (weights)\n--------------------------------------------------------------\nfig_intercept_only |    lm | 26300.0 (&lt;.001) | 26300.0 (&lt;.001)\nfig_covariate      |    lm | 24698.5 (&gt;.999) | 24698.5 (&gt;.999)\n\nName               |   BIC (weights) |    R2 | R2 (adj.) |  RMSE | Sigma\n------------------------------------------------------------------------\nfig_intercept_only | 26313.2 (&lt;.001) | 0.000 |     0.000 | 2.615 | 2.615\nfig_covariate      | 24718.4 (&gt;.999) | 0.252 |     0.252 | 2.262 | 2.262\n\n\nWhat was the model “improvement?”\n\n# improved fit\nBIC(fig_intercept_only) - BIC(fig_covariate)\n\n[1] 1594.839\n\n\n\n\nGenerate a report\nThis is easy with the report package\nFor example:\n\nreport::report_statistics(fig_covariate)\n\nbeta = 29.80, 95% CI [28.25, 31.35], t(5522) = 37.70, p &lt; .001; Std. beta = 7.21e-15, 95% CI [-0.02, 0.02]\nbeta = 0.54, 95% CI [0.52, 0.57], t(5522) = 43.12, p &lt; .001; Std. beta = 0.50, 95% CI [0.48, 0.52]\n\n\nOr, if you want a longer report:\n\nreport::report(fig_covariate)\n\nUse statistically significant in place of significant. This will avoid misleading your audience into thinking your result is important when what you intend to communicate is that it is reliable."
  },
  {
    "objectID": "content/03-content.html#assumptions-of-regression",
    "href": "content/03-content.html#assumptions-of-regression",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Assumptions of Regression",
    "text": "Assumptions of Regression\nFrom Gelman and Hill (Gelman and Hill 2006)\n\nValidity\n\nThe most important is that the data you are analyzing should map to the research question you are trying to answer (Gelman, Hill, and Vehtari 2020, 152)\n\nRepresentativeness\n\nA regression model is fit to data and is used to make inferences about a larger population, hence the implicit assumption in interpreting regression coefficients is that the sample is representative of the population. (Gelman, Hill, and Vehtari 2020, 153)\n\n\nLinearity\n\nThe most important mathematical assumption of the linear regression model is that its deterministic component is a linear function of the separate predictors: y = β0 + β1x1 + β2x2 +···. If additivity is violated, it might make sense to transform the data (for example, if y = abc, then log y = log a + log b + log c) or to add interactions. If linearity is violated, perhaps a predictor should be put in as 1/x or log(x) instead of simply linearly. Or a more complicated relationship could be expressed using a nonlinear function such as a spline or Gaussian process, (Gelman, Hill, and Vehtari 2020, 153)\n\nIndependence of errors\n\nThe simple regression model assumes that the errors from the prediction line are independent, an assumption that is violated in time series, spatial, and multilevel settings (Gelman, Hill, and Vehtari 2020, 153)\n\nEqual variance of errors\n\n\n…unequal variance does not affect the most important aspect of a regression model, which is the form of the predictors (Gelman, Hill, and Vehtari 2020, 153)\n\n\nNormality of errors (statistical independence)\n\n\nThe regression assumption that is generally least important is that the errors are normally distributed. In fact, for the purpose of estimating the regression line (as compared to predicting individual data points), the assumption of normality is barely important at all. Thus, in contrast to many regression textbooks, we do not recommend diagnostics of the normality of re-gression residuals. (Gelman and Hill 2006, 46)\n\n\nA good way to diagnose violations of some of the assumptions just considered (importantly, linearity) is to plot the residuals versus fitted values or simply individual predictors.(Gelman and Hill 2006, 46)\n\nGelman, Andrew, and Jennifer Hill. 2006. Data Analysis Using Regression and Multilevel/Hierarchical Models. Cambridge university press.\n\n\nCommon Confusions\n\nRegressions do not automatically give us “effects”\nPeople use the work “effect”, but that is not what regression gives us, by default.\n\n\n“Normality Assumption”\nGelman and Hill note that the “normality” assumption is the least important. The assumption pertains to the normality of residuals.\n\n\nStatistical Independence\nThis is the motivation for doing multi-level modelling: to condition on dependencies in the data. However, multi-level modelling can produce new problems if the error terms in the model are not independent of the outcome.\n\n\nExternal Validity (wrong population)\nWe sample from undergraduates, but infer about the human population.\n\n\n\n\n\n\nImportant\n\n\n\nNOTE: The concept of “better model fit” is relative to our interests and purposes. A better (lower) AIC statistic does not tell us whether a model is better for better causal inference. We must assess whether a model satisfies the assumptions necessary for valid causal inference."
  },
  {
    "objectID": "content/03-content.html#simulation-demonstration-1-how-regression-coefficients-mislead",
    "href": "content/03-content.html#simulation-demonstration-1-how-regression-coefficients-mislead",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Simulation Demonstration 1: How Regression Coefficients Mislead",
    "text": "Simulation Demonstration 1: How Regression Coefficients Mislead\n\nMethodology\n\nData Generation: we simulate a dataset for 1,000 individuals, where religious service attendance (A) affects wealth (L), which in turn affects charitable donations (Y). The simulation is based on predefined parameters that establish L as a mediator between A and Y.\nParameter Definitions:\n\nThe probability of religious service (A) is set at 0.5.\nThe effect of A on L (wealth) is given by \\beta = 2.\nThe effect of L on Y (charity) is given by \\delta = 1.5.\nStandard deviations for L and Y are set at 1 and 1.5, respectively.\n\nModel Specifications:\n\nModel 1 (Correct Assumption): considerss a linear regression model assuming L as a mediator, including A and L as regressors on Y. This model aligns with the data-generating process and correctly identifies L as a mediator. According to the rules of d-separation (last week): to identify the total effect of A on Y we must not include L\nModel 2 (Correct model): This fits a linear regression model that includes only A as a regressor on Y and omits the mediator L. This model assesses the direct effect of A on Y without accounting for mediation.\n\nAnalysis and Comparison: the analysis compares the estimated effects of A on Y under both model specifications. By including L as a predictor in Model 1, we induce mediation bias. Whereas Model 2 correctly excludes L from the model.\nPresentation: the results are displayed in a comparative table formatted for publication. The table contrasts the regression coefficients and significance levels obtained under each model.\n\n\n# simulation seed\nset.seed(123) #  reproducibility\n\n# define the parameters \nn = 1000 # Number of observations\np = 0.5  # Probability of A = 1 \nalpha = 0 # Intercept for L \nbeta = 2  # Effect of A on L \ngamma = 1 # Intercept for Y \ndelta = 1.5 # Effect of L on Y\nsigma_L = 1 # Standard deviation of L\nsigma_Y = 1.5 # Standard deviation of Y\n\n# simulate the data: fully mediated effect by L\nA = rbinom(n, 1, p) # binary exposure variable\nL = alpha + beta*A + rnorm(n, 0, sigma_L) # mediator L affect by A\nY = gamma + delta*L + rnorm(n, 0, sigma_Y) # Y affected only by L,\n\n# make the data frame\ndata = data.frame(A = A, L = L, Y = Y)\n\n# fit regression in which L is assumed to be a mediator\n# (cross-sectional data is consistent with this model)\nexample_fit_1 &lt;- lm( Y ~ A + L, data = data)\n\n# fit regression in which L is assumed to be a mediator\n# (cross-sectional data is also consistent with this model)\nexample_fit_2 &lt;- lm( Y ~ A, data = data)\n\n# create gtsummary tables for each regression model\ntable1 &lt;- gtsummary::tbl_regression(example_fit_1)\ntable2 &lt;- gtsummary::tbl_regression(example_fit_2)\n\n# merge the tables for comparison\ntable_comparison &lt;- gtsummary::tbl_merge(\n  list(table1, table2),\n  tab_spanner = c(\"Model: Wealth assumed confounder\", \n                  \"Model: Wealth assumed to be a mediator\")\n)\n# make latex table (for publication)\nmarkdown_table_0 &lt;- as_kable_extra(table_comparison, \n                                   format = \"markdown\", \n                                   booktabs = TRUE)\n# print markdown table (note, you might prefer \"latex\" or another format)                                \nmarkdown_table_0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModel: Wealth assumed confounder\n\n\nModel: Wealth assumed to be a mediator\n\n\n\nCharacteristic\nBeta\n95% CI\np-value\nBeta\n95% CI\np-value\n\n\n\n\nA\n-0.27\n-0.53, -0.01\n0.043\n2.9\n2.6, 3.2\n&lt;0.001\n\n\nL\n1.6\n1.5, 1.7\n&lt;0.001\n\n\n\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\n\n\n\n\nCode for a simulation of a data generating process in which the effect of exercise (L) fully mediates the effect of greenspace (A) on happiness (Y).\n\n\n\nCompare model fits\n\nBy all metrics, model 1 fits better but it is confounded\n\nperformance::compare_performance(example_fit_1, example_fit_2)\n\n# Comparison of Model Performance Indices\n\nName          | Model |  AIC (weights) | AICc (weights) |  BIC (weights)\n------------------------------------------------------------------------\nexample_fit_1 |    lm | 3620.6 (&gt;.999) | 3620.6 (&gt;.999) | 3640.2 (&gt;.999)\nexample_fit_2 |    lm | 4392.2 (&lt;.001) | 4392.2 (&lt;.001) | 4406.9 (&lt;.001)\n\nName          |    R2 | R2 (adj.) |  RMSE | Sigma\n-------------------------------------------------\nexample_fit_1 | 0.682 |     0.682 | 1.473 | 1.475\nexample_fit_2 | 0.312 |     0.311 | 2.169 | 2.171\n\n\nModel 1 exhibits mediator bias, but it has a considerably higher R^2, and a lower BIC\n\nFocussing on the BIC (lower is better) Model 1 fits better, but it is confounded.\n\nBIC(example_fit_1) - BIC(example_fit_2)\n\n[1] -766.643\n\n\n\n\n\n\n\n\nImportant\n\n\n\nIn this simulation, we discovered that if we assess “effect” by “model fit” we will get the wrong sign for the coefficient of interest. The use of model fit perpetuates the causality crisis in psychological science (Joseph A. Bulbulia 2023). Few are presently aware of this crisis. Causal diagrams show us how we can do better."
  },
  {
    "objectID": "content/03-content.html#simulation-demonstration-2-how-regression-coefficients-mislead",
    "href": "content/03-content.html#simulation-demonstration-2-how-regression-coefficients-mislead",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Simulation Demonstration 2: How Regression Coefficients Mislead",
    "text": "Simulation Demonstration 2: How Regression Coefficients Mislead\n\nMethodology\n\nData Generation: simulate a dataset for 1,000 individuals, where religious service attendance (A) affects wealth (L),and chartitable donations charitable donations (Y) also affects wealth L, but A and Y are not causally related\nParameter Definitions:\n\nThe probability of religious service (A) is set at 0.5.\nY is has a mean 0 and sd = 1, and is independent of A.\nL is a linear function of A and Y.\n\nModel Specifications:\n\nModel 1 (Correct Assumption): do not control for L\nModel 2 (Correct model): control for L\n\nAnalysis and Comparison: compare models.\nPresentation: a table.\n\n\n# simulation seed\nset.seed(123) #  reproducibility\n\n# define parameters \nn = 1000 # Number of observations\np = 0.5  # Probability of A = 1 \nalpha = 0 # Intercept for L\n\n\n# simulate the data\nA_1 = rbinom(n, 1, p) # binary exposure variable\nY_1 = rnorm(n, 0, 1) # Y affected only by L,\nL_2 = rnorm(n, A_1 + Y_1)\n\n# make the data frame\ndata_collider = data.frame(A = A_1, L = L_2, Y = Y_1)\n\n# fit regression in which L is assumed to be a mediator\n# (cross-sectional data is consistent with this model)\ncollider_example_fit_1 &lt;- lm( Y ~ A + L, data = data_collider)\n\n# fit regression in which L is assumed to be a mediator\n# (cross-sectional data is also consistent with this model)\ncollider_example_fit_2 &lt;- lm( Y ~ A, data = data_collider)\nsummary(collider_example_fit_1)\n\n\nCall:\nlm(formula = Y ~ A + L, data = data_collider)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.16111 -0.46220 -0.00342  0.45893  1.98913 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.008157   0.030247   -0.27    0.787    \nA           -0.476938   0.045314  -10.53   &lt;2e-16 ***\nL            0.508127   0.014894   34.12   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.681 on 997 degrees of freedom\nMultiple R-squared:  0.5386,    Adjusted R-squared:  0.5377 \nF-statistic:   582 on 2 and 997 DF,  p-value: &lt; 2.2e-16\n\n# create gtsummary tables for each regression model\ncollider_table1 &lt;- gtsummary::tbl_regression(collider_example_fit_1)\ncollider_table2 &lt;- gtsummary::tbl_regression(collider_example_fit_2)\n\n# merge the tables for comparison\ncollider_table_comparison &lt;- gtsummary::tbl_merge(\n  list(collider_table1, collider_table2),\n  tab_spanner = c(\"Model: Wealth assumed confounder\", \n                  \"Model: Wealth not assumed to be a mediator\")\n)\n# make latex table (for publication)\nmarkdown_table_1 &lt;- as_kable_extra(collider_table_comparison, \n                                   format = \"markdown\", \n                                   booktabs = TRUE)\n# print markdown table (note, you might prefer \"latex\" or another format)                                \ncollider_table_comparison\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCharacteristic\n\nModel: Wealth assumed confounder\n\n\nModel: Wealth not assumed to be a mediator\n\n\n\nBeta\n95% CI1\np-value\nBeta\n95% CI1\np-value\n\n\n\n\nA\n-0.48\n-0.57, -0.39\n&lt;0.001\n0.00\n-0.12, 0.13\n&gt;0.9\n\n\nL\n0.51\n0.48, 0.54\n&lt;0.001\n\n\n\n\n\n\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\nL is a collider of A and Y.\n\n\n\n\nCompare model fits\n\nBy all metrics, model 1 fits better but it is confounded.\nA is not causally associated with Y. We generated the data so we know. However, the confounded model shows a better fit, and in this model the coefficient for A is significant (and negative).\n\nperformance::compare_performance(collider_example_fit_1, collider_example_fit_2)\n\n# Comparison of Model Performance Indices\n\nName                   | Model |  AIC (weights) | AICc (weights)\n----------------------------------------------------------------\ncollider_example_fit_1 |    lm | 2074.4 (&gt;.999) | 2074.4 (&gt;.999)\ncollider_example_fit_2 |    lm | 2845.9 (&lt;.001) | 2845.9 (&lt;.001)\n\nName                   |  BIC (weights) |        R2 |  R2 (adj.) |  RMSE | Sigma\n--------------------------------------------------------------------------------\ncollider_example_fit_1 | 2094.0 (&gt;.999) |     0.539 |      0.538 | 0.680 | 0.681\ncollider_example_fit_2 | 2860.6 (&lt;.001) | 2.784e-06 | -9.992e-04 | 1.001 | 1.002\n\n\n\nAgain, the BIC for (lower is better) Model 1 fits better, but it is entirely confounded.\n\nBIC(collider_example_fit_1) - BIC(collider_example_fit_2)\n\n[1] -766.643\n\n\nHow does collider bias work? If we know that someone is not attending church, if they are charitable then we can predict they are wealthy. Similarly if we know someone is not wealthy but charitable, we can predict they attend religious service.\nHowever, in this simulation, we know the religion and wealth are not casually associated because we have simulated the data.\n\n\n\n\n\n\nImportant\n\n\n\nIn this simulation, we discovered that if we assess “effect” by “model fit”, we get the **wrong scientific inference. The use of model fit perpetuates the causality crisis* in psychological science (Joseph A. Bulbulia 2023). Let’s do better.\n\n\n\nBulbulia, Joseph A. 2023. “A Workflow for Causal Inference in Cross-Cultural Psychology.” Religion, Brain & Behavior 13 (3): 291–306. https://doi.org/10.1080/2153599X.2022.2070245."
  },
  {
    "objectID": "content/03-content.html#resources-on-regression-that-do-not-perpetuate-the-causality-crisis",
    "href": "content/03-content.html#resources-on-regression-that-do-not-perpetuate-the-causality-crisis",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Resources on Regression that Do Not Perpetuate The Causality Crisis",
    "text": "Resources on Regression that Do Not Perpetuate The Causality Crisis\n\nStatistical Rethinking (McElreath 2020)\nRegression and Other Stories (Gelman, Hill, and Vehtari 2020)\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. CRC press.\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Cambridge University Press."
  },
  {
    "objectID": "content/03-content.html#setup",
    "href": "content/03-content.html#setup",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Setup",
    "text": "Setup\n\nLibraries\n\nlibrary(tidyverse)\nlibrary(patchwork)\nlibrary(lubridate)\nlibrary(kableExtra)\nlibrary(gtsummary)\n\n\n\nGet data\n\n# package with data\nlibrary(margot)\n\n# load data\ndata(\"df_nz\")\n\n\n\nImport Pearson and Lee mother’s and daughters data\n\ndf_pearson_lee &lt;-\n  data.frame(read.table(\n    url(\n      \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/PearsonLee/data/MotherDaughterHeights.txt\"\n    ),\n    header = TRUE\n  ))\n# Center mother's height for later example\ndf_pearson_lee &lt;- df_pearson_lee|&gt;\n  dplyr::mutate(mother_height_c = as.numeric(scale(\n    mother_height, center = TRUE, scale = FALSE\n  )))\n\n# dplyr::glimpse(df_pearson_lee)\n\n# In 1903, Pearson and Lee collected 5,524 observations from mother/daughter height pairs. See lecture 5 for details\n\n\n\nNote\nFor all exercises below, use only the 2018 wave of the df_nz dataset.\ncolnames(df_nz) ## Q1. Create a descriptive table and a descriptive graph for the hlth_weight and hlth_height variables in the df_nz dataset\nSelect hlth_height, hlth_weight from the nz dataset.\nFilter only the 2018 wave.\nCreate a descriptive table and graph these two variables\nAnnotate your workflow (at each step, describe what you are doing and why)."
  },
  {
    "objectID": "content/03-content.html#q2.-regression-height-weight-and-report-results",
    "href": "content/03-content.html#q2.-regression-height-weight-and-report-results",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Q2. Regression height ~ weight and report results",
    "text": "Q2. Regression height ~ weight and report results\nUsing the df_nz dataset, write a regression model for height as predicted by weight.\nCreate a table for your results.\nCreate a graphs/graphs to clarify the results of your regression model.\nBriefly report your results."
  },
  {
    "objectID": "content/03-content.html#q3.-regress-height-male-and-report-results",
    "href": "content/03-content.html#q3.-regress-height-male-and-report-results",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Q3. Regress height ~ male and report results",
    "text": "Q3. Regress height ~ male and report results\nUsing the df_nz dataset, write a regression model for height as predicted by male\nCreate a table for your results.\nCreate a graphs/graphs to clarify the results of your regression model.\nBriefly report your results."
  },
  {
    "objectID": "content/03-content.html#q4.-regression-to-predict",
    "href": "content/03-content.html#q4.-regression-to-predict",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Q4. Regression to predict",
    "text": "Q4. Regression to predict\nUsing the regression coefficients from the Pearson and Lee 1903 dataset, predict the heights of daughters of women in the df_nz dataset."
  },
  {
    "objectID": "content/03-content.html#q5.-bonus",
    "href": "content/03-content.html#q5.-bonus",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Q5. Bonus",
    "text": "Q5. Bonus\nOn average, how much taller or shorter are women in New Zealand as sampled in 2019 df_nz dataset compared with women in 1903 as sampled in the Pearson and Lee dataset.\nClarify your inference."
  },
  {
    "objectID": "content/03-content.html#solutions-set-up",
    "href": "content/03-content.html#solutions-set-up",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solutions: Set Up",
    "text": "Solutions: Set Up\n\n### libraries\nlibrary(\"tidyverse\")\nlibrary(\"patchwork\")\nlibrary(\"lubridate\")\nlibrary(\"kableExtra\")\nlibrary(\"gtsummary\")\n\n\n# get data\nlibrary(\"margot\")\ndata(\"df_nz\")\n\n\n# Import `Pearson and Lee` mother's and daughters data\n# In 1903, Pearson and Lee collected 5,524 observations from mother/daughter height pairs. \n\ndf_pearson_lee &lt;- data.frame(read.table(\n  url(\n    \"https://raw.githubusercontent.com/avehtari/ROS-Examples/master/PearsonLee/data/MotherDaughterHeights.txt\"\n  ),\n  header = TRUE\n))\n# Center mother's height for later example\ndf_pearson_lee &lt;- df_pearson_lee|&gt;\n  dplyr::mutate(mother_height_c = as.numeric(scale(\n    mother_height, center = TRUE, scale = FALSE\n  )))\n\n# dplyr::glimpse(df_pearson_lee)"
  },
  {
    "objectID": "content/03-content.html#solution-q1-descriptive-table",
    "href": "content/03-content.html#solution-q1-descriptive-table",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solution Q1 descriptive table",
    "text": "Solution Q1 descriptive table\n\n# required libraries\nlibrary(gtsummary)\nlibrary(dplyr)\nlibrary(margot)\n\n# select focal variables and rename them for clarity\ndf_nzdat &lt;- df_nz  |&gt;\n  dplyr::filter(wave == 2019) |&gt;\n  dplyr::select(hlth_weight, hlth_height, male) |&gt;\n  dplyr::rename(weight = hlth_weight,\n                height = hlth_height) |&gt;\n  dplyr::select(weight, height, male) |&gt;\n  dplyr::mutate(weight_c = as.numeric(scale(\n    weight, scale = F, center = TRUE\n  )))\n\n\n# create table\ndf_nzdat |&gt; \n  dplyr::select(weight,\n                height) |&gt; \n  gtsummary::tbl_summary(\n    #by = wave,\n    statistic = list(\n      all_continuous() ~ \"{mean} ({sd})\",\n      all_categorical() ~ \"{n} / {N} ({p}%)\"\n    ),\n    digits = all_continuous() ~ 2,\n    missing_text = \"(Missing)\"\n  )|&gt;\n  bold_labels() \n\n\n\n\n\n\n\nCharacteristic\nN = 20,0001\n\n\n\n\nweight\n79.24 (18.42)\n\n\n    (Missing)\n5,655\n\n\nheight\n1.70 (0.10)\n\n\n    (Missing)\n5,655\n\n\n\n1 Mean (SD)\n\n\n\n\n\n\n\n\nHere’s another approach:\n\n# libs we need\nlibrary(table1)\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(margot)\n\n# filter 2019 wave\ndf_nz_1 &lt;- df_nz|&gt;\n  dplyr::filter(wave == 2019)\n\n# nicer labels\ntable1::label(df_nz_1$hlth_weight)     &lt;- \"Weight\"\ntable1::label(df_nz_1$hlth_height)     &lt;- \"Height\"\n\n# table\ntable1::table1(~ hlth_weight + hlth_height, data = df_nz_1)     \n\n\n\n\n\n\n\n\n\n\nOverall\n(N=20000)\n\n\n\n\nWeight\n\n\n\nMean (SD)\n79.2 (18.4)\n\n\nMedian [Min, Max]\n77.0 [38.0, 200]\n\n\nMissing\n5655 (28.3%)\n\n\nHeight\n\n\n\nMean (SD)\n1.70 (0.100)\n\n\nMedian [Min, Max]\n1.69 [1.26, 2.04]\n\n\nMissing\n5655 (28.3%)\n\n\n\n\n\n\n\nCreate graph\n\nlibrary(\"patchwork\")\n# create data set where filtering na vals\ndf_nzdat1 &lt;- df_nzdat |&gt; \n    dplyr::filter(!is.na(weight),\n                  !is.na(height),\n                  !is.na(male)) # filter na's for density plots\n  \nweight_density &lt;-ggplot2::ggplot(data = df_nzdat1, aes(x = weight)) + geom_density(fill = \"chocolate2\") + \n  labs(title = \"Density plot of weight of NZ sample years 2019/2020\") + theme_classic()\nweight_density\n\n\n\n\n\n\n\nheight_density &lt;-ggplot2::ggplot(data = df_nzdat1, aes(x = height)) + geom_density(fill =\"blue2\") + \n  labs(title = \"Density plot of height of NZ sample years 2019/2020\") + theme_classic()\n\nheight_density\n\n\n\n\n\n\n\nweight_density / height_density + plot_annotation(tag_levels = 'a')\n\n\n\n\n\n\n\n\nHere’s a density plot:\n\n# library\nlibrary(ggplot2)\n\n\nggplot2::ggplot(data = df_nzdat1, aes(x = weight, fill = as.factor(male))) +\n  geom_density() + \n  labs(title = \"Density plot of weight of NZ sample years 2019/2020\") +\n  theme_classic() + \n  scale_fill_viridis_d() # nicer colour"
  },
  {
    "objectID": "content/03-content.html#solution-q2.-regress-height-weight-and-report-results",
    "href": "content/03-content.html#solution-q2.-regress-height-weight-and-report-results",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solution Q2. Regress height ~ weight and report results",
    "text": "Solution Q2. Regress height ~ weight and report results\nUsing the nz dataset, write a regression model for height as predicted by weight. Create a table for your results. Create a graphs/graphs to clarify the results of your regression model. Briefly report your results.\nModel:\n\n# regression of height ~ weight\nfit_1 &lt;- lm(height ~ weight_c, data = df_nzdat)\n\nTable:\n\nlibrary(parameters)\n#table of model\nparameters::model_parameters( fit_1) |&gt; \n  print_html(  digits = 2,  # options\n               select = \"{coef}{stars}|({ci})\",\n               column_labels = c(\"Estimate\", \"95% CI\")\n) \n\n\n\n\n\n\n\nParameter\nEstimate\n95% CI\n\n\n\n\n(Intercept)\n1.70***\n(1.70, 1.70)\n\n\nweight c\n2.23e-03***\n(2.15e-03, 2.31e-03)\n\n\n\n\n\n\n\n\n\n\n\n\nPrediction:\n\n# Ensure necessary libraries are loaded\nlibrary(ggeffects)\nlibrary(ggplot2)\n\n# generate the plot with adjusted y-scale\nplot(ggeffects::ggpredict(fit_1, terms = \"weight_c\")) \n\n\n\n\n\n\n\n\nBriefly report your results. (note: please replace “significant” with “statistically significant.)\n\nreport::report(fit_1)\n\nWe fitted a linear model (estimated using OLS) to predict height with weight_c\n(formula: height ~ weight_c). The model explains a statistically significant\nand moderate proportion of variance (R2 = 0.17, F(1, 14286) = 2858.73, p &lt;\n.001, adj. R2 = 0.17). The model's intercept, corresponding to weight_c = 0, is\nat 1.70 (95% CI [1.70, 1.70], t(14286) = 2213.51, p &lt; .001). Within this model:\n\n  - The effect of weight c is statistically significant and positive (beta =\n2.23e-03, 95% CI [2.15e-03, 2.31e-03], t(14286) = 53.47, p &lt; .001; Std. beta =\n0.41, 95% CI [0.39, 0.42])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "content/03-content.html#solution-q3.-regress-height-male-and-report-results",
    "href": "content/03-content.html#solution-q3.-regress-height-male-and-report-results",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solution Q3. Regress height ~ male and report results",
    "text": "Solution Q3. Regress height ~ male and report results\nUsing the df_nz dataset, write a regression model for height as predicted by male Create a table for your results. Create a graph/graphs to clarify the results of your regression model. Briefly report your results.\nModel and table:\n\n# regression of height ~ weight\nfit_2 &lt;- lm(hlth_height ~ male, data = df_nz)\nsjPlot::tab_model(fit_2)\n\n\n\n\n \nhlth height\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n1.65\n1.65 – 1.65\n&lt;0.001\n\n\nmale\n0.13\n0.13 – 0.13\n&lt;0.001\n\n\nObservations\n47205\n\n\nR2 / R2 adjusted\n0.388 / 0.388\n\n\n\n\n\n\n\nGraph:\n\n# plot over the range of the data\nplot_fit_2 &lt;- plot(\n  ggeffects::ggpredict(fit_2, terms = \"male[all]\",\n  jitter = .1,\n  add.data = TRUE,\n  dot.alpha = .2\n) )\n\n# plot\nplot_fit_2 + \n  scale_y_continuous(limits = c(1.2, 2.1))\n\n\n\n\n\n\n\n\nReport\n\n# report\nreport::report(fit_2)\n\nWe fitted a linear model (estimated using OLS) to predict hlth_height with male\n(formula: hlth_height ~ male). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.39, F(1, 47203) = 29979.00, p &lt;\n.001, adj. R2 = 0.39). The model's intercept, corresponding to male = 0, is at\n1.65 (95% CI [1.65, 1.65], t(47203) = 3603.30, p &lt; .001). Within this model:\n\n  - The effect of male is statistically significant and positive (beta = 0.13,\n95% CI [0.13, 0.13], t(47203) = 173.14, p &lt; .001; Std. beta = 0.62, 95% CI\n[0.62, 0.63])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation."
  },
  {
    "objectID": "content/03-content.html#solution-q4.-regression-to-predict",
    "href": "content/03-content.html#solution-q4.-regression-to-predict",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solution Q4. Regression to predict",
    "text": "Solution Q4. Regression to predict\nUsing the regression coefficients from the Pearson and Lee 1903 dataset, predict the heights of daughters of women in the nz dataset. ::: {.cell}\n# model for daughter height from mother height\nfit_3 &lt;- lm(daughter_height ~ mother_height, data = df_pearson_lee)\n\n# create data frame of not_male's in 2019\n# notice problem. not_male != woman\n# additionally, woman != mother!\n\ndf_nz_2 &lt;- df_nz|&gt;\n  filter(male == 1)|&gt; # not_males\n  dplyr::select(hlth_height)|&gt; # variable of interest\n  dplyr::mutate(mother_height = hlth_height * 39.36)|&gt; # Convert meters to inches\n  dplyr::select(mother_height)|&gt;\n  dplyr::arrange((mother_height))\n\n# find min and max heights, store as objects\nmin_mother_height &lt;- min(df_nz_2$mother_height, na.rm = TRUE)\nmax_mother_height &lt;- max(df_nz_2$mother_height, na.rm = TRUE)\n\n# expand grid, use stored objects to define boundaries.\ndf_expand_grid_nz_2 &lt;-\n  expand.grid(mother_height = seq(\n    from = min_mother_height,\n    to = max_mother_height,\n    length.out = 200\n  ))\n\n# use the `predict` function to create a new response using the pearson and fox regression model\n\npredict_fit_3 &lt;-\n  predict(fit_3,\n          type = \"response\",\n          interval = \"confidence\",\n          newdata = df_expand_grid_nz_2)\n\n# create a new dataframe for the response variables, following the method in lecture 5\n\n# combine variables into a data frame\ndf_expand_grid_nz_2_predict_fit_3 &lt;-\n  data.frame(df_expand_grid_nz_2, predict_fit_3)\n\n# graph the expected average hypothetical heights of \"daughters\"\npredplot2 &lt;-\n  ggplot(data = df_expand_grid_nz_2_predict_fit_3,\n         aes(x = mother_height,\n             y = fit))  +\n  geom_line(colour = \"cadetblue\")  +  geom_errorbar(aes(ymin = lwr, ymax = upr), width = .1) + scale_x_continuous(limits = c(50, 75)) + scale_y_continuous(limits = c(50, 75)) + theme_classic()  +\n  xlab(\"NZ 2019 female population\") +\n  ylab(\"predicted daughter heights in inches\") +\n  labs(title = \"Regression prediction for hypothetical daughter heights of NZ population in 2019 \")\n\n# plot\npredplot2\n\n\n\n\n\n\n\n:::"
  },
  {
    "objectID": "content/03-content.html#solution-q6.-bonus",
    "href": "content/03-content.html#solution-q6.-bonus",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Solution Q6. Bonus",
    "text": "Solution Q6. Bonus\nOn average, how much taller or shorter are women in New Zealand as sampled in 2019 nz dataset compared with women in 1903 as sampled in the Pearson and Lee dataset.\n\n# create var for 1903 dataset\n# For the historical dataset (assuming year 1903 for df_pearson_lee_2)\ndf_pearson_lee_2 &lt;- df_pearson_lee |&gt;\n  dplyr::select(mother_height, daughter_height) |&gt;\n  tidyr::pivot_longer(everything(), names_to = \"relation\", values_to = \"f_height\") |&gt;\n  dplyr::mutate(year_is = factor(\"1903\"))\n\n# create var the 2019 dataset\ndf_nz_combine_pearson_lee &lt;- df_nz_2 |&gt;\n  dplyr::rename(f_height = mother_height) |&gt;\n  dplyr::mutate(year_is = factor(\"2019\"),\n                relation = factor(\"mother\"))\n\n# both dataframes have the `year_is` column but with different factor levels\n# check\nhead(df_nz_combine_pearson_lee)\n\n  f_height year_is relation\n1 49.59360    2019   mother\n2 51.21146    2019   mother\n3 51.45691    2019   mother\n4 51.95953    2019   mother\n5 52.92635    2019   mother\n6 53.22973    2019   mother\n\n# combine data frames row-wise\ndf_nz_combine_pearson_lee_1 &lt;- rbind(df_pearson_lee_2, df_nz_combine_pearson_lee)\n\n\n# look at data structure\n#dplyr::glimpse(df_nz_combine_pearson_lee_1)\n\nLook at heights in sample\n\n# get min and max heights for graph range\ntable(df_nz_combine_pearson_lee_1$year_is)\n\n\n 1903  2019 \n11048 22278 \n\n# box plot\nggplot2::ggplot(data =\n                  df_nz_combine_pearson_lee_1,\n                aes(x = year_is, y = f_height, fill = year_is)) +\n  geom_boxplot(notch = TRUE) +\n  labs(title = \"Comparison of female height 1903/2019\") +\n  theme_classic() + scale_fill_viridis_d()\n\n\n\n\n\n\n\n\nPredict heights out of sample\n\n# regression model\nfit_4 &lt;- lm(f_height ~ year_is, data = df_nz_combine_pearson_lee_1)\n\n# table\nsjPlot::tab_model(fit_4)\n\n\n\n\n \nf height\n\n\nPredictors\nEstimates\nCI\np\n\n\n(Intercept)\n63.18\n63.12 – 63.23\n&lt;0.001\n\n\nyear is [2019]\n6.97\n6.90 – 7.04\n&lt;0.001\n\n\nObservations\n28422\n\n\nR2 / R2 adjusted\n0.569 / 0.569\n\n\n\n\n\n\n\nWomen in 2019 are taller\n\nreport::report(fit_4)\n\nWe fitted a linear model (estimated using OLS) to predict f_height with year_is\n(formula: f_height ~ year_is). The model explains a statistically significant\nand substantial proportion of variance (R2 = 0.57, F(1, 28420) = 37516.23, p &lt;\n.001, adj. R2 = 0.57). The model's intercept, corresponding to year_is = 1903,\nis at 63.18 (95% CI [63.12, 63.23], t(28420) = 2244.43, p &lt; .001). Within this\nmodel:\n\n  - The effect of year is [2019] is statistically significant and positive (beta\n= 6.97, 95% CI [6.90, 7.04], t(28420) = 193.69, p &lt; .001; Std. beta = 1.55, 95%\nCI [1.53, 1.56])\n\nStandardized parameters were obtained by fitting the model on a standardized\nversion of the dataset. 95% Confidence Intervals (CIs) and p-values were\ncomputed using a Wald t-distribution approximation.\n\n\nGraph:\n\n# get meaningful values for the y access range\n\n# min\nmin_mother_height_for_range &lt;- min(df_nz_combine_pearson_lee_1$f_height, na.rm = TRUE)\n\n# max\nmax_mother_height_for_range &lt;- max(df_nz_combine_pearson_lee_1$f_height, na.rm = TRUE)\n\n# make graph \nplot(\n  ggeffects::ggpredict(fit_4, terms = \"year_is\",\n  add.data = TRUE,\n  dot.alpha = .2\n) )+ labs(title = \"Predicted difference in female heights 1903/2019\") + \n  xlab(\"Study year\") + \n  ylab (\"Predicted femal height (inches)\") +   scale_y_continuous(\n    limits = c(min_mother_height_for_range,max_mother_height_for_range))\n\n\n\n\n\n\n\n\nGraph with predicted points:\n\nggeffects::ggpredict(fit_4, terms = \"year_is\")\n\n# Predicted values of f_height\n\nyear_is | Predicted |       95% CI\n----------------------------------\n1903    |     63.18 | 63.12, 63.23\n2019    |     70.15 | 70.11, 70.19\n\n# graph with predicted values based on the model\nplot(\n  ggeffects::ggpredict(fit_4, terms = \"year_is\",\n  add.data = TRUE,\n  dot.alpha = .01,\n   colors = \"us\", # see colour pallet options \n  jitter =.5)) + labs(title = \"Predicted difference in female heights 1903/2019\") +\n  xlab(\"Study year\") +\n  ylab (\"Predicted femal height (inches)\") +\n  scale_y_continuous(limits = c(min_mother_height_for_range, max_mother_height_for_range))\n\n\n\n\n\n\n\n# show all color palettes\n#show_pals()"
  },
  {
    "objectID": "content/03-content.html#appendix-1-conceptual-background",
    "href": "content/03-content.html#appendix-1-conceptual-background",
    "title": "Causal Diagrams: The Structures of Confounding Bias",
    "section": "Appendix 1 Conceptual Background",
    "text": "Appendix 1 Conceptual Background\nSome preliminaries about science.\n\nScience begins with a question\nScience begins with a question about the world. The first step in science, then, is to clarify what you want to know.\nBecause science is a social practice, you will also need to clarify why your question is interesting: so what?\nIn short, know your question.\n\n\nScientific model (or theory)\nSometimes, scientists are interested in specific features of the world: how did virus x originate? Such a question might have a forensic interest: what constellation of events gave rise to a novel infectious disease?\nScientists typically seek generalisations. How do infectious diseases evolve? How do biological organisms evolve? Such questions have applied interests. How can we better prevent infectious diseases? How did life originate?\nA scientific model proposes how nature is structured (and unstructured). For example, the theory of evolution by natural selection proposes that life emerges from variation, inheritance, and differential reproduction/survival.\nTo evaluate a scientific model, scientists must make generalisations beyond individual cases. This is where statistics shines.\n\n\nWhat is statistics?\nMathematics is a logic of certainty.\nStatistics is a logic of uncertainty.\nA statistical model uses the logic of probability to make better guesses.\n\n\nApplications of statistical models in science\nScientific models seek to explain how nature is structured. Where scientific models conflict, we can combine statistical models with data collection to evaluate the credibility of of one theoretical model over others. To do this, a scientific model must make distinct, non-trivial predictions about the world.\nIf the predictions are not distinct, the observations will not enable a shift in credibility for one theory over another. Consider the theory that predicts any observation. Such a theory would be better classified as a conspiracy theory; it is compatible with any evidence.\n\n\n\nPackages\n\nreport::cite_packages()\n\n  - Anderson D, Heiss A, Sumners J (2024). _equatiomatic: Transform Models into 'LaTeX' Equations_. R package version 0.3.3, &lt;https://CRAN.R-project.org/package=equatiomatic&gt;.\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 &lt;https://doi.org/10.5281/zenodo.10907724&gt;, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., &lt;https://go-bayes.github.io/margot/&gt;.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D (2018). \"ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.\" _Journal of Open Source Software_, *3*(26), 772. doi:10.21105/joss.00772 &lt;https://doi.org/10.21105/joss.00772&gt;.\n  - Lüdecke D (2024). _sjPlot: Data Visualization for Statistics in Social Science_. R package version 2.8.17, &lt;https://CRAN.R-project.org/package=sjPlot&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 &lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Waggoner P, Makowski D (2021). \"performance: An R Package for Assessment, Comparison and Testing of Statistical Models.\" _Journal of Open Source Software_, *6*(60), 3139. doi:10.21105/joss.03139 &lt;https://doi.org/10.21105/joss.03139&gt;.\n  - Makowski D, Lüdecke D, Patil I, Thériault R, Ben-Shachar M, Wiernik B (2023). \"Automated Results Reporting as a Practical Tool to Improve Reproducibility and Methodological Best Practices Adoption.\" _CRAN_. &lt;https://easystats.github.io/report/&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, &lt;https://CRAN.R-project.org/package=patchwork&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Rich B (2023). _table1: Tables of Descriptive Statistics in HTML_. R package version 1.4.3, &lt;https://CRAN.R-project.org/package=table1&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible Summary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580. doi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;, &lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022). _skimr: Compact and Flexible Summaries of Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=skimr&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, Bryan J, Barrett M, Teucher A (2024). _usethis: Automate Package and Project Setup_. R package version 3.1.0, &lt;https://CRAN.R-project.org/package=usethis&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Hester J, Chang W, Bryan J (2022). _devtools: Tools to Make Developing R Packages Easier_. R package version 2.4.5, &lt;https://CRAN.R-project.org/package=devtools&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0, &lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "content/08-content.html",
    "href": "content/08-content.html",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "",
    "text": "Note\n\n\n\nRequired - (VanderWeele, Mathur, and Chen 2020) link\nOptional - (Suzuki, Shinozaki, and Yamamoto 2020) link - (Bulbulia 2024) link - (Hoffman et al. 2023) link"
  },
  {
    "objectID": "content/08-content.html#learning-outcomes",
    "href": "content/08-content.html#learning-outcomes",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nYou will learn how to state a causal question in a three-wave panel\nYou will learn how to identify causal effects in a three-waves of panel data.\nHow to do Propensity-score weighting: modelling the exposure or treatment, not the outcome.  \nSubgroup analysis by doubly-robust estimation\n\n\n\nWhy is this lesson important?\n\n\nThe methods you will learn today will help you to define and answer comparative questions in psychology."
  },
  {
    "objectID": "content/08-content.html#review-the-fundamental-problem-of-causal-inference-as-a-missing-data-problem",
    "href": "content/08-content.html#review-the-fundamental-problem-of-causal-inference-as-a-missing-data-problem",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Review: The Fundamental Problem of Causal Inference as a Missing Data Problem",
    "text": "Review: The Fundamental Problem of Causal Inference as a Missing Data Problem\nRecall the fundamental problem of causal inference, returning to the question of whether bilingualism improves cognitive abilities:\n\nY_i^{a = 1}: The cognitive ability of child i if they were bilingual. This is the counterfactual outcome when A = 1.\nY_i^{a = 0}:: The cognitive ability of child i if they were monolingual. This is the counterfactual outcome when A = 0.\n\nThe causal effect of bilingualism on cognitive ability for individual i is then defined as the difference between these potential outcomes:\n\n\\text{Causal Effect}_i = Y_i^{a=1} - Y_i^{a=0}\n\nWe say there is a causal effect if:\n\nY_i^{a=1} - Y_i^{a=0}  \\neq 0\n\nHowever, we only observe one of the potential outcomes for each child. The other outcome is not observed because physics prevents a child from both receiving and not receiving bilingual exposure.\nThe fact that causal contrasts are not observed in individuals is called “The fundamental problem of causal inference.”\nAlthough we typically cannot observe individual causal effects, we can obtain average causal effects when certain assumptions are satisfied.\n\\begin{align}\nE(\\delta) = E(Y^{a=1} - Y^{a=0})\\\\\n          ~  = E(Y^{a=1}) - E(Y^{a=0}) \\\\\n          ~  = ATE\n\\end{align}\nWe may identify average causal effects from the data when the following assumptions are met:\n\nCausal Consistency: The exposure values under comparisons correspond to well-defined interventions that, in turn, correspond to the treatment versions in the data.[]\nPositivity: The probability of receiving every value of the exposure within all strata of co-variates is greater than zero []\nExchangeability: The conditional probability of receiving every value of an exposure level, though not decided by the investigators, depends only on the measured covariates []\n\nFurther assumptions:\n\nNo Interference, also known as the Stable Unit Treatment Value Assumption (SUTVA), requires that the treatment given to one unit (e.g., person, group, organization) does not interfere with the potential outcomes of another unit. Put differently, there are no “spillover” effects. Note: this assumption may be thought to be part of causal consistency, namely individual has only one potential outcome under each treatment condition.\nCorrectly specified model: the requirement that the underlying statistical model used to estimate causal effects accurately represents the true relationships between the variables of interest. We say the model should be able to capture “the functional form” of the relationship between the treatment, the outcome, and any covariates. The model’s functional form should be flexible enough to capture the true underlying relationship. The estimated causal effects may be biased if the model’s functional form is incorrect. Additionally, the model must handle omitted variable bias by including all relevant confounders and should correctly handle missing data from non-response or loss-to follow up. We will return to the bias arising from missing data in the weeks ahead. For now, it is important to note that causal inference assumes that our model is correctly specified."
  },
  {
    "objectID": "content/08-content.html#subgroup-analysis",
    "href": "content/08-content.html#subgroup-analysis",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Subgroup analysis",
    "text": "Subgroup analysis\n\n\n\n\n\nRedcall, Effect Modification (also known as “heterogeneity of treatment effects”, and “Effect-measure modification”) occurs when the causal effect of intervention A varies across different levels of another variable R:\nE(Y^{a=1}|G=g_1, L=l) - E(Y^{a=0}|G=g_1, L=l) \\neq E(Y^{a=1}|G=g_2, L=l) - E(Y^{a=0}|G=g_2, L=l)\nEffect modification indicates that the magnitude of the causal effect of intervention A is related to the modifier variable G level. As discussed last week, effect modification can be observed even when there is no direct causal interaction between the treatment and the modifier variable. We noted that interaction in causal inference refers to a situation where the combined effect of two interventions is not equal to the sum of their individual effects. Effect modification, on the other hand, occurs when the causal effect of one intervention varies across different levels of another variable.\nWe also noted that\n\nFor comparative research, we are typically interested in effect-modification, which requires subgroup analysis.\n\n\nCausal Estimand, Statistical Estimand, Statistical Estimator\nLet’s set subgroup analysis to the side for a moment and begin focussing on statistical estimation.\nSuppose a researcher wants to understand the causal effect of marriage on individual happiness. Participants in the study are surveyed for their marital status (“married” or “not married”) and their self-reported happiness on a scale from 1 to 10.\n\nCausal Estimand\n\nDefinition: The causal estimand is the specific quantity or parameter that we aim to estimate to understand the causal effect of an intervention or treatment on an outcome.\nExample: Here, the Causal Estimand would be the Average Treatment Effect (ATE) of being married on happiness. Specifically, we define the ATE as the difference in the potential outcomes of happiness if all individuals were married versus if no individuals were married:\n\n\\text{ATE} = E[Y^{a=1} - Y^{a=0}]\n\nHere, Y^{a=1} represents the potential happiness score if an individual is married, and Y^{a=0} if they are not married.\n\n\n\nNext step: Are Causal Assumptions Met?\n\nIdentification (Exchangeability): balance in the confounders across the treatments to be compared\nConsistency: well-defined interventions\nPositivity: treatments occur within levels of covariates L\n\n\n\nStatistical Estimand (next step)\n\nThe problem: how do we bridge the gap between potential outcomes and data?\nDefinition: the statistical estimand is the parameter or function that summarises the relationship between variables as described by a statistical model applied to data.\nExample: for our study, the Statistical Estimand might be the mean difference in happiness scores between individuals who are married and those who are not, as derived from a linear regression model:\n\n\\text{Happiness} = \\beta_0 + \\beta_1 \\times \\text{Married} + \\epsilon\n\nIn this equation, \\beta_1 represents the estimated difference in happiness scores between the married and non-married groups.\n\n\n\nStatistical Estimator\n\nDefinition: a statistical estimator is a rule or method by which a numerical estimate of a statistical estimand is calculated from the data.\nExample: in our marriage study, the Statistical Estimator for \\beta_1 is the ordinary least squares (OLS) estimator. This estimator is used to calculate \\beta_1 from the sample data provided by the survey. It provides an estimate of the impact of being married on happiness, calculated using: \n\\hat{\\beta}_1 = \\frac{\\sum_{i=1}^n (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n (X_i - \\bar{X})^2}\n where X_i is a binary indicator for being married (1 for married, 0 for not married), Y_i is the observed happiness score, and \\bar{X}, \\bar{Y} are the sample means of X and Y, respectively.\n\n(Note: you will not need to know this equation for the quiz)\nThe upshot, we anchor our causal inquiries within a mult-step framework of data analysis. This involves:\n\nclearly defining our causal estimand within a specified target population,\nclarifying assumptions, & especially identification assumptions,\ndescribing a statistical strategy for extracting this estimand from the data, and then\napplying an algorithm that embodies this statistical method."
  },
  {
    "objectID": "content/08-content.html#methods-for-statistical-estimation-in-causal-inference-inverse-probability-of-treatment-weights-using-propensity-scores",
    "href": "content/08-content.html#methods-for-statistical-estimation-in-causal-inference-inverse-probability-of-treatment-weights-using-propensity-scores",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Methods for Statistical Estimation in Causal Inference: Inverse Probability of Treatment Weights Using Propensity Scores",
    "text": "Methods for Statistical Estimation in Causal Inference: Inverse Probability of Treatment Weights Using Propensity Scores\nLast week, we discussed confounding control using regression adjustment. Recall the formula for the average treatment effect (ATE) when conditioning on a set of covariates L:\n\n\\begin{aligned}\n\\text{ATE} = E[Y^{a=1} \\mid L = l] - E[Y^{a=0} \\mid L = l] \\quad \\text{for any value of } l\n\\end{aligned}\n\n\n“We say that a set L of measured non-descendants of L is a sufficient set for confounding adjustment when conditioning on L blocks all backdoor paths—that is, the treated and the untreated are exchangeable within levels of L” (Hernán & Robins, Causal Inference, p. 86).\n\nThis formula calculates the expected outcome difference between treated (a=1) and untreated (a=0) groups, given a specific value of the covariates l.\nInverse Probability of Treatment Weighting (IPTW) takes a different approach. We create a pseudo-population where the treatment assignment is independent of the observed covariates by assigning weights to each individual based on their propensity scores.\nWe do this by modelling the treatment\nDenote the treatment indicator by A, where A = 1 if an individual receives treatment and A = 0 otherwise. L represents the vector of observed covariates, and Y^a the potential outcomes. The propensity score, e(L), is defined as the probability of receiving the treatment given the observed covariates:\n\n\\hat{e}(L) = P(A = 1 \\mid L)\n\nTo obtain IPTW weights, compute the inverse probability of treatment:\n\nv_i = \\frac{A_i}{\\hat{e}(L_i)} + \\frac{1 - A_i}{1 - \\hat{e}(L_i)}\n\nWhich simplifies to\n\nv_i =\n\\begin{cases}\n\\frac{1}{\\hat{e}} & \\text{if } A_i = 1 \\\\\n\\frac{1}{1-\\hat{e}} & \\text{if } A_i = 0\n\\end{cases}\n\nwhere v_i is the IPTW weight for individual i, A_i is the treatment indicator for individual i, and \\hat{e}(L_i) is the estimated propensity score for individual i.\nHow might we use these weights to obtain causal effect estimates?"
  },
  {
    "objectID": "content/08-content.html#marginal-structural-models-msms",
    "href": "content/08-content.html#marginal-structural-models-msms",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Marginal Structural Models (MSMs)",
    "text": "Marginal Structural Models (MSMs)\nMarginal Structural Models (MSMs) estimate causal effects without requiring an “outcome model” that stratifies on covariates. Rather, MSMs employ weights derived from the inverse probability of treatment weighting (IPTW) to create a pseudo-population in which the distribution of covariates is independent of treatment assignment over time.\nThe general form of an MSM can be expressed as follows:\n\nE[Y^a] = \\beta_0 + \\beta_1a\n\nwhere E[Y^a] is the expected outcome under treatment a and \\beta_0 and \\beta_1 are parameters estimated by fitting the weighted model. Again, the weights used in the MSM, typically derived from the IPTW (or another treatment model), adjust for the confounding, allowing the model to estimate the unbiased effect of the treatment on the outcome without requiring covariates in the model.\nWhere do weights fit in? Note, we have E[Y^a] in please of E[Y|A=a]. When applying propensity score weights in the linear regression model E[Y^a] = \\beta_0 + \\beta_1a, each observation is weighted by v_i, such that v_i(\\beta_0 + \\beta_1a). This changes the estimation process to focus on a weighted sum of outcomes, where each individual’s contribution is adjusted to reflect their probability of receiving the treatment, given their covariates."
  },
  {
    "objectID": "content/08-content.html#interpretation-of-beta_0-and-beta_1-in-a-marginal-structural-model",
    "href": "content/08-content.html#interpretation-of-beta_0-and-beta_1-in-a-marginal-structural-model",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Interpretation of \\beta_0 and \\beta_1 in a Marginal Structural Model",
    "text": "Interpretation of \\beta_0 and \\beta_1 in a Marginal Structural Model\n\nBinary Treatment\nIn models where the treatment a is binary (e.g., a = 0 or a = 1), such as in many causal inference studies:\n\n\\beta_0: the expected value of the outcome Y when the treatment is not applied (a = 0). This is the baseline level of the outcome in the absence of treatment.\n\\beta_1: the change in the expected outcome when the treatment status changes from 0 to 1. In logistic regression, \\beta_1 represents the log-odds ratio of the outcome for the treatment group relative to the control group. In linear regression, \\beta_1 quantifies the difference in the average outcome between the treated and untreated groups.\n\n\n\nContinuous Treatment\nWhen the treatment a is continuous, the interpretation of \\beta_0 and \\beta_1 adjusts slightly:\n\n\\beta_0: represents the expected value of the outcome Y when the treatment a is at its reference value (often zero).\n\\beta_1: represents the expected change in the outcome for each unit increase in the treatment. In this case, \\beta_1 measures the gradient or slope of the relationship between the treatment and the outcome. For every one-unit increase in treatment, the outcome changes by \\beta_1 units, assuming all other factors remain constant.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow can we apply marginal structural models in subgroups?\n\n\nAssumptions\n\nModel assumptions: the treatment model is correctly specified.\nCausal assumptions: all confounders are appropriately controlled, positivity and consistency assumptions hold.\n\n\n\nCalculating Treatment Weights (Propensity Scores) and Confounding Control in Subgroups\nWe may often achieve greater balance when conducting weighted analyses in subgroups by estimating propensity scores within these subgroups. The propensity score $ e(L, G) $ is the conditional probability of receiving the exposure $ A = 1 $, given the covariates $ L $ and subgroup indicator $ G $. This is often modelled using logistic regression or other methods that ensure covariate balance We define the estimated propensity score as follows:\n\n\\hat{e} = P(A = 1 \\mid L, G) = f_A(L, G; \\theta_A)\n\nHere, $ f_A(L, G; _A) $ is the statistical model estimating the probability of exposure A = 1 given covariates L and subgroup G. We then calculate the weights for each individual, denoted v, using the estimated propensity score:\n\\theta_A encapsulates all the coefficients (parameters) in this model, including intercepts, slopes, and potentially other parameters depending on the model complexity (e.g., interaction terms, non-linear effects…etc).\nThese weights v depend on A and are calculated as the inverse of the propensity score for exposed individuals and as the inverse of $ 1- $ for unexposed individuals.\nPropensity scores are estimated separately within strata of the subgroup to control for potential confounding tailored to each subgroup. These weights v are specific to each individual in subgroup G. In the lab, we will clarify how to fit models to estimate contrasts for the causal effects within groups \\hat{\\delta}_{g}, \\hat{\\delta}_{g'}, etc., and how to obtain estimates for group-wise differences:\n\n\\hat{\\gamma} = \\overbrace{\\big( \\hat{E}[Y^a \\mid G=g] - \\hat{E}[Y^{a'} \\mid G=g] \\big)}^{\\hat{\\delta}_g} - \\overbrace{\\big( \\hat{E}[Y^{a'} \\mid G=g'] - \\hat{E}[Y^a \\mid G=g'] \\big)}^{\\hat{\\delta}_{g'}}\n\n\n\\hat{E}[Y^a \\mid G=g]: Estimated expected outcome when treatment a is applied to subgroup G=g.\n\\hat{E}[Y^{a'} \\mid G=g]: Estimated expected outcome when a different treatment or control a' is applied to the same subgroup G=g.\n\\hat{\\delta}_g: Represents the estimated treatment effect within subgroup G=g, computed as the difference in expected outcomes between treatment a and a' within this subgroup.\n\\hat{E}[Y^{a'} \\mid G=g']: Estimated expected outcome when treatment a' is applied to a different subgroup G=g'.\n\\hat{E}[Y^a \\mid G=g']: Estimated expected outcome when treatment a is applied to subgroup G=g'.\n\\hat{\\delta}_{g'}: Represents the estimated treatment effect within subgroup G=g', computed as the difference in expected outcomes between treatment a' and a within this subgroup.\n\\hat{\\gamma}: The overall measure calculated from your formula represents the difference in treatment effects between two subgroups, G=g and G=g'. It quantifies how the effect of switching between treatments a and a' differs across the two subgroups.\n\n\n\nConsiderations\n\nEstimation: to estimate the expected outcomes \\hat{E}[Y^a \\mid G] and \\hat{E}[Y^{a'} \\mid G], we require statistical models. If we use regression, we include interaction terms between treatment and subgroup indicators to directly estimate subgroup-specific treatment effects. Our use depends on correct model specification.\nConfidence intervals: we may compute confidence intervals for \\hat{\\gamma} using bootstrap, the delta method, or – in our excercises – simulation based methods.\nCausal assumptions: again, a causal interpretation of \\hat{\\gamma} relies on satisfying both causal assumptions and modelling assumptions. Here, we have described estimation using propensity scores."
  },
  {
    "objectID": "content/08-content.html#doubly-robust-estimation",
    "href": "content/08-content.html#doubly-robust-estimation",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Doubly Robust Estimation",
    "text": "Doubly Robust Estimation\nWe can combine regression-based estimation with propensity score estimation to obtain doubly robust estimation. I will walk you through the steps in the lab. The TL;DR is this: doubly robust estimation reduces reliance on correct model specification. If either the PS model or the regression model is correctly specified, the model will be unbiased – if the other causal inference assumptions are met.\nWe cannot know whether these assumptions are met, we will need to do a sensitivity analysis, the topic of next week.\nI’ll show you in lab how to employ simulation-based inference methods to compute standard errors and confidence intervals, following the approaches suggested by Greifer (2023)[]."
  },
  {
    "objectID": "content/08-content.html#readings",
    "href": "content/08-content.html#readings",
    "title": "Causal Inference: Estimation of ATE and CATE",
    "section": "Readings:",
    "text": "Readings:\nNoah Griefer’s Software and Blogs: https://ngreifer.github.io/blog/subgroup-analysis-psm/"
  },
  {
    "objectID": "content/v_2_tempate_causal_estimation.html",
    "href": "content/v_2_tempate_causal_estimation.html",
    "title": "Template: Causal Estimatation",
    "section": "",
    "text": "Answer the following:\n\nState the Question: is my question clearly stated? If not, state it.\nRelevance of the Question: Have I explained its importance? If not, explain.\nSubgroup Analysis: Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.\nCausality of the Question: Is my question causal? Briefly explain what this means with reference to the potential outcomes framework.\nState how you will use time-series data to address causality.\nDefine your exposure.\nDefine your outcome(s)\nExplain how the the exposure and outcome is relevant to your question.\nDefine your causal estimand (see: lecture 9). Hint: it is ATE_g_risk difference = E[Y(1)-(0)|G,L], where G is your multiple-group indicator and L is your set of baseline confounders."
  },
  {
    "objectID": "content/v_2_tempate_causal_estimation.html#intoduction",
    "href": "content/v_2_tempate_causal_estimation.html#intoduction",
    "title": "Template: Causal Estimatation",
    "section": "",
    "text": "Answer the following:\n\nState the Question: is my question clearly stated? If not, state it.\nRelevance of the Question: Have I explained its importance? If not, explain.\nSubgroup Analysis: Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.\nCausality of the Question: Is my question causal? Briefly explain what this means with reference to the potential outcomes framework.\nState how you will use time-series data to address causality.\nDefine your exposure.\nDefine your outcome(s)\nExplain how the the exposure and outcome is relevant to your question.\nDefine your causal estimand (see: lecture 9). Hint: it is ATE_g_risk difference = E[Y(1)-(0)|G,L], where G is your multiple-group indicator and L is your set of baseline confounders."
  },
  {
    "objectID": "content/v_2_tempate_causal_estimation.html#methods",
    "href": "content/v_2_tempate_causal_estimation.html#methods",
    "title": "Template: Causal Estimatation",
    "section": "Methods",
    "text": "Methods\n\nConsider any ethical implications.\nExplain the sample. Provide descriptive statistics\nDiscuss inclusion criteria.\nDiscuss how your sample relates to the “source population” (lecture 9.)\nExplain NZAVS measures. State the questions used in the items\nIn your own words describe how the data meet the following assumptions required for causal inference:\nPositivity: Can we intervene on the exposure at all levels of the covariates? Use the code I provided to test whether there is change in the exposure from the baseline in the source population(s)\nConsistency: Can I interpret what it means to intervene on the exposure?\nExchangeability: Are different versions of the exposure conditionally exchangeable given measured baseline confounders? This requires stating baseline confounders and explaining how they may be related to both the exposure and outcome. As part of this, you must explain why the baseline measure of your exposure and outcome are included as potential confounders.\nNote: Unmeasured Confounders: Does previous science suggest the presence of unmeasured confounders? (e.g. childhood exposures that are not measured).\nDraw a causal diagram: Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding?\nMeasurement Error: Have I described potential biases from measurement errors? Return to lecture 11.\nState that you do not have missing data in this synthetic dataset, but that ordinarily missing data would need to be handled.\nState what your estimator will be. Note I’ve given you the following text to modify:\n\n\nThe Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:\n\n\nStep 1 involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.\n\n\nStep 2 focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.\n\n\nStep 3 entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.\n\n\nStep 4 is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.\n\n\nStep 5 involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods (Greifer et al. 2023). This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.\n\n\n\nState what E-values are and how you will use them to clarify the risk of unmeasured confounding."
  },
  {
    "objectID": "content/v_2_tempate_causal_estimation.html#results",
    "href": "content/v_2_tempate_causal_estimation.html#results",
    "title": "Template: Causal Estimatation",
    "section": "Results",
    "text": "Results\n\nUse the scripts I have provided as a template for your analysis.\nPropensity Score Reporting: Detail the process of propensity score derivation, including the model used and any variable transformations: e.g.: A ~ x1 + x2 + x3 + .... using logistic regression, all continuous predictors were transformed to z-scores\n\nWeightIt Package Utilisation: Explicitly mention the use of the ‘WeightIt’ package in R, including any specific options or parameters used in the propensity score estimation process (Greifer 2023).\nReport if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as ‘ebal’, ‘energy’, and ‘ps’.\nIf your exposure is continuous only the ‘energy’ option was used for propensity score estimation.\nSubgroup Estimation: Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.\nCovariate Balance: Include a Love plot to visually represent covariate balance on the exposure both before and after weighting. The script will generate these plots.\nWeighting Algorithm Statistics: Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit. The script I gave you will generate this information\n\n\nExample:\n\nWe estimated propensity scores by fitting a model for the exposure A as it is predicted by the set of baseline covariates defined by L. Because we are interested in effect modification by group, we fit different propensity score models for within strata of G using the subgroup command of the WeightIt package. Thus the propensity score is the the probability of receiving a value of a treatment (A=a) conditional on the covariates L, and stratum within G. We compared balance using the following methods of weighting: “ebal” or entropy balancing, “energy” or energy balancing, and “ps” or traditional inverse probability of weighting balancing. Of these methods “ebal” performed the best. Table X and Figure Y present the results of the ebalancing method.\n\n\nInterpretation of Propensity Scores: we interpret the proposensity scores as yeilding good balance across the exposure conditions.\nOutcome Regression Model: Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation. Example\n\n\nWe fit a linear model using maximum likelihood estimation with the outcome Y predicted by the exposure A. We interacted the exposure with all baseline confounders L. Continuous baseline confounders were converted to z-scores, whereas categorical exposures were not. Also interacted with all baseline confounders was a term for the subgroup interactoin. This allowed uas to flexibily fit non-linearities for the modification of the effect of the exposure within levels of the levels of the cultural group strata of interest. We note that model coefficients have no interpretation in this context so are not reported. The remaining steps of Doubly-Robust estimation were performed as outlined in the Method section. We calculated confidence intervals and standard errors, using the clarify package in R, which relies on simulation based inference for these quantities of interest (Greifer et al. 2023)\n\n\nReport the causal estimates.\n\nATE contrasts for groups in setting the exposure to for each group in setting level A = a and A = a*\ndifferences between groups in the magnitude of the effects. (ATE_group 1 - ATE_group_2)\n\nReport the E-value: how sensitive are your results to unmeasured confounding? Hint I gave you code that will create a table for you: See here\n\ntable_depression &lt;- tab_ate_subgroup_rd(table_estimates_depression, delta = 1, sd = 1)"
  },
  {
    "objectID": "content/v_2_tempate_causal_estimation.html#discussion",
    "href": "content/v_2_tempate_causal_estimation.html#discussion",
    "title": "Template: Causal Estimatation",
    "section": "Discussion",
    "text": "Discussion\nMake sure to hit these points:\nConsider the following ideas about what to discuss in one’s findings. The order of exposition might be different.\n\nSummary of results: What did you find?\nInterpretation of E-values: Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.\nCausal Effect Interpretation: What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.\nComparison of Subgroups: Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.\nUncertainty and Confidence Intervals: Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.\nGeneralisability and Transportability: Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)\nAssumptions and Limitations: Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.\nTheoretical Relevance: How are these findings relevant to existing theories.\nReplication and Future Research: Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.\nReal-world Implications: Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;!–  –&gt;\n&lt;!–  –&gt;\n&lt;!–  –&gt;\n&lt;!–  –&gt;"
  },
  {
    "objectID": "content/step-by-step-reporting-guide.html",
    "href": "content/step-by-step-reporting-guide.html",
    "title": "Template: Stratified Causal Estimatation",
    "section": "",
    "text": "Your step-by-step guide to reporting is as follows:"
  },
  {
    "objectID": "content/step-by-step-reporting-guide.html#intoduction",
    "href": "content/step-by-step-reporting-guide.html#intoduction",
    "title": "Template: Stratified Causal Estimatation",
    "section": "Intoduction",
    "text": "Intoduction\nAnswer the following:\n\nState the Question: is my question clearly stated? If not, state it.\nRelevance of the Question: Have I explained its importance? If not, explain.\nSubgroup Analysis: Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.\nCausality of the Question: Is my question causal? Briefly explain what this means with reference to the potential outcomes framework.\nState how you will use time-series data to address causality.\nDefine your exposure.\nDefine your outcome(s)\nExplain how the the exposure and outcome is relevant to your question.\nDefine your causal estimand (see: lecture 8). Hint: it is ATE_g_risk difference = E[Y(1)-(0)|G,L], where G is your multiple-group indicator and L is your set of baseline confounders."
  },
  {
    "objectID": "content/step-by-step-reporting-guide.html#method",
    "href": "content/step-by-step-reporting-guide.html#method",
    "title": "Template: Stratified Causal Estimatation",
    "section": "Method",
    "text": "Method\n\nConsider any ethical implications.\nExplain the sample. Provide descriptive statistics\nDiscuss inclusion criteria.\nDiscuss how your sample relates to the “source population” (lecture 8.)\nExplain NZAVS measures. State the questions used in the items\nIn your own words describe how the data meet the following assumptions required for causal inference:\nPositivity: Can we intervene on the exposure at all levels of the covariates? Use the code I provided to test whether there is change in the exposure from the baseline in the source population(s)\nConsistency: Can I interpret what it means to intervene on the exposure?\nExchangeability: Are different versions of the exposure conditionally exchangeable given measured baseline confounders? This requires stating baseline confounders and explaining how they may be related to both the exposure and outcome. As part of this, you must explain why the baseline measure of your exposure and outcome are included as potential confounders.\nNote: Unmeasured Confounders: Does previous science suggest the presence of unmeasured confounders? (e.g. childhood exposures that are not measured).\nDraw a causal diagram: Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding?\nMeasurement Error: Have I described potential biases from measurement errors? Return to lecture 11.\nState how you will handle missing data\nState what your estimator will be. Note I’ve given you the following text to modify:\n\n\nThe Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:\n\n\nStep 1 involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.\n\n\nStep 2 focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.\n\n\nStep 3 entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.\n\n\nStep 4 is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.\n\n\nStep 5 involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods (Greifer et al. 2023). This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.\n\nOR if you decide to use machine learning:\n\nWe perform statistical estimation using semi-parametric Targeted Learning, specifically a Targeted Minimum Loss-based Estimation (TMLE) estimator. TMLE is a robust method that combines machine learning techniques with traditional statistical models to estimate causal effects while providing valid statistical uncertainty measures for these estimates (Van der Laan 2014; Laan and Gruber 2012).\n\nVan der Laan, Mark J. 2014. “Targeted Estimation of Nuisance Parameters to Obtain Valid Statistical Inference.” The International Journal of Biostatistics 10 (1): 29–57.\n\nLaan, Mark J van der, and Susan Gruber. 2012. “Targeted Minimum Loss Based Estimation of Causal Effects of Multiple Time Point Interventions.” The International Journal of Biostatistics 8 (1).\n\n\nTMLE operates through a two-step process that involves modelling both the outcome and treatment (exposure). Initially, TMLE employs machine learning algorithms to flexibly model the relationship between treatments, covariates, and outcomes. This flexibility allows TMLE to account for complex, high-dimensional covariate spaces efficiently without imposing restrictive model assumptions (Laan, Luedtke, and Dı́az 2014; Van Der Laan and Rose 2011, 2018). The outcome of this step is a set of initial estimates for these relationships.\n\nVan Der Laan, Mark J., and Sherri Rose. 2011. Targeted Learning: Causal Inference for Observational and Experimental Data. Springer Series in Statistics. New York, NY: Springer. https://link.springer.com/10.1007/978-1-4419-9782-1.\n\n———. 2018. Targeted Learning in Data Science: Causal Inference for Complex Longitudinal Studies. Springer Series in Statistics. Cham: Springer International Publishing. http://link.springer.com/10.1007/978-3-319-65304-4.\n\n\nThe second step of TMLE involves “targeting” these initial estimates by incorporating information about the observed data distribution to improve the accuracy of the causal effect estimate. TMLE achieves this precision through an iterative updating process, which adjusts the initial estimates towards the true causal effect. This updating process is guided by the efficient influence function, ensuring that the final TMLE estimate is as close as possible, given the measures and data, to the targeted causal effect while still being robust to model-misspecification in either the outcome or the treatment model (Laan, Luedtke, and Dı́az 2014).\n\nLaan, Mark J van der, Alexander R Luedtke, and Iván Dı́az. 2014. “Discussion of Identification, Estimation and Approximation of Risk Under Interventions That Depend on the Natural Value of Treatment Using Observational Data, by Jessica Young, Miguel Hernán, and James Robins.” Epidemiologic Methods 3 (1): 21–31.\n\n\nAgain, a central feature of TMLE is its double-robustness property. If either the treatment model or the outcome model is correctly specified, the TMLE estimator will consistently estimate the causal effect. Additionally, we used cross-validation to avoid over-fitting, following the pre-stated protocols in Bulbulia (2024b). The integration of TMLE and machine learning technologies reduces the dependence on restrictive modelling assumptions and introduces an additional layer of robustness. For further details of the specific targeted learning strategy we favour, see (Hoffman et al. 2022, 2023; Díaz et al. 2021). We perform estimation using the lmtp package (Williams and Díaz 2021). We used the superlearner library for semi-parametric estimation with the predefined libraries SL.ranger, SL.glmnet, and SL.xgboost (Polley et al. 2023; Chen et al. 2023; Wright and Ziegler 2017). We created graphs, tables and output reports using the margot package (Bulbulia 2024a).\n\n———. 2024b. “A Practical Guide to Causal Inference in Three-Wave Panel Studies.” PsyArXiv Preprints, February. https://doi.org/10.31234/osf.io/uyg3d.\n\nHoffman, Katherine L., Edward J. Schenck, Michael J. Satlin, William Whalen, Di Pan, Nicholas Williams, and Iván Díaz. 2022. “Comparison of a Target Trial Emulation Framework Vs Cox Regression to Estimate the Association of Corticosteroids with COVID-19 Mortality.” JAMA Network Open 5 (10): e2234425. https://doi.org/10.1001/jamanetworkopen.2022.34425.\n\nHoffman, Katherine L., Diego Salazar-Barreto, Kara E. Rudolph, and Iván Díaz. 2023. “Introducing Longitudinal Modified Treatment Policies: A Unified Framework for Studying Complex Exposures,” April. https://doi.org/10.48550/arXiv.2304.09460.\n\nDíaz, Iván, Nicholas Williams, Katherine L. Hoffman, and Edward J. Schenck. 2021. “Non-Parametric Causal Effects Based on Longitudinal Modified Treatment Policies.” Journal of the American Statistical Association. https://doi.org/10.1080/01621459.2021.1955691.\n\nWilliams, Nicholas T., and Iván Díaz. 2021. lmtp: Non-Parametric Causal Effects of Feasible Interventions Based on Modified Treatment Policies. https://doi.org/10.5281/zenodo.3874931.\n\nPolley, Eric, Erin LeDell, Chris Kennedy, and Mark van der Laan. 2023. SuperLearner: Super Learner Prediction. https://CRAN.R-project.org/package=SuperLearner.\n\nChen, Tianqi, Tong He, Michael Benesty, Vadim Khotilovich, Yuan Tang, Hyunsu Cho, Kailong Chen, et al. 2023. Xgboost: Extreme Gradient Boosting. https://CRAN.R-project.org/package=xgboost.\n\nWright, Marvin N., and Andreas Ziegler. 2017. “ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.” Journal of Statistical Software 77 (1): 1–17. https://doi.org/10.18637/jss.v077.i01.\n\nBulbulia, J. A. 2024a. Margot: MARGinal Observational Treatment-Effects. https://doi.org/10.5281/zenodo.10907724.\n\n\n\nState what E-values are (lecture 9) and how you will use Evalues to clarify the risk of unmeasured confounding."
  },
  {
    "objectID": "content/step-by-step-reporting-guide.html#results",
    "href": "content/step-by-step-reporting-guide.html#results",
    "title": "Template: Stratified Causal Estimatation",
    "section": "Results",
    "text": "Results\n\nUse the scripts I have provided as a template for your analysis.\nPropensity Score Reporting: Detail the process of propensity score derivation, including the model used and any variable transformations: e.g.: A ~ x1 + x2 + x3 + .... using logistic regression, all continuous predictors were transformed to z-scores\n\nWeightIt Package Utilisation: Explicitly mention the use of the ‘WeightIt’ package in R, including any specific options or parameters used in the propensity score estimation process (Greifer 2023).\nReport if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as ‘ebal’, ‘energy’, and ‘ps’.\nIf your exposure is continuous only the ‘energy’ option was used for propensity score estimation.\nSubgroup Estimation: Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.\nCovariate Balance: Include a Love plot to visually represent covariate balance on the exposure both before and after weighting. The script will generate these plots.\nWeighting Algorithm Statistics: Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit. The script I gave you will generate this information\n\n\n\nGreifer, Noah. 2023. WeightIt: Weighting for Covariate Balance in Observational Studies.\nExample:\n\nWe estimated propensity scores by fitting a model for the exposure A as it is predicted by the set of baseline covariates defined by L. Because we are interested in effect modification by group, we fit different propensity score models for within strata of G using the subgroup command of the WeightIt package. Thus the propensity score is the the probability of receiving a value of a treatment (A=a) conditional on the covariates L, and stratum within G. We compared balance using the following methods of weighting: “ebal” or entropy balancing, “energy” or energy balancing, and “ps” or traditional inverse probability of weighting balancing. Of these methods “ebal” performed the best. Table X and Figure Y present the results of the ebalancing method.\n\n\nInterpretation of Propensity Scores: we interpret the proposensity scores as yeilding good balance across the exposure conditions.\nOutcome Regression Model: Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation. Example\n\n\nWe fit a linear model using maximum likelihood estimation with the outcome Y predicted by the exposure A. We interacted the exposure with all baseline confounders L. Continuous baseline confounders were converted to z-scores, whereas categorical exposures were not. Also interacted with all baseline confounders was a term for the subgroup, which was also interacted with the exposure and baseline covariates. This allowed uas to flexibily fit non-linearities for the modification of the effect of the exposure within levels of the cultural group strata of interest. We note that model coefficients have no interpretation in this context so are not reported. The remaining steps of Doubly-Robust estimation were performed as outlined in the Method section. We calculated confidence intervals and standard errors, using the clarify package in R, which relies on simulation based inference for these quantities of interest (Greifer et al. 2023)\n\nGreifer, Noah, Steven Worthington, Stefano Iacus, and Gary King. 2023. Clarify: Simulation-Based Inference for Regression Models. https://iqss.github.io/clarify/.\n\n\nReport the causal estimates.\n\nATE contrasts for groups in setting the exposure to for each group in setting level A = a and A = a*\ndifferences between groups in the magnitude of the effects. (ATE_group 1 - ATE_group_2)\n\nReport the E-value: how sensitive are your results to unmeasured confounding? Hint: see the code below. I’ve substantially automated this task."
  },
  {
    "objectID": "content/step-by-step-reporting-guide.html#discussion",
    "href": "content/step-by-step-reporting-guide.html#discussion",
    "title": "Template: Stratified Causal Estimatation",
    "section": "Discussion",
    "text": "Discussion\nMake sure to hit these points:\nConsider the following ideas about what to discuss in one’s findings. The order of exposition might be different.\n\nSummary of results: What did you find?\nInterpretation of E-values: Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.\nCausal Effect Interpretation: What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.\nComparison of Subgroups: Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.\nUncertainty and Confidence Intervals: Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.\nGeneralisability and Transportability: Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)\nAssumptions and Limitations: Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.\nTheoretical Relevance: How are these findings relevant to existing theories.\nReplication and Future Research: Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.\nReal-world Implications: Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;!–  –&gt;\n&lt;!–  –&gt;\n&lt;!–  –&gt;\n&lt;!–  –&gt;"
  },
  {
    "objectID": "content/07-content.html",
    "href": "content/07-content.html",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "",
    "text": "Note\n\n\n\nRequired - (Hernan and Robins 2024) Chapters 4-5 link\nOptional - (Tyler J. VanderWeele and Robins 2007a) link - (Tyler J. VanderWeele 2009) link"
  },
  {
    "objectID": "content/07-content.html#if-you-learning-nothing-else-from-this-course",
    "href": "content/07-content.html#if-you-learning-nothing-else-from-this-course",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "If you learning nothing else from this course…",
    "text": "If you learning nothing else from this course…\nTo answer a psychological question we must first ask it."
  },
  {
    "objectID": "content/07-content.html#causal-inference-begins-by-stating-a-counterfactual-contrast",
    "href": "content/07-content.html#causal-inference-begins-by-stating-a-counterfactual-contrast",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Causal inference begins by stating a counterfactual contrast",
    "text": "Causal inference begins by stating a counterfactual contrast\nIn the simpliest case, we calculate the contrast between two or more “treatments” or equivalently “exposures”:\n\n\\text{Average Treatment Effect} = \\mathbb{E}[Y(a^*) -Y(a)]\n\n\nAfter Stating the Causal Interest, We State the Conditions Needed for Identifying This Effect from Data\nIn observational studies, the next step is to identify this effect by controlling for common causes of both the treatment and outcome (or proxies of such common causes). The regression standardization formula is:\n\n\\widehat{\\text{ATE}} = \\int \\left( \\mathbb{E}[Y(a^*) \\mid L] - \\mathbb{E}[Y(a) \\mid L] \\right) dP(L)\n\nWhere:\n\nStatistical Estimand: \\widehat{\\text{ATE}}, is the estimated average treatment effect.\n\\mathbb{E}[Y(a^*) \\mid L]: is the expected value (mean) of the outcome variable Y when the treatment a^* is applied, given the confounders L.\n\\mathbb{E}[Y(a) \\mid L]: is the expected value of Y when the treatment a is applied, given L.\n\\mathbb{E}[Y(a^*) \\mid L] - \\mathbb{E}[Y(a) \\mid L]: is the difference in the expected treatments, controlling for L.\n\\int (...) dP(L): dP(L) is an integral (remember high school math?). Integrals give us areas under curves. Here the area is a distribution of probabilities. To obtain valid inference, the treatment effect is computed over all the probability distribution of L in the population.\n\n\n\nSo, in the simplest possible terms\nUnderstanding causal inference is fundamentally about comparing what happened with what could have happened an average under different conditions or treatments in some population, while carefully accounting for factors that might confound or distort the comparison that interests us (i.e. that might give a false answer to the question we asked)."
  },
  {
    "objectID": "content/07-content.html#what-do-the-words-moderation-and-interaction-mean",
    "href": "content/07-content.html#what-do-the-words-moderation-and-interaction-mean",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "What do the words “Moderation” and “Interaction” mean?",
    "text": "What do the words “Moderation” and “Interaction” mean?\nWe here these words used freely in psychology. What do they mean? Causal inference allows us to be precise.\nLet’s set the term moderation to the side, and in its place consider “effect-modification.” Our task today is to use counterfactual notation to distinguish between two concepts:\n\nInteraction\nEffect-modification"
  },
  {
    "objectID": "content/07-content.html#interaction",
    "href": "content/07-content.html#interaction",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Interaction",
    "text": "Interaction\nAn interaction is a joint intervention\nWhen assessing “interaction” we are interested in the combined effect of two interventions (two “treatments” or “exposures”).\nCall these treatments, A and B. Call the outcome Y.\nRecall that in potential outcomes terminology, we defined the potential outcome under treatment A = \\tilde{a}:\n\nY(\\tilde{a})\n\nAnd we identify Y(\\tilde{a}) from data using the consistency assumption: Y_i(\\tilde{a}) = (Y_i |A_i = \\tilde{a}), assuming that Y_i(\\tilde{a})\\coprod A|L, where, again, L donotes a set of measured covariates sufficient to insure no confounding (no common causes), or equivalently, no open backdoor path between A and Y.\nA joint intervention of two treatments, call them A and B, which may act on Y, requires that we extend our notation:\n\nY(\\tilde{a}, \\tilde{b})\n This is the effect on Y when A is set to \\tilde{a} amd B is set to \\tilde{b}.\nIn addition to requiring Y_i(\\tilde{a}) = (Y_i \\mid A_i = \\tilde{a}), assuming that Y_i(\\tilde{a}) \\coprod A \\mid L, we require that for all i \\in 1\\dots N individuals in the target population, both Y_i(\\tilde{b}) = (Y_i \\mid B_i = \\tilde{b}), and that Y_i(\\tilde{b}) \\coprod B \\mid Q, where Q denotes a set of confounders sufficient to ensure no confounding for the effect of B on Y.\nNotably, the sets L and Q may have overlapping variables, which in set notation we write:\n\nL \\cap Q \\not\\equiv \\emptyset\n\nThat is the union of L and Q does not imply the empty set, which implies that identification may be harder when there are interactions. Statistical estimation is more difficult too, but we’ll ignore that.\n\nHow do we define such a contrast between two interventions of equal status in our model?\nConsider the effect of beliefs in Big Gods (treatment, denoted A) on social complexity (outcome, denotedY), potentially influenced by a culture’s monumental architecture (treatment, denoted B). Suppose we wish to assess the individual and combined effects of A and B on the difference scale. Let assume the treatments are binary variables.\nIn the counterfactual framework, we say there is evidence for interaction only if the following inequality were to hold:\n\\bigg(\\underbrace{\\mathbb{E}[Y(1,1)]}_{\\text{joint exposure}} - \\underbrace{\\mathbb{E}[Y(0,0)]}_{\\text{neither exposed}}\\bigg) - \\bigg[ \\bigg(\\underbrace{\\mathbb{E}[Y(1,0)]}_{\\text{only A exposed}} - \\underbrace{\\mathbb{E}[Y(0,0)]}_{\\text{neither exposed}}\\bigg) + \\bigg(\\underbrace{\\mathbb{E}[Y(0,1)]}_{\\text{only B exposed}} - \\underbrace{\\mathbb{E}[Y(0,0)]}_{\\text{neither exposed}} \\bigg)\\bigg] \\neq 0 \nExpanding the terms inside the brackets:\n \\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(0,0)] - \\mathbb{E}[Y(1,0)] + \\mathbb{E}[Y(0,0)] - \\mathbb{E}[Y(0,1)] + \\mathbb{E}[Y(0,0)] \nAnd cancelling \\mathbb{E}[Y(0,0)], which appears three times, once with a minus sign and twice with a plus sign, simplifies to:\n \\mathbb{E}[Y(1,1)] - \\mathbb{E}[Y(1,0)] - \\mathbb{E}[Y(0,1)] + \\mathbb{E}[Y(0,0)] \nAnd we define interaction on the additive scale:\n \\underbrace{\\mathbb{E}[Y(1,1)]}_{\\text{joint exposure}} - \\underbrace{\\mathbb{E}[Y(1,0)]}_{\\text{only A exposed}} - \\underbrace{\\mathbb{E}[Y(0,1)]}_{\\text{only B exposed}} + \\underbrace{\\mathbb{E}[Y(0,0)]}_{\\text{neither exposed}} \\neq 0 \nThe estimand is net interaction effect, after accounting for the individual effects of A and B, as well as the baseline where neither treatment A nor treatment B is given.\nA positive value would indicate evidence for additive interaction. A negative value would indicate evidence for sub-additive interaction. A value near zero would imply no reliable evidence for interaction.\nNote that the order of the terms does not matter:\n\nY(\\tilde{a}, \\tilde{b})\\equiv Y(\\tilde{b}, \\tilde{a})\n\n\nHaving defined the causal estimand, we next consider what would be needed to identify it using data?\nFor this we can write our causal diagram. Figure 1 describes the structure of the identification problem:\n\n\n\n\n\n\n\n\nFigure 1: This diagram presents the individual and joint effects of two exposures, A and B, on outcome Y. We assume that A and B are causally independent. If either exposure affects the other, then we may conduct effect-modification analysis or mediation analysis, but we should avoid causal interaction analysis. The diagram includes confounders L and W. Control for these confounders is necessary to close the backdoor paths that relate each exposure, A and B, to the outcome. Each exposure has equal status in our model: Y(a,b) = Y(b,a). The red path denotes paths of confounding.\n\n\n\n\n\nHere, Figure 1 clarifies the need to evaluate two sources of counfounding, one for each intervention (A and B).\nBy adjusting for L_{0} we obtain an unbiased estimate of the A\\to Y path.\nBy adjusting for Q_{0} we obtain an unbiased estimate of the B\\to Y path. As indicated in Figure 2, we must condition on both L_{0} and Q_{0} to identify causal interaction conceived as a joint interaction.\n\n\n\n\n\n\n\n\n\n\nFigure 2: We adjust for confounding in causal interaction analysis by adjusting for all confounders of the A to Y path as well as all for the B to Y path. The box over the confounders indicates the biasing paths are closed.\n\n\n\n\n\nConsider the following set of plausible confounders:\nL: variables in L that might confound the relationship between beliefs in Big Gods and social complexity:\n\nGeneral religiosity: prevalence of religion might influence both the belief in Big Gods and social complexity.\nCultural norms and values: ingrained social norms and values, not any part of religion.\nHistorical path dependent events: e.g. conquest.\nEducation: affects religious beliefs and the complexity.\nEconomic development: economic conditions might whether people prefer religious practices or resource intensive hobbies and also, social complexity.\nPolitical stability: stable governance can influence both the proliferation of religious practices and the development of complex social structures\nPolitical complexity in the past: huge confounder, must be adjusted for.\nBeliefs in big gods in the past: huge confounder, must be adjusted for.\n\nQ: variables in Q that that might confound the relationship between monumental architecture and social complexity:\n\nTechnology: for constructing of monumental architecture and managing social complexity.\nEconomic resources: as above (overlap)\nHistorical path dependent events: e.g. conquestm as above\nLabour: the availability of builders, slaves, etc.\nGeography: natural resources can affect a society’s ability to build monumental structures and its social development.\nCultural norms and values: ingrained social norms and values, not any part of religion.\nPolitical complexity in the past: huge confounder, must be adjusted for.\nBeliefs in big gods in the past: huge confounder, must be adjusted for.\n\nAs we see:\n\nL \\cap Q \\not\\equiv \\emptyset\n\nHowever, the set of control variables are larger, and note, we are assuming that monumental architecture and big God beliefs do not affect each other."
  },
  {
    "objectID": "content/07-content.html#effect-modification",
    "href": "content/07-content.html#effect-modification",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Effect Modification",
    "text": "Effect Modification\nIt is often scientifically interesting to consider whether treatment effects vary over levels of other variable without imagining a double intervention. Broadly, we will think of “effect-modification” as a set of related and overlapping concepts pertaining to the understanding variability of a single effect within a population.\n\nHeterogeneous Treatment Effects – a broad concept of effect-modification\nHeterogeneous Treatment Effects (HTE) refer to settings where treatment effects vary across individuals or subgroups within a study population. This variability can arise from differences in baseline characteristics, environmental conditions, histories, …. much of which is unmeasured.\nAppendix A discusses the challenges in identifying HTE from data, but we already know that individual causal effects are not typically identifiable, and so heteroeneous treatment effects, at the limit of individual causal effects, are elusive.\n\n\nConditional Average Treatment Effect (CATE) – a narrower concept of effect-modification.\nWe might be interested estimating average treatment effects within specific levels of measured covariates\nWhen our focus is estimation of the average treatment effect conditional on a specific level of a covariate or set of covariates. Our causal estimand is often written:\n\\text{CATE}(x) = E[Y(1) - Y(0) | X = x]\nwhere X = x, where X denotes the level of a measured covariate or covariates of interest.\nThe question: how does a causal effect vary within the population defined by levels of stratum X=x\n\n\nComparing Effect Heterogenity in Groups.\nWe might be interested in the following causal quantity (estimand), which compares two conditional average treatment effects between levels defined by G = \\tilde{g}:\n{\\gamma} = \\overbrace{\\big( \\mathbb{E}[Y(a^*)|G=g] - \\mathbb{E}[Y(a)|G=g] \\big)}^{{\\delta_g}} - \\overbrace{\\big(\\mathbb{E}[Y(a^*)|G=g^{\\prime}]- \\mathbb{E}[Y(a)|G=g']\\big)}^{{\\delta_{g^{\\prime}}}}\nSuppose A is the treatment, G is the effect-modifier, and Y is the outcome. The analysis of effect-modification assesses whether the effect of A on Y is different across levels of G (i.e., whether the effect of A on Y is different when G = g_1 compared to when G = g_2).\nWhat do we need to identify such effects? Note that G here is not an intervention variable. It might not be coherent to imagine that G can be intervened upon.\nFigure 3 is a causal diagram. Imagine we are intereste in whether the effect of A on Y differs across levels of G. Because we are not interested in the causal effect of G as such, but rather, how the effect of A varies across G, we need not adjust by Q. However, which variables shall we include in our model? What will happen if we assess the G by examining a regression coefficient? Suppose L were not a confounder of A to Y. How then should we interpret our model?\n\n\n\n\n\n\n\n\nFigure 3: Imagine A is an experiment. How shall we investigate effect modification of A on Y by Z? Can you see why regression coefficients will not work?\n\n\n\n\n\nOften, it is useful to obtain causal effects by restricting to one level of a population. Where G denotes a society, consider:\n\nCausal effect within North American societies (G=1): \\delta_{g_1} = \\mathbb{E}[Y(1)|G= g_1] - \\mathbb{E}[Y(0)|G = g_1]\n\nHere, \\delta_{g_2} represents the estimated causal effect of changing the exposure from A = 0 to A = 1 within the North American societies.\n\nCausal effect within Continental societies (G=g_2):\n\\delta_{g2} = \\mathbb{E}[Y(1)|G=g_2] - \\mathbb{E}[Y(0)|G=g_2]\nSimilarly, {\\delta}_{g_2} denotes the estimated causal effect for the Continental societies.\nComparing causal effects across groups:\n{\\gamma} = {\\delta}_{g_1} - {\\delta}_{g_2}\n\nThe quantity {\\gamma} defines the difference in the causal estimands between the two groups. A nonzero \\hat{\\gamma} indicates effect-modification, suggesting that the effect of changing the exposure differs between the two groups. If we were to observe that \\hat{\\gamma} \\neq 0, this would provide evidence for variability in the effect of the exposure on the outcome in different groups. Note that the causal effect for one group might be indistinguishable from zero, and yet we might nevertheless find evidence for effect-modification if the comparison group exhibits reliably different responses from the contrast group that is indistinguishable from zero.\nThat’s it, we now know our causal quantity of interest. Next week, we’ll develop our statistical estimands, estimators, and begin evaluating effect-modification by groups.\n\n\nSummary of what we learned\n\nInteraction targets a joint intervention in a population\nEffect modificiation targets how a single intervention varies by groups within a population\n\nNote, to obtain the group-wise contrasts, we must be able to imagine the groups as belonging to a larger population. When thinking of people, we all belong Later we shall consider how measurement complicates this assumption, even if all humans belong to the same species…"
  },
  {
    "objectID": "content/07-content.html#lab-part-1-setting-up-your-data",
    "href": "content/07-content.html#lab-part-1-setting-up-your-data",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Lab Part 1: Setting up your data",
    "text": "Lab Part 1: Setting up your data\n\nSet up your libraries\n\nlibrary(\"margot\")\nlibrary(\"tidyverse\")\nlibrary(\"ggplot2\")\nlibrary(\"here\")\nlibrary(\"skimr\")\nif (!require(gtsummary)) install.packages(\"gtsummary\")\nif (!require(janitor)) install.packages(\"janitor\")\n\n\n# if you need to update the margot package, uncomment and do this\n# devtools::install_github(\"go-bayes/margot\")\n#devtools::install_github(\"go-bayes/margot\")\n\n\n\nSet up a path to a folder in your directory\nThis will allow you to save the outputs of models and other information, which will be handy when you are producing your manuscript. Call this push_mods\n\n### Set up a path to a folder in your directory \n\n# create a folder called saved and make a path like this\npush_mods &lt;- here::here('/Users/joseph/Library/CloudStorage/Dropbox-v-project/data/saved')\n\n# view it (will be different for you)\npush_mods\n\n[1] \"/Users/joseph/Library/CloudStorage/Dropbox-v-project/data/saved\"\n\n# another option\n# saveRDS(object, here::here(push_mods, \"object\"))\n\n\n\nInitial Data Wrangling to select the study sample\n\nWhere to find variable names information\nFind it the data directory here: https://osf.io/75snb/\nAlso see here: https://github.com/go-bayes/templates/tree/main/method\n\n\nThink, what are my eligibility criteria?\n\nParticipated in at baseline\nParticipated at treatment wave\nMay have been lost to follow up at the end of the study\nFull information on the treatment variable (think about this…)\n\n\nlibrary(margot)\n# eliminate haven labels\ndf_nz &lt;- as.data.frame(df_nz)\ndf_nz &lt;- haven::zap_formats(df_nz)\ndf_nz &lt;- haven::zap_label(df_nz)\ndf_nz &lt;- haven::zap_widths(df_nz)\n\n# name output folder\npush_mods &lt;- here::here(\"outputs\")\n\n# set exposure name\nname_exposure &lt;-  \"perfectionism\"\n\n# obtain ids for individuals who participated in 2018 and have no missing baseline exposure\nids_2018 &lt;- df_nz %&gt;%\n   dplyr::filter(year_measured == 1, wave == 2018) %&gt;%\n   dplyr::filter(!is.na(!!sym(name_exposure))) |&gt; # criteria, no missing\n  pull(id)\n\n# obtain ids for individuals who participated in 2019\nids_2019 &lt;- df_nz %&gt;%\n   dplyr::filter(year_measured == 1, wave == 2019) %&gt;%\n   dplyr::filter(!is.na(!!sym(name_exposure))) |&gt; # criteria, no missing\n  pull(id)\n\n# intersect IDs from 2018 and 2019 to ensure participation in both years\nids_2018_2019 &lt;- intersect(ids_2018, ids_2019)\n\n# data wrangling\ndat_long &lt;- df_nz |&gt;\n  dplyr::filter(id %in% ids_2018_2019 &\n                  wave %in% c(2018, 2019, 2020)) |&gt;\n  arrange(id, wave) |&gt;\n  select(\n    \"id\",\n    \"wave\",\n    \"year_measured\",\n    \"age\",\n    \"male\",\n    \"born_nz\",\n    \"eth_cat\",\n    #factor(EthCat, labels = c(\"Euro\", \"Maori\", \"Pacific\", \"Asian\")),\n    \"employed\",\n    # Are you currently employed? (this includes self-employment or casual work)\n    \"edu\",\n    # \"gen_cohort\",\n    \"household_inc\",\n    \"partner\",\n    # 0 = no, 1 = yes\n    \"parent\",\n    \"alert_level_combined_lead\", # see bibliography\n    # 0 = no, 1 = yes\n    \"political_conservative\", # see nzavs sheet\n    \"hours_exercise\", # see nzavs sheet\n    \"agreeableness\", \n    # Mini-IPIP6 Agreeableness (also modelled as empathy facet)\n    # Sympathize with others' feelings.\n    # Am not interested in other people's problems.\n    # Feel others' emotions.\n    # Am not really interested in others.\n    \"conscientiousness\",\n    # see mini ipip6\n    # Get chores done right away.\n    # Like order.\n    # Make a mess of things.\n    # Often forget to put things back in their proper place.\n    \"extraversion\",\n    # Mini-IPIP6 Extraversion\n    # Am the life of the party.\n    # Don't talk a lot.\n    # Keep in the background.\n    # Talk to a lot of different people at parties.\n    \"honesty_humility\",\n    # see mini ipip6\n    # Would like to be seen driving around in a very expensive car.\n    # Would get a lot of pleasure from owning expensive luxury goods.\n    # Feel entitled to more of everything.\n    # Deserve more things in life.\n    \"openness\",\n    # see mini ipip6\n    # Have a vivid imagination.\n    # Have difficulty understanding abstract ideas.\n    # Do not have a good imagination.\n    # Am not interested in abstract ideas.\n    \"neuroticism\",\n    # see mini ipip6\n    # Have frequent mood swings.\n    # Am relaxed most of the time.\n    # Get upset easily.\n    # Seldom feel blue.\n    \"modesty\",\n    # # see mini ipip6\n    # # I want people to know that I am an important person of high status,\n    # # I am an ordinary person who is no better than others.\n    # # I wouldn’t want people to treat me as though I were superior to them.\n    # # I think that I am entitled to more respect than the average person is\n    #\"w_gend_age_ethnic\",\n    \"sample_weights\", # see nzavs sheet\n    \"neighbourhood_community\",\n    # #I feel a sense of community with others in my local neighbourhood.\n    \"belong\", # see nzavs sheet\n    \"rural_gch_2018_l\",# see nzavs sheet\n    \"support\",\n    # \"support_help\",\n    # # 'There are people I can depend on to help me if I really need it.\n    # \"support_turnto\",\n    # # There is no one I can turn to for guidance in times of stress.\n    # \"support_rnoguidance\",\n    #There is no one I can turn to for guidance in times of stress.\n    \"perfectionism\",\n    \"religion_religious\",\n    \"kessler_latent_depression\",\n    \"kessler_latent_anxiety\"\n  ) |&gt;\n  mutate(\n    #initialize 'censored'\n    censored = ifelse(lead(year_measured) == 1, 1, 0),\n    \n    # modify 'censored' based on the condition; no need to check for NA here as 'censored' is already defined in the previous step\n    censored =  ifelse(is.na(censored) &\n                         year_measured == 1, 1, censored)\n  ) |&gt;\n  select(-year_measured) |&gt;\n  dplyr::mutate(\n    # rescale these variables, to get all variables on a similar scale\n    # otherwise your models can blow up, or become uninterpretable. \n    household_inc_log = log(household_inc + 1),\n    hours_exercise_log = log(hours_exercise + 1)  ) |&gt;\n  dplyr::select(\n    -c(\n      household_inc,\n      hours_exercise)\n  ) |&gt;\n  droplevels() |&gt;\n  # dplyr::rename(sample_weights = w_gend_age_ethnic,\n  #               sample_origin =  sample_origin_names_combined) |&gt;\n  arrange(id, wave) |&gt;\n  mutate(\n  rural_gch_2018_l = as.numeric(as.character(rural_gch_2018_l)),\n  #   parent = as.numeric(as.character(parent)),\n  partner = as.numeric(as.character(partner)),\n  born_nz = as.numeric(as.character(born_nz)),\n  censored = as.numeric(as.character(censored)),\n  employed = as.numeric(as.character(employed))\n  ) |&gt;\n  droplevels() |&gt;\n  data.frame() |&gt;\n  droplevels() |&gt;\n  arrange(id, wave) |&gt;\n  data.frame()\n\n# check n in this sample\nn_participants &lt;- skimr::n_unique(dat_long$id)\n\n\n# make number pretty\nn_participants&lt;- prettyNum(n_participants,big.mark=\",\")\n\n# save this so that you can use it in your manuscript\nmargot::here_save(n_participants, \"n_participants\")\n\nObject saved to: /Users/joseph/GIT/psych-434-2025/outputs/n_participants.rds\nObject size: 0.00 MB\n👍 Save operation completed successfully!\n\n# try reading \nn_participants_did_it_work_question_mark &lt;- margot::here_read(\"n_participants\")\n\nObject read from: /Users/joseph/GIT/psych-434-2025/outputs/n_participants.rds\nObject size: 0.00 MB\n👍 Read operation completed successfully!\n\n# view\n# n_participants_did_it_work_question_mark\n\nThere are N = 14,439 participants.\n\n\n\nDefine your baseline covariates, treatment (exposure), and outcome\n\n# for example \nbaseline_vars = c(\"age\", \"male\", \"edu\", \"eth_cat\", \"partner\", \"employed\", \"born_nz\", \"neighbourhood_community\", \"household_inc_log\",\n\"parent\", \"religion_religious\", \"rural_gch_2018_l\",\"sample_weights\", \"employed\", \"alert_level_combined_lead\")\n\n# treatment\nexposure_var = c(\"perfectionism\", \"censored\") # we will use the censored variable later\n\n# outcome, can be many\noutcome_vars = c(\"kessler_latent_anxiety\", \"kessler_latent_depression\")\n\n\n\nMake your baseline table\n\nlibrary(gtsummary)\n# the setdiff command allows us to remove names from the baseline vars list that we do not want\nbase_var &lt;-\n  setdiff(baseline_vars, c(\"censored\", \"sample_weights\", \"alert_level_combined_lead\", outcome_vars))\n\n\n#  we only want the data at baseline \n\n# select only baseline wave\ndt_18 &lt;- dat_long |&gt; \n  dplyr::filter(wave == 2018)\n\n\n# get only the baseline variables for the table\nselected_base_cols &lt;-\n  dt_18 |&gt; select(all_of(base_var))\n\n#check\ncolnames_use &lt;- colnames(selected_base_cols)\ncolnames_use\n\n [1] \"age\"                     \"male\"                   \n [3] \"edu\"                     \"eth_cat\"                \n [5] \"partner\"                 \"employed\"               \n [7] \"born_nz\"                 \"neighbourhood_community\"\n [9] \"household_inc_log\"       \"parent\"                 \n[11] \"religion_religious\"      \"rural_gch_2018_l\"       \n\n# # aside to get different names in lists\n# everything_better_cols &lt;- c(colnames_use, \"inkuk\")\n# everything_better_cols\n# \n# # get rid of name\n# everything_worse_cols &lt;- setdiff(everything_better_cols, \"inkuk\")\n\n# baseline table\nlibrary(gtsummary)\n\n\n# this is just a demo of another package, which can be useful for quick tables, less for your manuscripts\nno_miss_df &lt;- df_nz |&gt; \n  drop_na()\n\ntable1::table1( ~ perfectionism  | wave * eth_cat ,\n                data = no_miss_df,\n                overall = FALSE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2018\n\n\n2020\n\n\n\n\neuro\n(N=6165)\nmaori\n(N=717)\npacific\n(N=156)\nasian\n(N=305)\neuro\n(N=4690)\nmaori\n(N=493)\npacific\n(N=95)\nasian\n(N=226)\n\n\n\n\nperfectionism\n\n\n\n\n\n\n\n\n\n\nMean (SD)\n3.06 (1.32)\n3.15 (1.34)\n3.22 (1.31)\n3.47 (1.26)\n2.94 (1.33)\n3.12 (1.44)\n3.20 (1.34)\n3.36 (1.37)\n\n\nMedian [Min, Max]\n2.97 [1.00, 7.00]\n3.00 [1.00, 7.00]\n3.04 [1.00, 6.97]\n3.35 [1.00, 7.00]\n2.69 [1.00, 7.00]\n2.98 [1.00, 7.00]\n3.00 [1.00, 6.69]\n3.34 [1.00, 6.64]\n\n\n\n\n\n\ntable_baseline &lt;- selected_base_cols |&gt; \n  janitor::clean_names(case = \"title\") |&gt; \n  tbl_summary(\n    missing = \"ifany\",\n    percent = \"column\",\n    statistic = list(\n      all_continuous() ~ c(\n        \"{mean} ({sd})\", # Mean and SD\n        \"{min}, {max}\", # Range (Min, Max)\n        \"{p25}, {p75}\" # IQR (25th percentile, 75th percentile)\n      )\n    ),\n    type = all_continuous() ~ \"continuous2\"\n  ) |&gt;\n  modify_header(label = \"**Exposure + Demographic Variables**\") |&gt; # update the column header\n  bold_labels() \n\n\n# baseline\ntable_baseline\n\n\n\n\n\n\n\n\n\n\n\nExposure + Demographic Variables\nN = 14,4391\n\n\n\n\nAge\n\n\n\n\n    Mean (SD)\n50 (14)\n\n\n    Min, Max\n18, 94\n\n\n    Q1, Q3\n41, 61\n\n\nMale\n5,238 (36%)\n\n\nEdu\n\n\n\n\n    Mean (SD)\n5.38 (2.72)\n\n\n    Min, Max\n0.00, 10.00\n\n\n    Q1, Q3\n3.00, 7.00\n\n\n    Unknown\n110\n\n\nEth Cat\n\n\n\n\n    euro\n11,835 (83%)\n\n\n    maori\n1,526 (11%)\n\n\n    pacific\n314 (2.2%)\n\n\n    asian\n655 (4.6%)\n\n\n    Unknown\n109\n\n\nPartner\n10,661 (76%)\n\n\n    Unknown\n399\n\n\nEmployed\n11,466 (80%)\n\n\n    Unknown\n22\n\n\nBorn Nz\n11,398 (79%)\n\n\n    Unknown\n25\n\n\nNeighbourhood Community\n\n\n\n\n    Mean (SD)\n4.23 (1.66)\n\n\n    Min, Max\n1.00, 7.00\n\n\n    Q1, Q3\n2.99, 5.95\n\n\n    Unknown\n73\n\n\nHousehold Inc log\n\n\n\n\n    Mean (SD)\n11.41 (0.74)\n\n\n    Min, Max\n0.71, 14.40\n\n\n    Q1, Q3\n11.00, 11.92\n\n\n    Unknown\n655\n\n\nParent\n10,350 (72%)\n\n\n    Unknown\n8\n\n\nReligion Religious\n5,218 (36%)\n\n\n    Unknown\n19\n\n\nRural Gch 2018 l\n\n\n\n\n    1\n8,822 (62%)\n\n\n    2\n2,784 (19%)\n\n\n    3\n1,740 (12%)\n\n\n    4\n820 (5.7%)\n\n\n    5\n170 (1.2%)\n\n\n    Unknown\n103\n\n\n\n1 n (%)\n\n\n\n\n\n\n\n# save your baseline table\nmargot::here_save(table_baseline, \"table_baseline\")\n\nObject saved to: /Users/joseph/GIT/psych-434-2025/outputs/table_baseline.rds\nObject size: 0.00 MB\n👍 Save operation completed successfully!\n\n\n\n\nMake exposure wave table\n\n# get first and second wave\ndt_18_19 &lt;- dat_long |&gt; \n  dplyr::filter(wave == 2018 | wave == 2019) |&gt; \n  # we need to drop unused levels of the wave\n  droplevels()\n\n# get vars.\nselected_exposure_cols &lt;-\n  dt_18_19 %&gt;% select(\n    c(\n      \"perfectionism\",\n      \"wave\"\n    )\n  )\n\n# check\n#str(selected_exposure_cols)\n\n\nlibrary(gtsummary)\n\ntable_exposures &lt;- selected_exposure_cols %&gt;%\n  janitor::clean_names(case = \"title\") %&gt;% \n  labelled::to_factor() %&gt;%  # ensure consistent use of pipe operator\n  tbl_summary(\n    by = \"Wave\",  #specify the grouping variable. Adjust \"Wave\" to match the cleaned column name\n    missing = \"always\", \n    percent = \"column\",\n    # statistic = list(all_continuous() ~ \"{mean} ({sd})\")  # Uncomment and adjust if needed for continuous variables\n  ) %&gt;%\n  #  add_n() %&gt;%  # Add column with total number of non-missing observations\n  modify_header(label = \"**Exposure Variables by Wave**\") %&gt;%  # Update the column header\n  bold_labels()\n\ntable_exposures\n\n\n\n\n\n\n\n\n\n\n\n\nExposure Variables by Wave\n2018 N = 14,4391\n2019 N = 14,4391\n\n\n\n\nPerfectionism\n3.00 (2.01, 4.02)\n2.99 (2.00, 4.02)\n\n\n    Unknown\n0\n0\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n# save baseline\nhere_save(table_exposures, \"table_exposures\")\n\nObject saved to: /Users/joseph/GIT/psych-434-2025/outputs/table_exposures.rds\nObject size: 0.00 MB\n👍 Save operation completed successfully!\n\ntable_exposures\n\n\n\n\n\n\n\n\n\n\n\n\nExposure Variables by Wave\n2018 N = 14,4391\n2019 N = 14,4391\n\n\n\n\nPerfectionism\n3.00 (2.01, 4.02)\n2.99 (2.00, 4.02)\n\n\n    Unknown\n0\n0\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\n\n\nTable for the outcome\n\n# outcome table -----------------------------------------------------------\ndt_18_20 &lt;- dat_long |&gt; \n  dplyr::filter(wave == 2018 | wave == 2020) |&gt; \n  droplevels()\n\nnames_outcomes_tab &lt;- setdiff(outcome_vars, dt_18_20)\nnames_outcomes_sorted &lt;- sort(names_outcomes_tab)\nnames_outcomes_final &lt;- names_outcomes_sorted # consistent workflow\n\n# better names if desirable\nselected_outcome_cols &lt;-\n  dt_18_20 %&gt;% select(all_of(names_outcomes_final),\n                      wave) \n# |&gt; # example if you want to rename your variables for the table\n#   rename(\n#     Social_belonging = belong,\n#     Annual_charity = charity_donate,\n#     Volunteering_hours = hours_charity,\n#     Community_gives_money_binary = community_money_binary,\n#     Community_gives_time_binary = community_time_binary,\n#     Family_gives_money_binary = family_money_binary,\n#     Family_gives_time_binary = family_time_binary,\n#     Friends_give_money_binary = friends_money_binary,\n#     Friends_give_time = friends_time_binary,\n#     Social_support = support,\n#     Sense_neighbourhood_community = neighbourhood_community\n#   )\n\n# order names correctly\nselected_outcome_cols &lt;- selected_outcome_cols %&gt;%\n  select(sort(names(selected_outcome_cols)))\n\n# checks\n# str(selected_outcome_cols)\n# colnames(selected_outcome_cols)\n\ntable_outcomes &lt;- selected_outcome_cols %&gt;%\n  janitor::clean_names(case = \"title\") %&gt;% \n  labelled::to_factor() %&gt;%  # ensure consistent use of pipe operator\n  tbl_summary(\n    by = \"Wave\",  #specify the grouping variable. Adjust \"Wave\" to match the cleaned column name\n    missing = \"always\", \n    percent = \"column\",\n    # statistic = list(all_continuous() ~ \"{mean} ({sd})\")  # Uncomment and adjust if needed for continuous variables\n  ) %&gt;%\n  #  add_n() %&gt;%  # Add column with total number of non-missing observations\n  modify_header(label = \"**Outcome Variables by Wave**\") %&gt;%  # Update the column header\n  bold_labels()\n\n\n# save\nmargot::here_save(table_outcomes, \"table_outcomes\")\n\nObject saved to: /Users/joseph/GIT/psych-434-2025/outputs/table_outcomes.rds\nObject size: 0.00 MB\n👍 Save operation completed successfully!\n\n# read if needed\ntable_outcomes &lt;- margot::here_read(\"table_outcomes\")\n\nObject read from: /Users/joseph/GIT/psych-434-2025/outputs/table_outcomes.rds\nObject size: 1.44 MB\n👍 Read operation completed successfully!\n\ntable_outcomes\n\n\n\n\n\n\n\n\n\n\n\n\nOutcome Variables by Wave\n2018 N = 14,4391\n2020 N = 14,4391\n\n\n\n\nKessler Latent Anxiety\n1.04 (0.65, 1.67)\n1.03 (0.65, 1.67)\n\n\n    Unknown\n148\n2,893\n\n\nKessler Latent Depression\n0.31 (0.01, 0.96)\n0.31 (0.01, 0.96)\n\n\n    Unknown\n152\n2,890\n\n\n\n1 Median (Q1, Q3)\n\n\n\n\n\n\n\n\n\n\nInspect the distribution of the exposure in treatment wave\n\n# select 2019 wave\ndt_19 &lt;- dat_long |&gt; dplyr::filter(wave == 2019)\n\n# mean\nmean_exposure &lt;-mean(dt_19$perfectionism, na.rm=TRUE)\n\n# median\nmedian_exposure &lt;-median(dt_19$perfectionism, na.rm=TRUE)\n\n# check if you like\n# median_exposure\n# mean_exposure\n\n# # generate bar plot\ngraph_density_of_exposure_up &lt;- margot::coloured_histogram_shift(\n  dt_19,\n  shift = \"up\",\n  col_name = \"perfectionism\",\n  binwidth = .25, \n  range_highlight = c(0,mean_exposure)\n)\n\n# show\ngraph_density_of_exposure_up\n\n\n\n\n\n\n\n# save\n#margot::here_save(graph_density_of_exposure_up, \"graph_density_of_exposure_up\")\n\n\n\nAnother Graph: Shift Interventions Up\n\nmargot::coloured_histogram(\n  dt_19,\n  col_name = \"perfectionism\",\n  binwidth = .25,\n  unit_of_change = 1,\n  scale_min = 1,\n  scale_max = 7,\n  highlight_range = \"both\"\n)\n\n\n\n\n\n\n\n\n\n\nCheck for change in the treatment (Positivity )\n\n#  select data from wave 18 and 19 \ndt_18_19_positivity &lt;- dat_long |&gt;\n  dplyr::filter(wave == 2018 | wave == 2019) |&gt;\n  dplyr::mutate(perfectionism_round = round(perfectionism, digits = 0)) |&gt;\n  dplyr::select(perfectionism_round, id, wave) |&gt;\n  droplevels()\n\nout &lt;-margot::create_transition_matrix(data = dt_18_19_positivity, state_var = \"perfectionism_round\", id_var = \"id\")\n\n\n# t_tab_2_labels &lt;- c(\"&lt; weekly\", \"&gt;= weekly\")\n# transition table\ntransition_table  &lt;- margot::transition_table(out)\n\n# for import later\n# margot::here_save(transition_table, \"transition_table\")\n\n\nprint(transition_table$table)\n\n\n\n|  From   | State 1 | State 2  | State 3  | State 4  | State 5 | State 6 | State 7 |\n|:-------:|:-------:|:--------:|:--------:|:--------:|:-------:|:-------:|:-------:|\n| State 1 | **893** |   484    |   194    |    40    |   16    |    3    |    2    |\n| State 2 |   657   | **1737** |   904    |   283    |   78    |    9    |    1    |\n| State 3 |   237   |   1073   | **1368** |   768    |   245   |   40    |    5    |\n| State 4 |   66    |   335    |   803    | **1076** |   523   |   108   |   10    |\n| State 5 |   24    |    77    |   253    |   531    | **579** |   223   |   26    |\n| State 6 |    7    |    9     |    38    |   106    |   205   | **216** |   53    |\n| State 7 |    2    |    1     |    5     |    8     |   25    |   45    | **48**  |\n\n\n\n\nExplanation for the table\n\ntransition_table$explanation\n\n[1] \"This transition matrix captures shifts in states across across the treatment intervals. Each cell in the matrix represents the count of individuals transitioning from one state to another. The rows correspond to the treatment at baseline (From), and the columns correspond to the state at the following wave (To). **Diagonal entries** (in **bold**) correspond to the number of individuals who remained in their initial state across both waves. **Off-diagonal entries** correspond to the transitions of individuals from their baseline state to a different state in the treatment wave.\\nA higher number on the diagonal relative to the off-diagonal entries in the same row indicates greater stability in a state. Conversely, higher off-diagonal numbers suggest more frequent shifts from the baseline state to other states.\""
  },
  {
    "objectID": "content/07-content.html#lab-part-2-simulation-to-clarify-why-the-distribution-of-effect-modifiers-matter-for-estimating-treatment-effects",
    "href": "content/07-content.html#lab-part-2-simulation-to-clarify-why-the-distribution-of-effect-modifiers-matter-for-estimating-treatment-effects",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Lab Part 2: Simulation to Clarify Why The Distribution of Effect Modifiers Matter For Estimating Treatment Effects",
    "text": "Lab Part 2: Simulation to Clarify Why The Distribution of Effect Modifiers Matter For Estimating Treatment Effects\nFirst, we load the stdReg library, which obtains marginal effect estimates by simulating counterfactuals under different levels of treatment (Sjölander 2016). If a treatment is continuous, the levels can be specified.\n\nSjölander, Arvid. 2016. “Regression Standardization with the R Package stdReg.” European Journal of Epidemiology 31 (6): 563–74. https://doi.org/10.1007/s10654-016-0157-3.\n\nLüdecke, Daniel, Mattan S. Ben-Shachar, Indrajeet Patil, and Dominique Makowski. 2020. “Extracting, Computing and Exploring the Parameters of Statistical Models Using R.” Journal of Open Source Software 5 (53): 2445. https://doi.org/10.21105/joss.02445.\nWe also load the parameters library, which creates nice tables (Lüdecke et al. 2020).\n\n# to obtain marginal effects\nlibrary(stdReg)\n# to create nice tables\nlibrary(parameters)\n\nNext, we write a function to simulate data for the sample and and target populations.\nWe assume the treatment effect is the same in the sample and target population. We will assume that the coefficient for the effect-modifier and the coefficient for interaction are the same. We assume no unmeasured confounding throughout the study. We assume only selective attrition of one effect modifier such that the baseline population differs from the sample population at the end of the study.\nThat is: the distribution of effect modifiers is the only respect in which the sample will differ from the target population.\nThis function will generate data under a range of scenarios.1\n1 See documentation in the margot package: Bulbulia (2024)\nBulbulia, J. A. 2024. Margot: MARGinal Observational Treatment-Effects. https://doi.org/10.5281/zenodo.10907724.\n\n# function to generate data for the sample and population, \n# along with precise sample weights for the population, there are differences \n# in the distribution of the true effect modifier but no differences in the treatment effect \n# or the effect modification.all that differs between the sample and the population is \n# the distribution of effect-modifiers.\n\n\n# reproducability\nset.seed(123)\n\n# simulate the data -- you can use different parameters\ndata &lt;- margot::simulate_ate_data_with_weights(\n  n_sample = 10000,\n  n_population = 100000,\n  p_z_sample = 0.1,\n  p_z_population = 0.5,\n  beta_a = 1,\n  beta_z = 2.5,\n  noise_sd = 0.5\n)\n\nskimr::skim(data)\n\n\n\n\n\nName\ndata\n\n\nNumber of rows\n100000\n\n\nNumber of columns\n7\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nData summaryVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nsample_data.y_sample\n0\n1\n0.74\n1.08\n-1.71\n0.01\n0.59\n1.21\n5.21\n▂▇▃▁▁\n\n\nsample_data.a_sample\n0\n1\n0.49\n0.50\n0.00\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nsample_data.z_sample\n0\n1\n0.09\n0.29\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nsample_data.weights\n0\n1\n0.98\n1.30\n0.56\n0.56\n0.56\n0.56\n5.00\n▇▁▁▁▁\n\n\npopulation_data.y_population\n0\n1\n1.88\n1.60\n-2.09\n0.51\n1.76\n3.26\n6.01\n▁▇▆▆▁\n\n\npopulation_data.a_population\n0\n1\n0.50\n0.50\n0.00\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\npopulation_data.z_population\n0\n1\n0.50\n0.50\n0.00\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\n\n\n\nOk, we have generated both sample and population data.\nNext, we verify that the distributions of effect modifiers differ in the sample and in the target population:\n\n# obtain the generated data\nsample_data &lt;- data$sample_data\npopulation_data &lt;- data$population_data\n\n\n# check imbalance\ntable(sample_data$z_sample) # type 1 is rare\n\n\n   0    1 \n9055  945 \n\ntable(population_data$z_population) # type 1 is common\n\n\n    0     1 \n49916 50084 \n\n\nGood, the distributions differ. The simulation is working as intended.\nNext, consider the question: “What are the differences in the coefficients that we obtain from the study population at the end of study, as compared with the target population?”\nFirst, we obtain the coefficients for the sample. They are as follows:\n\n# model coefficients sample\nmodel_sample  &lt;-\n  glm(y_sample ~ a_sample * z_sample, data = sample_data)\n\n# summary\nparameters::model_parameters(model_sample, ci_method = \"wald\")\n\nParameter           | Coefficient |       SE |        95% CI | t(9996) |      p\n-------------------------------------------------------------------------------\n(Intercept)         |   -6.89e-03 | 7.38e-03 | [-0.02, 0.01] |   -0.93 | 0.350 \na sample            |        1.01 |     0.01 | [ 0.99, 1.03] |   95.84 | &lt; .001\nz sample            |        2.47 |     0.02 | [ 2.43, 2.52] |  104.09 | &lt; .001\na sample × z sample |        0.51 |     0.03 | [ 0.44, 0.57] |   14.82 | &lt; .001\n\n\nOk, let’s obtain the coefficients for the weighted regression of the sample. Notice that the coefficients are virtually the same:\n\n# model the sample weighted to the population, again note that these coefficients are similar \nmodel_weighted_sample &lt;-\n  glm(y_sample ~  a_sample  * z_sample,\n      data = sample_data,\n      weights = weights)\n\n# summary\nsummary(parameters::model_parameters(model_weighted_sample, ci_method =\n                                       \"wald\"))\n\nParameter           | Coefficient |        95% CI |      p\n----------------------------------------------------------\n(Intercept)         |   -6.89e-03 | [-0.03, 0.01] | 0.480 \na sample            |        1.01 | [ 0.98, 1.04] | &lt; .001\nz sample            |        2.47 | [ 2.45, 2.50] | &lt; .001\na sample × z sample |        0.51 | [ 0.47, 0.55] | &lt; .001\n\nModel: y_sample ~ a_sample * z_sample (10000 Observations)\nSigma: 0.494 (df = 9996)\n\n\nWe might be tempted to infer that weighting wasn’t relevant to the analysis. However, we’ll see that such an interpretation would be a mistake.\nNext, let us obtain model coefficients for the population. Note again there is no difference – only narrower errors owing to the large sample size.\n\n# model coefficients population -- note that these coefficients are very similar. \nmodel_population &lt;-\n  glm(y_population ~ a_population * z_population, data = population_data)\n\nparameters::model_parameters(model_population, ci_method = \"wald\")\n\nParameter                   | Coefficient |       SE |        95% CI | t(99996) |      p\n----------------------------------------------------------------------------------------\n(Intercept)                 |    2.49e-03 | 3.18e-03 | [ 0.00, 0.01] |     0.78 | 0.434 \na population                |        1.00 | 4.49e-03 | [ 0.99, 1.01] |   222.35 | &lt; .001\nz population                |        2.50 | 4.49e-03 | [ 2.49, 2.51] |   556.80 | &lt; .001\na population × z population |        0.50 | 6.35e-03 | [ 0.49, 0.51] |    78.80 | &lt; .001\n\n\nAgain, there is no difference. That is, we find that all model coefficients are practically equivalent. The different distribution of effect modifiers does not result in different coefficient values for the treatment effect, the effect-modifier “effect,” or the interaction of effect modifier and treatment.\nConsider why this is the case: in a large sample where the causal effects are invariant – as we have simulated them to be – we will have good replication in the effect modifiers within the sample, so our statistical model can recover the coefficients for the population – no problem.\nHowever, in causal inference, we are interested in obtaining the marginal effect of the treatment. That is, we seek an estimate for the counterfactual contrast in which everyone in a pre-specified population was subject to one level of treatment compared with a counterfactual condition in which everyone in a population was subject to another level of the same treatment. When the sample population differs in the distribution of effect modifiers from the target population effect, the marginal effect estimates will typically differ.\nTo see this, we use the stdReg package to recover marginal effect estimates, comparing (1) the sample ATE, (2) the true oracle ATE for the population, and (3) the weighted sample ATE. We will use the outputs of the same models above. The only difference is that we will calculate marginal effects from these outputs. We will contrast a difference from an intervention in which everyone receives treatment = 0 with one in which everyone receives treatment = 1, however, this choice is arbitrary, and the general lessons apply irrespective of the estimand.\nFirst, consider this ATE for the sample population.\n\n# What inference do we draw?  We cannot say the models are unbiased for the marginal effect estimates. \n# regression standardisation \nlibrary(stdReg) # to obtain marginal effects \n\n\n# obtain sample ate\nfit_std_sample &lt;-\n  stdReg::stdGlm(model_sample, data = sample_data, X = \"a_sample\")\n\n# summary\nsummary(fit_std_sample,\n        contrast = \"difference\",\n        reference = 0)\n\n\nFormula: y_sample ~ a_sample * z_sample\nFamily: gaussian \nLink function: identity \nExposure:  a_sample \nReference level:  a_sample = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00     0.0000       0.00       0.00\n1     1.06     0.0101       1.04       1.08\n\n\nThe treatment effect is given as a 1.06 unit change in the outcome across the sample population, with a confidence interval from 1.04 to 1.08.\nNext, we obtain the true (oracle) treatment effect for the population under the same intervention.\n\n## note the population effect is different\n\n#obtain true ate\nfit_std_population &lt;-\n  stdReg::stdGlm(model_population, data = population_data, X = \"a_population\")\n\n# summary\nsummary(fit_std_population,\n        contrast = \"difference\",\n        reference = 0)\n\n\nFormula: y_population ~ a_population * z_population\nFamily: gaussian \nLink function: identity \nExposure:  a_population \nReference level:  a_population = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00    0.00000       0.00       0.00\n1     1.25    0.00327       1.24       1.26\n\n\nNote, the true treatment effect is a 1.25 unit change in the population, with a confidence bound between 1.24 and 1.26. This is well outside the ATE that we obtain from the sample population!\nNext, consider the ATE in the weighted regression, where the sample was weighted to the target population’s true distribution of effect modifiers.\n\n## next try weights adjusted ate where we correctly assign population weights to the sample\nfit_std_weighted_sample_weights &lt;- stdReg::stdGlm( model_weighted_sample, \n    data = sample_data, \n    X = \"a_sample\")\n\n# this gives us the right answer\nsummary(fit_std_weighted_sample_weights, \n    contrast = \"difference\", \n    reference = 0)\n\n\nFormula: y_sample ~ a_sample * z_sample\nFamily: gaussian \nLink function: identity \nExposure:  a_sample \nReference level:  a_sample = 0 \nContrast:  difference \n\n  Estimate Std. Error lower 0.95 upper 0.95\n0     0.00     0.0000       0.00       0.00\n1     1.25     0.0172       1.22       1.29\n\n# Moral of the story. When we marginalise over the entire sample we need to weight estimates to the target population. \n\nWe find that we obtain the population-level causal effect estimate with accurate coverage by weighting the sample to the target population. So with appropriate weights, our results generalise from the sample to the target population."
  },
  {
    "objectID": "content/07-content.html#lessons-from-lab-2",
    "href": "content/07-content.html#lessons-from-lab-2",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Lessons from Lab 2",
    "text": "Lessons from Lab 2\n\nRegression coefficients do not clarify the problem of sample/target population mismatch – or selection bias as discussed in this manuscript.\nThe correct advice to investigators is that they should not rely on regression coefficients when evaluating the biases that arise from sample attrition. This advice applies to both methods that the authors use to investigate threats of bias. That is, to implement this advice, the authors must first take it.\nGenerally, observed data are insufficient for assessing threats. Observed data do not clarify structural sources of bias, nor do they clarify effect-modification in the full counterfactual data condition in which all receive the treatment and all do not receive the treatment (at the same level).\nTo properly assess bias, one would need access to the counterfactual outcome—what would have happened to the missing participants had they not been lost to follow-up or had they responded. Again, the join distributions over “full data” are inherently unobservable (Van Der Laan and Rose 2011).\nIn simple settings like the one we just simulated, we may address the gap between the sample and target population using methods such as modelling the censoring (e.g., censoring weighting). However, we never know what setting we are in or whether it is simple—such modelling must be handled with care. There is a large and growing epidemiology literature on this topic (see, for example, Li, Miao, and Tchetgen Tchetgen (2023)). \n\n\nVan Der Laan, Mark J., and Sherri Rose. 2011. Targeted Learning: Causal Inference for Observational and Experimental Data. Springer Series in Statistics. New York, NY: Springer. https://link.springer.com/10.1007/978-1-4419-9782-1.\n\nLi, Wei, Wang Miao, and Eric Tchetgen Tchetgen. 2023. “Non-Parametric Inference about Mean Functionals of Non-Ignorable Non-Response Data Without Identifying the Joint Distribution.” Journal of the Royal Statistical Society Series B: Statistical Methodology 85 (3): 913–35."
  },
  {
    "objectID": "content/07-content.html#appendix-a",
    "href": "content/07-content.html#appendix-a",
    "title": "Causal Inference: Effect-Modification and Interaction",
    "section": "Appendix A",
    "text": "Appendix A\n\nEvidence for effect-modification is relative to inclusion of other variables in the model\nThe ‘sharp-null hypothesis’ states there is no effect of the exposure on the outcome for any unit in the target population. Unless the ‘sharp-null hypothesis’ is false, there may be effect-modification. For any study worth conducting, we cannot evaluate whether the sharp-null hypothesis is false. If we could the experiment would be otiose. Therefore, we must assume the possibility of effect-modification. Notably, whether a variable is an effect-modifier also depends on which other variables are included in the model. That is, just as for the concept of a ‘confounder’, where a variable is an ‘effect-modifier’ cannot be stated without reference to an assumed causal order and an explicit statement about which other variables will be included in the model (Tyler J. VanderWeele 2012).\n\nVanderWeele, Tyler J. 2012. “Confounding and Effect Modification: Distribution and Measure.” Epidemiologic Methods 1 (1): 55–82. https://doi.org/10.1515/2161-962X.1004.\nAs illustrated in Figure 4, the marginal association between A and Y is unbiased. Here, exposure A is unconditionally associated with Y. Recall our convention G denotes effect-modification with conditioning and Z indicates effect-modification without conditioning.\n\n\n\n\n\n\n\n\nFigure 4: Consider a randomised experiment. There is no confounding. Here, the marginal association between A and Y provides an unbiased estimate for the causal effect of A on Y. Does the conditional association of A on Y vary within levels of G? The causal diagram allows for a classification of G as an effect modifier of A on Y by proxy. G modifies A’s effect on Y in virtue of G’s relationship to Z, which, according to this graph, is a direct effect modifier for the effect of A on Y.\n\n\n\n\n\nFigure 5 presents the same a randomised experiment as in the previous causal diagram. We again assume that there is no confounding of the marginal association between the exposure, A, and the outcome, Y. However, suppose we were to adjust for Z and ask, does the conditional association of A on Y vary within levels of G, after adjusting for Z? That is, does G remain an effect-modifier of the exposure on the outcome? Tyler J. VanderWeele and Robins (2007b) proved that for effect-modification to occur, at least one other arrow besides the treatment must enter into the outcome. According to Figure 5 the only arrow into Y other than A arrives from Z. Because Y is independent of G conditional on Z we may infer that G is no longer an effect modifier for the effect of A on Y. Viewed another way, G no longer co-varies with Y conditional on Z and so cannot act as an effect-modifier.\n\n\n\n\n\n\n\n\nFigure 5: Conditioning on Z renders G independent of Y. G is no longer an effect modifier after conditioning on Z because G is independent of Y. Although Z is an unconditional effect modifier, G is not.\n\n\n\n\n\nFigure 6 presents the same a randomised experiment as in the previous graph. We assume a true effect of A \\rightarrow Y. If we do not condition on B, then G will not modify the effect of A  \\rightarrow Y because G will not be associated with Y. However, if we were to condition on B, then both B (an effect modifier by proxy) and G may become effect-modifiers for the causal effect of A on Y. In this setting, both B and G are conditional effect-modifiers.\nNote that casual graphs help us to evaluate classifications of conditional and unconditional effect modifiers. They may also help to clarify conditions in which conditioning on unconditional effect-modifiers may remove conditional effect-modification. However we cannot not tell from a causal diagram whether the ancestors of an unconditional effect-modifier will be conditional effect-modifiers for the effect of the exposure on the outcome; see: Tyler J. VanderWeele and Robins (2007b), also Suzuki et al. (2013). Causal diagrams express non-parametric relations. I have adopted an off-label colouring convention to denote instances of effect-modification to highlight possible pathways for effect-modification, which may be relative to other variables in a model.\n\nVanderWeele, Tyler J., and James M. Robins. 2007b. “Four types of effect modification: a classification based on directed acyclic graphs.” Epidemiology (Cambridge, Mass.) 18 (5): 561–68. https://doi.org/10.1097/EDE.0b013e318127181b.\n\n\n\n\n\n\n\n\nFigure 6: Blue path denotes effect-modification for G by conditioning on B. Both B and G are conditional effect modifiers.\n\n\n\n\n\nFigure 7 reveals the relativity of effect-modification. If investigators do not condition on B, then G cannot be a conditional effect-modifier because G would then be independent of Z because B is a collider. However, as we observed in Figure 6, conditioning on B, a collider, may open a path for effect-modification of G by Z. Both B and G are conditional effect modifiers.\n\n\n\n\n\n\n\n\nFigure 7: Blue path denotes effect-modification. Here G is not an effect modifier because B, a common effect (collider) of G and Z, is not conditioned on. Any conditional effect modification for G would require conditioning on B, and not-conditioning on G. Otherwise G will be d-separated from Y.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 8: Blue path denotes effect-modification. Neither, G nor B are unconditional effect-modifiers for the effect of A on Y after Z is conditioned upon. If investigators condition on Z, the causal diagram implies they will not find evidence for effect-modification by B or G, which are conditionally independent of Y once Z is conditioned upon.\n\n\n\n\n\nFigure 8 considers the implications of conditioning on Z, which is the only unconditional effect-modifier on the graph. If Z is measured, conditioning on Z will remove effect-modification for B and G because B,G\\coprod Y |Z. This examples again reveals the context dependency of effect-modification. Here, causal diagrams are useful for clarifying features of dependent and independent effect modification. For further discussion, see: Suzuki et al. (2013); Tyler J. VanderWeele (2009).\n\nSuzuki, Etsuji, Toshiharu Mitsuhashi, Toshihide Tsuda, and Eiji Yamamoto. 2013. “A Counterfactual Approach to Bias and Effect Modification in Terms of Response Types.” BMC Medical Research Methodology 13 (1): 1–17.\n\nVanderWeele, Tyler J. 2009. “On the Distinction Between Interaction and Effect Modification.” Epidemiology, 863–71.\n\n\nPackages\n\nreport::cite_packages()\n\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 &lt;https://doi.org/10.5281/zenodo.10907724&gt;, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., &lt;https://go-bayes.github.io/margot/&gt;.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, &lt;https://CRAN.R-project.org/package=janitor&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 &lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Müller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, &lt;https://CRAN.R-project.org/package=here&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible Summary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580. doi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;, &lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Sjolander A, Dahlqwist E (2021). _stdReg: Regression Standardization_. R package version 3.4.1, &lt;https://CRAN.R-project.org/package=stdReg&gt;.\n  - Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022). _skimr: Compact and Flexible Summaries of Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=skimr&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;."
  },
  {
    "objectID": "content/12-content.html",
    "href": "content/12-content.html",
    "title": "Measurement from a Causal Perspective",
    "section": "",
    "text": "Note\n\n\n\nRequired\n\n(Tyler J. VanderWeele 2022) link\n\nSuggested\n\n(Harkness, Van de Vijver, and Johnson 2003) link"
  },
  {
    "objectID": "content/12-content.html#overview",
    "href": "content/12-content.html#overview",
    "title": "Measurement from a Causal Perspective",
    "section": "Overview",
    "text": "Overview\nBy the end of this lecture you will:\n\nUnderstand the causal assumptions implied by the factor analytic interpretation of the formative and reflective models.\nBe able to distinguish between statistical and structural interpretations of these models.\nUnderstand why Vanderweele thinks consistent causal estimation is possible using the theory of multiple versions of treatments for constructs with multiple indicators"
  },
  {
    "objectID": "content/12-content.html#two-ways-of-thinking-about-measurement-in-psychometric-research.",
    "href": "content/12-content.html#two-ways-of-thinking-about-measurement-in-psychometric-research.",
    "title": "Measurement from a Causal Perspective",
    "section": "Two ways of thinking about measurement in psychometric research.",
    "text": "Two ways of thinking about measurement in psychometric research.\nIn psychometric research, formative and reflective models describe the relationship between latent variables and their respective indicators. VanderWeele discusses this in the assigned reading for this week (Tyler J. VanderWeele 2022).\n\nVanderWeele, Tyler J. 2022. “Constructed Measures and Causal Inference: Towards a New Model of Measurement for Psychosocial Constructs.” Epidemiology 33 (1): 141. https://doi.org/10.1097/EDE.0000000000001434.\n\nReflective Model (Factor Analysis)\nIn a reflective measurement model, also known as an effect indicator model, the latent variable is understood to cause the observed variables. In this model, changes in the latent variable cause changes in the observed variables. Each indicator (observed variable) is a ‘reflection’ of the latent variable. In other words, they are effects or manifestations of the latent variable. These relations are presented in Figure 1.\nThe reflective model may be expressed:\nX_i = \\lambda_i \\eta + \\varepsilon_i\nHere, X_i is an observed variable (indicator), \\lambda_i is the factor loading for X_i, \\eta is the latent variable, and \\varepsilon_i is the error term associated with X_i. It is assumed that all the indicators are interchangeable and have a common cause, which is the latent variable \\eta.\nIn the conventional approach of factor analysis, the assumption is that a common latent variable is responsible for the correlation seen among the indicators. Thus, any fluctuation in the latent variable should immediately lead to similar changes in the indicators.These assumptions are presented in Figure 1.\n\n\n\n\n\n\n\n\nFigure 1: Reflective model: assume univariate latent variable η giving rise to indicators X1…X3. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\nThe Formative Model (Factor Analysis)\nIn a formative measurement model, the observed variables are seen as causing or determining the latent variable. Here again, there is a single latent variable. However this latent variable is taken to be an effect of the underlying indicators. These relations are presented in Figure 2.\nThe formative model may be expressed:\n\\eta = \\sum_i\\lambda_i X_i + \\varepsilon\nIn this equation, \\eta is the latent variable, \\lambda_i is the weight for X_i (the observed variable), and \\varepsilon is the error term. The latent variable \\eta is a composite of the observed variables X_i.\nIn the context of a formative model, correlation or interchangeability between indicators is not required. Each indicator contributes distinctively to the latent variable. As such, a modification in one indicator doesn’t automatically imply a corresponding change in the other indicators.\n\n\n\n\n\n\n\n\nFigure 2: Formative model:: assume univariate latent variable from which the indicators X1…X3 give rise. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
  },
  {
    "objectID": "content/12-content.html#structural-interpretation-of-the-formative-model-and-reflective-models-factor-analysis",
    "href": "content/12-content.html#structural-interpretation-of-the-formative-model-and-reflective-models-factor-analysis",
    "title": "Measurement from a Causal Perspective",
    "section": "Structural Interpretation of the formative model and reflective models (Factor Analysis)",
    "text": "Structural Interpretation of the formative model and reflective models (Factor Analysis)\n\nHowever, this analysis of reflective and formative models assumed that the latent η was causally efficacious. This may not be the case (VanderWeele 2022)\n\nVanderWeele distinguishes between statistical and structural interpretations of the equations preesented above.\n\nStatistical Model: a mathematical construct that shows how observable variables, also known as indicators, are related to latent or unseen variables. These are presented in the equations above\nStructural Model: A structural model refers to the causal assumptions or hypotheses about the relationships among variables in a statistical model. The assumptions of the factor analytic tradition are presented in Figure 2 and Figure 1 are structural models.\n\nWe have seen that the reflective model statistically implies that the observed variables (indicators) are reflections or manifestations of the latent variable, expressed as X_i = \\lambda_i \\eta + \\varepsilon_i. However, the factor analytic tradition makes the additional structural assumption that a univariate latent variable is causally efficacious and influences the observed variables, as in: Figure 3 (a).\nWe have also seen that the formative model statistically implies that the latent variable is formed or influenced by the observed variables, expressed as \\eta = \\sum_i\\lambda_i X_i + \\varepsilon. However, the factor analytic tradition makes the additional assumption that the observed variables give rise to a univariate latent variable, as in Figure 3 (b).\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Reflective Model: causal assumptions. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Formative model: causal assumptions. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\nThe reflective model implies X_i = \\lambda_i \\eta + \\varepsilon_i, which factor analysts take to imply Figure 3 (a).\n\n\n\n\nFigure 3: The formative model implies \\eta = \\sum_i\\lambda_i X_i + \\varepsilon, which factor analysts take to imply Figure 3 (b)."
  },
  {
    "objectID": "content/12-content.html#problems-with-the-structural-interpretations-of-the-reflective-and-formative-factor-models.",
    "href": "content/12-content.html#problems-with-the-structural-interpretations-of-the-reflective-and-formative-factor-models.",
    "title": "Measurement from a Causal Perspective",
    "section": "Problems with the structural interpretations of the reflective and formative factor models.",
    "text": "Problems with the structural interpretations of the reflective and formative factor models.\nWhile the statistical model X_i = \\lambda_i \\eta + \\varepsilon_i aligns with Figure 3 (a), it also alings with Figure 4. Cross-sectional data, unfortunately, do not provide enough information to discern between these different structural interpretations.\nSimilarly, the statistical model \\eta = \\sum_i\\lambda_i X_i + \\varepsilon agrees with Figure 3 (b) but it also agrees with@fig-dag-reflectiveassumptions-compatible_again. Here too, cross-sectional data cannot decide between these two potential structural interpretations.\nThere are other, compatible structural interprestations as well. The formative and reflective conceptions of factor analysis are compatible with indicators having causal effects as shown in (fig_dag_multivariate_reality_again?). They are also compatible with a multivariate reality giving rise to multiple indicators as shown in Figure 6.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4: Formative model is compatible with indicators causing outcome.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 5: Reflective model is compatible with indicators causing the outcome. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\n\n\n\n\nMultivariate reality gives rise to the indicators, from which we draw our measures. Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 6: Although we take our constructs, A, to be functions of indicators, X, such that, perhaps only one or several of the indicators are efficacious.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\n\n\n\nVanderWeele’s key observation is this:\n\n\n\n\nWhile cross-sectional data can provide insights into the relationships between variables, they cannot conclusively determine the causal direction of these relationships.\n\n\n\n\nThis results is worrying. The structural assumptions of factor analysis underpin nearly all psychological research. If the cross-sectional data used to derive factor structures cannot decide whether the structural interpretations of factor models are accurate, where does that leave us?\n\n\n\n\nMore worrying still, VanderWeele discusses several longitudinal tests for structural interpretations of univariate latent variables that do not pass.\n\n\n\n\nWhere does that leave us? In psychology we have heard about a replication crisis. We might describe the reliance on factor models as an aspect of a much larger, and more worrying “causal crisis” (Bulbulia 2023)\n\nBulbulia, Joseph A. 2023. “A Workflow for Causal Inference in Cross-Cultural Psychology.” Religion, Brain & Behavior 13 (3): 291–306. https://doi.org/10.1080/2153599X.2022.2070245."
  },
  {
    "objectID": "content/12-content.html#review-of-the-theory-of-multiple-versions-of-treatment",
    "href": "content/12-content.html#review-of-the-theory-of-multiple-versions-of-treatment",
    "title": "Measurement from a Causal Perspective",
    "section": "Review of the theory of multiple versions of treatment",
    "text": "Review of the theory of multiple versions of treatment\n\n\n\n\n\nMultiple Versions of treatment. Heae, A is regarded to bbe a coarseneed version of K\n\n\n\n\nPerhaps not all is lost. VanderWeele looks to the theory of multiple versions of treatment for solace.\nRecall, a causal effect is defined as the difference in the expected potential outcome when everyone is exposed (perhaps contrary to fact) to one level of a treatment, conditional on their levels of a confounder, with the expected potential outcome when everyone is exposed to a a different level of a treatement (perhaps contrary to fact), conditional on their levels of a counfounder.\n \\delta = \\sum_l \\left( \\mathbb{E}[Y|A=a,l] - \\mathbb{E}[Y|A=a^*,l] \\right) P(l)\nwhere \\delta is the causal estimand on the difference scale (\\mathbb{E}[Y^0 - Y^0]).\nIn causal inference, the multiple versions of treatment theory allows us to handle situations where the treatment isn’t uniform, but instead has several variations. Each variation of the treatment, or “version”, can have a different impact on the outcome. Consistency is not violated because it is redefined: for each version of the treatment, the outcome under that version is equal to the observed outcome when that version is received. Put differently we may think of the indicator A as corresponding to many version of the true treament K. Where conditional independence holds such that there is a absence of confounding for the effect of K on Y given L, we have: Y_k \\coprod A|K,L. This states conditional on L, A gives no information about Y once K and L are accounted for. When Y = Y_k if K = k and Y_k is independent of K, condition on L, then A may be thought of as a coarsened indicator of K, as shown in (fig_dag_multiple_version_treatment_dag?). We may estimate consistent causal effects where:\n \\delta = \\sum_{k,l} \\mathbb{E}[Y_k|l] P(k|a,l) P(l) - \\sum_{k,l} \\mathbb{E}[Y_k|l] P(k|a^*,l) P(l)\nThe scenario represents a hypothetical randomised trial where within strata of covariates L, individuals in one group receive a treatment K version randomly assigned from the distribution of K distribution (A = 1, L = l) sub-population. Meanwhile, individuals in the other group receive a randomly assigned K version from (A = 0, L = l)\nThis theory finds its utility in practical scenarios where treatments seldom resemble each other – we discussed the example of obesity last week (see: (Tyler J. VanderWeele and Hernan 2013)).\n\nVanderWeele, Tyler J, and Miguel A Hernan. 2013. “Causal Inference Under Multiple Versions of Treatment.” Journal of Causal Inference 1 (1): 1–20.\n\nReflective and formative measurement models may be approached as multiple versions of treatment\nVanderweele applies the following substitution:\n\\delta = \\sum_{\\eta,l} \\mathbb{E}[Y_\\eta|l] P(\\eta|A=a+1,l) P(l) - \\sum_{\\eta,l} \\mathbb{E}[Y_\\eta|l] P(\\eta|A=a,l) P(l)\nSpecifically, we substitue K with \\eta from the previous section, and compare the measurement response A = a + 1 with A = a. We discover that if the influence of \\eta on Y is not confounded given L, then the multiple versions of reality consistent with the reflective and formative statistical models of reality will not lead to biased estimation. \\delta retains its interpretability as a comparison in a hypothetical randomised trial in which the distribution of coarsened measures of \\eta_A are balanced within levels of the treatment, conditional on \\eta_L.\nThis connection between measurement and the multiple versions of treatment framework provides a hope for consistent causal inference varying reliabilities of measurement.\nHowever, as with the theory of multiple treatments, we might not known how to interpret our results because we don’t know the true relationships between our measured indicators and underlying reality.\nHow can we do better?\n\n\n\n\n\n\n\n\nFigure 7: Multiple Versions of treatment applied to measuremen.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434"
  },
  {
    "objectID": "content/12-content.html#vanderweeles-model-of-reality",
    "href": "content/12-content.html#vanderweeles-model-of-reality",
    "title": "Measurement from a Causal Perspective",
    "section": "VanderWeele’s model of reality",
    "text": "VanderWeele’s model of reality\nVanderWeele’s article concludes as follows:\n\nA preliminary outline of a more adequate approach to the construction and use of psychosocial measures might thus be summarized by the following propositions, that I have argued for in this article: (1) Traditional univariate reflective and formative models do not adequately capture the relations between the underlying causally relevant phenomena and our indicators and measures. (2) The causally relevant constituents of reality related to our constructs are almost always multidimensional, giving rise both to our indicators from which we construct measures, and also to our language and concepts, from which we can more precisely define constructs. (3) In measure construction, we ought to always specify a definition of the underlying construct, from which items are derived, and by which analytic relations of the items to the definition are made clear. (4) The presumption of a structural univariate reflective model impairs measure construction, evaluation, and use. (5) If a structural interpretation of a univariate reflective factor model is being proposed this should be formally tested, not presumed; factor analysis is not sufficient for assessing the relevant evidence. (6) Even when the causally relevant constituents of reality are multidimensional, and a univariate measure is used, we can still interpret associations with outcomes using theory for multiple versions of treatment, though the interpretation is obscured when we do not have a clear sense of what the causally relevant constituents are. (7) When data permit, examining associations item-by-item, or with conceptually related item sets, may give insight into the various facets of the construct.\n\n\nA new integrated theory of measurement for psychosocial constructs is needed in light of these points – one that better respects the relations between our constructs, items, indicators, measures, and the underlying causally relevant phenomena. (VanderWeele 2022)\n\n\n\n\n\n\n\n\n\nFigure 8: Multivariate reality gives rise to the latent variables.Figure adapted from VanderWeele: doi: 10.1097/EDE.0000000000001434\n\n\n\n\n\nThis seems to me sensible. However, Figure 8 this is not a causal graph. The arrows to not clearly represent causal relations. It leaves me unclear about what to practically do.\nLet’s return to the three wave many-outcomes model described in previous weeks. How should we revise this model in light of measurement theory?"
  },
  {
    "objectID": "content/12-content.html#how-theory-of-dependent-and-directed-measurement-error-might-be-usefully-employed-to-develop-a-pragmatic-responses-to-construct-measurement",
    "href": "content/12-content.html#how-theory-of-dependent-and-directed-measurement-error-might-be-usefully-employed-to-develop-a-pragmatic-responses-to-construct-measurement",
    "title": "Measurement from a Causal Perspective",
    "section": "How theory of dependent and directed measurement error might be usefully employed to develop a pragmatic responses to construct measurement",
    "text": "How theory of dependent and directed measurement error might be usefully employed to develop a pragmatic responses to construct measurement\nBy now you are all familiar with The New Zealand Attitudes and Values Study (NZAVS),which is a national probability survey collects a wide range of information, including data on distress, exercise habits, and cultural backgrounds.\n\n\n\n\n\n\n\n\nFigure 9: Uncorrelated non-differential measurement error does not bias estimates under the null. Note, however, we assume that L is measured with sufficient precision to block the path from A_eta –&gt; L_eta –&gt; Y_eta, which, otherwise, we would assume to be open.\n\n\n\n\n\nConsider a study that seeks to use this dataset to investigate the effect of regular exercise on psychological distress. In contrast to previous graphs, let us allow for latent reality to affect our measurements, as well as the discrepencies between our measurements and true underlying reality. We shall use Figure 9 as our initial guide.\nWe represent the true exercise by \\eta_A. We represent true psychological distress by \\eta_Y. Let \\eta_L denote a persons true workload, and assume that this state of work affects both levels of excercise and psychological distress.\nTo bring the model into contact with measurement theory, Let us describe measurements of these latent true underlying realities as functions of multiple indicators: L_{f(X_1\\dots X_n)}, A_{f(X_1\\dots X_n)}, and A_{f(X_1\\dots X_n)}. These constructs are measured realisations of the underlying true states. We assume that the true states of these variables affect their corresponding measured states, and so draw arrows from \\eta_L\\rightarrow{L_{f(X_1\\dots X_n)}}, \\eta_A\\rightarrow{A_{f(X_1\\dots X_n)}}, \\eta_Y\\rightarrow{Y_{f(X_1\\dots X_n)}}.\nWe also assume unmeasured sources of error that affect the measurements: U_{L} \\rightarrow L_{f(X_1\\dots X_n)}, U_{A} \\rightarrow A_{f(X_1\\dots X_n)}, and U_{Y} \\rightarrow Y_{f(X_1\\dots X_n)}. That is, we allow that our measured indicators may “see as through a mirror, in darkness,” the underlying true reality they hope to capture (Corinthians 13:12). We use U_{L}, U_{A} and U_{Y} to denote the unmeasured sources of error in the measured indicators. These are the unknown, and perhaps unknowable, darkness and mirror.\nAllow that the true underlying reality represented by the \\eta_{var} may be multivariate. Similarly, allow the true underlying reality represented by \\U_{var} is multivariate.\nWe now have a causal diagramme that more precisely captures VanderWeele’s thinking as presented in Figure 8. In our Figure 9, we have fleshed out \\mathcal{R} in a way that may include natural language concepts and scientific language, or constructs, as latent realities and latent unmeasured sources of error in our constructs.\nThe utility of describing the measurement dynamics using causal graphs is apparrent. We can understand that the measured states, once conditioned upon create collider biases which opens path between the unmeasured sources of error and the true underlying state that gives rise to our measurements. This is depicted by a the arrows U_{var} and from \\eta_{var} into each var_{f(X1, X2,\\dots X_n)}\nNotice: where true unmeasured (multivariate) psycho-physical states are related to true unmeasured (multivariate) sources of error in the measurement of those states, the very act of measurement opens pathways to confounding.\nIf for each measured construct var_{f(X1, X2,\\dots X_n)}, the sources of error U_{var} and the unmeasured consituents of reality that give rise to our measures \\eta_{var} are uncorrelated with other variables U\\prime_{var} and from \\eta\\prime_{var} and var\\prime_{f(X1, X2,\\dots X_n)}, our estimates may be downwardly biased toward the null. However, d-separation is preserved. Where errors are uncorrelated with true latent realities, there is no new pathway that opens information between our exposure and outcome. Consider the relations presented in Figure 10\n\n\n\n\n\n\n\n\nFigure 10: Measurement error opens an additional pathway to confounding if either there are correlated errors, or a directed effect of the exposure on the errors of measured outcome.\n\n\n\n\n\nHere,\n\\eta_L \\rightarrow L: We assume that the true workload state affects its measurement. This measurement, however, may be affected by an unmeasured error source, U_{L}. Personal perceptions of workload can introduce this error. For instance, a person may perceive their workload differently based on recent personal experiences or cultural backgrounds. Additionally, unmeasured cultural influences like societal expectations of productivity could shape their responses independently of the true workload state. There may be cultural differences - Americans may verstate; the British may present effortless superiority.\n\\eta_A \\rightarrow A: When it comes to exercise, the true state may affect the measured frequency (questions about exercise are not totally uninformative). However, this measurement is also affected by an unmeasured source of error, which we denote by U_{A}. For example, a cultural shift towards valuing physical health might prompt participants toreport higher activity levels, introducing an error, U_{A}.\n\\eta_Y \\rightarrow Y: We assume questions about distress are not totally uninformative: actual distress affects the measured distress. However this measurement is subject to unmeasured error: U_{Y}. For instance, an increased societal acceptance of mental health might change how distress is reported creating an error, U_{Y}, in the measurement of distress. Such norms, moreover, may change over time.\nU_{L} \\rightarrow L, U_{A} \\rightarrow A, and U_{Y} \\rightarrow Y: These edges between the nodes indicate how each unmeasured error source can influence its corresponding measurement, leading to a discrepancy between the true state and the measured state.\nU_{L} \\rightarrow U_{A} and U_{L} \\rightarrow U_{Y}: These relationships indicate that the error in the stress measurement can correlate with those in the exercise and mood measurements. This could stem from a common cultural bias affecting how a participant self-reports across these areas.\n\\eta_A \\rightarrow U_{Y} and \\eta_L \\rightarrow U_{A}: These relationships indicate that the actual state of one variable can affect the error in another variable’s measurement. For example, a cultural emphasis on physical health leading to increased exercise might, in turn, affect the reporting of distress levels, causing an error, U_{Y}, in the distress measurement. Similarly, if a cultural trend pushes people to work more, it might cause them to over or underestimate their exercise frequency, introducing an error, U_{A}, in the exercise measurement.\n\nConfounding control by baseline measures of exposure and outcome: Dependent Directed Measurement Error in Three-Wave Panels\n\nWe propose a three-wave panel design to control confounding. This design adjusts for baseline measurements of both exposure and the outcome.\nUnderstanding this approach in the context of potential directed and correlated measurement errors gives us a clearer picture of its strengths and limitations.\nThis three-wave panel design incorporates baseline measurements of both exposure and confounders. As a result, any bias that could come from unmeasured sources of measurement errors should be uncorrelated with their baseline effects.\nFor instance, if individuals have a social desirability bias at the baseline, they would have to develop a different bias unrelated to the initial one for new bias to occur due to correlated unmeasured sources of measurement errors.\nHowever, we cannot completely eliminate the possibility of such new bias development. There could also be potential new sources of bias from directed effects of the exposure on the error term of the outcome, which can often occur due to panel attrition.\nTo mitigate this risk, we adjust for panel attrition/non-response using methods like multiple imputation. We also consistently perform sensitivity analyses to detect any unanticipated bias.\nDespite these potential challenges, it is worth noting that by including measures of both exposure and outcome at baseline, the chances of new confounding are significantly reduced.\nTherefore, adopting this practice should be a standard procedure in multi-wave studies as it substantially minimizes the likelihood of introducing novel confounding factors.\n\n\n\n\n\n\n\n\n\nFigure 11: TBA\n\n\n\n\n\n\n\nComment on slow changes\nOver long periods of time we can expect additional sources of confounding. Changes in cultural norms and attitudes can occur over the duration of a longitudinal study like the NZAVS, leading to residual confounding. For example, if there is a cultural shift towards increased acceptance of mental health issues, this might change how psychological distress is reported over time, irrespective of baseline responses.\n\n\n\n\n\n\n\n\n\n\n\n\nNeed for Sensitivity Analysis The Key takehome message is that we must always perform sensitivity analyses because we can never be certain that our confounding control strategy has worked."
  },
  {
    "objectID": "content/12-content.html#lab-advice-on-you-final-report",
    "href": "content/12-content.html#lab-advice-on-you-final-report",
    "title": "Measurement from a Causal Perspective",
    "section": "Lab: Advice on you Final Report",
    "text": "Lab: Advice on you Final Report"
  },
  {
    "objectID": "content/12-content.html#intoduction",
    "href": "content/12-content.html#intoduction",
    "title": "Measurement from a Causal Perspective",
    "section": "Intoduction",
    "text": "Intoduction\nAnswer the following:\n\nState the Question: is my question clearly stated? If not, state it.\nRelevance of the Question: Have I explained its importance? If not, explain.\nSubgroup Analysis: Does my question involve a subgroup (e.g., cultural group)? If not, develop a subgroup analysis question.\nCausality of the Question: Is my question causal? Briefly explain what this means with reference to the potential outcomes framework.\nState how you will use time-series data to address causality.\nDefine your exposure.\nDefine your outcome(s)\nExplain how the the exposure and outcome is relevant to your question.\nDefine your causal estimand (see: lecture 9). Hint: it is ATE_g_risk difference = E[Y(1)-(0)|G,L], where G is your multiple-group indicator and L is your set of baseline confounders."
  },
  {
    "objectID": "content/12-content.html#methods",
    "href": "content/12-content.html#methods",
    "title": "Measurement from a Causal Perspective",
    "section": "Methods",
    "text": "Methods\n\nConsider any ethical implications.\nExplain the sample. Provide descriptive statistics\nDiscuss inclusion criteria.\nDiscuss how your sample relates to the “source population” (lecture 9.)\nExplain NZAVS measures. State the questions used in the items\nIn your own words describe how the data meet the following assumptions required for causal inference:\nPositivity: Can we intervene on the exposure at all levels of the covariates? Use the code I provided to test whether there is change in the exposure from the baseline in the source population(s)\nConsistency: Can I interpret what it means to intervene on the exposure?\nExchangeability: Are different versions of the exposure conditionally exchangeable given measured baseline confounders? This requires stating baseline confounders and explaining how they may be related to both the exposure and outcome. As part of this, you must explain why the baseline measure of your exposure and outcome are included as potential confounders.\nNote: Unmeasured Confounders: Does previous science suggest the presence of unmeasured confounders? (e.g. childhood exposures that are not measured).\nDraw a causal diagram: Have I drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding?\nMeasurement Error: Have I described potential biases from measurement errors? Return to lecture 11.\nState that you do not have missing data in this synthetic dataset, but that ordinarily missing data would need to be handled.\nState what your estimator will be. Note I’ve given you the following text to modify:\n\n\nThe Doubly Robust Estimation method for Subgroup Analysis Estimator is a sophisticated tool combining features of both IPTW and G-computation methods, providing unbiased estimates if either the propensity score or outcome model is correctly specified. The process involves five main steps:\n\n\nStep 1 involves the estimation of the propensity score, a measure of the conditional probability of exposure given the covariates and the subgroup indicator. This score is calculated using statistical models such as logistic regression, with the model choice depending on the nature of the data and exposure. Weights for each individual are then calculated using this propensity score. These weights depend on the exposure status and are computed differently for exposed and unexposed individuals. The estimation of propensity scores is performed separately within each subgroup stratum.\n\n\nStep 2 focuses on fitting a weighted outcome model, making use of the previously calculated weights from the propensity scores. This model estimates the outcome conditional on exposure, covariates, and subgroup, integrating the weights into the estimation process. Unlike in propensity score model estimation, covariates are included as variables in the outcome model. This inclusion makes the method doubly robust - providing a consistent effect estimate if either the propensity score or the outcome model is correctly specified, thereby reducing the assumption of correct model specification.\n\n\nStep 3 entails the simulation of potential outcomes for each individual in each subgroup. These hypothetical scenarios assume universal exposure to the intervention within each subgroup, regardless of actual exposure levels. The expectation of potential outcomes is calculated for each individual in each subgroup, using individual-specific weights. These scenarios are performed for both the current and alternative interventions.\n\n\nStep 4 is the estimation of the average causal effect for each subgroup, achieved by comparing the computed expected values of potential outcomes under each intervention level. The difference represents the average causal effect of changing the exposure within each subgroup.\n\n\nStep 5 involves comparing differences in causal effects across groups by calculating the differences in the estimated causal effects between different subgroups. Confidence intervals and standard errors for these calculations are determined using simulation-based inference methods (Greifer et al. 2023). This step allows for a comprehensive comparison of the impact of different interventions across various subgroups, while encorporating uncertainty.\n\nAlso see the appendix here\n\nState what E-values are and how you will use them to clarify the risk of unmeasured confounding."
  },
  {
    "objectID": "content/12-content.html#results",
    "href": "content/12-content.html#results",
    "title": "Measurement from a Causal Perspective",
    "section": "Results",
    "text": "Results\n\nUse the scripts I have provided as a template for your analysis.\nPropensity Score Reporting: Detail the process of propensity score derivation, including the model used and any variable transformations: e.g.: A ~ x1 + x2 + x3 + .... using logistic regression, all continuous predictors were transformed to z-scores\n\nWeightIt Package Utilisation: Explicitly mention the use of the ‘WeightIt’ package in R, including any specific options or parameters used in the propensity score estimation process (Greifer 2023).\nReport if different methods were used to obtain propensity scores, and the reasons behind the choice of methods such as ‘ebal’, ‘energy’, and ‘ps’.\nIf your exposure is continuous only the ‘energy’ option was used for propensity score estimation.\nSubgroup Estimation: Confirm that the propensity scores for subgroups were estimated separately, and discuss how the weights were subsequently combined with the original data.\nCovariate Balance: Include a Love plot to visually represent covariate balance on the exposure both before and after weighting. The script will generate these plots.\nWeighting Algorithm Statistics: Report the statistics for the weighting algorithms as provided by the WeightIt package, including any measures of balance or fit. The script I gave you will generate this information\n\n\n\nGreifer, Noah. 2023. WeightIt: Weighting for Covariate Balance in Observational Studies.\nExample:\n\nWe estimated propensity scores by fitting a model for the exposure A as it is predicted by the set of baseline covariates defined by L. Because we are interested in effect modification by group, we fit different propensity score models for within strata of G using the subgroup command of the WeightIt package. Thus the propensity score is the the probability of receiving a value of a treatment (A=a) conditional on the covariates L, and stratum within G. We compared balance using the following methods of weighting: “ebal” or entropy balancing, “energy” or energy balancing, and “ps” or traditional inverse probability of weighting balancing. Of these methods “ebal” performed the best. Table X and Figure Y present the results of the ebalancing method.\n\n\nInterpretation of Propensity Scores: we interpret the proposensity scores as yeilding good balance across the exposure conditions.\nOutcome Regression Model: Clearly report the type of regression model used to estimate outcome model coefficients (e.g., linear regression, Poisson, binomial), and mention if the exposure was interacted with the baseline covariates. Do not report model coefficients as these have no interpretation. Example\n\n\nWe fit a linear model using maximum likelihood estimation with the outcome Y predicted by the exposure A. We interacted the exposure with all baseline confounders L. Continuous baseline confounders were converted to z-scores, whereas categorical exposures were not. Also interacted with all baseline confounders was a term for the subgroup interactoin. This allowed uas to flexibily fit non-linearities for the modification of the effect of the exposure within levels of the levels of the cultural group strata of interest. We note that model coefficients have no interpretation in this context so are not reported. The remaining steps of Doubly-Robust estimation were performed as outlined in the Method section. We calculated confidence intervals and standard errors, using the clarify package in R, which relies on simulation based inference for these quantities of interest (Greifer et al. 2023)\n\nGreifer, Noah, Steven Worthington, Stefano Iacus, and Gary King. 2023. Clarify: Simulation-Based Inference for Regression Models. https://iqss.github.io/clarify/.\n\nReport the causal estimates.\n\nATE contrasts for groups in setting the exposure to for each group in setting level A = a and A = a*\ndifferences between groups in the magnitude of the effects. (ATE_group 1 - ATE_group_2)\nReport the E-value: how sensitive are your results to unmeasured confounding?"
  },
  {
    "objectID": "content/12-content.html#discussion",
    "href": "content/12-content.html#discussion",
    "title": "Measurement from a Causal Perspective",
    "section": "Discussion",
    "text": "Discussion\nMake sure to hit these points:\nConsider the following ideas about what to discuss in one’s findings. The order of exposition might be different.\n\nSummary of results: What did you find?\nInterpretation of E-values: Interpret the E-values used for sensitivity analysis. State what they represent in terms of the robustness of the findings to potential unmeasured confounding.\nCausal Effect Interpretation: What is the interest of the effect, if any, if an effect was observed? Interpret the average causal effect of changing the exposure level within each subgroup, and discuss its relevance to the research question.\nComparison of Subgroups: Discuss how differences in causal effect estimates between different subgroups, if observed, or if not observed, contribute to the overall findings of the study.\nUncertainty and Confidence Intervals: Consider the uncertainty around the estimated causal effects, and interpret the confidence intervals to understand the precision of the estimates.\nGeneralisability and Transportability: Reflect on the generalizability of the study results to other contexts or populations. Discuss any factors that might influence the transportability of the causal effects found in the study. (Again see lecture 9.)\nAssumptions and Limitations: Reflect on the assumptions made during the study and identify any limitations in the methodology that could affect the interpretation of results. State that the implications of different intervention levels on potential outcomes are not analysed.\nTheoretical Relevance: How are these findings relevant to existing theories.\nReplication and Future Research: Consider how the study could be replicated or expanded upon in future research, and how the findings contribute to the existing body of knowledge in the field.\nReal-World Implications: Discuss the real-world implications of the findings, and how they could be applied in policy, practice, or further research."
  },
  {
    "objectID": "content/12-content.html#example-anlaysis-week-10",
    "href": "content/12-content.html#example-anlaysis-week-10",
    "title": "Measurement from a Causal Perspective",
    "section": "Example anlaysis (week 10)",
    "text": "Example anlaysis (week 10)\n\nPackages\n\nreport::cite_packages()\n\n  - Arel-Bundock V, Greifer N, Heiss A (2024). \"How to Interpret Statistical Models Using marginaleffects for R and Python.\" _Journal of Statistical Software_, *111*(9), 1-32. doi:10.18637/jss.v111.i09 &lt;https://doi.org/10.18637/jss.v111.i09&gt;.\n  - Barrett M (2021). _ggokabeito: 'Okabe-Ito' Scales for 'ggplot2' and 'ggraph'_. R package version 0.1.0, &lt;https://CRAN.R-project.org/package=ggokabeito&gt;.\n  - Bates D, Mächler M, Bolker B, Walker S (2015). \"Fitting Linear Mixed-Effects Models Using lme4.\" _Journal of Statistical Software_, *67*(1), 1-48. doi:10.18637/jss.v067.i01 &lt;https://doi.org/10.18637/jss.v067.i01&gt;.\n  - Bates D, Maechler M, Jagan M (2025). _Matrix: Sparse and Dense Matrix Classes and Methods_. R package version 1.7-2, &lt;https://CRAN.R-project.org/package=Matrix&gt;.\n  - Bengtsson H (2021). \"A Unifying Framework for Parallel and Distributed Processing in R using Futures.\" _The R Journal_, *13*(2), 208-227. doi:10.32614/RJ-2021-048 &lt;https://doi.org/10.32614/RJ-2021-048&gt;, &lt;https://doi.org/10.32614/RJ-2021-048&gt;.\n  - Bengtsson H (2021). \"A Unifying Framework for Parallel and Distributed Processing in R using Futures.\" _The R Journal_, *13*(2), 208-227. doi:10.32614/RJ-2021-048 &lt;https://doi.org/10.32614/RJ-2021-048&gt;, &lt;https://doi.org/10.32614/RJ-2021-048&gt;.\n  - Bengtsson H (2024). _progressr: An Inclusive, Unifying API for Progress Updates_. R package version 0.15.1, &lt;https://CRAN.R-project.org/package=progressr&gt;.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Bicalho C, Fultz N, Medina L (2021). _DesignLibrary: Library of Research Designs_. R package version 0.1.10, &lt;https://CRAN.R-project.org/package=DesignLibrary&gt;.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Rudkin A, Fultz N (2024). _fabricatr: Imagine Your Data Before You Collect It_. R package version 1.0.2, &lt;https://CRAN.R-project.org/package=fabricatr&gt;.\n  - Blair G, Cooper J, Coppock A, Humphreys M, Sonnet L (2024). _estimatr: Fast Estimators for Design-Based Inference_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=estimatr&gt;.\n  - Blair G, Coppock A, Humphreys M (2023). _Research Design in the Social Sciences: Declaration, Diagnosis, and Redesign_. Princeton University Press, Princeton. &lt;https://book.declaredesign.org&gt;. Blair G, Cooper J, Coppock A, Humphreys M (2019). \"Declaring and Diagnosing Research Designs.\" _American Political Science Review_, *113*, 838-859. &lt;https://declaredesign.org/paper.pdf&gt;.\n  - Brown C (2018). _formula.tools: Programmatic Utilities for Manipulating Formulas, Expressions, Calls, Assignments and Other R Objects_. R package version 1.7.1, &lt;https://CRAN.R-project.org/package=formula.tools&gt;.\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 &lt;https://doi.org/10.5281/zenodo.10907724&gt;, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., &lt;https://go-bayes.github.io/margot/&gt;.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - Chen T, He T, Benesty M, Khotilovich V, Tang Y, Cho H, Chen K, Mitchell R, Cano I, Zhou T, Li M, Xie J, Lin M, Geng Y, Li Y, Yuan J (2024). _xgboost: Extreme Gradient Boosting_. R package version 1.7.8.1, &lt;https://CRAN.R-project.org/package=xgboost&gt;.\n  - Christopher H. Jackson (2011). \"Multi-State Models for Panel Data: The msm Package for R.\" _Journal of Statistical Software_, *38*(8), 1-29. doi:10.18637/jss.v038.i08 &lt;https://doi.org/10.18637/jss.v038.i08&gt;.\n  - Coppock A (2023). _randomizr: Easy-to-Use Tools for Common Forms of Random Assignment and Sampling_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=randomizr&gt;.\n  - Csárdi G, Hester J, Wickham H, Chang W, Morgan M, Tenenbaum D (2024). _remotes: R Package Installation from Remote Repositories, Including 'GitHub'_. R package version 2.5.0, &lt;https://CRAN.R-project.org/package=remotes&gt;.\n  - Eddelbuettel D, Francois R, Allaire J, Ushey K, Kou Q, Russell N, Ucar I, Bates D, Chambers J (2025). _Rcpp: Seamless R and C++ Integration_. R package version 1.0.14, &lt;https://CRAN.R-project.org/package=Rcpp&gt;. Eddelbuettel D, François R (2011). \"Rcpp: Seamless R and C++ Integration.\" _Journal of Statistical Software_, *40*(8), 1-18. doi:10.18637/jss.v040.i08 &lt;https://doi.org/10.18637/jss.v040.i08&gt;. Eddelbuettel D (2013). _Seamless R and C++ Integration with Rcpp_. Springer, New York. doi:10.1007/978-1-4614-6868-4 &lt;https://doi.org/10.1007/978-1-4614-6868-4&gt;, ISBN 978-1-4614-6867-7. Eddelbuettel D, Balamuta J (2018). \"Extending R with C++: A Brief Introduction to Rcpp.\" _The American Statistician_, *72*(1), 28-36. doi:10.1080/00031305.2017.1375990 &lt;https://doi.org/10.1080/00031305.2017.1375990&gt;.\n  - Firke S (2024). _janitor: Simple Tools for Examining and Cleaning Dirty Data_. R package version 2.2.1, &lt;https://CRAN.R-project.org/package=janitor&gt;.\n  - Friedman J, Tibshirani R, Hastie T (2010). \"Regularization Paths for Generalized Linear Models via Coordinate Descent.\" _Journal of Statistical Software_, *33*(1), 1-22. doi:10.18637/jss.v033.i01 &lt;https://doi.org/10.18637/jss.v033.i01&gt;. Simon N, Friedman J, Tibshirani R, Hastie T (2011). \"Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent.\" _Journal of Statistical Software_, *39*(5), 1-13. doi:10.18637/jss.v039.i05 &lt;https://doi.org/10.18637/jss.v039.i05&gt;. Tay JK, Narasimhan B, Hastie T (2023). \"Elastic Net Regularization Paths for All Generalized Linear Models.\" _Journal of Statistical Software_, *106*(1), 1-31. doi:10.18637/jss.v106.i01 &lt;https://doi.org/10.18637/jss.v106.i01&gt;.\n  - Greifer N (2024). _cobalt: Covariate Balance Tables and Plots_. R package version 4.5.5, &lt;https://CRAN.R-project.org/package=cobalt&gt;.\n  - Greifer N (2024). _WeightIt: Weighting for Covariate Balance in Observational Studies_. R package version 1.3.2, &lt;https://CRAN.R-project.org/package=WeightIt&gt;.\n  - Greifer N, Worthington S, Iacus S, King G (2024). _clarify: Simulation-Based Inference for Regression Models_. R package version 0.2.1, &lt;https://CRAN.R-project.org/package=clarify&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Halekoh U, Højsgaard S, Yan J (2006). \"The R Package geepack for Generalized Estimating Equations.\" _Journal of Statistical Software_, *15/2*, 1-11. Yan J, Fine JP (2004). \"Estimating Equations for Association Structures.\" _Statistics in Medicine_, *23*, 859-880. Yan J (2002). \"geepack: Yet Another Package for Generalized Estimating Equations.\" _R-News_, *2/3*, 12-14.\n  - Hansen BB, Klopfer SO (2006). \"Optimal full matching and related designs via network flows.\" _Journal of Computational and Graphical Statistics_, *15*(3), 609-627.\n  - Hastie T (2024). _gam: Generalized Additive Models_. R package version 1.22-5, &lt;https://CRAN.R-project.org/package=gam&gt;.\n  - Helske S, Helske J (2019). \"Mixture Hidden Markov Models for Sequence Data: The seqHMM Package in R.\" _Journal of Statistical Software_, *88*(3), 1-32. doi:10.18637/jss.v088.i03 &lt;https://doi.org/10.18637/jss.v088.i03&gt;. Helske J, Helske S (2023). _seqHMM: Mixture hidden Markov models for social sequence data and other multivariate, multichannel categorical time series_. R package version 1.2.6, &lt;https://cran.r-project.org/package=seqHMM&gt;.\n  - Henry L, Wickham H (2025). _rlang: Functions for Base Types and Core R and 'Tidyverse' Features_. R package version 1.1.5, &lt;https://CRAN.R-project.org/package=rlang&gt;.\n  - Hester J, Bryan J (2024). _glue: Interpreted String Literals_. R package version 1.8.0, &lt;https://CRAN.R-project.org/package=glue&gt;.\n  - Hester J, Wickham H, Csárdi G (2024). _fs: Cross-Platform File System Operations Based on 'libuv'_. R package version 1.6.5, &lt;https://CRAN.R-project.org/package=fs&gt;.\n  - Ho D, Imai K, King G, Stuart E (2011). \"MatchIt: Nonparametric Preprocessing for Parametric Causal Inference.\" _Journal of Statistical Software_, *42*(8), 1-28. doi:10.18637/jss.v042.i08 &lt;https://doi.org/10.18637/jss.v042.i08&gt;.\n  - Honaker J, King G, Blackwell M (2011). \"Amelia II: A Program for Missing Data.\" _Journal of Statistical Software_, *45*(7), 1-47. doi:10.18637/jss.v045.i07 &lt;https://doi.org/10.18637/jss.v045.i07&gt;.\n  - Iannone R, Cheng J, Schloerke B, Hughes E, Lauer A, Seo J, Brevoort K, Roy O (2024). _gt: Easily Create Presentation-Ready Display Tables_. R package version 0.11.1, &lt;https://CRAN.R-project.org/package=gt&gt;.\n  - J L (2006). \"Plotrix: a package in the red light district of R.\" _R-News_, *6*(4), 8-12.\n  - Kassambara A (2023). _ggpubr: 'ggplot2' Based Publication Ready Plots_. R package version 0.6.0, &lt;https://CRAN.R-project.org/package=ggpubr&gt;.\n  - Kay M (2024). \"ggdist: Visualizations of Distributions and Uncertainty in the Grammar of Graphics.\" _IEEE Transactions on Visualization and Computer Graphics_, *30*(1), 414-424. doi:10.1109/TVCG.2023.3327195 &lt;https://doi.org/10.1109/TVCG.2023.3327195&gt;. Kay M (2024). _ggdist: Visualizations of Distributions and Uncertainty_. doi:10.5281/zenodo.3879620 &lt;https://doi.org/10.5281/zenodo.3879620&gt;, R package version 3.3.2, &lt;https://mjskay.github.io/ggdist/&gt;.\n  - Lüdecke D (2018). \"ggeffects: Tidy Data Frames of Marginal Effects from Regression Models.\" _Journal of Open Source Software_, *3*(26), 772. doi:10.21105/joss.00772 &lt;https://doi.org/10.21105/joss.00772&gt;.\n  - Lüdecke D, Ben-Shachar M, Patil I, Makowski D (2020). \"Extracting, Computing and Exploring the Parameters of Statistical Models using R.\" _Journal of Open Source Software_, *5*(53), 2445. doi:10.21105/joss.02445 &lt;https://doi.org/10.21105/joss.02445&gt;.\n  - Lumley T (2024). \"survey: analysis of complex survey samples.\" R package version 4.4. Lumley T (2004). \"Analysis of Complex Survey Samples.\" _Journal of Statistical Software_, *9*(1), 1-19. R package verson 2.2. Lumley T (2010). _Complex Surveys: A Guide to Analysis Using R: A Guide to Analysis Using R_. John Wiley and Sons.\n  - Microsoft, Weston S (2022). _foreach: Provides Foreach Looping Construct_. R package version 1.5.2, &lt;https://CRAN.R-project.org/package=foreach&gt;.\n  - Milborrow S (2024). _plotmo: Plot a Model's Residuals, Response, and Partial Dependence Plots_. R package version 3.6.4, &lt;https://CRAN.R-project.org/package=plotmo&gt;.\n  - Milborrow S, Hastie T, Tibshirani R (2024). _earth: Multivariate Adaptive Regression Splines_. R package version 5.3.4, &lt;https://CRAN.R-project.org/package=earth&gt;.\n  - Mullen KM, van Stokkum IHM (2024). _nnls: The Lawson-Hanson Algorithm for Non-Negative Least Squares (NNLS)_. R package version 1.6, &lt;https://CRAN.R-project.org/package=nnls&gt;.\n  - Müller K (2020). _here: A Simpler Way to Find Your Files_. R package version 1.0.1, &lt;https://CRAN.R-project.org/package=here&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - Ooms J (2024). _katex: Rendering Math to HTML, 'MathML', or R-Documentation Format_. R package version 1.5.0, &lt;https://CRAN.R-project.org/package=katex&gt;.\n  - Ooms J (2024). _pdftools: Text Extraction, Rendering and Converting of PDF Documents_. R package version 3.4.1, &lt;https://CRAN.R-project.org/package=pdftools&gt;.\n  - Pedersen T (2024). _patchwork: The Composer of Plots_. R package version 1.3.0, &lt;https://CRAN.R-project.org/package=patchwork&gt;.\n  - Pishgar F, Greifer N, Leyrat C, Stuart E (2021). \"MatchThem:: Matching and Weighting after Multiple Imputation.\" _The R Journal_. doi:10.32614/RJ-2021-073 &lt;https://doi.org/10.32614/RJ-2021-073&gt;, &lt;https://journal.r-project.org/archive/2021/RJ-2021-073/&gt;.\n  - Polley E, LeDell E, Kennedy C, van der Laan M (2024). _SuperLearner: Super Learner Prediction_. R package version 2.0-29, &lt;https://CRAN.R-project.org/package=SuperLearner&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Rich B (2023). _table1: Tables of Descriptive Statistics in HTML_. R package version 1.4.3, &lt;https://CRAN.R-project.org/package=table1&gt;.\n  - Richardson N, Cook I, Crane N, Dunnington D, François R, Keane J, Moldovan-Grünfeld D, Ooms J, Wujciak-Jens J, Apache Arrow (2025). _arrow: Integration to 'Apache' 'Arrow'_. R package version 18.1.0.1, &lt;https://CRAN.R-project.org/package=arrow&gt;.\n  - Robinson D, Hayes A, Couch S (2024). _broom: Convert Statistical Objects into Tidy Tibbles_. R package version 1.0.7, &lt;https://CRAN.R-project.org/package=broom&gt;.\n  - Robitzsch A, Grund S (2024). _miceadds: Some Additional Multiple Imputation Functions, Especially for 'mice'_. R package version 3.17-44, &lt;https://CRAN.R-project.org/package=miceadds&gt;.\n  - Sjoberg D, Whiting K, Curry M, Lavery J, Larmarange J (2021). \"Reproducible Summary Tables with the gtsummary Package.\" _The R Journal_, *13*, 570-580. doi:10.32614/RJ-2021-053 &lt;https://doi.org/10.32614/RJ-2021-053&gt;, &lt;https://doi.org/10.32614/RJ-2021-053&gt;.\n  - Sjolander A, Dahlqwist E (2021). _stdReg: Regression Standardization_. R package version 3.4.1, &lt;https://CRAN.R-project.org/package=stdReg&gt;.\n  - Therneau T (2024). _A Package for Survival Analysis in R_. R package version 3.8-3, &lt;https://CRAN.R-project.org/package=survival&gt;. Terry M. Therneau, Patricia M. Grambsch (2000). _Modeling Survival Data: Extending the Cox Model_. Springer, New York. ISBN 0-387-98784-3.\n  - Tibshirani J, Athey S, Sverdrup E, Wager S (2024). _grf: Generalized Random Forests_. R package version 2.4.0, &lt;https://CRAN.R-project.org/package=grf&gt;.\n  - Tierney N, Cook D (2023). \"Expanding Tidy Data Principles to Facilitate Missing Data Exploration, Visualization and Assessment of Imputations.\" _Journal of Statistical Software_, *105*(7), 1-31. doi:10.18637/jss.v105.i07 &lt;https://doi.org/10.18637/jss.v105.i07&gt;.\n  - van Buuren S, Groothuis-Oudshoorn K (2011). \"mice: Multivariate Imputation by Chained Equations in R.\" _Journal of Statistical Software_, *45*(3), 1-67. doi:10.18637/jss.v045.i03 &lt;https://doi.org/10.18637/jss.v045.i03&gt;.\n  - van der Wal WM, Geskus RB (2011). \"ipw: An R Package for Inverse Probability Weighting.\" _Journal of Statistical Software_, *43*(13), 1-23. doi:10.18637/jss.v043.i13 &lt;https://doi.org/10.18637/jss.v043.i13&gt;.\n  - Waring E, Quinn M, McNamara A, Arino de la Rubia E, Zhu H, Ellis S (2022). _skimr: Compact and Flexible Summaries of Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=skimr&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _conflicted: An Alternative Conflict Resolution Strategy_. R package version 1.2.0, &lt;https://CRAN.R-project.org/package=conflicted&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, Bryan J, Barrett M, Teucher A (2024). _usethis: Automate Package and Project Setup_. R package version 3.1.0, &lt;https://CRAN.R-project.org/package=usethis&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Hester J, Chang W, Bryan J (2022). _devtools: Tools to Make Developing R Packages Easier_. R package version 2.4.5, &lt;https://CRAN.R-project.org/package=devtools&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Williams N, Díaz I (2023). \"lmtp: An R package for estimating the causal effects of modified treatment policies.\" _Observational Studies_. &lt;https://muse.jhu.edu/article/883479&gt;. Díaz I, Williams N, Hoffman K, Schneck E (2021). \"Non-parametric causal effects based on longitudinal modified treatment policies.\" _Journal of the American Statistical Association_. doi:10.1080/01621459.2021.1955691 &lt;https://doi.org/10.1080/01621459.2021.1955691&gt;.\n  - Wright MN, Ziegler A (2017). \"ranger: A Fast Implementation of Random Forests for High Dimensional Data in C++ and R.\" _Journal of Statistical Software_, *77*(1), 1-17. doi:10.18637/jss.v077.i01 &lt;https://doi.org/10.18637/jss.v077.i01&gt;.\n  - Xie Y (2024). _knitr: A General-Purpose Package for Dynamic Report Generation in R_. R package version 1.49, &lt;https://yihui.org/knitr/&gt;. Xie Y (2015). _Dynamic Documents with R and knitr_, 2nd edition. Chapman and Hall/CRC, Boca Raton, Florida. ISBN 978-1498716963, &lt;https://yihui.org/knitr/&gt;. Xie Y (2014). \"knitr: A Comprehensive Tool for Reproducible Research in R.\" In Stodden V, Leisch F, Peng RD (eds.), _Implementing Reproducible Computational Research_. Chapman and Hall/CRC. ISBN 978-1466561595.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;.\n  - Zeileis A, Croissant Y (2010). \"Extended Model Formulas in R: Multiple Parts and Multiple Responses.\" _Journal of Statistical Software_, *34*(1), 1-13. doi:10.18637/jss.v034.i01 &lt;https://doi.org/10.18637/jss.v034.i01&gt;.\n  - Zeileis A, Köll S, Graham N (2020). \"Various Versatile Variances: An Object-Oriented Implementation of Clustered Covariances in R.\" _Journal of Statistical Software_, *95*(1), 1-36. doi:10.18637/jss.v095.i01 &lt;https://doi.org/10.18637/jss.v095.i01&gt;. Zeileis A (2004). \"Econometric Computing with HC and HAC Covariance Matrix Estimators.\" _Journal of Statistical Software_, *11*(10), 1-17. doi:10.18637/jss.v011.i10 &lt;https://doi.org/10.18637/jss.v011.i10&gt;. Zeileis A (2006). \"Object-Oriented Computation of Sandwich Estimators.\" _Journal of Statistical Software_, *16*(9), 1-16. doi:10.18637/jss.v016.i09 &lt;https://doi.org/10.18637/jss.v016.i09&gt;.\n  - Zhu H (2024). _kableExtra: Construct Complex Table with 'kable' and Pipe Syntax_. R package version 1.4.0, &lt;https://CRAN.R-project.org/package=kableExtra&gt;."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2\n\n\n\n\n\nReuseCC BY-NC-SA 4.0"
  },
  {
    "objectID": "content/more-old-advice.html",
    "href": "content/more-old-advice.html",
    "title": "Measurement Matters",
    "section": "",
    "text": "Today, we consider deep into data analysis for causal inference as it applies to observational cultural psychology. By the end, you will:\n\nBetter understand how to integrate measurement theory with causal inference\nEnhance your proficiency in causal analysis using doubly robust methods\nGain insights into the application of sensitivity analysis using E-Values"
  },
  {
    "objectID": "content/more-old-advice.html#overview",
    "href": "content/more-old-advice.html#overview",
    "title": "Measurement Matters",
    "section": "",
    "text": "Today, we consider deep into data analysis for causal inference as it applies to observational cultural psychology. By the end, you will:\n\nBetter understand how to integrate measurement theory with causal inference\nEnhance your proficiency in causal analysis using doubly robust methods\nGain insights into the application of sensitivity analysis using E-Values"
  },
  {
    "objectID": "content/more-old-advice.html#set-up-your-workspace-.",
    "href": "content/more-old-advice.html#set-up-your-workspace-.",
    "title": "Measurement Matters",
    "section": "Set up your workspace .",
    "text": "Set up your workspace .\n\n\nCode\n# Before running this source code, make sure to update to the current version of R, and to update all existing packages.\n\n\n# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI\nsource(\"/Users/joseph/GIT/templates/functions/libs2.R\")\n\n# WARNING:  COMMENT THIS OUT. JB DOES THIS FOR WORKING WITHOUT WIFI\nsource(\"/Users/joseph/GIT/templates/functions/funs.R\")\n\n\nsource(\"/Users/joseph/GIT/templates/functions/experimental_funs.R\")\n\n\n# ALERT: UNCOMMENT THIS AND DOWNLOAD THE FUNCTIONS FROM JB's GITHUB\n# source(\n#   \"https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R\"\n# )\n\n\n#  If you haven't already, you should have created a folder called \"data\", in your Rstudio project. If not, download this file, add it to your the folder called \"data\" in your Rstudio project. # \"https://www.dropbox.com/s/vwqijg4ha17hbs1/nzavs_dat_synth_t10_t12?dl=0\"\n\n# A function we will use for our tables.\ntab_ate_subgroup_rd &lt;- function(x,\n                                new_name,\n                                delta = 1,\n                                sd = 1) {\n  # Check if required packages are installed\n  required_packages &lt;- c(\"EValue\", \"dplyr\")\n  new_packages &lt;-\n    required_packages[!(required_packages %in% installed.packages()[, \"Package\"])]\n  if (length(new_packages))\n    stop(\"Missing packages: \", paste(new_packages, collapse = \", \"))\n  \n  require(EValue)\n  require(dplyr)\n  \n  # check if input data is a dataframe\n  if (!is.data.frame(x))\n    stop(\"Input x must be a dataframe\")\n  \n  # Check if required columns are in the dataframe\n  required_cols &lt;- c(\"estimate\", \"lower_ci\", \"upper_ci\")\n  missing_cols &lt;- required_cols[!(required_cols %in% colnames(x))]\n  if (length(missing_cols) &gt; 0)\n    stop(\"Missing columns in dataframe: \",\n         paste(missing_cols, collapse = \", \"))\n  \n  # Check if lower_ci and upper_ci do not contain NA values\n  if (any(is.na(x$lower_ci), is.na(x$upper_ci)))\n    stop(\"Columns 'lower_ci' and 'upper_ci' should not contain NA values\")\n  \n  x &lt;- x %&gt;%\n    dplyr::mutate(across(where(is.numeric), round, digits = 3)) %&gt;%\n    dplyr::rename(\"E[Y(1)]-E[Y(0)]\" = estimate)\n  \n  x$standard_error &lt;- abs(x$lower_ci - x$upper_ci) / 3.92\n  \n  evalues_list &lt;- lapply(seq_len(nrow(x)), function(i) {\n    row_evalue &lt;- EValue::evalues.OLS(\n      x[i, \"E[Y(1)]-E[Y(0)]\"],\n      se = x[i, \"standard_error\"],\n      sd = sd,\n      delta = delta,\n      true = 0\n    )\n    # If E_value is NA, set it to 1\n    if (is.na(row_evalue[2, \"lower\"])) {\n      row_evalue[2, \"lower\"] &lt;- 1\n    }\n    if (is.na(row_evalue[2, \"upper\"])) {\n      row_evalue[2, \"upper\"] &lt;- 1\n    }\n    data.frame(round(as.data.frame(row_evalue)[2, ], 3)) # exclude the NA column\n  })\n  \n  evalues_df &lt;- do.call(rbind, evalues_list)\n  colnames(evalues_df) &lt;- c(\"E_Value\", \"E_Val_bound\")\n  \n  tab_p &lt;- cbind(x, evalues_df)\n  \n  tab &lt;-\n    tab_p |&gt; select(c(\n      \"E[Y(1)]-E[Y(0)]\",\n      \"lower_ci\",\n      \"upper_ci\",\n      \"E_Value\",\n      \"E_Val_bound\"\n    ))\n  \n  return(tab)\n}\n\n# extra packages we need\n# for efa/cfa\nif (!require(psych)) {\n  install.packages(\"psych\")\n  library(\"psych\")\n}\n\n# for reporting\nif (!require(parameters)) {\n  install.packages(\"parameters\")\n  library(\"parameters\")\n}\n\n# for graphing\nif (!require(see)) {\n  install.packages(\"see\")\n  library(\"see\")\n}\n\n# for graphing\nif (!require(lavaan)) {\n  install.packages(\"lavaan\")\n  library(\"lavaan\")\n}\n\n\n# for graphing\nif (!require(datawizard)) {\n  install.packages(\"datawizard\")\n  library(\"datawizard\")\n}\n\n\n\nImport the data\n\n# This will read the synthetic data into Rstudio.  Note that the arrow package allows us to have lower memory demands in the storage and retrieval of data.\n\nnzavs_synth &lt;- arrow::read_parquet(here::here(\"data\", \"nzavs_dat_synth_t10_t12\"))\n\nNext, we will inspect column names.\nMake sure to familiarise your self with the variable names here\nIt is alwasy a good idea to plot the data (do on your own time.)"
  },
  {
    "objectID": "content/more-old-advice.html#revisit-the-checklist",
    "href": "content/more-old-advice.html#revisit-the-checklist",
    "title": "Measurement Matters",
    "section": "Revisit the checklist",
    "text": "Revisit the checklist\nIt is essential to remember our checklist:\n\nClearly state your question.\nExplain its relevance.\nEnsure your question is causal.\nDevelop a subgroup analysis question if applicable.\n\nOur discussion today revolves around two main questions:\n\nDoes exercise influence anxiety/depression?\nDo these effects differ among NZ Europeans and Māori?\n\nWhile these questions offer a starting point, they lack specificity. We need to clarify:\n\nThe amount, regularity, and duration of exercise\nThe measures of depression to be used\nThe expected timeline for observing the effects\n\nRemember, we can clarify these by emulating a hypothetical experiment, a concept we call the Target Trial.\nOur initial responses will be guided by the NZAVS measure of exercise, focusing on the hours of activity per week, the 1-year effect on Kessler-6 depression after initiating a change in exercise, and a particular emphasis on effect-modification by NZ European and Māori ethnic identification.\nThis analysis has practical motivation, as the effects of exercise on mental health and possible differences between cultural groups remain largely uncharted territory.\nOur initial responses will be guided by the NZAVS measure of exercise, focusing on the hours of activity per week, the 1-year effect on Kessler-6 depression after initiating a change in exercise, and a particular emphasis on effect-modification by NZ European and Māori ethnic identification. This analysis has practical motivation, as the effects of exercise on mental health and possible differences between cultural groups remain largely uncharted territory.\n\nSculpting the Data: A Hands-On Approach\nAs we venture further, we’ll perform a series of transformations to shape our data according to our needs. Our process will involve:\n\nConstructing a Kessler 6 average score\nBuilding a Kessler 6 sum score\nCoarsening the Exercise score\n\nConsider the ambiguity in the NZAVS exercise question: “During the past week, list ‘Hours spent exercising/physical activity’.” Different people interpret physical activity differently; John may consider any wakeful time as physical activity, while Jane counts only aerobic exercise. Such variation underlines the importance of the consistency assumption in causal inference. But we’ll delve deeper into that later.\nFor now, let’s transform our indicators.\n\n# create sum score of kessler 6\ndt_start &lt;- nzavs_synth %&gt;%\n  arrange(id, wave) %&gt;%\n  rowwise() %&gt;%\n  mutate(lifesat_composite  = mean(\n    c(lifesat_satlife,                         \n    lifesat_ideal) ))|&gt; \n  mutate(kessler_6  = mean(\n    # Specify the Kessler scale items\n    c(\n      kessler_depressed,\n      # During the last 30 days, how often did you feel so depressed that nothing could cheer you up?\n      kessler_hopeless,\n      # During the last 30 days, how often did you feel hopeless?\n      kessler_nervous,\n      # During the last 30 days, how often did you feel nervous?\n      kessler_effort,\n      # During the last 30 days, how often did you feel that everything was an effort?\n      kessler_restless,\n      # During the last 30 days, how often did you feel restless or fidgety ?\n      kessler_worthless  # During the last 30 days, how often did you feel worthless?\n    )\n  )) |&gt;\n  mutate(kessler_6_sum = round(sum(\n    c (\n      kessler_depressed,\n      kessler_hopeless,\n      kessler_nervous,\n      kessler_effort,\n      kessler_restless,\n      kessler_worthless\n    )\n  ),\n  digits = 0)) |&gt;  ungroup() |&gt;\n  # Coarsen 'hours_exercise' into categories\n  mutate(\n    hours_exercise_coarsen = cut(\n      hours_exercise,\n      # Hours spent exercising/ physical activity\n      breaks = c(-1, 3, 8, 200),\n      labels = c(\"inactive\",\n                 \"active\",\n                 \"very_active\"),\n      # Define thresholds for categories\n      levels = c(\"(-1,3]\", \"(3,8]\", \"(8,200]\"),\n      ordered = TRUE\n    ))|&gt;\n  # Create a binary 'urban' variable based on the 'rural_gch2018' variable\n  mutate(urban = factor(\n    ifelse(\n      rural_gch2018 == \"medium_urban_accessibility\" |\n        # Define urban condition\n        rural_gch2018 == \"high_urban_accessibility\",\n      \"urban\",\n      # Label 'urban' if condition is met\n      \"rural\"  # Label 'rural' if condition is not met\n    )\n  ))\n\nWhy do we coarsen the exposure? Recall the consistency assumption of causal inference:\nConsistency: Can I interpret what it means to intervene on the exposure? I should be able to.\nWhat is th hypothetical experiment here for change in exercise?\nThrough data wrangling, we can answer our research questions more effectively by manipulating variables into more meaningful and digestible forms. We imagine an experiment in which people were within one band of the coarsened exercise band and we\nThese data checks will ensure the accuracy and reliability of our transformations, setting the foundation for solid data analysis.\n\n\nCode\n# do some checks\nlevels(dt_start$hours_exercise_coarsen)\ntable(dt_start$hours_exercise_coarsen)\nmax(dt_start$hours_exercise)\nmin(dt_start$hours_exercise)\n# checks\n\n\n# justification for transforming exercise\" has a very long tail\nhist(dt_start$hours_exercise, breaks = 1000)\n# consider only those cases below &lt; or = to 20\nhist(subset(dt_start, hours_exercise &lt;= 20)$hours_exercise)\nhist(as.numeric(dt_start$hours_exercise_coarsen))\n\n\n\n\nCreate variables for the latent factors\nLet’s next get the data into shape for analysis. Here we create a variable for the two factors (see Appendix)\n\n# get two factors from data\ndt_start2 &lt;- dt_start |&gt;\n  arrange(id, wave) |&gt;\n  rowwise() |&gt;\n  mutate(\n    kessler_latent_depression = mean(c(kessler_depressed, kessler_hopeless, kessler_effort), na.rm = TRUE),\n    kessler_latent_anxiety  = mean(c(kessler_effort, kessler_nervous, kessler_restless), na.rm = TRUE)\n  ) |&gt;\n  ungroup()\n\nInspect the data: anxiety\n\n#hist(dt_start2$kessler_latent_anxiety, by = dt_start2$eth_cat)\n\ncreate_histograms_anxiety &lt;- function(df) {\n  # require patchwork\n  library(patchwork)\n  \n  # separate the data by eth_cat\n  df1 &lt;- df %&gt;% filter(eth_cat == \"euro\") # replace \"level_1\" with actual level\n  df2 &lt;- df %&gt;% filter(eth_cat == \"māori\") # replace \"level_2\" with actual level\n  \n  # create the histograms\n  p1 &lt;- ggplot(df1, aes(x=kessler_latent_anxiety)) +\n    geom_histogram(binwidth = 1, fill = \"dodgerblue\", color = \"black\") +\n    ggtitle(\"Kessler Latent Anxiety: NZ Euro\") +\n    xlab(\"kessler_latent_anxiety\") +\n    ylab(\"Count\")\n  \n  p2 &lt;- ggplot(df2, aes(x=kessler_latent_anxiety)) +\n    geom_histogram(binwidth = 1, fill = \"brown\", color = \"black\") +\n    ggtitle(\"Kessler Latent Anxiety: Māori\") +\n    xlab(\"kessler_latent_anxiety\") +\n    ylab(\"Count\")\n  \n  # plot the histograms\n p1 + p2 + plot_annotation(tag_levels = \"a\", title = \"comparison of anxiety histograms\")\n}\n\ncreate_histograms_anxiety(dt_start2)\n\n\ncreate_histograms_depression &lt;- function(df) {\n  # require patchwork\n  library(patchwork)\n  \n  # separate the data by eth_cat\n  df11 &lt;- df %&gt;% filter(eth_cat == \"euro\") # replace \"level_1\" with actual level\n  df22 &lt;- df %&gt;% filter(eth_cat == \"māori\") # replace \"level_2\" with actual level\n  \n  # create the histograms\n  p11 &lt;- ggplot(df11, aes(x=kessler_latent_depression)) +\n    geom_histogram(binwidth = 1, fill = \"dodgerblue\", color = \"black\") +\n    ggtitle(\"Kessler Latent Depression: NZ Euro\") +\n    xlab(\"kessler_latent_depression\") +\n    ylab(\"Count\") + theme_classic()\n  \n  p22 &lt;- ggplot(df22, aes(x=kessler_latent_depression)) +\n    geom_histogram(binwidth = 1, fill = \"brown\", color = \"black\") +\n    ggtitle(\"Kessler Latent Depression: Māori\") +\n    xlab(\"kessler_latent_depression\") +\n    ylab(\"Count\") + theme_classic()\n  \n  # plot the histograms\n p11 + p22 + plot_annotation(tag_levels = \"a\", title = \"comparison of depression histograms\")\n}\n\ncreate_histograms_depression(dt_start2)\n\nWhat do you make of these histograms?"
  },
  {
    "objectID": "content/more-old-advice.html#investigate-assumption-of-positivity",
    "href": "content/more-old-advice.html#investigate-assumption-of-positivity",
    "title": "Measurement Matters",
    "section": "Investigate assumption of positivity:",
    "text": "Investigate assumption of positivity:\nRecall the positive assumption:\nPositivity: Can we intervene on the exposure at all levels of the covariates? We should be able to.\nNot this is just a description of the the summary scores. We do not assess change within indivuals\n\n#  select only the baseline year and the exposure year.  That will give us change in the exposure. ()\ndt_exposure &lt;- dt_start2 |&gt;\n\n  # select baseline year and exposure year\n  filter(wave == \"2018\" | wave == \"2019\") |&gt;\n\n  # select variables of interest\n  select(id, wave, hours_exercise_coarsen,  eth_cat) |&gt;\n\n  # the categorical variable needs to be numeric for us to use msm package to investigate change\n  mutate(hours_exercise_coarsen_n = as.numeric(hours_exercise_coarsen)) |&gt;\n  droplevels()\n\n\n# check\ndt_exposure |&gt;\n  tabyl(hours_exercise_coarsen_n, eth_cat,  wave )\n\nI’ve written a function called transition_table that will help us assess change in the exposure at the individual level.\n\n#   consider people going from active to vary active\nout &lt;- msm::statetable.msm(round(hours_exercise_coarsen_n, 0), id, data = dt_exposure)\n\n\n# for a function I wrote to create state tables\nstate_names &lt;- c(\"Inactive\", \"Somewhat Active\", \"Active\", \"Extremely Active\")\n\nNext consider Māori only\n\n# Maori only\n\ndt_exposure_maori &lt;- dt_exposure |&gt;\n  filter(eth_cat == \"māori\")\n\nout_m &lt;- msm::statetable.msm(round(hours_exercise_coarsen_n, 0), id, data = dt_exposure_maori)\n\n# with this little support we might consider parametric models\n#t_tab_m&lt;- transition_table_2( out_m, state_names)\n\n#interpretation\n# cat(t_tab_m$explanation)\n# print(t_tab_m$table)\n\n\n# filter euro\ndt_exposure_euro &lt;- dt_exposure |&gt;\n  filter(eth_cat == \"euro\")\n\n# model change\nout_e &lt;- msm::statetable.msm(round(hours_exercise_coarsen_n, 0), id, data = dt_exposure_euro)\n\n\n# creat transition table.\n# t_tab_e &lt;- transition_table_2( out_e, state_names)\n\n#interpretation\n# cat(t_tab_e$explanation)\n# \n# # table\n# print(t_tab_e$table)\n\nOverall we find evidence for change in the exposure variable. This suggest that we are ready to proceed with the next step of causal estimation.\n\nCreate wide data frame for analysis\nRecall, I wrote a function for you that will put the data into temporal order such that measurement of the exposure and outcome appear at baseline, along with a rich set of baseline confounders, the exposure appears in the following wave, and the outcome appears in the wave following the exposure.\nThe graph encodes our assumptions about the world. It is a qualitative instrument to help us understand how to move from our assumptions to decisions about our analysis, in the first instance, the decision about whether to proceed with an analysis.\nIt is perhaps useful here to stop and consider what does this graph implies.\nQuestion: 1. Does the graph imply unmeasured confounding?\nQuestion 2. If there is unmeasured confounding, should we proceed?\n\n\nE-value\n\nThe minimum strength of association on the risk ratio scale that an unmeasured confounder would need to have with both the exposure and the outcome, conditional on the measured covariates, to fully explain away a specific exposure-outcome association\n\nSee: [VanderWeele, Mathur, and Chen (2020)](mathur2018a?)\nFor example, suppose that the lower bound of the the E-value was 1.3 with the lower bound of the confidence interval = 1.12, we might then write:\n\nWith an observed risk ratio of RR=1.3, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 1.3-fold each (or 30%), above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 1.12-fold (or 12%) each could do so, but weaker joint confounder associations could not.\n\nThe equations are as follows (for risk ratios)\n\nE-value_{RR} = RR + \\sqrt{RR \\times (RR - 1)}\n \nE-value_{LCL} = LCL + \\sqrt{LCL \\times (LCL - 1)}\n\nHere is an R function that will calculate E-values\n\ncalculate_e_value &lt;- function(rr, lcl) {\n  e_value_rr = rr + sqrt(rr*(rr - 1))\n  e_value_lcl = lcl + sqrt(lcl*(lcl - 1))\n  \n  list(e_value_rr = e_value_rr, e_value_lcl = e_value_lcl)\n}\n\n# e.g. smoking causes cancer\n\n# finding   RR = 10.73 (95% CI: 8.02, 14.36)\n\ncalculate_e_value(10.73, 8.02)\n\nWe write:\n\nWith an observed risk ratio of RR=10.7, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 20.9-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 15.5-fold each could do so, but weaker joint confounder associations could not.\n\nNote that in this class, most of the outcomes will be (standardised) continuous outcomes. Here’s a function and LaTeX code to describe the approximation.\nThis function takes a linear regression coefficient estimate (est), its standard error (se), the standard deviation of the outcome (sd), a contrast of interest in the exposure (delta, which defaults to 1), and a “true” standardized mean difference (true, which defaults to 0). It calculates the odds ratio using the formula from Chinn (2000) and VanderWeele (2017), and then uses this to calculate the E-value.\n\n#| label: evalue_ols\n\ncompute_evalue_ols &lt;- function(est, se, delta = 1, true = 0) {\n  # Rescale estimate and SE to reflect a contrast of size delta\n  est &lt;- est / delta\n  se &lt;- se / delta\n\n  # Compute transformed odds ratio and confidence intervals\n  odds_ratio &lt;- exp(0.91 * est)\n  lo &lt;- exp(0.91 * est - 1.78 * se)\n  hi &lt;- exp(0.91 * est + 1.78 * se)\n\n  # Compute E-Values based on the RR values\n  evalue_point_estimate &lt;- odds_ratio * sqrt(odds_ratio + 1)\n  evalue_lower_ci &lt;- lo * sqrt(lo + 1)\n\n  # Return the E-values\n  return(list(EValue_PointEstimate = evalue_point_estimate,\n              EValue_LowerCI = evalue_lower_ci))\n}\n\n\n\n\n# exampl:\n# suppose we have an estimate of 0.5, a standard error of 0.1, and a standard deviation of 1.\n# This would correspond to a half a standard deviation increase in the outcome per unit increase in the exposure.\nresults &lt;- compute_evalue_ols(est = 0.5, se = 0.1, delta = 1)\nprint(results)\n\nWe write:\n\nWith an observed risk ratio of RR=2.92, an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of 2.92-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of 2.23-fold each could do so, but weaker joint confounder associations could not.\n\nNote the E-values package will do the computational work for us (note we get slightly different estimates)\nNote:\nFirst, the fucntion converts the estimate to an odds ratio:\n\nOdds Ratio Conversion:\n(OddsRatio = e^{ })\n\nThen, it calculates the confidence intervals for the odds ratio:\n\nConfidence Intervals:\n(LowerConfidenceInterval = e^{log(OddsRatio) - 1.78 SE})\n(UpperConfidenceInterval = e^{log(OddsRatio) + 1.78 SE})\n\nFinally, it calculates the E-value for the point estimate and the lower confidence interval:\n\nE-Values Calculation:\n(EValue_{PointEstimate} = OddsRatio + )\n(EValue_{LowerCI} = LowerConfidenceInterval + )\n\n[[JB: NEED TO CHECK]]\nGenerally, best to use the EValue function.\n\nlibrary(EValue)\n\nEValue::evalues.OLS(est = 0.5, se = 0.1, sd = 1, delta = 1, true = 0)\n\n\n############## ############## ############## ############## ############## ############## ############## ########\n####  ####  ####  CREATE DATA FRAME FOR ANALYSIS ####  ####  ################## ############## ######## #########\n############## ############## ############## ############## ############## ############## ############# #########\n\n\n# I have created a function that will put the data into the correct shape. Here are the steps.\n\n# Step 1: choose baseline variables (confounders).  here we select standard demographic variablees plus personality variables.\n\n# Note again that the function will automatically include the baseline exposure and basline outcome in the baseline variable confounder set so you don't need to include these. \n\n\n# here are some plausible baseline confounders\nbaseline_vars = c(\n  \"edu\",\n  \"male\",\n  \"eth_cat\",\n  \"employed\",\n  \"gen_cohort\",\n  \"nz_dep2018\", # nz dep\n  \"nzsei13\", # occupational prestige\n  \"partner\",\n  \"parent\",\n  \"pol_orient\",\n # \"rural_gch2018\",\n   \"urban\", # use the two level urban varaible. \n  \"agreeableness\",\n  \"conscientiousness\",\n  \"extraversion\",\n  \"honesty_humility\",\n  \"openness\",\n  \"neuroticism\",\n  \"modesty\",\n  \"religion_identification_level\"\n)\n\n\n## Step 2, select the exposure variable.  This is the \"cause\"\nexposure_var = c(\"hours_exercise_coarsen\")\n\n\n## step 3. select the outcome variable.  These are the outcomes.\noutcome_vars_reflective = c(\"kessler_latent_anxiety\",\n                            \"kessler_latent_depression\")\n\n\n\n# the function \"create_wide_data\" should be in your environment.\n# If not, make sure to run the first line of code in this script once more.  You may ignore the warnings. or uncomment and run the code below\n# source(\"https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R\")\ndt_prepare &lt;-\n  create_wide_data(\n    dat_long = dt_start2,\n    baseline_vars = baseline_vars,\n    exposure_var = exposure_var,\n    outcome_vars = outcome_vars_reflective\n  )"
  },
  {
    "objectID": "content/more-old-advice.html#descriptive-table",
    "href": "content/more-old-advice.html#descriptive-table",
    "title": "Measurement Matters",
    "section": "Descriptive table",
    "text": "Descriptive table\n\n\nCode\n# I have created a function that will allow you to take a data frame and\n# create a table\nbaseline_table(dt_prepare, output_format = \"markdown\")\n\n# but it is not very nice. Next up, is a better table\n\n\n\n# get data into shape\ndt_new &lt;- dt_prepare %&gt;%\n  select(starts_with(\"t0\")) %&gt;%\n  rename_all( ~ stringr::str_replace(., \"^t0_\", \"\")) %&gt;%\n  mutate(wave = factor(rep(\"baseline\", nrow(dt_prepare)))) |&gt;\n  janitor::clean_names(case = \"screaming_snake\")\n\n\n# create a formula string\nbaseline_vars_names &lt;- dt_new %&gt;%\n  select(-WAVE) %&gt;%\n  colnames()\n\ntable_baseline_vars &lt;-\n  paste(baseline_vars_names, collapse = \"+\")\n\nformula_string_table_baseline &lt;-\n  paste(\"~\", table_baseline_vars, \"|WAVE\")\n\ntable1::table1(as.formula(formula_string_table_baseline),\n               data = dt_new,\n               overall = FALSE)\n\n\n# another method for making a table\n# x &lt;- table1::table1(as.formula(formula_string_table_baseline),\n#                     data = dt_new,\n#                     overall = FALSE)\n\n# # some options, see: https://cran.r-project.org/web/packages/kableExtra/vignettes/awesome_table_in_html.html\n# table1::t1kable(x, format = \"html\", booktabs = TRUE) |&gt;\n#   kable_material(c(\"striped\", \"hover\"))\n\nWe need to do some more data wrangling, alas! Data wrangling is the majority of data analysis. The good news is that R makes wrangling relatively straightforward.\n\nmutate(id = factor(1:nrow(dt_prepare))): This creates a new column called id that has unique identification factors for each row in the dataset. It ranges from 1 to the number of rows in the dataset.\nThe next mutate operation is used to convert the t0_eth_cat, t0_urban, and t0_gen_cohort variables to factor type, if they are not already.\nThe filter command is used to subset the dataset to only include rows where the t0_eth_cat is either “euro” or “māori”. The original dataset includes data with four different ethnic categories. This command filters out any row not related to these two groups.\nungroup() ensures that there’s no grouping in the dataframe.\nThe mutate(across(where(is.numeric), ~ scale(.x), .names = \"{col}_z\")) step standardizes all numeric columns in the dataset by subtracting the mean and dividing by the standard deviation (a z-score transformation). The resulting columns are renamed to include “_z” at the end of their original names.\nThe select function is used to keep only specific columns: the id column, any columns that are factors, and any columns that end in “_z”.\nThe relocate functions re-order columns. The first relocate places the id column at the beginning. The next three relocate functions order the rest of the columns based on their names: those starting with “t0_” are placed before “t1_” columns, and those starting with “t2_” are placed after “t1_” columns.\ndroplevels() removes unused factor levels in the dataframe.\nFinally, skimr::skim(dt) will print out a summary of the data in the dt object using the skimr package. This provides a useful overview of the data, including data types and summary statistics.\n\nThis function seems to be part of a data preparation pipeline in a longitudinal or panel analysis, where observations are ordered over time (indicated by t0_, t1_, t2_, etc.).\n\n### ### ### ### ### ### SUBGROUP DATA ANALYSIS: DATA WRANGLING  ### ### ### ###\n\ndt &lt;- dt_prepare|&gt;\n  mutate(id = factor(1:nrow(dt_prepare))) |&gt;\n  mutate(\n  t0_eth_cat = as.factor(t0_eth_cat),\n  t0_urban = as.factor(t0_urban),\n  t0_gen_cohort = as.factor(t0_gen_cohort)\n) |&gt;\n  dplyr::filter(t0_eth_cat == \"euro\" |\n                t0_eth_cat == \"māori\") |&gt; # Too few asian and pacific\n  ungroup() |&gt;\n  # transform numeric variables into z scores (improves estimation)\n  dplyr::mutate(across(where(is.numeric), ~ scale(.x), .names = \"{col}_z\")) %&gt;%\n  # select only factors and numeric values that are z-scores\n  select(id, # category is too sparse\n         where(is.factor),\n         ends_with(\"_z\"), ) |&gt;\n  # tidy data frame so that the columns are ordered by time (useful for more complex models)\n  relocate(id, .before = starts_with(\"t1_\"))   |&gt;\n  relocate(starts_with(\"t0_\"), .before = starts_with(\"t1_\"))  |&gt;\n  relocate(starts_with(\"t2_\"), .after = starts_with(\"t1_\")) |&gt;\n  droplevels()\n\n# view object\nskimr::skim(dt)\n\n\n# quick cross table\n#table( dt$t1_hours_exercise_coarsen, dt$t0_eth_cat )\n\n# checks\nhist(dt$t2_kessler_latent_depression_z)\nhist(dt$t2_kessler_latent_anxiety_z)\n\ndt |&gt;\n  tabyl(t0_eth_cat, t1_hours_exercise_coarsen ) |&gt;\n  kbl(format = \"markdown\")\n\n# Visualise missingness\nnaniar::vis_miss(dt)\n\n# save your dataframe for future use\n\n# make dataframe\ndt = as.data.frame(dt)\n\n# save data\nsaveRDS(dt, here::here(\"data\", \"dt\"))"
  },
  {
    "objectID": "content/more-old-advice.html#propensity-scores",
    "href": "content/more-old-advice.html#propensity-scores",
    "title": "Measurement Matters",
    "section": "Propensity scores",
    "text": "Propensity scores\nNext we generate propensity scores. Instead of modelling the outcome (t2_y) we will model the exposure (t1_x) as predicted by baseline indicators (t0_c) that we assume may be associated with the outcome and the exposure.\nThe first step is to obtain the baseline variables. note that we must remove “t0_eth_cat” because we are performing separate weighting for each stratum within this variable.\n\n# read  data -- you may start here if you need to repeat the analysis\ndt &lt;- readRDS(here::here(\"data\", \"dt\"))\n\n# get column names\nbaseline_vars_reflective_propensity &lt;- dt|&gt;\n  dplyr::select(starts_with(\"t0\"), -t0_eth_cat) |&gt; colnames()\n\n# define our exposure\nX &lt;- \"t1_hours_exercise_coarsen\"\n\n# define subclasses\nS &lt;- \"t0_eth_cat\"\n\n# Make sure data is in a data frame format\ndt &lt;- data.frame(dt)\n\n\n# next we use our trick for creating a formula string, which will reduce our work\nformula_str_prop &lt;-\n  paste(X,\n        \"~\",\n        paste(baseline_vars_reflective_propensity, collapse = \"+\"))\n\n# this shows the exposure variable as predicted by the baseline confounders.\n\nFor propensity score analysis, we will try several different approaches. We will want to select the method that produces the best balance.\nI typically use ps (classical propensity scores), ebal and energy. The latter two in my experience yeild good balance. Also energy will work with continuous exposures.\nFor more information, see https://ngreifer.github.io/WeightIt/\n\n# traditional propensity scores-- note we select the ATT and we have a subgroup \ndt_match_ps &lt;- match_mi_general(\n  data = dt,\n  X = X,\n  baseline_vars = baseline_vars_reflective_propensity,\n  subgroup = \"t0_eth_cat\",\n  estimand = \"ATE\",\n  method = \"ps\"\n)\n\nsaveRDS(dt_match_ps, here::here(\"data\", \"dt_match_ps\"))\n\n\n# ebalance\ndt_match_ebal &lt;- match_mi_general(\n  data = dt,\n  X = X,\n  baseline_vars = baseline_vars_reflective_propensity,\n  subgroup = \"t0_eth_cat\",\n  estimand = \"ATE\",\n  method = \"ebal\"\n)\n\n# save output\nsaveRDS(dt_match_ebal, here::here(\"data\", \"dt_match_ebal\"))\n\n\n\n## energy balance method\ndt_match_energy &lt;- match_mi_general(\n  data = dt,\n  X = X,\n  baseline_vars = baseline_vars_reflective_propensity,\n  subgroup = \"t0_eth_cat\",\n  estimand = \"ATE\",\n  #focal = \"high\", # for use with ATT\n  method = \"energy\"\n)\nsaveRDS(dt_match_energy, here::here(\"data\", \"dt_match_energy\"))\n\nResults, first for Europeans\n\n#dt_match_energy &lt;- readRDS(here::here(\"data\", \"dt_match_energy\"))\ndt_match_ebal &lt;- readRDS(here::here(\"data\", \"dt_match_ebal\"))\n#dt_match_ps &lt;- readRDS(here::here(\"data\", \"dt_match_ps\"))\n\n# next we inspect balance. \"Max.Diff.Adj\" should ideally be less than .05, but less than .1 is ok. This is the standardised mean difference. The variance ratio should be less than 2. \n# note that if the variables are unlikely to influence the outcome we can be less strict. \n\n#See: Hainmueller, J. 2012. “Entropy Balancing for Causal Effects: A Multivariate Reweighting Method to Produce Balanced Samples in Observational Studies.” Political Analysis 20 (1): 25–46. https://doi.org/10.1093/pan/mpr025.\n\n# Cole SR, Hernan MA. Constructing inverse probability weights for marginal structural models. American Journal of\n# Epidemiology 2008; 168(6):656–664.\n\n# Moving towards best practice when using inverse probability of treatment weighting (IPTW) using the propensity score to estimate causal treatment effects in observational studies\n# Peter C. Austin, Elizabeth A. Stuart\n# https://onlinelibrary.wiley.com/doi/10.1002/sim.6607\n\n#bal.tab(dt_match_energy$euro)   #  good\nbal.tab(dt_match_ebal$euro)   #  best\n#bal.tab(dt_match_ps$euro)   #  not as good\n\n# here we show only the best tab, but you should put all information into an appendix\n\nResults for Maori\n\n# who only Ebal\n#bal.tab(dt_match_energy$māori)   #  good\nbal.tab(dt_match_ebal$māori)   #  best\n#bal.tab(dt_match_ps$māori)   #  not good\n\n\n# code for summar\nsum_e &lt;- summary(dt_match_ebal$euro)\nsum_m &lt;- summary(dt_match_ebal$māori)\n\n# summary euro\nsum_e\n\n# summary maori\nsum_m\n\n\nlove_plot_e &lt;- love.plot(dt_match_ebal$euro,\n          binary = \"std\",\n          thresholds = c(m = .1))+ labs(title = \"NZ Euro Weighting: method e-balance\")\n\n# plot\nlove_plot_e \n\n\nlove_plot_m &lt;- love.plot(dt_match_ebal$māori,\n          binary = \"std\",\n          thresholds = c(m = .1)) + labs(title = \"Māori Weighting: method e-balance\")\n# plot\nlove_plot_m\n\n\nExample Summary NZ Euro Propensity scores.\nWe estimated propensity score analysis using entropy balancing, energy balancing and traditional propensity scores. Of these approaches, entropy balancing provided the best balance. The results indicate an excellent balance across all variables, with Max.Diff.Adj values significantly below the target threshold of 0.05 across a range of binary and continuous baseline confounders, including gender, generation cohort, urban_location, exercise hours (coarsened, baseline), education, employment status, depression, anxiety, and various personality traits. The Max.Diff.Adj values for all variables were well below the target threshold of 0.05, with most variables achieving a Max.Diff.Adj of 0.0001 or lower. This indicates a high level of balance across all treatment pairs.\nThe effective sample sizes were also adjusted using entropy balancing. The unadjusted sample sizes for the inactive, active, and very active groups were 2880, 3927, and 1834, respectively. After adjustment, the effective sample sizes were reduced to 1855.89, 3659.59, and 1052.01, respectively.\nThe weight ranges for the inactive, active, and very active groups varied, with the inactive group showing the widest range (0.2310 to 7.0511) and the active group showing the narrowest range (0.5769 to 1.9603). Despite these variations, the coefficient of variation, mean absolute deviation (MAD), and entropy were all within acceptable limits for each group, indicating a good balance of weights.\nWe also identified the units with the five most extreme weights by group. These units exhibited higher weights compared to the rest of the units in their respective groups, but they did not significantly affect the overall balance of weights.\nWe plotted these results using love plots, visually confirming both the balance in the propensity score model using entropy balanced weights, and the imbalance in the model that does not adjust for baseline confounders.\nOverall, these findings support the use of entropy balancing in propensity score analysis to ensure a balanced distribution of covariates across treatment groups, conditional on the measured covariates included in the model.\n\n\nExample Summary Maori Propensity scores.\nResults:\nThe entropy balancing method was also the best performing method that was applied to a subgroup analysis of the Māori population. Similar to the NZ European subgroup analysis, the method achieved a high level of balance across all treatment pairs for the Māori subgroup. The Max.Diff.Adj values for all variables were well below the target threshold of 0.05, with most variables achieving a Max.Diff.Adj of 0.0001 or lower. This indicates a high level of balance across all treatment pairs for the Māori subgroup.\nThe effective sample sizes for the Māori subgroup were also adjusted using entropy balancing. The unadjusted sample sizes for the inactive, active, and very active groups were 307, 354, and 160, respectively. After adjustment, the effective sample sizes were reduced to 220.54, 321.09, and 76.39, respectively\nThe weight ranges for the inactive, active, and very active groups in the Māori subgroup varied, with the inactive group showing the widest range (0.2213 to 3.8101) and the active group showing the narrowest range (0.3995 to 1.9800). Despite these variations, the coefficient of variation, mean absolute deviation (MAD), and entropy were all within acceptable limits for each group, indicating a good balance of weights.\nThe study also identified the units with the five most extreme weights by group for the Māori subgroup. These units exhibited higher weights compared to the rest of the units in their respective groups, but they did not significantly affect the overall balance of weights.\nIn conclusion, the results of the Māori subgroup analysis are consistent with the overall analysis. The entropy balancing method achieved a high level of balance across all treatment pairs, with Max.Diff.Adj values significantly below the target threshold. These findings support the use of entropy balancing in propensity score analysis to ensure a balanced distribution of covariates across treatment groups, even in subgroup analyses.\n\n\nMore data wrangling\nNote that we need to attach the weights from the propensity score model back to the data.\nHowever, because our weighting analysis estimates a model for the exposure, we only need to do this analysis once, no matter how many outcomes we investigate. So there’s a little good news.\n\n# prepare nz_euro data\ndt_ref_e &lt;- subset(dt, t0_eth_cat == \"euro\") # original data subset only nz europeans\n\n# add weights\ndt_ref_e$weights &lt;- dt_match_ebal$euro$weights # get weights from the ps matching model,add to data\n\n# prepare maori data\ndt_ref_m &lt;- subset(dt, t0_eth_cat == \"māori\")# original data subset only maori\n\n# add weights\ndt_ref_m$weights &lt;- dt_match_ebal$māori$weights # get weights from the ps matching model, add to data\n\n# combine data into one data frame\ndt_ref_all &lt;- rbind(dt_ref_e, dt_ref_m) # combine the data into one dataframe."
  },
  {
    "objectID": "content/more-old-advice.html#graph-of-the-result",
    "href": "content/more-old-advice.html#graph-of-the-result",
    "title": "Measurement Matters",
    "section": "Graph of the result",
    "text": "Graph of the result\nI’ve create a function you can use to graph your results. Here is the code, adjust to suit.\n\n# group tables\nsub_group_plot_ate(big_tab, title = \"Effect of Exercise on Anxiety\", subtitle = \"Subgroup Analysis: NZ Euro and Māori\", xlab = \"Groups\", ylab = \"Effects\",\n                 x_offset = -1,\n                           x_lim_lo = -1,\n                           x_lim_hi = 1.5)\n\n\nReport the anxiety result.\n\nFor the New Zealand European group, our results suggest that exercise potentially reduces anxiety, with an estimated causal contrast value (E[Y(1)]-E[Y(0)]) of -0.077. The associated confidence interval, ranging from -0.131 to -0.022, does not cross zero, providing more certainty in our estimate.\n\n\nE-values quantify the minimum strength of association that an unmeasured confounding variable would need to have with both the treatment and outcome, to fully explain away our observed effect. In this case, any unmeasured confounder would need to be associated with both exercise and anxiety reduction, with a risk ratio of at least 1.352 to explain away the observed effect, and at least 1.167 to shift the confidence interval to include a null effect.\n\n\nTurning to the Māori group, the data suggest a possible reducing effect of exercise on anxiety, with a causal contrast value of 0.027. Yet, the confidence interval for this estimate (-0.114 to 0.188) also crosses zero, indicating similar uncertainties. An unmeasured confounder would need to have a risk ratio of at least 1.183 with both exercise and anxiety to account for our observed effect, and a risk ratio of at least 1 to render the confidence interval inclusive of a null effect.\n\n\nThus, while our analysis suggests that exercise could potentially reduce anxiety in both New Zealand Europeans and Māori, we advise caution in interpretation. The confidence intervals crossing zero reflect substantial uncertainties, and the possible impact of unmeasured confounding factors further complicates the picture.\n\nHere’s a function that will do much of this work for you. However, you’ll need to adjust it, and supply your own interpretation.\n\n#|label: interpretation function\n#| eval: false\ninterpret_results_subgroup &lt;- function(df, outcome, exposure) {\n  df &lt;- df %&gt;%\n    mutate(\n      report = case_when(\n        E_Val_bound &gt; 1.2 & E_Val_bound &lt; 2 ~ paste0(\n          \"For the \", group, \", our results suggest that \", exposure, \" may potentially influence \", outcome, \", with an estimated causal contrast value (E[Y(1)]-E[Y(0)]) of \", `E[Y(1)]-E[Y(0)]`, \".\\n\",\n          \"The associated confidence interval, ranging from \", `2.5 %`, \" to \", `97.5 %`, \", does not cross zero, providing more certainty in our estimate. \",\n          \"The E-values indicate that any unmeasured confounder would need to have a minimum risk ratio of \", E_Value, \" with both the treatment and outcome to explain away the observed effect, and a minimum risk ratio of \", E_Val_bound, \" to shift the confidence interval to include the null effect. This suggests stronger confidence in our findings.\"\n        ),\n        E_Val_bound &gt;= 2 ~ paste0(\n          \"For the \", group, \", our results suggest that \", exposure, \" may potentially influence \", outcome, \", with an estimated causal contrast value (E[Y(1)]-E[Y(0)]) of \", `E[Y(1)]-E[Y(0)]`, \".\\n\",\n          \"The associated confidence interval, ranging from \", `2.5 %`, \" to \", `97.5 %`, \", does not cross zero, providing more certainty in our estimate. \",\n          \"With an observed risk ratio of RR = \", E_Value, \", an unmeasured confounder that was associated with both the outcome and the exposure by a risk ratio of \", E_Val_bound, \"-fold each, above and beyond the measured confounders, could explain away the estimate, but weaker joint confounder associations could not; to move the confidence interval to include the null, an unmeasured confounder that was associated with the outcome and the exposure by a risk ratio of \", E_Val_bound, \"-fold each could do so, but weaker joint confounder associations could not. Here we find stronger evidence that the result is robust to unmeasured confounding.\"\n        ),\n        E_Val_bound &lt; 1.2 & E_Val_bound &gt; 1 ~ paste0(\n          \"For the \", group, \", our results suggest that \", exposure, \" may potentially influence \", outcome, \", with an estimated causal contrast value (E[Y(1)]-E[Y(0)]) of \", `E[Y(1)]-E[Y(0)]`, \".\\n\",\n          \"The associated confidence interval, ranging from \", `2.5 %`, \" to \", `97.5 %`, \", does not cross zero, providing more certainty in our estimate. \",\n          \"The E-values indicate that any unmeasured confounder would need to have a minimum risk ratio of \", E_Value, \" with both the treatment and outcome to explain away the observed effect, and a minimum risk ratio of \", E_Val_bound, \" to shift the confidence interval to include the null effect. This suggests we should interpret these findings with caution given uncertainty in the model.\"\n        ),\n        E_Val_bound == 1 ~ paste0(\n          \"For the \", group, \", the data suggests a potential effect of \", exposure, \" on \", outcome, \", with a causal contrast value of \", `E[Y(1)]-E[Y(0)]`, \".\\n\",\n          \"However, the confidence interval for this estimate, ranging from \", `2.5 %`,\" to \", `97.5 %`, \", crosses zero, indicating considerable uncertainties. The E-values indicate that an unmeasured confounder that is associated with both the \", outcome, \" and the \", exposure, \" by a risk ratio of \", E_Value, \" could explain away the observed associations, even after accounting for the measured confounders. \",\n          \"This finding further reduces confidence in a true causal effect. Hence, while the estimates suggest a potential effect of \", exposure, \" on \", outcome, \" for the \", group, \", the substantial uncertainty and possible influence of unmeasured confounders mean these findings should be interpreted with caution.\"\n        )\n      )\n    )\n  return(df$report)\n}\n\nYou run the function like this:\n\ninterpret_results_subgroup(big_tab, outcome = \"Anxiety\", exposure = \"Excercise\")\n\nEasy!\n\n\nEstimate the subgroup contrast\n\n# calculated above\nest_all_anxiety &lt;- readRDS( here::here(\"data\",\"est_all_anxiety\"))\n\n# make the sumamry into a dataframe so we can make a table\ndf &lt;- as.data.frame(summary(est_all_anxiety))\n\n# get rownames for selecting the correct row\ndf$RowName &lt;- row.names(df)\n\n# select the correct row -- the group contrast\nfiltered_df &lt;- df |&gt; \n  dplyr::filter(RowName == \"RD_m - RD_e\") \n\n\n# pring the filtered data frame\nlibrary(kableExtra)\nfiltered_df  |&gt; \n  select(-RowName) |&gt; \n  kbl(digits = 3) |&gt; \n  kable_material(c(\"striped\", \"hover\")) \n\nAnother option for making the table using markdown. This would be useful if you were writing your article using qaurto.\n\nfiltered_df  |&gt; \n  select(-RowName) |&gt; \n  kbl(digits = 3, format = \"markdown\")\n\nReport result along the following lines:\n\nThe estimated reduction of anxiety from exercise is higher overall for New Zealand Europeans (RD_e) compared to Māori (RD_m). This is indicated by the estimated risk difference (RD_m - RD_e) of 0.104. However, there is uncertainty in this estimate, as the confidence interval (-0.042 to 0.279) crosses zero. This indicates that we cannot be confident that the difference in anxiety reduction between New Zealand Europeans and Māori is reliable. It’s possible that the true difference could be zero or even negative, suggesting higher anxiety reduction for Māori. Thus, while there’s an indication of higher anxiety reduction for New Zealand Europeans, the uncertainty in the estimate means we should interpret this difference with caution."
  },
  {
    "objectID": "content/more-old-advice.html#depression-analysis-and-results",
    "href": "content/more-old-advice.html#depression-analysis-and-results",
    "title": "Measurement Matters",
    "section": "Depression Analysis and Results",
    "text": "Depression Analysis and Results\n\n### SUBGROUP analysis\ndt_ref_all &lt;- readRDS(here::here(\"data\", \"dt_ref_all\"))\n# get column names\nbaseline_vars_reflective_propensity &lt;- dt|&gt;\n  dplyr::select(starts_with(\"t0\"), -t0_eth_cat) |&gt; colnames()\ndf &lt;-  dt_ref_all\nY &lt;-  \"t2_kessler_latent_depression_z\"\nX &lt;- \"t1_hours_exercise_coarsen\" # already defined above\nbaseline_vars = baseline_vars_reflective_propensity\ntreat_0 = \"inactive\"\ntreat_1 = \"very_active\"\nestimand = \"ATE\"\nscale = \"RD\"\nnsims = 1000\nfamily = \"gaussian\"\ncontinuous_X = FALSE\nsplines = FALSE\ncores = parallel::detectCores()\nS = \"t0_eth_cat\"\n\n# not we interact the subclass X treatment X covariates\n\nformula_str &lt;-\n  paste(\n    Y,\n    \"~\",\n    S,\n    \"*\",\n    \"(\",\n    X ,\n    \"*\",\n    \"(\",\n    paste(baseline_vars_reflective_propensity, collapse = \"+\"),\n    \")\",\n    \")\"\n  )\n\n# fit model\nfit_all_dep  &lt;- glm(\n  as.formula(formula_str),\n  weights = weights,\n  # weights = if (!is.null(weight_var)) weight_var else NULL,\n  family = family,\n  data = df\n)\n\n\n# coefs &lt;- coef(fit_all_dep)\n# table(is.na(coefs))#   \n# insight::get_varcov(fit_all_all)\n\n# simulate coefficients\nconflicts_prefer(clarify::sim)\nsim_model_all &lt;- sim(fit_all_dep, n = nsims, vcov = \"HC1\")\n\n\n# simulate effect as modified in europeans\nsim_estimand_all_e_d &lt;- sim_ame(\n  sim_model_all,\n  var = X,\n  cl = cores,\n  subset = t0_eth_cat == \"euro\",\n  verbose = TRUE)\n\n\n# note contrast of interest\nsim_estimand_all_e_d &lt;-\n  transform(sim_estimand_all_e_d, RD = `E[Y(very_active)]` - `E[Y(inactive)]`)\n\n\n# simulate effect as modified in māori\nsim_estimand_all_m_d &lt;- sim_ame(\n  sim_model_all,\n  var = X,\n  cl = cores,\n  subset = t0_eth_cat == \"māori\",\n  verbose = TRUE\n)\n\n# combine\nsim_estimand_all_m_d &lt;-\n  transform(sim_estimand_all_m_d, RD = `E[Y(very_active)]` - `E[Y(inactive)]`)\n\n\n# summary\n#summary(sim_estimand_all_e_d)\n#summary(sim_estimand_all_m_d)\n\n# rearrange\nnames(sim_estimand_all_e_d) &lt;-\n  paste(names(sim_estimand_all_e_d), \"e\", sep = \"_\")\n\nnames(sim_estimand_all_m_d) &lt;-\n  paste(names(sim_estimand_all_m_d), \"m\", sep = \"_\")\n\n\nest_all_d &lt;- cbind(sim_estimand_all_m_d, sim_estimand_all_e_d)\nest_all_d &lt;- transform(est_all_d, `RD_m - RD_e` = RD_m - RD_e)\nsaveRDS(sim_estimand_all_m_d, here::here(\"data\", \"sim_estimand_all_m_d\"))\nsaveRDS(sim_estimand_all_e_d, here::here(\"data\", \"sim_estimand_all_e_d\"))\n\n\nReport anxiety results\n\n# return stored estimates \nsim_estimand_all_e_d &lt;- readRDS(here::here(\"data\",\"sim_estimand_all_e_d\"))\nsim_estimand_all_m_d&lt;- readRDS(here::here(\"data\",\"sim_estimand_all_m_d\"))\n\n# create individual summaries \nsum_e_d &lt;- summary(sim_estimand_all_e_d)\nsum_m_d &lt;- summary(sim_estimand_all_m_d)\n\n\n# create individual tables\ntab_ed &lt;- sub_tab_ate(sum_e_d, new_name = \"NZ Euro Depression\")\ntab_md &lt;- sub_tab_ate(sum_m_d, new_name = \"Māori Depression\")\n\n\n# expand tables \nplot_ed &lt;- sub_group_tab(tab_ed, type= \"RD\")\nplot_md &lt;- sub_group_tab(tab_md, type= \"RD\")\n\nbig_tab_d &lt;- rbind(plot_ed,plot_md)\n\n\n# table for anxiety outcome --format as \"markdown\" if you are using quarto documents\nbig_tab_d |&gt; \n  kbl(format=\"markdown\")\n\n\n\nGraph Anxiety result\n\n# group tables\nsub_group_plot_ate(big_tab_d, title = \"Effect of Exercise on Depression\", subtitle = \"Subgroup Analysis: NZ Euro and Māori\", xlab = \"Groups\", ylab = \"Effects\",\n                 x_offset = -1,\n                           x_lim_lo = -1,\n                           x_lim_hi = 1.5)\n\n\n\nInterpretation\nUse the function, again, modify the outputs to fit with your study and results and provide your own interpretation.\n\ninterpret_results_subgroup(big_tab_d, exposure = \"Exercise\", outcome = \"Depression\")\n\n\n\nEstimate the subgroup contrast\n\n# calculated above\nest_all_d &lt;- readRDS( here::here(\"data\",\"est_all_d\"))\n\n# make the sumamry into a dataframe so we can make a table\ndfd &lt;- as.data.frame(summary(est_all_d))\n\n# get rownames for selecting the correct row\ndfd$RowName &lt;- row.names(dfd)\n\n# select the correct row -- the group contrast\nfiltered_dfd &lt;- dfd |&gt; \n  dplyr::filter(RowName == \"RD_m - RD_e\") \n\n\n# Print the filtered data frame\nlibrary(kableExtra)\nfiltered_dfd  |&gt; \n  select(-RowName) |&gt; \n  kbl(digits = 3) |&gt; \n  kable_material(c(\"striped\", \"hover\")) \n\nReporting might be:\n\nThe estimated reduction of depression from exercise is higher overall for New Zealand Europeans (RD_e) compared to Māori (RD_m). This is suggested by the estimated risk difference (RD_m - RD_e) of 0.068. However, there is a degree of uncertainty in this estimate, as the confidence interval (-0.09 to 0.229) crosses zero. This suggests that we cannot be confident that the difference in depression reduction between New Zealand Europeans and Māori is statistically significant. It’s possible that the true difference could be zero or even negative, implying a greater depression reduction for Māori than New Zealand Europeans. Thus, while the results hint at a larger depression reduction for New Zealand Europeans, the uncertainty in this estimate urges us to interpret this difference with caution.\n\n\n\nDiscusion\nYou’ll need to do this yourself. Here’s a start:\n\nIn our study, we employed a robust statistical method that helps us estimate the impact of exercise on reducing anxiety among different population groups – New Zealand Europeans and Māori. This method has the advantage of providing reliable results even if our underlying assumptions aren’t entirely accurate – a likely scenario given the complexity of real-world data. However, this robustness comes with a trade-off: it gives us wider ranges of uncertainty in our estimates. This doesn’t mean the analysis is flawed; rather, it accurately represents our level of certainty given the data we have.\n\n\nExercise and Anxiety\n\nOur analysis suggests that exercise may have a greater effect in reducing anxiety among New Zealand Europeans compared to Māori. This conclusion comes from our primary causal estimate, the risk difference, which is 0.104. However, it’s crucial to consider our uncertainty in this value. We represent this uncertainty as a range, also known as a confidence interval. In this case, the interval ranges from -0.042 to 0.279. What this means is, given our current data and method, the true effect could plausibly be anywhere within this range. While our best estimate shows a higher reduction in anxiety for New Zealand Europeans, the range of plausible values includes zero and even negative values. This implies that the true effect could be no difference between the two groups or even a higher reduction in Māori. Hence, while there’s an indication of a difference, we should interpret it cautiously given the wide range of uncertainty.\n\n\nThus, although our analysis points towards a potential difference in how exercise reduces anxiety among these groups, the level of uncertainty means we should be careful about drawing firm conclusions. More research is needed to further explore these patterns.\n\n\n\nExercise and Depression\n\nIn addition to anxiety, we also examined the effect of exercise on depression. We do not find evidence for reduction of depression from exercise in either group. We do not find evidence for the effect of weekly exercise – as self-reported – on depression.\n\n\n\nProviso\n\nIt is important to bear in mind that statistical results are only one piece of a larger scientific puzzle about the relationship between excercise and well-being. Other pieces include understanding the context, incorporating subject matter knowledge, and considering the implications of the findings. In the present study, wide confidence intervals suggest the possibility of considerable individual differences.\\dots nevertheless, \\dots"
  },
  {
    "objectID": "content/more-old-advice.html#exercises",
    "href": "content/more-old-advice.html#exercises",
    "title": "Measurement Matters",
    "section": "Exercises",
    "text": "Exercises\n\nGenerate a Kessler 6 binary score (Not Depressed vs. Moderately or Severely Depressed)\n\nand also:\n\nCreate a variable for the log of exercise hour\nTake Home: estimate whether exercise causally affects nervousness, using the single item of the kessler 6 score. Briefly write up your results."
  },
  {
    "objectID": "content/more-old-advice.html#appendix-mg-cfa",
    "href": "content/more-old-advice.html#appendix-mg-cfa",
    "title": "Measurement Matters",
    "section": "Appendix: MG-CFA",
    "text": "Appendix: MG-CFA\n\nCFA for Kessler 6\nWe have learned how to do confirmatory factor analysis. Let’s put this knowledge to use but clarifying the underlying factor structure of Kessler-6\nThe code below will:\n\nLoad required packages.\nSelect the Kessler 6 items\nCheck whether there is sufficient correlation among the variables to support factor analysis.\n\n\n# select the columns we need. \ndt_only_k6 &lt;- dt_start |&gt; select(kessler_depressed, kessler_effort,kessler_hopeless,\n                                 kessler_worthless, kessler_nervous,\n                                 kessler_restless)\n\n\n# check factor structure\nperformance::check_factorstructure(dt_only_k6)\n\nThe code below will allow us to explore the factor structure, on the assumption of n = 3 factors.\n\n# exploratory factor analysis\n# explore a factor structure made of 3 latent variables\nefa &lt;- psych::fa(dt_only_k6, nfactors = 3) %&gt;%\n  model_parameters(sort = TRUE, threshold = \"max\")\n\nefa\n\nThis output describes an exploratory factor analysis (EFA) with 3 factors conducted on the Kessler 6 (K6) scale data. The K6 scale is used to measure psychological distress.\nThe analysis identifies three latent factors, labeled MR1, MR2, and MR3, which collectively account for 66.05% of the variance in the K6 data. The factors MR1, MR2, and MR3 explain 35.14%, 17.17%, and 13.73% of the variance respectively.\nFactor loadings, indicating the strength and direction of the relationship between the K6 items and the latent factors, are as follows:\n\nFactor MR1 is strongly associated with ‘kessler_depressed’, ‘kessler_worthless’, and ‘kessler_hopeless’ with loadings of 0.85, 0.79, and 0.75 respectively.\nFactor MR2 is exclusively linked with ‘kessler_nervous’ with a loading of 1.00.\nFactor MR3 relates to ‘kessler_restless’ and ‘kessler_effort’ with loadings of 0.69 and 0.48 respectively.\n\nThe ‘Uniqueness’ values show the proportion of each variable’s variance that isn’t shared with the other variables.\nThe ‘Complexity’ values give a measure of how each item loads on more than one factor. All the items are either loading exclusively on one factor (complexity=1.00) or slightly more than one factor. ‘kessler_effort’ with complexity of 1.66 shows it’s the item most shared between the factors.\nThe analysis suggests these K6 items measure may measure three somewhat distinct, yet related, factors of psychological distress.\nHowever, the meaning of these factors would need to be interpreted in the context of the variables and the theoretical framework of the study.\nNotably, there are many many theoretical frameworks for in measurement theory. Here is a brief description of the different conclusions one might make, depending on one’s preferred theory.\n\n\nCode\nn &lt;- n_factors(dt_only_k6)\n\n# plot\nplot(n) + theme_classic()\n\n\n\n\nConfirmatory factor analysis (ignoring groups)\n\n# first partition the data \npart_data &lt;- datawizard::data_partition(dt_only_k6, traing_proportion = .7, seed = 123)\n\n\n# set up training data\ntraining &lt;- part_data$p_0.7\ntest &lt;- part_data$test\n\n\n# one factor model\nstructure_k6_one &lt;- psych::fa(training, nfactors = 1) |&gt;\n  efa_to_cfa()\n\n# two factor model model\nstructure_k6_two &lt;- psych::fa(training, nfactors = 2) |&gt;\n  efa_to_cfa()\n\n# three factor model\nstructure_k6_three &lt;- psych::fa(training, nfactors = 3) %&gt;%\n  efa_to_cfa()\n\n# inspect models\nstructure_k6_one\nstructure_k6_two\nstructure_k6_three\n\nNext we perform the confirmatory factor analysis.\n\n# fit and compare models\n\n# one latent model\none_latent &lt;-\n  suppressWarnings(lavaan::cfa(structure_k6_one, data = test))\n\n# two latents model\ntwo_latents &lt;-\n  suppressWarnings(lavaan::cfa(structure_k6_two, data = test))\n\n# three latents model\nthree_latents &lt;-\n  suppressWarnings(lavaan::cfa(structure_k6_three, data = test))\n\n\n# compare models\ncompare &lt;-\n  performance::compare_performance(one_latent, two_latents, three_latents, verbose = FALSE)\n\n# view as html table\nas.data.frame(compare) |&gt;\n  kbl(format = \"markdown\")\n\nThis table provides the results of three different Confirmatory Factor Analysis (CFA) models: one that specifies a single latent factor, one that specifies two latent factors, and one that specifies three latent factors. The results include a number of goodness-of-fit statistics, which can be used to assess how well each model fits the data.\n\nOne_latent CFA:\nThis model assumes that there is only one underlying latent factor contributing to all variables. This model has a chi-square statistic of 1359.7 with 14 degrees of freedom, which is highly significant (p&lt;0.001), indicating a poor fit of the model to the data. Other goodness-of-fit indices like GFI, AGFI, NFI, NNFI, and CFI are all high (above 0.9), generally indicating good fit, but these indices can be misleading in the presence of large sample sizes. RMSEA is above 0.1 which indicates a poor fit. The SRMR is less than 0.08 which suggests a good fit, but given the high Chi-square and RMSEA values, we can’t solely rely on this index. The Akaike information criterion (AIC), Bayesian information criterion (BIC) and adjusted BIC are used for comparing models, with lower values indicating better fit.\n\n\nTwo_latents CFA\nThis model assumes that there are two underlying latent factors. The chi-square statistic is lower than the one-factor model (317.97 with 13 df), suggesting a better fit. The p-value is still less than 0.05, indicating a statistically significant chi-square, which typically suggests a poor fit. However, all other fit indices (GFI, AGFI, NFI, NNFI, and CFI) are above 0.9 and the RMSEA is 0.051, which generally indicate good fit. The SRMR is also less than 0.08 which suggests a good fit. This model has the lowest AIC and BIC values among the three models, indicating the best fit according to these criteria.\n\n\nThree_latents CFA\nThis model assumes three underlying latent factors. The chi-square statistic is 747.87 with 12 df, higher than the two-factor model, suggesting a worse fit to the data. Other fit indices such as GFI, AGFI, NFI, NNFI, and CFI are below 0.97 and the RMSEA is 0.083, which generally indicate acceptable but not excellent fit. The SRMR is less than 0.08 which suggests a good fit. The AIC and BIC values are higher than the two-factor model but lower than the one-factor model, indicating a fit that is better than the one-factor model but worse than the two-factor model.\nBased on these results, the two-latents model seems to provide the best fit to the data among the three models, according to most of the fit indices and the AIC and BIC. Note, all models have significant chi-square statistics, which suggests some degree of misfit. It’s also important to consider the substantive interpretation of the factors, to make sure the model makes sense theoretically.\n\n\n\nMulti-group Confirmatory Factor Analysis\nThis script runs multi-group confirmatory factor analysis (MG-CFA)\n\n# select needed columns plus 'ethnicity'\n# filter dataset for only 'euro' and 'maori' ethnic categories\ndt_eth_k6_eth &lt;- dt_start |&gt; \n  filter(eth_cat == \"euro\" | eth_cat == \"maori\") |&gt; \n  select(kessler_depressed, kessler_effort,kessler_hopeless,\n         kessler_worthless, kessler_nervous,\n         kessler_restless, eth_cat)\n\n# partition the dataset into training and test subsets\n# stratify by ethnic category to ensure balanced representation\npart_data_eth &lt;- datawizard::data_partition(dt_eth_k6_eth, traing_proportion = .7, seed = 123, group = \"eth_cat\")\n\ntraining_eth &lt;- part_data_eth$p_0.7\ntest_eth &lt;- part_data_eth$test\n\n# run confirmatory factor analysis (CFA) models for configural invariance across ethnic groups\n# models specify one, two, and three latent variables\none_latent_eth_configural &lt;- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", data = test_eth))\ntwo_latents_eth_configural &lt;- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", data = test_eth))\nthree_latents_eth_configural &lt;- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\", data = test_eth))\n\n# compare model performances for configural invariance\ncompare_eth_configural &lt;- performance::compare_performance(one_latent_eth_configural, two_latents_eth_configural, three_latents_eth_configural, verbose = FALSE)\n\n# run CFA models for metric invariance, holding factor loadings equal across groups\n# models specify one, two, and three latent variables\none_latent_eth_metric &lt;- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", group.equal = \"loadings\", data = test_eth))\ntwo_latents_eth_metric  &lt;- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", group.equal = \"loadings\", data = test_eth))\nthree_latents_eth_metric  &lt;- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\",group.equal = \"loadings\", data = test_eth))\n\n# compare model performances for metric invariance\ncompare_eth_metric  &lt;- performance::compare_performance(one_latent_eth_metric, two_latents_eth_metric, three_latents_eth_metric, verbose = FALSE)\n\n# run CFA models for scalar invariance, holding factor loadings and intercepts equal across groups\n# models specify one, two, and three latent variables\none_latent_eth_scalar &lt;- suppressWarnings(lavaan::cfa(structure_k6_one, group = \"eth_cat\", group.equal = c(\"loadings\",\"intercepts\"), data = test_eth))\ntwo_latents_eth_scalar  &lt;- suppressWarnings(lavaan::cfa(structure_k6_two, group = \"eth_cat\", group.equal =  c(\"loadings\",\"intercepts\"), data = test_eth))\nthree_latents_eth_scalar  &lt;- suppressWarnings(lavaan::cfa(structure_k6_three, group = \"eth_cat\",group.equal =  c(\"loadings\",\"intercepts\"), data = test_eth))\n\n# compare model performances for scalar invariance\ncompare_eth_scalar  &lt;- performance::compare_performance(one_latent_eth_scalar, two_latents_eth_scalar, three_latents_eth_scalar, verbose = FALSE)\n\nRecall, in the context of measurement and factor analysis, the concepts of configural, metric, and scalar invariance relate to the comparability of a measurement instrument, such as a survey or test, across different groups.\nWe saw in part 1 of this course that these invariance concepts are frequently tested in the context of cross-cultural, multi-group, or longitudinal studies.\nLet’s first define these concepts, and then apply them to the context of the Kessler 6 (K6) Distress Scale used among Maori and New Zealand Europeans.\n\nConfigural invariance refers to the most basic level of measurement invariance, and it is established when the same pattern of factor loadings and structure is observed across groups. This means that the underlying or “latent” constructs (factors) are defined the same way for different groups. This doesn’t mean the strength of relationship between items and factors (loadings) or the item means (intercepts) are the same, just that the items relate to the same factors in all groups.\n\nIn the context of the K6 Distress Scale, configural invariance would suggest that the same six items are measuring the construct of psychological distress in the same way for both Māori and New Zealand Europeans, even though the strength of the relationship between the items and the construct (distress), or the average scores, might differ.\n\nMetric invariance (also known as “weak invariance”) refers to the assumption that factor loadings are equivalent across groups, meaning that the relationship or association between the measured items and their underlying factor is the same in all groups. This is important when comparing the strength of relationships with other variables across groups.\n\nIf metric invariance holds for the K6 Distress Scale, this would mean that a unit change in the latent distress factor would correspond to the same change in each item score (e.g., feeling nervous, hopeless, restless, etc.) for both Māori and New Zealand Europeans.\n\nScalar invariance (also known as “strong invariance”) involves equivalence of both factor loadings and intercepts (item means) across groups. This means that not only are the relationships between the items and the factors the same across groups (as with metric invariance), but also the zero-points or origins of the scales are the same. Scalar invariance is necessary when one wants to compare latent mean scores across groups.\n\nIn the context of the K6 Distress Scale, if scalar invariance holds, it would mean that a specific score on the scale would correspond to the same level of the underlying distress factor for both Māori and New Zealand Europeans. It would mean that the groups do not differ systematically in how they interpret and respond to the items. If this holds, one can make meaningful comparisons of distress level between Maori and New Zealand Europeans based on the scale scores.\nNote: each of these levels of invariance is a progressively stricter test of the equivalence of the measurement instrument across groups. Demonstrating scalar invariance, for example, also demonstrates configural and metric invariance. On the other hand, failure to demonstrate metric invariance means that scalar invariance also does not hold. These tests are therefore usually conducted in sequence. The results of these tests should be considered when comparing group means or examining the relationship between a scale and other variables across groups.\n\n\nConfigural invariance\n\nas.data.frame(compare_eth_configural)|&gt;\n  kbl(format = \"markdown\")\n\nThe table represents the comparison of three multi-group confirmatory factor analysis (CFA) models conducted to test for configural invariance across different ethnic categories (eth_cat). Configural invariance refers to whether the pattern of factor loadings is the same across groups. It’s the most basic form of measurement invariance.\nLooking at the results, we can draw the following conclusions:\n\nChi2 (Chi-square): A lower value suggests a better model fit. In this case, the two_latents_eth_configural model exhibits the lowest Chi2 value, suggesting it has the best fit according to this metric.\nGFI (Goodness of Fit Index) and AGFI (Adjusted Goodness of Fit Index): These values range from 0 to 1, with values closer to 1 suggesting a better fit. The two_latents_eth_configural model has the highest GFI and AGFI values, indicating it is the best fit according to these indices.\nNFI (Normed Fit Index), NNFI (Non-Normed Fit Index, also called TLI), CFI (Comparative Fit Index): These range from 0 to 1, with values closer to 1 suggesting a better fit. The one_latent_eth_configural model has the highest values, suggesting it is the best fit according to these metrics.\nRMSEA (Root Mean Square Error of Approximation): Lower values are better, with values below 0.05 considered good and up to 0.08 considered acceptable. In this table, the two_latents_eth_configural model has an RMSEA of 0.05, which falls within the acceptable range.\nRMR (Root Mean Square Residual) and SRMR (Standardized Root Mean Square Residual): Lower values are better, typically less than 0.08 is considered a good fit. All models exhibit acceptable RMR and SRMR values, with the two_latents_eth_configural model having the lowest.\nRFI (Relative Fit Index), PNFI (Parsimonious Normed Fit Index), IFI (Incremental Fit Index), RNI (Relative Noncentrality Index): These range from 0 to 1, with values closer to 1 suggesting a better fit. The one_latent_eth_configural model has the highest values, suggesting the best fit according to these measures.\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion): Lower values indicate a better fit when comparing models. The two_latents_eth_configural model has the lowest AIC and BIC, suggesting it is the best fit according to these criteria.\np_Chi2 and p_RMSEA: These are the significance levels for the Chi-square test and the RMSEA, respectively. Non-significant values (p &gt; 0.05) suggest a good fit. Only the RMSEA for the two_latents_eth_configural model is non-significant, suggesting a good fit.\n\nOverall, the two_latents_eth_configural model appears to provide the best fit across multiple indices, suggesting configural invariance (i.e., the same general factor structure) across ethnic categories with a two-factor solution. As with the previous assessment, theoretical soundness and other substantive considerations should also be taken into account when deciding on the final model. We will return to these issues next week.\n\n\nMetric Equivalence\n\nas.data.frame(compare_eth_metric)|&gt;\n  kbl(format = \"markdown\")\n\nThis table presents the results of a multi-group confirmatory factor analysis (CFA) conducted to test metric equivalence (also known as measurement invariance) across different ethnic categories (eth_cat). The models (one_latent_eth_metric, two_latents_eth_metric, three_latents_eth_metric) were run with a constraint of equal factor loadings across groups, which is a requirement for metric invariance.\nHere’s the interpretation of the fit indices:\n\nChi2 (Chi-square): Lower values indicate better model fit. The two_latents_eth_metric model has the lowest Chi2 value, suggesting the best fit according to this measure.\nGFI (Goodness of Fit Index), AGFI (Adjusted Goodness of Fit Index): These range from 0 to 1, with values closer to 1 indicating a better fit. The two_latents_eth_metric model has the highest GFI and AGFI values, suggesting the best fit according to these indices.\nNFI (Normed Fit Index), NNFI (Non-Normed Fit Index, or TLI), CFI (Comparative Fit Index): These range from 0 to 1, with values closer to 1 indicating a better fit. For these indices, the one_latent_eth_metric model has the highest values, suggesting the best fit according to these measures.\nRMSEA (Root Mean Square Error of Approximation): Lower values are better, with values below 0.05 generally considered good, and values up to 0.08 considered acceptable. Only the two_latents_eth_metric model has an RMSEA within the acceptable range (0.051).\nRMR (Root Mean Square Residual) and SRMR (Standardized Root Mean Square Residual): Lower values are better, typically less than 0.08 is considered a good fit. All models have acceptable RMR and SRMR values, with the two_latents_eth_metric model having the lowest, indicating the best fit.\nRFI (Relative Fit Index), PNFI (Parsimonious Normed Fit Index), IFI (Incremental Fit Index), RNI (Relative Noncentrality Index): These range from 0 to 1, with values closer to 1 indicating better fit. The one_latent_eth_metric model has the highest values, suggesting the best fit according to these indices.\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion): Lower values indicate a better fit when comparing models. The two_latents_eth_metric model has the lowest AIC and BIC, indicating the best fit according to these criteria.\np_Chi2 and p_RMSEA: These are the significance levels for the Chi-square test and the RMSEA, respectively. Statistically non-significant values at the traditional threshold (p &gt; 0.05) suggest a good fit. Only the RMSEA for the two_latents_eth_metric model is statistically non-significant, suggesting a good fit.\n\nIn summary, the two_latents_eth_metric model appears to provide the best fit overall, indicating that a two-factor solution might be appropriate and that the metric equivalence (equal factor loadings) assumption is supported across ethnic categories. However, one must also take into consideration the theoretical soundness of the model and other substantive considerations when deciding on the final model.\n\n\nScalar Equivalence\n\n# view as html table\nas.data.frame(compare_eth_scalar)|&gt;\n  kbl(format = \"markdown\")\n\nThe table presents the results of a multi-group confirmatory factor analysis (CFA) conducted to test scalar equivalence (also known as measurement invariance) across different ethnic categories (eth_cat). The models (one_latent_eth_scalar, two_latents_eth_scalar, three_latents_eth_scalar) were run with constraints on both factor loadings and intercepts to be equal across groups, a requirement for scalar invariance.\nHere’s the interpretation of the fit indices:\n\nChi2 (Chi-square): Lower values indicate better model fit. The two_latents_eth_scalar model has the lowest Chi2 value, suggesting the best fit according to this measure.\nGFI (Goodness of Fit Index), AGFI (Adjusted Goodness of Fit Index): These range from 0 to 1, with values closer to 1 indicating a better fit. The two_latents_eth_scalar model has the highest GFI and AGFI values, suggesting the best fit according to these indices.\nNFI (Normed Fit Index), NNFI (Non-Normed Fit Index, or TLI), CFI (Comparative Fit Index): These range from 0 to 1, with values closer to 1 indicating a better fit. The one_latent_eth_scalar model has the highest values, suggesting the best fit according to these measures.\nRMSEA (Root Mean Square Error of Approximation): Lower values are better, with values below 0.05 generally considered good, and values up to 0.08 considered acceptable. Only the two_latents_eth_scalar model has an RMSEA within the acceptable range (0.05).\nRMR (Root Mean Square Residual) and SRMR (Standardized Root Mean Square Residual): Lower values are better, typically less than 0.08 is considered a good fit. All models have acceptable RMR and SRMR values, with the two_latents_eth_scalar model having the lowest, indicating the best fit.\nRFI (Relative Fit Index), PNFI (Parsimonious Normed Fit Index), IFI (Incremental Fit Index), RNI (Relative Noncentrality Index): These range from 0 to 1, with values closer to 1 indicating better fit. The one_latent_eth_scalar model has the highest values, suggesting the best fit according to these indices.\nAIC (Akaike Information Criterion) and BIC (Bayesian Information Criterion): Lower values indicate a better fit when comparing models. The two_latents_eth_scalar model has the lowest AIC and BIC, indicating the best fit according to these criteria.\np_Chi2 and p_RMSEA: These are the significance levels for the Chi-square test and the RMSEA, respectively. Non-significant values (p &gt; 0.05) suggest a good fit. Only the RMSEA for the two_latents_eth_scalar model is non-significant, suggesting a good fit.\n\nIn summary, the two_latents_eth_scalar model appears to provide the best fit overall, indicating that a two-factor solution might be appropriate and that the scalar equivalence (equal factor loadings and intercepts) assumption is supported across ethnic categories. However, we must also consider the theoretical soundness of the model and other substantive considerations when deciding on the final model (a matter to which we will return next week.)\nOverall it seems that we have good evidence for the two-factor model of Kessler-6."
  },
  {
    "objectID": "content/more-old-advice.html#solutions",
    "href": "content/more-old-advice.html#solutions",
    "title": "Measurement Matters",
    "section": "Solutions",
    "text": "Solutions\n\nGenerate a Kessler 6 binary score (Not Depressed vs. Moderately or Severely Depressed)\n\nand also:\n\nCreate a variable for the log of exercise hour\n\n\n# functions \n#source(\"https://raw.githubusercontent.com/go-bayes/templates/main/functions/funs.R\")\n\n\n# experimental functions (more functions)\n#source(\n # \"https://raw.githubusercontent.com/go-bayes/templates/main/functions/experimental_funs.R\"\n#)\n\n\n\nnzavs_synth &lt;-\n  arrow::read_parquet(here::here(\"data\", \"nzavs_dat_synth_t10_t12\"))\n\n\ndt_new &lt;- nzavs_synth %&gt;%\n  arrange(id, wave) %&gt;%\n  rowwise() %&gt;%\n  mutate(kessler_6  = mean(sum(\n    # Specify the Kessler scale items\n    c(\n      kessler_depressed,\n      # During the last 30 days, how often did you feel so depressed that nothing could cheer you up?\n      kessler_hopeless,\n      # During the last 30 days, how often did you feel hopeless?\n      kessler_nervous,\n      # During the last 30 days, how often did you feel nervous?\n      kessler_effort,\n      # During the last 30 days, how often did you feel that everything was an effort?\n      kessler_restless,\n      # During the last 30 days, how often did you feel restless or fidgety ?\n      kessler_worthless  # During the last 30 days, how often did you feel worthless?\n    )\n  ))) |&gt;\n  mutate(kessler_6_sum = round(sum(\n    c (\n      kessler_depressed,\n      kessler_hopeless,\n      kessler_nervous,\n      kessler_effort,\n      kessler_restless,\n      kessler_worthless\n    )\n  ),\n  digits = 0)) |&gt;  ungroup() |&gt;\n  # Create a categorical variable 'kessler_6_coarsen' based on the sum of Kessler scale items\n  mutate(\n    kessler_6_coarsen = cut(\n      kessler_6_sum,\n      breaks = c(0, 5, 24),\n      labels = c(\"not_depressed\",\n                 \"mildly_to_severely_depressed\"),\n      include.lowest = TRUE,\n      include.highest = TRUE,\n      na.rm = TRUE,\n      right = FALSE\n    )\n  ) |&gt;\n  # Transform 'hours_exercise' by applying the log function to compress its scale\n  mutate(hours_exercise_log = log(hours_exercise + 1)) # Add 1 to avoid undefined log(0). Hours spent exercising/physical activity\n\n\nTake Home: estimate whether exercise causally affects nervousness, using the single item of the kessler 6 score. Briefly write up your results."
  },
  {
    "objectID": "content/more-old-advice.html#readings",
    "href": "content/more-old-advice.html#readings",
    "title": "Measurement Matters",
    "section": "Readings",
    "text": "Readings\n(He and Vijver 2012)\n(vandevijver2021?)\n(Berry 1989)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Accessing Lectures and Readings\n\n\n\n\nSeminar Time/Location: Tuesdays, 9:00-11:50am Easterfield Building Room: EA201\nCourse Outline: find a detailed schedule of topics, readings, and assignments in the Course Outline tab.\nReadings: links to readings are directly within the Course Outline tab, essential for lecture preparation.\nLecture Materials: access slides, video recordings, and more under the Content tab, organised by week for ease of use.\nTests: in the same room as the seminar\n\n\n\n\n\nTest/Quiz Location IN CLASS\n\n\n\nThe Contents tab offers direct access to weekly seminar and lab materials, including lecture outlines and lab resources.\n\nAccess it from the top right of the course platform by selecting the appropriate week.\nLab materials are available one week before the lecture; seminar review materials post-seminar.\n\n\n\n\n\n\n\n\n\n\nCourse Coordinator Prof Joseph Bulbulia joseph.bulbulia@vuw.ac.nz\nCourse Coordinator’s Office EA324\nR Help from  Dr.Inkuk Kim inkuk.kim@vuw.ac.nz\n\n\n\n\n\n\n\n\nAssessment\nCLOs\nPercent\nDue\n\n\n\n\nClass participation\n1,2,3\n10\nWeekly\n\n\nTest 1\n2\n25\n25 March (w5)\n\n\nTake Home Assignment\n2\n25\n6 May (w10)\n\n\nResearch Report\n1,2,3\n40\n3 June (w12)\n\n\n\n\n\n\n\n\n\n\nThe official description:\nThis course will focus on theoretical and practical challenges for conducting research involving individuals from more than one cultural background or ethnicity. Topics are likely to include defining and measuring culture; developing culture-sensitive studies, choice of language and translation; communication styles and bias; questionnaire and interview design; qualitative and quantitative data analysis for cultural and cross-cultural research; minorities, power and ethics in cross-cultural research; and ethno-methodologies and indigenous research methodologies. Appropriate background for this course: PSYC 338.\n\n\n\nPreamble: in this advanced course, students will develop foundational skills in cross-cultural psychological research with a strong emphasis on causal inference, a new and critical methodological approach.\n\nProgramming in R students will learn the basics of programming in the statistical language R, gaining essential computational tools for psychological research. The skills you acquire will lay the foundation for applying data analysis techniques in a causal inference framework and beyond.\nUnderstanding Causal Inference. students will develop a robust understanding of causal inference concepts and approaches, with particular emphasis on how they mitigate common pitfalls in cross-cultural research. We will focus on designing studies, analysing data, and drawing strong conclusions about cause-and-effect relationships across cultures.\nUnderstanding Measurement in Comparative Settings. students will learn techniques for constructing and validating psychometrically sound measures across diverse cultures. We will examine how to ensure measurements are reliable, cross-culturally valid, and aligned with theoretical constructs while focusing strongly on causal reasoning.\n\n\n\n\n\n\n\n\n\nAssessment\nCLOs\nPercent\nDue\n\n\n\n\nClass participation\n1,2,3\n10\nWeekly\n\n\nTest (1)\n2\n25\n25 March (w5)\n\n\nTake Home (2)\n2\n25\n13 May (w10)\n\n\nResearch Report\n1,2,3\n40\n3 June (w13)\n\n\n\n\n\n\n\n\n\n\n\nClass attendance and active participation.\n\n\nLab attendance and active participation.\n\n\nPresentation (Week 10)\n\n\n\n\n\n\n\n\n\n\nTest duration is one hour. The allocated time is nearly two hours.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nTHE TEST IS IN CLASS (i.e. come to class with a writing instrument).\n\n\n\n\nEach lecture starts and ends with key concept definitions and reviews for the test.\nR or RStudio knowledge isn’t part of the test. R support aims to enhance research report skills.\nTests are conducted in the lecture room without the aids of notes, a computer, or a phone.\nRequired: pen/pencil.\nTest (50 minutes, total time allowed: 1 hour 50 minutes):\n\nFocuses on revising core statistical and methodological concepts.\nAims to refresh basic statistical knowledge foundational for later course material.\n\n\n\n\n\n\nTake Home Asssessment (~6 Hours) due March 12**:\nBuilds upon the course concepts, emphasising the application of basic conceptual, statistical, and theoretical knowledge as applied to your research question.\nSpecifically, how to formulate a research question and develop a strategy for answering it.\n\nTask - Write a draft Introduction to your final writing assessment. - Write a draft Method section for your writing assessment. - Prepare an in-class presentation of 10 minutes summaring your study. - You are encouraged to use AI, and you will be marked as if you are using Ai. - Note that even the best AI models make mistakes and hallucinate, particularly in causal inference. You must therefore internalise understanding. Be warned: I will mark hallucinations and errors harshly. - Although I encourage you to use AI, I also encourage you to you write in your own voice. Your self-expression will make you interesting, and employable. Writing in your own voice will cultivate this part of you.\n\n\n\n\n\nState your question: is your question clearly stated?\nRelevance: have you explained its scientific importance?\nCausality: Is your question causal?\nSubgroup analysis: does your question involve a subgroups (e.g., cultural group)? Which?\nExplain the framework: Have you explained the causal inference framework in a way that is comprehensible to non-specialists?\nEthics/Policy interests have you explained how this question might practically affect people?\nData source: are your data from the NZAVS simulated data set? (if not, consult with me)\nData waves: are your data using three waves?\n\n\n\n\n\nOutcome variable: is your outcome variable Y well-defined?\nMultiple outcomes: do you assess multiple outcomes are are these well-defined?\nOutcome relevance: can you explain how the outcome variable/s relate to your question?\nOutcome type: is your outcome binary and rare? … etc.\nOutcome timing: does your outcome appear after your exposure?\n\n\n\n\n\nExposure variable: is your exposure variable A well-defined?\nMultiple exposures: are there multiple exposures? (If yes, for this study, reassess).\nExposure relevance: have you explained how the exposure variable relates to your question?\nPositivity: can we intervene on the exposure at all levels of the covariates?\nConsistency: can we interpret what it means to intervene on the exposure?\nExchangeability: are there different versions of the exposure conditionally exchangeable given measured baseline confounders?\nExposure type: is the exposure binary or continuous?\nShift intervention: do you contrast static interventions or modified treatment policies?\nExposure timing: does your exposure appear before the outcome? (It should.)\n\n\n\n\n\nBaseline confounders: Have you defined your baseline confounders L?\nJustification: Can you explain how the baseline confounders could affect both A and Y?\nTiming: Are the baseline confounders measured before the exposure?\nInclusion: Is the baseline measure of the exposure and the baseline outcome included in the set of baseline confounders?\nSufficiency: Are the baseline confounders sufficient to ensure balance on the exposure, such that A is independent of Y given L? If not, explain your sensitivity analysis (E-values)\nConfounder type: Are the confounders continuous or binary? If so, consider converting them to z-scores. If they are categorical with three or more levels, do not convert them to z-scores, but rather use one-hot encoding (see lecture 9.)\n\n\n\n\n\nCausal diagram: Have you drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding?\nMeasurement error: Have you described potential biases from measurement errors?\nTemporal order: Does your DAG have time indicators to ensure correct temporal order?\nTime consistency: Is your DAG organized so that time follows in a consistent direction?\n\n\n\n\n\nWhat is the casual contrast?\nHow will you estimate heterogeneity?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulations identified: Have you explained how your sample relates to your target populations?\n\n\n\n\n\nCriteria stated: Have you stated the eligibility criteria for the study?\n\n\n\n\n\nDescriptive statistics: have you provided descriptive statistics for demographic information taken at baseline?\nExposure change: Have you described the magnitudes of change in the exposure from baseline to the exposure interval\nReferences: Have you included references for more information about the sample (e.g. the NZAVS website)? I should have.\nDATA ARE SIMULATED: Have you made it clear you are working with simulated data?\n\n\n\n\n\nMissing data checks: Have you checked for missing data?\nMissing data plan: If there are missing data, have you described how you will address the problem? (IPCW, see week 9)\n\n\n\n\n\nApproach decision: G-computation, IPTW, or Doubly-Robust Estimation?\nModel specification: Model Specification?\nMachine Learning: have you explained how machine learning works?\nOutcome Specifics: If the outcome is rare and binary, have you specified logistic regression? If it’s continuous, have I considered converting it to z-scores?\nSensitivity analysis: Have you described your sensitivity analysis (e.g. E-values.)\n\nNote most of these tasks can be ticked off in a sentence or two, but all need to be covered.\nLength: ~ 1,000 - 2,000 words (note it is a draft introduction and draft methods section).\n\n\n\n\n\n\n\n\n\n\nResearch Report Instructions\n\n\n\n\nWe will supply the data.\nLab sessions are designed to support you in this assignment.\nWe assume no statistical background.\n\n\n\n\nTitle: “Causal Inference in Cultural Psychology: Examining Exposure Effects on Dimensions of Well-being Modified by Cultural or Sociodemographic Categories”.\nObjective:\n\nTo quantify the causal effect of a specific exposure on well-being dimensions, modified by sociodemographic categories (born_nz, eth_cat, big_doms, gen_cohort) using the NZAVS longitudinal synthetic dataset.\n\nInstructions:\n\nTheoretical Interest and Research Question:\n\nDescribe the significance of your chosen exposure and its potential impact on the selected outcomes, modified by the cultural or sociodemographic category.\nState the research question clearly.\n\nDirected Acyclic Graph (DAG):\n\nConstruct a DAG illustrating the relationships between exposure, outcomes, sociodemographic category, and potential bias sources. Ensure clarity in labelling.\n\nConfounding Control Strategy:\n\nOutline your strategy for confounding control, justifying the chosen confounders.\n\nMeasurement Biases:\n\nAddress and analyse measurement biases as relevant.\n\nAssumptions and Statistical Models:\n\nDiscuss the assumptions of your causal inference approach and your statistical model, including their limitations.\n\n\nRequirements:\n\nIntroduction: 1,500 words limit.\nConclusion: 1,500 words limit.\nMethod and Results sections should be concise; no specific word limit.\nUse any useful sources, citing appropriately to avoid academic misconduct.\nFollow APA style for citations and references.\nInclude tables/figures as needed.\nSubmit as a single PDF, including R code in an appendix.\n\nEvaluation Criteria:\n\nClarity of theoretical framework, research question, and design.\nValidity of confounding control strategy.\nDiscussion on assumptions and statistical models.\nOrganisation and presentation quality.\n\n\n\n\n\n\nExtensions:\n\nNegotiate a new due date by writing (email) before March 11th, 2025, if necessary.\nEvery reasonable request will be accepted (e.g. too many assignments falling in the same week, you want another week to complete.)\n\nPenalties:\n\nLate submissions incur a one full grade-per-week penalty, e.g. if late by one day, B \\to C, one week later, C \\to D.\nOver-length assignments will be penalised.\n\nUnforeseeable Events:\n\nExtensions after March 11th will require evidence (e.g., medical certificate).\n\n\n\n\n\n\nBring a laptop with R and RStudio installed for data analysis sessions. Contact the instructor if you lack computer access.\nFor in-class tests, bring a writing utensil. Again, electronic devices are not permitted."
  },
  {
    "objectID": "index.html#class-times-and-locations",
    "href": "index.html#class-times-and-locations",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Test/Quiz Location IN CLASS"
  },
  {
    "objectID": "index.html#contents-tab",
    "href": "index.html#contents-tab",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "The Contents tab offers direct access to weekly seminar and lab materials, including lecture outlines and lab resources.\n\nAccess it from the top right of the course platform by selecting the appropriate week.\nLab materials are available one week before the lecture; seminar review materials post-seminar."
  },
  {
    "objectID": "index.html#names-and-contact-details",
    "href": "index.html#names-and-contact-details",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Course Coordinator Prof Joseph Bulbulia joseph.bulbulia@vuw.ac.nz\nCourse Coordinator’s Office EA324\nR Help from  Dr.Inkuk Kim inkuk.kim@vuw.ac.nz"
  },
  {
    "objectID": "index.html#assignments-and-due-dates",
    "href": "index.html#assignments-and-due-dates",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Assessment\nCLOs\nPercent\nDue\n\n\n\n\nClass participation\n1,2,3\n10\nWeekly\n\n\nTest 1\n2\n25\n25 March (w5)\n\n\nTake Home Assignment\n2\n25\n6 May (w10)\n\n\nResearch Report\n1,2,3\n40\n3 June (w12)"
  },
  {
    "objectID": "index.html#course-description",
    "href": "index.html#course-description",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "The official description:\nThis course will focus on theoretical and practical challenges for conducting research involving individuals from more than one cultural background or ethnicity. Topics are likely to include defining and measuring culture; developing culture-sensitive studies, choice of language and translation; communication styles and bias; questionnaire and interview design; qualitative and quantitative data analysis for cultural and cross-cultural research; minorities, power and ethics in cross-cultural research; and ethno-methodologies and indigenous research methodologies. Appropriate background for this course: PSYC 338."
  },
  {
    "objectID": "index.html#course-learning-objectives",
    "href": "index.html#course-learning-objectives",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Preamble: in this advanced course, students will develop foundational skills in cross-cultural psychological research with a strong emphasis on causal inference, a new and critical methodological approach.\n\nProgramming in R students will learn the basics of programming in the statistical language R, gaining essential computational tools for psychological research. The skills you acquire will lay the foundation for applying data analysis techniques in a causal inference framework and beyond.\nUnderstanding Causal Inference. students will develop a robust understanding of causal inference concepts and approaches, with particular emphasis on how they mitigate common pitfalls in cross-cultural research. We will focus on designing studies, analysing data, and drawing strong conclusions about cause-and-effect relationships across cultures.\nUnderstanding Measurement in Comparative Settings. students will learn techniques for constructing and validating psychometrically sound measures across diverse cultures. We will examine how to ensure measurements are reliable, cross-culturally valid, and aligned with theoretical constructs while focusing strongly on causal reasoning."
  },
  {
    "objectID": "index.html#assignments-and-due-dates-1",
    "href": "index.html#assignments-and-due-dates-1",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Assessment\nCLOs\nPercent\nDue\n\n\n\n\nClass participation\n1,2,3\n10\nWeekly\n\n\nTest (1)\n2\n25\n25 March (w5)\n\n\nTake Home (2)\n2\n25\n13 May (w10)\n\n\nResearch Report\n1,2,3\n40\n3 June (w13)\n\n\n\n\n\n\n\n\n\n\n\nClass attendance and active participation.\n\n\nLab attendance and active participation.\n\n\nPresentation (Week 10)"
  },
  {
    "objectID": "index.html#take-home-assessment",
    "href": "index.html#take-home-assessment",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Take Home Asssessment (~6 Hours) due March 12**:\nBuilds upon the course concepts, emphasising the application of basic conceptual, statistical, and theoretical knowledge as applied to your research question.\nSpecifically, how to formulate a research question and develop a strategy for answering it.\n\nTask - Write a draft Introduction to your final writing assessment. - Write a draft Method section for your writing assessment. - Prepare an in-class presentation of 10 minutes summaring your study. - You are encouraged to use AI, and you will be marked as if you are using Ai. - Note that even the best AI models make mistakes and hallucinate, particularly in causal inference. You must therefore internalise understanding. Be warned: I will mark hallucinations and errors harshly. - Although I encourage you to use AI, I also encourage you to you write in your own voice. Your self-expression will make you interesting, and employable. Writing in your own voice will cultivate this part of you.\n\n\n\n\n\nState your question: is your question clearly stated?\nRelevance: have you explained its scientific importance?\nCausality: Is your question causal?\nSubgroup analysis: does your question involve a subgroups (e.g., cultural group)? Which?\nExplain the framework: Have you explained the causal inference framework in a way that is comprehensible to non-specialists?\nEthics/Policy interests have you explained how this question might practically affect people?\nData source: are your data from the NZAVS simulated data set? (if not, consult with me)\nData waves: are your data using three waves?\n\n\n\n\n\nOutcome variable: is your outcome variable Y well-defined?\nMultiple outcomes: do you assess multiple outcomes are are these well-defined?\nOutcome relevance: can you explain how the outcome variable/s relate to your question?\nOutcome type: is your outcome binary and rare? … etc.\nOutcome timing: does your outcome appear after your exposure?\n\n\n\n\n\nExposure variable: is your exposure variable A well-defined?\nMultiple exposures: are there multiple exposures? (If yes, for this study, reassess).\nExposure relevance: have you explained how the exposure variable relates to your question?\nPositivity: can we intervene on the exposure at all levels of the covariates?\nConsistency: can we interpret what it means to intervene on the exposure?\nExchangeability: are there different versions of the exposure conditionally exchangeable given measured baseline confounders?\nExposure type: is the exposure binary or continuous?\nShift intervention: do you contrast static interventions or modified treatment policies?\nExposure timing: does your exposure appear before the outcome? (It should.)\n\n\n\n\n\nBaseline confounders: Have you defined your baseline confounders L?\nJustification: Can you explain how the baseline confounders could affect both A and Y?\nTiming: Are the baseline confounders measured before the exposure?\nInclusion: Is the baseline measure of the exposure and the baseline outcome included in the set of baseline confounders?\nSufficiency: Are the baseline confounders sufficient to ensure balance on the exposure, such that A is independent of Y given L? If not, explain your sensitivity analysis (E-values)\nConfounder type: Are the confounders continuous or binary? If so, consider converting them to z-scores. If they are categorical with three or more levels, do not convert them to z-scores, but rather use one-hot encoding (see lecture 9.)\n\n\n\n\n\nCausal diagram: Have you drawn a causal diagram (DAG) to highlight both measured and unmeasured sources of confounding?\nMeasurement error: Have you described potential biases from measurement errors?\nTemporal order: Does your DAG have time indicators to ensure correct temporal order?\nTime consistency: Is your DAG organized so that time follows in a consistent direction?\n\n\n\n\n\nWhat is the casual contrast?\nHow will you estimate heterogeneity?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPopulations identified: Have you explained how your sample relates to your target populations?\n\n\n\n\n\nCriteria stated: Have you stated the eligibility criteria for the study?\n\n\n\n\n\nDescriptive statistics: have you provided descriptive statistics for demographic information taken at baseline?\nExposure change: Have you described the magnitudes of change in the exposure from baseline to the exposure interval\nReferences: Have you included references for more information about the sample (e.g. the NZAVS website)? I should have.\nDATA ARE SIMULATED: Have you made it clear you are working with simulated data?\n\n\n\n\n\nMissing data checks: Have you checked for missing data?\nMissing data plan: If there are missing data, have you described how you will address the problem? (IPCW, see week 9)\n\n\n\n\n\nApproach decision: G-computation, IPTW, or Doubly-Robust Estimation?\nModel specification: Model Specification?\nMachine Learning: have you explained how machine learning works?\nOutcome Specifics: If the outcome is rare and binary, have you specified logistic regression? If it’s continuous, have I considered converting it to z-scores?\nSensitivity analysis: Have you described your sensitivity analysis (e.g. E-values.)\n\nNote most of these tasks can be ticked off in a sentence or two, but all need to be covered.\nLength: ~ 1,000 - 2,000 words (note it is a draft introduction and draft methods section).\n\n\n\n\n\n\n\n\n\n\nResearch Report Instructions\n\n\n\n\nWe will supply the data.\nLab sessions are designed to support you in this assignment.\nWe assume no statistical background.\n\n\n\n\nTitle: “Causal Inference in Cultural Psychology: Examining Exposure Effects on Dimensions of Well-being Modified by Cultural or Sociodemographic Categories”.\nObjective:\n\nTo quantify the causal effect of a specific exposure on well-being dimensions, modified by sociodemographic categories (born_nz, eth_cat, big_doms, gen_cohort) using the NZAVS longitudinal synthetic dataset.\n\nInstructions:\n\nTheoretical Interest and Research Question:\n\nDescribe the significance of your chosen exposure and its potential impact on the selected outcomes, modified by the cultural or sociodemographic category.\nState the research question clearly.\n\nDirected Acyclic Graph (DAG):\n\nConstruct a DAG illustrating the relationships between exposure, outcomes, sociodemographic category, and potential bias sources. Ensure clarity in labelling.\n\nConfounding Control Strategy:\n\nOutline your strategy for confounding control, justifying the chosen confounders.\n\nMeasurement Biases:\n\nAddress and analyse measurement biases as relevant.\n\nAssumptions and Statistical Models:\n\nDiscuss the assumptions of your causal inference approach and your statistical model, including their limitations.\n\n\nRequirements:\n\nIntroduction: 1,500 words limit.\nConclusion: 1,500 words limit.\nMethod and Results sections should be concise; no specific word limit.\nUse any useful sources, citing appropriately to avoid academic misconduct.\nFollow APA style for citations and references.\nInclude tables/figures as needed.\nSubmit as a single PDF, including R code in an appendix.\n\nEvaluation Criteria:\n\nClarity of theoretical framework, research question, and design.\nValidity of confounding control strategy.\nDiscussion on assumptions and statistical models.\nOrganisation and presentation quality.\n\n\n\n\n\n\nExtensions:\n\nNegotiate a new due date by writing (email) before March 11th, 2025, if necessary.\nEvery reasonable request will be accepted (e.g. too many assignments falling in the same week, you want another week to complete.)\n\nPenalties:\n\nLate submissions incur a one full grade-per-week penalty, e.g. if late by one day, B \\to C, one week later, C \\to D.\nOver-length assignments will be penalised.\n\nUnforeseeable Events:\n\nExtensions after March 11th will require evidence (e.g., medical certificate).\n\n\n\n\n\n\nBring a laptop with R and RStudio installed for data analysis sessions. Contact the instructor if you lack computer access.\nFor in-class tests, bring a writing utensil. Again, electronic devices are not permitted."
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Preliminaries",
    "section": "",
    "text": "Class times and locations Lectures Day/Time: Tuesday, 1:10-3:00pm\nLecture Location: Easterfield Building EA407"
  },
  {
    "objectID": "slides/index.html#where-do-we-meet",
    "href": "slides/index.html#where-do-we-meet",
    "title": "Preliminaries",
    "section": "Where do we meet?",
    "text": "Where do we meet?\n\nClass times and locations Lectures Day/Time: Tuesday, 1:10-3:00pm\nLecture Location: Easterfield Building EA407"
  },
  {
    "objectID": "slides/index.html#course-learning-objectives",
    "href": "slides/index.html#course-learning-objectives",
    "title": "Preliminaries",
    "section": "Course Learning Objectives",
    "text": "Course Learning Objectives\n\nEthical Reasoning. Beginning in week 1, we will explore questions that are typically reserved for philosophy courses but are central to the conduct of psychology: why do we need to think about right and wrong in science? What if different people have different ideas about what is right and wrong in science? Is there hope for ethical progress? Can science play a role in ethical progress? We will provide you with a set of strategies for addressing these questions.\nProgramming in R. Beginning in week 2, we will teach you the basics of programming in the statistical language R. The past several decades have brought extraordinary new tools to psychological scientists, many of which require literacy in computer programming. While some of you may find the thought of programming thrilling, others may find it terrifying or boring! We promise that programming can be fun. This course is designed to help you find that joy.\nUnderstanding measurement. Beginning in week 3 the course will turn its focus to developing skills for constructing and validating measures in cross-cultural research. Again these skills will be invaluable for a wide range of tasks you may face in psychological science and will help you to address problems that will arise in other areas of your research and work. Measurement will occupy our attention through week 6.\nUnderstanding causal inference. Beginning in week 7 and for the following four weeks, the course will impart skills that you require to disentangle causation from correlation. Again our focus will be on the special problems that arise for cultural datasets. Notably, in psychological science, causal inference remains underdeveloped, and the material in this part of the course will position you to make potentially important contributions, whether or not your interests lie in cross-cultural psychology."
  },
  {
    "objectID": "slides/index.html#assignments-and-due-dates",
    "href": "slides/index.html#assignments-and-due-dates",
    "title": "Preliminaries",
    "section": "Assignments and due dates",
    "text": "Assignments and due dates\n\n\n\n\n\nAssessment\nCLOs\nPercent\nDue\n\n\n\n\nClass participation\n*\n10\nWeekly\n\n\nTake-home\n3,4\n10\nMarch 19 (w3)\n\n\nTheoretical application\n1,2,3\n30\n9 May (w9)\n\n\nPre-reg review\n1,2,3,4\n10\n28 May (w11)\n\n\nStatistical application\n1,2,3\n30\n11 June (w13)\n\n\nLetter to the reviewer\n1,2,3\n10\n11 June (w13)"
  },
  {
    "objectID": "slides/index.html#assessment-1-class-participation",
    "href": "slides/index.html#assessment-1-class-participation",
    "title": "Preliminaries",
    "section": "Assessment 1: Class Participation",
    "text": "Assessment 1: Class Participation\n\n\nyour willingness to ask/answer questions and generally contribute to class discussion; and\n\n\nthe quality of your contributions\n\nNOTE: if you’re sick, you shouldn’t come to class. Just let me know in advance. Your participation will not be affected."
  },
  {
    "objectID": "slides/index.html#assessment-2-take-home-research-concepts-workbook",
    "href": "slides/index.html#assessment-2-take-home-research-concepts-workbook",
    "title": "Preliminaries",
    "section": "Assessment 2: Take Home Research Concepts Workbook",
    "text": "Assessment 2: Take Home Research Concepts Workbook\n\nThis test will help you revise core statistical and methodological issues. It is a chance to brush up on basic statistical knowledge and will help you re-familiarize yourself with material that we will build on later in this course.\nThe key focus is the revision of basic terms, including correlation, regression, and on basic R applications.\nThe test contains a theoretical and a practical component. Therefore, it is essential that you complete these questions since you will need to understand the material for the more advanced techniques and approaches that we cover in this course.\nThere is no word limit (be reasonable)\nYou can use any source that you find useful.\nWarning: AI chatbots may be used but they make errors confidently.\nGenerally, it is better practice, to use peer-reviewed publications.\nAny resource you use must be cited. Failure to cite your source is a form of academic misconduct.\nYou may complete the test in your own study time. We ask that you work individually."
  },
  {
    "objectID": "slides/index.html#assessment-3theoretical-application-5000-word-maximum-including-references",
    "href": "slides/index.html#assessment-3theoretical-application-5000-word-maximum-including-references",
    "title": "Preliminaries",
    "section": "Assessment 3:Theoretical Application (5,000 word maximum including references)",
    "text": "Assessment 3:Theoretical Application (5,000 word maximum including references)\nChoose one particular psychological concept or variable of interest to you. Provide a brief introduction to the concept or variable. Provide a sketch of the methodology for your study (what analysis will you run: equivalence tests, regressions, etc.) following the provided pre-registration template. Identify and justify your research participants’ cultural background. This assessment is equivalent to the introduction and methods part of an empirical paper.\nThe word limit for this assignment is 5000 words max (including references), and it must be typed and double spaced with a 12point Times New Roman font (or similar)."
  },
  {
    "objectID": "slides/index.html#pre-registration-review-1000-words-maximum-including-references",
    "href": "slides/index.html#pre-registration-review-1000-words-maximum-including-references",
    "title": "Preliminaries",
    "section": "Pre-Registration Review (1000 words maximum, including references)",
    "text": "Pre-Registration Review (1000 words maximum, including references)\nYou will be invited to provide a review of one submitted pre-registration from another student. Using what you have learned about cross-cultural research provide feedback on both theory and suggested methods. Make sure to provide concrete and respectful feedback.\nStatistical Application (4,000 word maximum excluding tables and any references)\nOption 1 Measurement (see outline)\nOption 2 Causality (see outline)"
  },
  {
    "objectID": "slides/index.html#letter-to-the-reviewer",
    "href": "slides/index.html#letter-to-the-reviewer",
    "title": "Preliminaries",
    "section": "Letter to the Reviewer",
    "text": "Letter to the Reviewer\nUsing the reviewer letter you received, respond to the points raised by the reviewer. Where did you alter your methods and pre-registration, where do results support your reviewer, where do they not support their claims.\nSubmission and return of work"
  },
  {
    "objectID": "slides/index.html#assessments-or-detailed-feedback-on-your-performance-will-typically-be-returned-to-you-within-10-working-days.",
    "href": "slides/index.html#assessments-or-detailed-feedback-on-your-performance-will-typically-be-returned-to-you-within-10-working-days.",
    "title": "Preliminaries",
    "section": "Assessments or detailed feedback on your performance will typically be returned to you within 10 working days.",
    "text": "Assessments or detailed feedback on your performance will typically be returned to you within 10 working days."
  },
  {
    "objectID": "slides/index.html#extensions",
    "href": "slides/index.html#extensions",
    "title": "Preliminaries",
    "section": "Extensions",
    "text": "Extensions\nIf any due date does not suit you, you may negotiate a new due date, in writing, that suits you. Any request for revision must be submitted in writing (by email) to your instructor before class on March 14th, 2023"
  },
  {
    "objectID": "slides/index.html#penalties",
    "href": "slides/index.html#penalties",
    "title": "Preliminaries",
    "section": "Penalties",
    "text": "Penalties\nThe submission of late assignments is strongly discouraged. A penalty of one grade per day (e.g., B down to B-) from the hand-in date will be deducted from the final grade for any late work."
  },
  {
    "objectID": "slides/index.html#unforeseeable-events",
    "href": "slides/index.html#unforeseeable-events",
    "title": "Preliminaries",
    "section": "Unforeseeable events",
    "text": "Unforeseeable events\nIn general, we require evidence (medical certificate etc.) to grant an extension."
  },
  {
    "objectID": "slides/index.html#word-limits",
    "href": "slides/index.html#word-limits",
    "title": "Preliminaries",
    "section": "Word limits",
    "text": "Word limits\nAssignments that are over the word limit (see above) will be penalized. All submitted assessments are expected to be your own. You should neither give nor receive any aid on the assessments. Giving or receiving aid on assessments will be considered academic misconduct, resulting in registration in the Academic Misconduct Register (AMR). You may use any source, but the source must be cited. Penalties appropriate for the level of academic misconduct may be applied. Failure to cite your source will be considered academic misconduct and will result in registration in the Academic Misconduct Register (AMR)."
  },
  {
    "objectID": "slides/index.html#materials-and-equipment",
    "href": "slides/index.html#materials-and-equipment",
    "title": "Preliminaries",
    "section": "Materials and equipment",
    "text": "Materials and equipment\nYou should bring paper and a writing utensil or laptop/tablet to seminars. For the data analysis sessions, having your personal laptop with the relevant computer programs (R and RStudio) installed is essential. Most sessions will require data analysis.\n\nNote: If you do not have a laptop, let me know. We will find a solution."
  },
  {
    "objectID": "slides/index.html#help",
    "href": "slides/index.html#help",
    "title": "Preliminaries",
    "section": "Help",
    "text": "Help\nDr.Inkuk Kim inkuk.kim@vuw.ac.nz\n\n\n\n\n\n\n\n\n\nDr. In Kuk Kim\n\n\n\n\n\nTorven Schalk torven.schalk@vuw.ac.nz\n\n\n\n\n\n\n\n\n\nTorven Schalk\n\n\n\n\n\nJoseph Bulbulia joseph.bulbulia@vuw.ac.nz\n\n\n\n\n\n\n\n\n\nJoseph Bulbulia"
  },
  {
    "objectID": "slides/index.html#thanks-to-johannes-karl-and-ron-fischer",
    "href": "slides/index.html#thanks-to-johannes-karl-and-ron-fischer",
    "title": "Preliminaries",
    "section": "Thanks to Johannes Karl and Ron Fischer",
    "text": "Thanks to Johannes Karl and Ron Fischer\nFor developing measurement components of the course\n\n\n\n\n\n\n\n\n\nJohannes Karl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRonald Fischer"
  },
  {
    "objectID": "slides/01-slides-lab.html",
    "href": "slides/01-slides-lab.html",
    "title": "Week 1: Intalling and Using R",
    "section": "",
    "text": "Have R and R-studio Downloaded on your machine\nBe able to use R for basic analysis and graphing"
  },
  {
    "objectID": "slides/01-slides-lab.html#introduction",
    "href": "slides/01-slides-lab.html#introduction",
    "title": "Week 1: Intalling and Using R",
    "section": "Introduction",
    "text": "Introduction\n\nWhy learn R?\nYou’ll need it for your final report.\nSupports your psychology coursework.\nEnhances your coding skills."
  },
  {
    "objectID": "slides/01-slides-lab.html#install-r",
    "href": "slides/01-slides-lab.html#install-r",
    "title": "Week 1: Intalling and Using R",
    "section": "Install R",
    "text": "Install R\n\nVisit the comprehensive r archive network (cran) at https://cran.r-project.org/\nSelect the version of r suitable for your operating system (windows, mac, or linux)\nDownload and install it by following the on-screen instructions"
  },
  {
    "objectID": "slides/01-slides-lab.html#install-rstudio",
    "href": "slides/01-slides-lab.html#install-rstudio",
    "title": "Week 1: Intalling and Using R",
    "section": "Install RStudio",
    "text": "Install RStudio\n\nVisit rstudio download page at https://www.rstudio.com/products/rstudio/download/\nChoose the free version of rstudio desktop,\nDownload it for your operating system\nInstall and open"
  },
  {
    "objectID": "slides/01-slides-lab.html#create-new-project",
    "href": "slides/01-slides-lab.html#create-new-project",
    "title": "Week 1: Intalling and Using R",
    "section": "Create new project",
    "text": "Create new project\n\nfile &gt; new project\nChoose new directory\nSpecify the location where the project folder will be created\nClick create project"
  },
  {
    "objectID": "slides/01-slides-lab.html#exercise-1-install-tidyverse",
    "href": "slides/01-slides-lab.html#exercise-1-install-tidyverse",
    "title": "Week 1: Intalling and Using R",
    "section": "Exercise 1: Install tidyverse",
    "text": "Exercise 1: Install tidyverse\n\nOpen rstudio: launch rstudio on your computer\ntools &gt; install packages\nType tidyverse\nClick on the install button\nType library(tidyverse) in the console and press enter"
  },
  {
    "objectID": "slides/01-slides-lab.html#execut-code",
    "href": "slides/01-slides-lab.html#execut-code",
    "title": "Week 1: Intalling and Using R",
    "section": "Execut Code",
    "text": "Execut Code\n\nUse Ctrl + Enter (Windows/Linux) or Cmd + Enter (Mac)."
  },
  {
    "objectID": "slides/01-slides-lab.html#assignment-operator",
    "href": "slides/01-slides-lab.html#assignment-operator",
    "title": "Week 1: Intalling and Using R",
    "section": "Assignment Operator",
    "text": "Assignment Operator\nThe assignment operator in R is &lt;-. This operator assigns values to variables.\n\nx &lt;- 10 # assigns the value 10 to x\ny &lt;- 5  # assigns the value 5 to y\n\nAlternative assignment: ::: {.cell}\nx = 10\ny = 5\n:::\nComparing values: ::: {.cell}\n10 == 5 # returns FALSE\n\n[1] FALSE\n\n:::"
  },
  {
    "objectID": "slides/01-slides-lab.html#rstudio-assignment-operator-shortcut",
    "href": "slides/01-slides-lab.html#rstudio-assignment-operator-shortcut",
    "title": "Week 1: Intalling and Using R",
    "section": "RStudio Assignment Operator Shortcut",
    "text": "RStudio Assignment Operator Shortcut\n\nFor macOS: Option + - inserts &lt;-.\nFor Windows and Linux: Alt + - inserts &lt;-."
  },
  {
    "objectID": "slides/01-slides-lab.html#keyboard-shortcuts",
    "href": "slides/01-slides-lab.html#keyboard-shortcuts",
    "title": "Week 1: Intalling and Using R",
    "section": "Keyboard Shortcuts",
    "text": "Keyboard Shortcuts\nExplore keyboard shortcuts in RStudio through Tools -&gt; Keyboard Shortcuts Help."
  },
  {
    "objectID": "slides/01-slides-lab.html#concatenation",
    "href": "slides/01-slides-lab.html#concatenation",
    "title": "Week 1: Intalling and Using R",
    "section": "Concatenation",
    "text": "Concatenation\nThe c() function combines multiple elements into a vector.\n\nnumbers &lt;- c(1, 2, 3, 4, 5) # a vector of numbers\nprint(numbers)\n\n[1] 1 2 3 4 5"
  },
  {
    "objectID": "slides/01-slides-lab.html#arithmetic-operations",
    "href": "slides/01-slides-lab.html#arithmetic-operations",
    "title": "Week 1: Intalling and Using R",
    "section": "Arithmetic Operations",
    "text": "Arithmetic Operations\nAddition and subtraction in R:\n\nsum &lt;- x + y\nprint(sum)\n\n[1] 15\n\ndifference &lt;- x - y\nprint(difference)\n\n[1] 5"
  },
  {
    "objectID": "slides/01-slides-lab.html#multiplication-and-division",
    "href": "slides/01-slides-lab.html#multiplication-and-division",
    "title": "Week 1: Intalling and Using R",
    "section": "Multiplication and Division",
    "text": "Multiplication and Division\n\n# Scalar operations\nproduct &lt;- x * y\nquotient &lt;- x / y\n\n\n# vector multiplication and division\nvector1 &lt;- c(1, 2, 3)\nvector2 &lt;- c(4, 5, 6)\n\n# Vector operations\nvector_product &lt;- vector1 * vector2\nvector_division &lt;- vector1 / vector2\n\nBe cautious with division by zero:\n\nresult &lt;- 10 / 0 # Inf\nzero_division &lt;- 0 / 0 # NaN\n\nInteger division and modulo operation:\n\ninteger_division &lt;- 10 %/% 3\nremainder &lt;- 10 %% 3"
  },
  {
    "objectID": "slides/01-slides-lab.html#logical-operators",
    "href": "slides/01-slides-lab.html#logical-operators",
    "title": "Week 1: Intalling and Using R",
    "section": "Logical Operators",
    "text": "Logical Operators\nExamples of NOT, NOT EQUAL, and EQUAL operations:\n\nx_not_y &lt;- x != y\nx_equal_10 &lt;- x == 10\n\nOR and AND operations:\n\nvector_or &lt;- c(TRUE, FALSE) | c(FALSE, TRUE)\nsingle_or &lt;- TRUE || FALSE\n\nvector_and &lt;- c(TRUE, FALSE) & c(FALSE, TRUE)\nsingle_and &lt;- TRUE && FALSE"
  },
  {
    "objectID": "slides/01-slides-lab.html#integers",
    "href": "slides/01-slides-lab.html#integers",
    "title": "Week 1: Intalling and Using R",
    "section": "Integers",
    "text": "Integers\n\nWhole numbers without decimal points, defined with an L suffix\n\n\nx &lt;- 42L\nstr(x) # check type\n\n int 42\n\n\n\nConversion to numeric\n\n\ny &lt;- as.numeric(x)\nstr(y)\n\n num 42"
  },
  {
    "objectID": "slides/01-slides-lab.html#characters",
    "href": "slides/01-slides-lab.html#characters",
    "title": "Week 1: Intalling and Using R",
    "section": "Characters",
    "text": "Characters\n\nText strings enclosed in quotes\n\n\nname &lt;- \"alice\""
  },
  {
    "objectID": "slides/01-slides-lab.html#factors",
    "href": "slides/01-slides-lab.html#factors",
    "title": "Week 1: Intalling and Using R",
    "section": "Factors",
    "text": "Factors\n\nRepresent categorical data with limited values\n\n\ncolors &lt;- factor(c(\"red\", \"blue\", \"green\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#ordered-factors",
    "href": "slides/01-slides-lab.html#ordered-factors",
    "title": "Week 1: Intalling and Using R",
    "section": "Ordered Factors",
    "text": "Ordered Factors\n\nFactors with and without inherent order\n\n\neducation_levels &lt;- c(\"high school\", \"bachelor\", \"master\", \"ph.d.\")\neducation_factor_no_order &lt;- factor(education_levels, ordered = FALSE)\neducation_factor &lt;- factor(education_levels, ordered = TRUE)\neducation_ordered_explicit &lt;- factor(education_levels, levels = education_levels, ordered = TRUE)\n\n\nOperations with ordered factors\n\n\nedu1 &lt;- ordered(\"bachelor\", levels = education_levels)\nedu2 &lt;- ordered(\"master\", levels = education_levels)\nedu2 &gt; edu1 # logical comparison\n\n[1] TRUE\n\n\n\nModifying ordered factors\n\n\nnew_levels &lt;- c(\"primary school\", \"high school\", \"bachelor\", \"master\", \"ph.d.\")\neducation_updated &lt;- factor(education_levels, levels = new_levels, ordered = TRUE)\nstr(education_updated)\n\n Ord.factor w/ 5 levels \"primary school\"&lt;..: 2 3 4 5\n\ntable(education_updated)\n\neducation_updated\nprimary school    high school       bachelor         master          ph.d. \n             0              1              1              1              1"
  },
  {
    "objectID": "slides/01-slides-lab.html#strings",
    "href": "slides/01-slides-lab.html#strings",
    "title": "Week 1: Intalling and Using R",
    "section": "Strings",
    "text": "Strings\n\nSequences of characters\n\n\nyou &lt;- 'world!'\ngreeting &lt;- paste(\"hello,\", you)\n# hello world\ngreeting\n\n[1] \"hello, world!\""
  },
  {
    "objectID": "slides/01-slides-lab.html#vectors",
    "href": "slides/01-slides-lab.html#vectors",
    "title": "Week 1: Intalling and Using R",
    "section": "Vectors",
    "text": "Vectors\n\nFundamental data structure in R\n\n\nnumeric_vector &lt;- c(1, 2, 3, 4, 5)\ncharacter_vector &lt;- c(\"apple\", \"banana\", \"cherry\")\nlogical_vector &lt;- c(TRUE, FALSE, TRUE, FALSE)\n\n\nManipulating vectors\n\n\nvector_sum &lt;- numeric_vector + 10\nvector_multiplication &lt;- numeric_vector * 2\nvector_greater_than_three &lt;- numeric_vector &gt; 3"
  },
  {
    "objectID": "slides/01-slides-lab.html#table-function",
    "href": "slides/01-slides-lab.html#table-function",
    "title": "Week 1: Intalling and Using R",
    "section": "table() Function",
    "text": "table() Function\n\nGenerates frequency tables for categorical data\n\n\ntable(vector_greater_than_three)\n\nvector_greater_than_three\nFALSE  TRUE \n    3     2"
  },
  {
    "objectID": "slides/01-slides-lab.html#dataframes",
    "href": "slides/01-slides-lab.html#dataframes",
    "title": "Week 1: Intalling and Using R",
    "section": "Dataframes",
    "text": "Dataframes\n\nCreating and manipulating data frames\n\n\n# clear previous `df` object (if any)\nrm(df)\ndf &lt;- data.frame(\n  name = c(\"alice\", \"bob\", \"charlie\"),\n  age = c(25, 30, 35),\n  gender = c(\"female\", \"male\", \"male\")\n)\n# look at structure\nhead(df)\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\nstr(df)\n\n'data.frame':   3 obs. of  3 variables:\n $ name  : chr  \"alice\" \"bob\" \"charlie\"\n $ age   : num  25 30 35\n $ gender: chr  \"female\" \"male\" \"male\"\n\ntable(df$gender)\n\n\nfemale   male \n     1      2 \n\ntable(df$age)\n\n\n25 30 35 \n 1  1  1 \n\ntable(df$name)\n\n\n  alice     bob charlie \n      1       1       1"
  },
  {
    "objectID": "slides/01-slides-lab.html#access-data-frame-elements",
    "href": "slides/01-slides-lab.html#access-data-frame-elements",
    "title": "Week 1: Intalling and Using R",
    "section": "Access Data Frame Elements",
    "text": "Access Data Frame Elements\n\nBy column name and row/column indexing\n\n\n# by column name\nnames &lt;- df$name\n# by row and column\nsecond_person &lt;- df[2, ]\nage_column &lt;- df[, \"age\"]"
  },
  {
    "objectID": "slides/01-slides-lab.html#using-subset-function",
    "href": "slides/01-slides-lab.html#using-subset-function",
    "title": "Week 1: Intalling and Using R",
    "section": "Using subset() Function",
    "text": "Using subset() Function\n\nExtracting rows based on conditions\n\n\nvery_old_people &lt;- subset(df, age &gt; 25)\nsummary(very_old_people$age)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  30.00   31.25   32.50   32.50   33.75   35.00 \n\nmean(very_old_people$age)\n\n[1] 32.5\n\nmin(very_old_people$age)\n\n[1] 30"
  },
  {
    "objectID": "slides/01-slides-lab.html#explore-data-frames",
    "href": "slides/01-slides-lab.html#explore-data-frames",
    "title": "Week 1: Intalling and Using R",
    "section": "Explore Data Frames",
    "text": "Explore Data Frames\n\nUsing head(), tail(), and str()\n\n\nhead(df)\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\ntail(df)\n\n     name age gender\n1   alice  25 female\n2     bob  30   male\n3 charlie  35   male\n\nstr(df)\n\n'data.frame':   3 obs. of  3 variables:\n $ name  : chr  \"alice\" \"bob\" \"charlie\"\n $ age   : num  25 30 35\n $ gender: chr  \"female\" \"male\" \"male\""
  },
  {
    "objectID": "slides/01-slides-lab.html#modify-data-frames",
    "href": "slides/01-slides-lab.html#modify-data-frames",
    "title": "Week 1: Intalling and Using R",
    "section": "Modify Data Frames",
    "text": "Modify Data Frames\n\nAdd and modify columns and rows\n\n\n# add columns\ndf$employed &lt;- c(TRUE, TRUE, FALSE)\n# add rows\nnew_person &lt;- data.frame(name = \"diana\", age = 28, gender = \"female\", employed = TRUE)\ndf &lt;- rbind(df, new_person)\n# modify values\ndf[4, \"age\"] &lt;- 26\ndf\n\n     name age gender employed\n1   alice  25 female     TRUE\n2     bob  30   male     TRUE\n3 charlie  35   male    FALSE\n4   diana  26 female     TRUE"
  },
  {
    "objectID": "slides/01-slides-lab.html#rbind-and-cbind",
    "href": "slides/01-slides-lab.html#rbind-and-cbind",
    "title": "Week 1: Intalling and Using R",
    "section": "rbind() and cbind()",
    "text": "rbind() and cbind()\n\nAdding rows and columns to data frames\n\n\n# add rows with `rbind()`\nnew_person &lt;- data.frame(name = \"eve\", age = 32, gender = \"female\", employed = TRUE)\ndf &lt;- rbind(df, new_person)\n# add columns with `cbind()`\noccupation_vector &lt;- c(\"engineer\", \"doctor\", \"artist\", \"teacher\", \"doctor\")\ndf &lt;- cbind(df, occupation_vector)\ndf\n\n     name age gender employed occupation_vector\n1   alice  25 female     TRUE          engineer\n2     bob  30   male     TRUE            doctor\n3 charlie  35   male    FALSE            artist\n4   diana  26 female     TRUE           teacher\n5     eve  32 female     TRUE            doctor"
  },
  {
    "objectID": "slides/01-slides-lab.html#data-structure-view",
    "href": "slides/01-slides-lab.html#data-structure-view",
    "title": "Week 1: Intalling and Using R",
    "section": "Data Structure View",
    "text": "Data Structure View\n\nUsing summary(), str(), head(), and tail()\n\n\nstr(iris)\n\n'data.frame':   150 obs. of  5 variables:\n $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n\nsummary(iris)\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\ntail(iris)\n\n    Sepal.Length Sepal.Width Petal.Length Petal.Width   Species\n145          6.7         3.3          5.7         2.5 virginica\n146          6.7         3.0          5.2         2.3 virginica\n147          6.3         2.5          5.0         1.9 virginica\n148          6.5         3.0          5.2         2.0 virginica\n149          6.2         3.4          5.4         2.3 virginica\n150          5.9         3.0          5.1         1.8 virginica"
  },
  {
    "objectID": "slides/01-slides-lab.html#statistical-functions",
    "href": "slides/01-slides-lab.html#statistical-functions",
    "title": "Week 1: Intalling and Using R",
    "section": "Statistical Functions",
    "text": "Statistical Functions\n\nmean(), sd(), min(), max(), and table()\n\n\n#  seed for reproducibility\nset.seed(12345)\nvector &lt;- rnorm(n = 40, mean = 0, sd = 1)\nmean(vector)  # calculates mean\n\n[1] 0.2401853\n\nsd(vector)  # computes standard deviation\n\n[1] 1.038425\n\nmin(vector)  # finds minimum value\n\n[1] -1.817956\n\nmax(vector)  # finds maximum value\n\n[1] 2.196834"
  },
  {
    "objectID": "slides/01-slides-lab.html#introduction-to-ggplot2",
    "href": "slides/01-slides-lab.html#introduction-to-ggplot2",
    "title": "Week 1: Intalling and Using R",
    "section": "Introduction to ggplot2",
    "text": "Introduction to ggplot2\n\nVisualizing data with ggplot2\n\n\n#  seed for reproducibility\nset.seed(12345)\n# ensure ggplot2 is installed and loaded\nif (!require(ggplot2)) install.packages(\"ggplot2\")\nlibrary(ggplot2)\n# simulate student data\nstudent_data &lt;- data.frame(\n  name = c(\"alice\", \"bob\", \"charlie\", \"diana\", \"ethan\", \"fiona\", \"george\", \"hannah\"),\n  score = sample(80:100, 8, replace = TRUE),\n  stringsasfactors = FALSE\n)\nstudent_data$passed &lt;- ifelse(student_data$score &gt;= 90, \"passed\", \"failed\")\nstudent_data$passed &lt;- factor(student_data$passed, levels = c(\"failed\", \"passed\"))\nstudent_data$study_hours &lt;- sample(5:15, 8, replace = TRUE)"
  },
  {
    "objectID": "slides/01-slides-lab.html#ggplot2-barplot-score-for-each-name",
    "href": "slides/01-slides-lab.html#ggplot2-barplot-score-for-each-name",
    "title": "Week 1: Intalling and Using R",
    "section": "ggplot2 Barplot: score for each name",
    "text": "ggplot2 Barplot: score for each name\n\nggplot(student_data, aes(x = name, y = score)) +\n  geom_bar(stat = \"identity\")\n\n\n\n\n\n\n\n\n\nenhanced bar plot with titles, axis labels, and modified colours\n\n\nggplot(student_data, aes(x = name, y = score, fill = passed)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"TRUE\" = \"blue\", \"FALSE\" = \"red\")) +\n  labs(title = \"student scores\", x = \"student name\", y = \"score\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/01-slides-lab.html#ggplot2-scatterplot-student-scores-against-study-hours",
    "href": "slides/01-slides-lab.html#ggplot2-scatterplot-student-scores-against-study-hours",
    "title": "Week 1: Intalling and Using R",
    "section": "ggplot2 Scatterplot: student scores against study hours",
    "text": "ggplot2 Scatterplot: student scores against study hours\n\nggplot(student_data, aes(x = study_hours, y = score, color = passed)) +\n  geom_point(size = 4) +\n  labs(title = \"student scores vs. study hours\", x = \"study hours\", y = \"score\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#ggplot2-boxplot-scores-by-passfail-status",
    "href": "slides/01-slides-lab.html#ggplot2-boxplot-scores-by-passfail-status",
    "title": "Week 1: Intalling and Using R",
    "section": "ggplot2 Boxplot: scores by pass/fail status",
    "text": "ggplot2 Boxplot: scores by pass/fail status\n\nggplot(student_data, aes(x = passed, y = score, fill = passed)) +\n  geom_boxplot() +\n  labs(title = \"score distribution by pass/fail status\", x = \"status\", y = \"score\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#ggplot2-histogram-distribution-of-scores",
    "href": "slides/01-slides-lab.html#ggplot2-histogram-distribution-of-scores",
    "title": "Week 1: Intalling and Using R",
    "section": "ggplot2 Histogram: distribution of scores",
    "text": "ggplot2 Histogram: distribution of scores\n\nggplot(student_data, aes(x = score, fill = passed)) +\n  geom_histogram(binwidth = 5, color = \"black\", alpha = 0.7) +\n  labs(title = \"histogram of scores\", x = \"score\", y = \"count\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"failed\" = \"red\", \"passed\" = \"blue\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#ggplot2-lineplot",
    "href": "slides/01-slides-lab.html#ggplot2-lineplot",
    "title": "Week 1: Intalling and Using R",
    "section": "ggplot2 Lineplot",
    "text": "ggplot2 Lineplot\n\n# prep data\nmonths &lt;- factor(month.abb[1:8], levels = month.abb[1:8])\nstudy_hours &lt;- c(0, 3, 15, 30, 35, 120, 18, 15)\nstudy_data &lt;- data.frame(month = months, study_hours = study_hours)\n\n# line plot\nggplot(study_data, aes(x = month, y = study_hours, group = 1)) +\n  geom_line(linewidth = 1, color = \"blue\") +\n  geom_point(color = \"red\", size = 1) +\n  labs(title = \"monthly study hours\", x = \"month\", y = \"study hours\") +\n  theme_minimal()"
  },
  {
    "objectID": "slides/01-slides-lab.html#base-r-scatter-plot-scores-vs.-study-hours",
    "href": "slides/01-slides-lab.html#base-r-scatter-plot-scores-vs.-study-hours",
    "title": "Week 1: Intalling and Using R",
    "section": "Base R Scatter Plot: scores vs. study hours",
    "text": "Base R Scatter Plot: scores vs. study hours\n\n# scatter plot\nplot(student_data$study_hours, student_data$score,\n     main = \"scatter plot of scores vs. study hours\",\n     xlab = \"study hours\", ylab = \"score\",\n     pch = 19, col = ifelse(student_data$passed == \"passed\", \"blue\", \"red\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#base-r-histogram",
    "href": "slides/01-slides-lab.html#base-r-histogram",
    "title": "Week 1: Intalling and Using R",
    "section": "Base R Histogram",
    "text": "Base R Histogram\n\nhistogram to visualise distribution of student scores\n\n\n# histogram \nhist(student_data$score,\n     breaks = 5,\n     col = \"skyblue\",\n     main = \"histogram of student scores\",\n     xlab = \"scores\",\n     border = \"white\")"
  },
  {
    "objectID": "slides/01-slides-lab.html#base-r-boxplots-distribution-by-passfail",
    "href": "slides/01-slides-lab.html#base-r-boxplots-distribution-by-passfail",
    "title": "Week 1: Intalling and Using R",
    "section": "Base R Boxplots: Distribution by Pass/Fail",
    "text": "Base R Boxplots: Distribution by Pass/Fail\n\n# boxplot\nboxplot(score ~ passed, data = student_data,\n        main = \"score distribution by pass/fail status\",\n        xlab = \"status\", ylab = \"scores\",\n        col = c(\"red\", \"blue\"))"
  },
  {
    "objectID": "slides/01-slides-lab.html#base-r-barplot-score-distributions",
    "href": "slides/01-slides-lab.html#base-r-barplot-score-distributions",
    "title": "Week 1: Intalling and Using R",
    "section": "Base R Barplot: Score Distributions",
    "text": "Base R Barplot: Score Distributions\n\n# prep data for the barplot\nscores_table &lt;- table(student_data$score)\nbarplot(scores_table,\n        main = \"Barplot of Scores\",\n        xlab = \"Scores\",\n        ylab = \"Frequency\",\n        col = \"skyblue\",\n        border = \"white\")"
  },
  {
    "objectID": "slides/01-slides-lab.html#base-r-line-plot",
    "href": "slides/01-slides-lab.html#base-r-line-plot",
    "title": "Week 1: Intalling and Using R",
    "section": "Base R Line Plot",
    "text": "Base R Line Plot\n\n# convert 'month' to a numeric scale for plotting positions\nmonths_num &lt;- 1:length(study_data$month) # Simple numeric sequence\n\n# Plotting points with suppressed x-axis\nplot(months_num, study_data$study_hours, \n     type = \"p\", # Points\n     pch = 19,   # Type of point\n     col = \"red\", \n     xlab = \"Month\", \n     ylab = \"Study Hours\", \n     main = \"Monthly Study Hours\",\n     xaxt = \"n\") # Suppress the x-axis\n\n# add lines between points\nlines(months_num, study_data$study_hours, \n      col = \"blue\", \n      lwd = 1) # Line width\n\n# add custom month labels to the x-axis at appropriate positions\naxis(1, at = months_num, labels = study_data$month, las=2) # `las=2` makes labels perpendicular to axis"
  },
  {
    "objectID": "slides/01-slides-lab.html#what-have-your-learned",
    "href": "slides/01-slides-lab.html#what-have-your-learned",
    "title": "Week 1: Intalling and Using R",
    "section": "What have your learned?",
    "text": "What have your learned?\n\nYou have Base R and R-studio Downloaded on your machine\nYou are able able to use R for basic analysis and graphing\nYou will need to practice, and will have lots of opporunity."
  },
  {
    "objectID": "slides/01-slides-lab.html#where-to-get-help",
    "href": "slides/01-slides-lab.html#where-to-get-help",
    "title": "Week 1: Intalling and Using R",
    "section": "Where to Get Help",
    "text": "Where to Get Help\n\nLarge Language Models (LLMs): LLMs are trained on extensive datasets. They are extremely good coding tutors. Open AI’s GPT-4 considerably outperforms GPT-3.5. However GPT 3.5 should be good enough. Gemini has a two-month free trial. LLM’s are rapidly evolving. However, presently, to use these tools, and to spot their errors, you will need to know how to code. Which is fortunate because coding makes you smarter!\n\nNote: you will not be assessed for R-code. Help from LLM’s for coding does not consitute a breach of academic integrity in this course. Your tests are in-class; no LLM’s allowed. For your final report, you will need to cite all sources, and how you used them, including LLMs.\n\nStack Overflow: an outstanding resource for most problems. Great community.\nCross-validated the best place to go for stats advice. (LLM’s are only safe for standard statistics. They do not perform well for causal inference.)\nDeveloper Websites and GitHub Pages: Tidyverse\nYour tutors and course coordinator. We care. We’re here to help you!"
  },
  {
    "objectID": "slides/01-slides-lab.html#references",
    "href": "slides/01-slides-lab.html#references",
    "title": "Week 1: Intalling and Using R",
    "section": "References",
    "text": "References\n\nWickham, H., & Grolemund, G. (2016). R for Data Science. O’Reilly Media. [Available online](https://r4ds.had.co.nz\nA helpful resource for learning R is Megan Hall’s lecture available at: https://meghan.rbind.io/talk/neair/.\nRStudio has compiled numerous accessible materials for learning R, which can be found here: https://education.rstudio.com/learn/beginner/."
  },
  {
    "objectID": "index.html#test-guidelines",
    "href": "index.html#test-guidelines",
    "title": "Psych 434: Conducting Research Across Cultures",
    "section": "",
    "text": "Test duration is one hour. The allocated time is nearly two hours.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nTHE TEST IS IN CLASS (i.e. come to class with a writing instrument).\n\n\n\n\nEach lecture starts and ends with key concept definitions and reviews for the test.\nR or RStudio knowledge isn’t part of the test. R support aims to enhance research report skills.\nTests are conducted in the lecture room without the aids of notes, a computer, or a phone.\nRequired: pen/pencil.\nTest (50 minutes, total time allowed: 1 hour 50 minutes):\n\nFocuses on revising core statistical and methodological concepts.\nAims to refresh basic statistical knowledge foundational for later course material."
  },
  {
    "objectID": "content/10-content.html#part-2-quarto-manuscripts",
    "href": "content/10-content.html#part-2-quarto-manuscripts",
    "title": "Student Presentations and Hands On Working With Quarto Manuscript",
    "section": "Part 2: Quarto manuscripts",
    "text": "Part 2: Quarto manuscripts\n\n\n\n\n\n\nNote\n\n\n\nRequired Download Quarto here: - Use the prelease version: https://quarto.org/docs/download/ Optional - (Bulbulia 2024) link - (Hoffman et al. 2023) link\n\n\n\nHoffman, Katherine L., Diego Salazar-Barreto, Kara E. Rudolph, and Iván Díaz. 2023. “Introducing Longitudinal Modified Treatment Policies: A Unified Framework for Studying Complex Exposures,” April. https://doi.org/10.48550/arXiv.2304.09460.\n\nBulbulia, J. A. 2024. “A Practical Guide to Causal Inference in Three-Wave Panel Studies.” OSF. https://doi.org/10.31234/osf.io/uyg3d.\n\n\n\n\n\n\nKey concepts\n\n\n\n\nWriting up your manuscript\n\n\n\n\n\n\n\n\n\nFor the lab, download the script\n\n\n\n\nWe will go through this script step-by-step.\n\n\n\n\nTo Do\n\nDownload the script (from week 9) and store in our R directory: link to analysis script\nDownload the manuscript template and store in our R directory: link to manuscript template\nDownload the following tex file and save it to your R directory: latex macros\nDownload the followign tex file and save it to your R directory: title preamble\nDownload the following csl file and save it to your R directory: csl preamble\nMake sure you can install all libraries required of the manuscript template.\nCome to the seminar prepared to work through the analysis"
  },
  {
    "objectID": "content/10-content.html#what-you-will-learn",
    "href": "content/10-content.html#what-you-will-learn",
    "title": "Student Presentations and Hands On Working With Quarto Manuscript",
    "section": "What You Will Learn",
    "text": "What You Will Learn\n\nHow to create a publication quality manuscript\nHow to create a workflow for references\nHow to import results into your manuscript\nHow to make graphs of your results (using) margot\nHow to report your results\nHow to interpret your results\n\n\nPackages\n\nreport::cite_packages()\n\n  - Bulbulia J (2024). _margot: MARGinal Observational Treatment-effects_. doi:10.5281/zenodo.10907724 &lt;https://doi.org/10.5281/zenodo.10907724&gt;, R package version 0.3.1.1 Functions to obtain MARGinal Observational Treatment-effects from observational data., &lt;https://go-bayes.github.io/margot/&gt;.\n  - Chang W (2023). _extrafont: Tools for Using Fonts_. R package version 0.19, &lt;https://CRAN.R-project.org/package=extrafont&gt;.\n  - Grolemund G, Wickham H (2011). \"Dates and Times Made Easy with lubridate.\" _Journal of Statistical Software_, *40*(3), 1-25. &lt;https://www.jstatsoft.org/v40/i03/&gt;.\n  - Müller K, Wickham H (2023). _tibble: Simple Data Frames_. R package version 3.2.1, &lt;https://CRAN.R-project.org/package=tibble&gt;.\n  - R Core Team (2024). _R: A Language and Environment for Statistical Computing_. R Foundation for Statistical Computing, Vienna, Austria. &lt;https://www.R-project.org/&gt;.\n  - Wickham H (2016). _ggplot2: Elegant Graphics for Data Analysis_. Springer-Verlag New York. ISBN 978-3-319-24277-4, &lt;https://ggplot2.tidyverse.org&gt;.\n  - Wickham H (2023). _forcats: Tools for Working with Categorical Variables (Factors)_. R package version 1.0.0, &lt;https://CRAN.R-project.org/package=forcats&gt;.\n  - Wickham H (2023). _stringr: Simple, Consistent Wrappers for Common String Operations_. R package version 1.5.1, &lt;https://CRAN.R-project.org/package=stringr&gt;.\n  - Wickham H, Averick M, Bryan J, Chang W, McGowan LD, François R, Grolemund G, Hayes A, Henry L, Hester J, Kuhn M, Pedersen TL, Miller E, Bache SM, Müller K, Ooms J, Robinson D, Seidel DP, Spinu V, Takahashi K, Vaughan D, Wilke C, Woo K, Yutani H (2019). \"Welcome to the tidyverse.\" _Journal of Open Source Software_, *4*(43), 1686. doi:10.21105/joss.01686 &lt;https://doi.org/10.21105/joss.01686&gt;.\n  - Wickham H, François R, Henry L, Müller K, Vaughan D (2023). _dplyr: A Grammar of Data Manipulation_. R package version 1.1.4, &lt;https://CRAN.R-project.org/package=dplyr&gt;.\n  - Wickham H, Henry L (2025). _purrr: Functional Programming Tools_. R package version 1.0.4, &lt;https://CRAN.R-project.org/package=purrr&gt;.\n  - Wickham H, Hester J, Bryan J (2024). _readr: Read Rectangular Text Data_. R package version 2.1.5, &lt;https://CRAN.R-project.org/package=readr&gt;.\n  - Wickham H, Vaughan D, Girlich M (2024). _tidyr: Tidy Messy Data_. R package version 1.3.1, &lt;https://CRAN.R-project.org/package=tidyr&gt;.\n  - Xie Y (2024). _tinytex: Helper Functions to Install and Maintain TeX Live, and Compile LaTeX Documents_. R package version 0.54, &lt;https://github.com/rstudio/tinytex&gt;. Xie Y (2019). \"TinyTeX: A lightweight, cross-platform, and easy-to-maintain LaTeX distribution based on TeX Live.\" _TUGboat_, *40*(1), 30-32. &lt;https://tug.org/TUGboat/Contents/contents40-1.html&gt;."
  }
]